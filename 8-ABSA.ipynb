{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "827be93c-f184-45dd-a832-f5666f593fa6",
   "metadata": {},
   "source": [
    "## ABSA Training and Fine Tuning for Large Language Models on German hospital reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7656b984-9b27-4388-97e2-57bbd226d08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sc.uni-leipzig.de/ch31qoni/venv/absa/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# need the sys package to load modules from another directory:\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from functions.absa_model_train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b9b9284-08bc-4833-bfff-0251985762c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA available: True\n",
      "CUDA version: 12.6\n",
      "GPU device name: NVIDIA A30\n"
     ]
    }
   ],
   "source": [
    "print(\"Is CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"GPU device name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47ea5b2b-225a-4f32-aba6-9f4026f7da34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset into a DataFrame\n",
    "data_ano = pd.read_csv(\"./data/hospitalABSA/patient_review_labels_absa_ano.csv\")\n",
    "data = pd.read_csv(\"./data/hospitalABSA/patient_review_labels_absa.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7988bfa-75b1-4529-aabd-561ffe03738e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"google-bert/bert-base-german-cased\",\"dbmdz/bert-base-german-cased\", \"dbmdz/bert-base-german-uncased\",\n",
    "          \"FacebookAI/xlm-roberta-base\", \"TUM/GottBERT_base_best\", \"TUM/GottBERT_filtered_base_best\", \"TUM/GottBERT_base_last\",\n",
    "          \"distilbert/distilbert-base-german-cased\", \"GerMedBERT/medbert-512\", \"deepset/gbert-base\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba26742f-0a88-44c3-820a-cfc81dc2813a",
   "metadata": {},
   "source": [
    "### Train ABSA Model with new training, validation, test split\n",
    "\n",
    "train for 5, 6, 7, 8, 10, 12, 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75794f33-8912-40df-9263-c820a0bda1de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training and results for google-bert/bert-base-german-cased:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 2443.78 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3916.08 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 3849.42 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for google-bert/bert-base-german-cased with 5 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2780' max='2780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2780/2780 04:52, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.838300</td>\n",
       "      <td>0.911232</td>\n",
       "      <td>0.775194</td>\n",
       "      <td>0.786194</td>\n",
       "      <td>0.775194</td>\n",
       "      <td>0.776692</td>\n",
       "      <td>{0: 51, 1: 25, 2: 53}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.476800</td>\n",
       "      <td>0.932275</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.799154</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.788306</td>\n",
       "      <td>{0: 33, 1: 36, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.421500</td>\n",
       "      <td>1.166174</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.781570</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.782010</td>\n",
       "      <td>{0: 40, 1: 27, 2: 62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.237500</td>\n",
       "      <td>1.274274</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.784735</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.783112</td>\n",
       "      <td>{0: 39, 1: 30, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.132000</td>\n",
       "      <td>1.326507</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.777174</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.769552</td>\n",
       "      <td>{0: 38, 1: 34, 2: 57}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_google-bert_bert-base-german-cased_42_42_5\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_google-bert_bert-base-german-cased_42_42_5\n",
      "Evaluation results for google-bert/bert-base-german-cased with 5 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9676937460899353, 'eval_accuracy': 0.7647058823529411, 'eval_precision': 0.7889484344670435, 'eval_recall': 0.7647058823529411, 'eval_f1': 0.7680431024084274, 'eval_class_distribution': {0: 41, 1: 44, 2: 68}, 'eval_runtime': 2.3765, 'eval_samples_per_second': 64.38, 'eval_steps_per_second': 32.4, 'epoch': 5.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.75      0.83      0.79        36\n",
      "     Neutral       0.60      0.88      0.72        33\n",
      "     Positiv       0.92      0.71      0.81        84\n",
      "\n",
      "    accuracy                           0.78       153\n",
      "   macro avg       0.76      0.81      0.77       153\n",
      "weighted avg       0.81      0.78      0.78       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 40, 1: 48, 2: 65}\n",
      "Negativ Precision Score: 0.75\n",
      "Negativ Recall Score: 0.8333333333333334\n",
      "Negativ F1 Score: 0.7894736842105263\n",
      "\n",
      "Neutral Precision Score: 0.6041666666666666\n",
      "Neutral Recall Score: 0.8787878787878788\n",
      "Neutral F1 Score: 0.7160493827160493\n",
      "\n",
      "Positiv Precision Score: 0.9230769230769231\n",
      "Positiv Recall Score: 0.7142857142857143\n",
      "Positiv F1 Score: 0.8053691275167785\n",
      "\n",
      "Macro Average Precision Score: 0.7590811965811964\n",
      "Macro Average Recall Score: 0.8088023088023087\n",
      "Macro Average F1 Score: 0.7702973981477846\n",
      "\n",
      "Weighted Average Scores:\n",
      "Weighted Average Precision: 0.8135683760683762\n",
      "Weighted Average Recall: 0.7777777777777778\n",
      "Weighted Average F1: 0.7823639802131893\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/5_epochs/google-bert_bert-base-german-cased_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/5_epochs/google-bert_bert-base-german-cased_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-cased:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 4066.37 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3971.85 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 3869.28 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for dbmdz/bert-base-german-cased with 5 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2780' max='2780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2780/2780 04:53, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.857900</td>\n",
       "      <td>0.607639</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.858825</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.843355</td>\n",
       "      <td>{0: 54, 1: 20, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.555100</td>\n",
       "      <td>0.743898</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.838790</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.836884</td>\n",
       "      <td>{0: 38, 1: 27, 2: 64}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.492000</td>\n",
       "      <td>0.903522</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.835397</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.833369</td>\n",
       "      <td>{0: 44, 1: 21, 2: 64}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.260500</td>\n",
       "      <td>0.880561</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.838488</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.837269</td>\n",
       "      <td>{0: 45, 1: 25, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.201500</td>\n",
       "      <td>0.872499</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.838359</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.837702</td>\n",
       "      <td>{0: 42, 1: 28, 2: 59}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_dbmdz_bert-base-german-cased_42_42_5\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_dbmdz_bert-base-german-cased_42_42_5\n",
      "Evaluation results for dbmdz/bert-base-german-cased with 5 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.997826099395752, 'eval_accuracy': 0.7647058823529411, 'eval_precision': 0.7945879187120263, 'eval_recall': 0.7647058823529411, 'eval_f1': 0.7671448865777926, 'eval_class_distribution': {0: 53, 1: 33, 2: 67}, 'eval_runtime': 2.3467, 'eval_samples_per_second': 65.198, 'eval_steps_per_second': 32.812, 'epoch': 5.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.65      0.97      0.78        36\n",
      "     Neutral       0.79      0.67      0.72        33\n",
      "     Positiv       0.92      0.77      0.84        84\n",
      "\n",
      "    accuracy                           0.80       153\n",
      "   macro avg       0.78      0.80      0.78       153\n",
      "weighted avg       0.82      0.80      0.80       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 54, 1: 28, 2: 71}\n",
      "Negativ Precision Score: 0.6481481481481481\n",
      "Negativ Recall Score: 0.9722222222222222\n",
      "Negativ F1 Score: 0.7777777777777778\n",
      "\n",
      "Neutral Precision Score: 0.7857142857142857\n",
      "Neutral Recall Score: 0.6666666666666666\n",
      "Neutral F1 Score: 0.7213114754098361\n",
      "\n",
      "Positiv Precision Score: 0.9154929577464789\n",
      "Positiv Recall Score: 0.7738095238095238\n",
      "Positiv F1 Score: 0.8387096774193549\n",
      "\n",
      "Macro Average Precision Score: 0.7831184638696377\n",
      "Macro Average Recall Score: 0.8042328042328042\n",
      "Macro Average F1 Score: 0.7792663102023228\n",
      "\n",
      "Weighted Average Scores:\n",
      "Weighted Average Precision: 0.8245968183830652\n",
      "Weighted Average Recall: 0.7973856209150327\n",
      "Weighted Average F1: 0.7990515790310484\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/5_epochs/dbmdz_bert-base-german-cased_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/5_epochs/dbmdz_bert-base-german-cased_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-uncased:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 3861.12 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3804.53 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 3731.07 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for dbmdz/bert-base-german-uncased with 5 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2780' max='2780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2780/2780 04:53, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.849200</td>\n",
       "      <td>0.683184</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.848891</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.844586</td>\n",
       "      <td>{0: 48, 1: 23, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.561500</td>\n",
       "      <td>0.583890</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.840033</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.832542</td>\n",
       "      <td>{0: 40, 1: 33, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.448500</td>\n",
       "      <td>0.777486</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.855932</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.853683</td>\n",
       "      <td>{0: 40, 1: 30, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.225700</td>\n",
       "      <td>0.679980</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.863138</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.861469</td>\n",
       "      <td>{0: 42, 1: 29, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.218200</td>\n",
       "      <td>0.789800</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.854681</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.847538</td>\n",
       "      <td>{0: 40, 1: 33, 2: 56}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_dbmdz_bert-base-german-uncased_42_42_5\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_dbmdz_bert-base-german-uncased_42_42_5\n",
      "Evaluation results for dbmdz/bert-base-german-uncased with 5 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0990517139434814, 'eval_accuracy': 0.8169934640522876, 'eval_precision': 0.8299243206054351, 'eval_recall': 0.8169934640522876, 'eval_f1': 0.8203795299412042, 'eval_class_distribution': {0: 38, 1: 40, 2: 75}, 'eval_runtime': 2.3525, 'eval_samples_per_second': 65.036, 'eval_steps_per_second': 32.731, 'epoch': 5.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.84      0.89      0.86        36\n",
      "     Neutral       0.67      0.85      0.75        33\n",
      "     Positiv       0.95      0.82      0.88        84\n",
      "\n",
      "    accuracy                           0.84       153\n",
      "   macro avg       0.82      0.85      0.83       153\n",
      "weighted avg       0.86      0.84      0.85       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 38, 1: 42, 2: 73}\n",
      "Negativ Precision Score: 0.8421052631578947\n",
      "Negativ Recall Score: 0.8888888888888888\n",
      "Negativ F1 Score: 0.8648648648648649\n",
      "\n",
      "Neutral Precision Score: 0.6666666666666666\n",
      "Neutral Recall Score: 0.8484848484848485\n",
      "Neutral F1 Score: 0.7466666666666667\n",
      "\n",
      "Positiv Precision Score: 0.9452054794520548\n",
      "Positiv Recall Score: 0.8214285714285714\n",
      "Positiv F1 Score: 0.8789808917197452\n",
      "\n",
      "Macro Average Precision Score: 0.8179924697588721\n",
      "Macro Average Recall Score: 0.852934102934103\n",
      "Macro Average F1 Score: 0.8301708077504255\n",
      "\n",
      "Weighted Average Scores:\n",
      "Weighted Average Precision: 0.8608696061938353\n",
      "Weighted Average Recall: 0.8431372549019608\n",
      "Weighted Average F1: 0.8471211113698938\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/5_epochs/dbmdz_bert-base-german-uncased_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/5_epochs/dbmdz_bert-base-german-uncased_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for FacebookAI/xlm-roberta-base:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 4859.54 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 4176.21 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 4453.29 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for FacebookAI/xlm-roberta-base with 5 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2780' max='2780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2780/2780 06:12, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.899500</td>\n",
       "      <td>0.633655</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.846253</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.801034</td>\n",
       "      <td>{0: 63, 1: 18, 2: 48}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.766900</td>\n",
       "      <td>0.958312</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.790303</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.787535</td>\n",
       "      <td>{0: 40, 1: 22, 2: 67}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.783400</td>\n",
       "      <td>1.038330</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.839276</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.830989</td>\n",
       "      <td>{0: 50, 1: 25, 2: 54}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>1.157330</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.810956</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.808082</td>\n",
       "      <td>{0: 43, 1: 29, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.499500</td>\n",
       "      <td>1.159907</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.810956</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.808082</td>\n",
       "      <td>{0: 43, 1: 29, 2: 57}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_FacebookAI_xlm-roberta-base_42_42_5\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_FacebookAI_xlm-roberta-base_42_42_5\n",
      "Evaluation results for FacebookAI/xlm-roberta-base with 5 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1958260536193848, 'eval_accuracy': 0.7973856209150327, 'eval_precision': 0.8035030726757454, 'eval_recall': 0.7973856209150327, 'eval_f1': 0.7955541330407017, 'eval_class_distribution': {0: 47, 1: 29, 2: 77}, 'eval_runtime': 2.297, 'eval_samples_per_second': 66.608, 'eval_steps_per_second': 33.522, 'epoch': 5.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.69      0.94      0.80        36\n",
      "     Neutral       0.66      0.58      0.61        33\n",
      "     Positiv       0.89      0.80      0.84        84\n",
      "\n",
      "    accuracy                           0.78       153\n",
      "   macro avg       0.75      0.77      0.75       153\n",
      "weighted avg       0.80      0.78      0.78       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 49, 1: 29, 2: 75}\n",
      "Negativ Precision Score: 0.6938775510204082\n",
      "Negativ Recall Score: 0.9444444444444444\n",
      "Negativ F1 Score: 0.8\n",
      "\n",
      "Neutral Precision Score: 0.6551724137931034\n",
      "Neutral Recall Score: 0.5757575757575758\n",
      "Neutral F1 Score: 0.6129032258064516\n",
      "\n",
      "Positiv Precision Score: 0.8933333333333333\n",
      "Positiv Recall Score: 0.7976190476190477\n",
      "Positiv F1 Score: 0.8427672955974843\n",
      "\n",
      "Macro Average Precision Score: 0.7474610993822818\n",
      "Macro Average Recall Score: 0.7726070226070227\n",
      "Macro Average F1 Score: 0.7518901738013121\n",
      "\n",
      "Weighted Average Scores:\n",
      "Weighted Average Precision: 0.7950345195549484\n",
      "Weighted Average Recall: 0.7843137254901961\n",
      "Weighted Average F1: 0.7831258776588339\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/5_epochs/FacebookAI_xlm-roberta-base_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/5_epochs/FacebookAI_xlm-roberta-base_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_best:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at TUM/GottBERT_base_best and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 5001.08 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 4406.00 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 4614.43 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for TUM/GottBERT_base_best with 5 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2780' max='2780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2780/2780 04:58, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.887200</td>\n",
       "      <td>0.654201</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.867849</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.860479</td>\n",
       "      <td>{0: 50, 1: 23, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.538800</td>\n",
       "      <td>0.510353</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.867489</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.867765</td>\n",
       "      <td>{0: 42, 1: 26, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.474300</td>\n",
       "      <td>0.825377</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.852485</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.842293</td>\n",
       "      <td>{0: 49, 1: 19, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.287500</td>\n",
       "      <td>0.759579</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.847627</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.842292</td>\n",
       "      <td>{0: 49, 1: 21, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.198700</td>\n",
       "      <td>0.784528</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.841860</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.838667</td>\n",
       "      <td>{0: 45, 1: 28, 2: 56}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_TUM_GottBERT_base_best_42_42_5\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_TUM_GottBERT_base_best_42_42_5\n",
      "Evaluation results for TUM/GottBERT_base_best with 5 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8579771518707275, 'eval_accuracy': 0.8235294117647058, 'eval_precision': 0.8285151667504609, 'eval_recall': 0.8235294117647058, 'eval_f1': 0.8247620851883427, 'eval_class_distribution': {0: 39, 1: 36, 2: 78}, 'eval_runtime': 2.2943, 'eval_samples_per_second': 66.688, 'eval_steps_per_second': 33.562, 'epoch': 5.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.78      0.89      0.83        36\n",
      "     Neutral       0.68      0.70      0.69        33\n",
      "     Positiv       0.88      0.82      0.85        84\n",
      "\n",
      "    accuracy                           0.81       153\n",
      "   macro avg       0.78      0.80      0.79       153\n",
      "weighted avg       0.82      0.81      0.81       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 41, 1: 34, 2: 78}\n",
      "Negativ Precision Score: 0.7804878048780488\n",
      "Negativ Recall Score: 0.8888888888888888\n",
      "Negativ F1 Score: 0.8311688311688312\n",
      "\n",
      "Neutral Precision Score: 0.6764705882352942\n",
      "Neutral Recall Score: 0.696969696969697\n",
      "Neutral F1 Score: 0.6865671641791045\n",
      "\n",
      "Positiv Precision Score: 0.8846153846153846\n",
      "Positiv Recall Score: 0.8214285714285714\n",
      "Positiv F1 Score: 0.8518518518518519\n",
      "\n",
      "Macro Average Precision Score: 0.7805245925762425\n",
      "Macro Average Recall Score: 0.8024290524290524\n",
      "Macro Average F1 Score: 0.7898626157332626\n",
      "\n",
      "Weighted Average Scores:\n",
      "Weighted Average Precision: 0.815220801928541\n",
      "Weighted Average Recall: 0.8104575163398693\n",
      "Weighted Average F1: 0.8113356202323133\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/5_epochs/TUM_GottBERT_base_best_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/5_epochs/TUM_GottBERT_base_best_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_filtered_base_best:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at TUM/GottBERT_filtered_base_best and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 4998.43 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 4484.44 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 4494.90 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for TUM/GottBERT_filtered_base_best with 5 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2780' max='2780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2780/2780 04:58, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.837600</td>\n",
       "      <td>0.725310</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.856285</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.846382</td>\n",
       "      <td>{0: 51, 1: 24, 2: 54}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.530200</td>\n",
       "      <td>0.590942</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.884948</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.883406</td>\n",
       "      <td>{0: 45, 1: 24, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.473300</td>\n",
       "      <td>0.643328</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.887434</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.883974</td>\n",
       "      <td>{0: 47, 1: 24, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.307400</td>\n",
       "      <td>0.692748</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.885469</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.883973</td>\n",
       "      <td>{0: 45, 1: 25, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.282400</td>\n",
       "      <td>0.721027</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.894203</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.891869</td>\n",
       "      <td>{0: 46, 1: 25, 2: 58}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_TUM_GottBERT_filtered_base_best_42_42_5\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_TUM_GottBERT_filtered_base_best_42_42_5\n",
      "Evaluation results for TUM/GottBERT_filtered_base_best with 5 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2548445463180542, 'eval_accuracy': 0.803921568627451, 'eval_precision': 0.8144595274007039, 'eval_recall': 0.803921568627451, 'eval_f1': 0.8063563119168004, 'eval_class_distribution': {0: 39, 1: 39, 2: 75}, 'eval_runtime': 2.2714, 'eval_samples_per_second': 67.361, 'eval_steps_per_second': 33.9, 'epoch': 5.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.78      0.89      0.83        36\n",
      "     Neutral       0.64      0.76      0.69        33\n",
      "     Positiv       0.90      0.79      0.84        84\n",
      "\n",
      "    accuracy                           0.80       153\n",
      "   macro avg       0.78      0.81      0.79       153\n",
      "weighted avg       0.82      0.80      0.81       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 41, 1: 39, 2: 73}\n",
      "Negativ Precision Score: 0.7804878048780488\n",
      "Negativ Recall Score: 0.8888888888888888\n",
      "Negativ F1 Score: 0.8311688311688312\n",
      "\n",
      "Neutral Precision Score: 0.6410256410256411\n",
      "Neutral Recall Score: 0.7575757575757576\n",
      "Neutral F1 Score: 0.6944444444444444\n",
      "\n",
      "Positiv Precision Score: 0.9041095890410958\n",
      "Positiv Recall Score: 0.7857142857142857\n",
      "Positiv F1 Score: 0.8407643312101911\n",
      "\n",
      "Macro Average Precision Score: 0.7752076783149286\n",
      "Macro Average Recall Score: 0.8107263107263107\n",
      "Macro Average F1 Score: 0.7887925356078224\n",
      "\n",
      "Weighted Average Scores:\n",
      "Weighted Average Precision: 0.8182785137837122\n",
      "Weighted Average Recall: 0.803921568627451\n",
      "Weighted Average F1: 0.8069473752313767\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/5_epochs/TUM_GottBERT_filtered_base_best_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/5_epochs/TUM_GottBERT_filtered_base_best_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_last:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at TUM/GottBERT_base_last were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at TUM/GottBERT_base_last and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 4923.72 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 4421.77 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 4416.91 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for TUM/GottBERT_base_last with 5 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2780' max='2780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2780/2780 04:58, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.911200</td>\n",
       "      <td>1.300491</td>\n",
       "      <td>0.728682</td>\n",
       "      <td>0.812171</td>\n",
       "      <td>0.728682</td>\n",
       "      <td>0.701999</td>\n",
       "      <td>{0: 75, 1: 6, 2: 48}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.577000</td>\n",
       "      <td>0.600182</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.868397</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.867761</td>\n",
       "      <td>{0: 39, 1: 28, 2: 62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.461900</td>\n",
       "      <td>0.643950</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.858948</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.858245</td>\n",
       "      <td>{0: 42, 1: 23, 2: 64}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.310300</td>\n",
       "      <td>0.655676</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.865701</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.861973</td>\n",
       "      <td>{0: 41, 1: 31, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.248100</td>\n",
       "      <td>0.619495</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.891052</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.878868</td>\n",
       "      <td>{0: 46, 1: 32, 2: 51}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_TUM_GottBERT_base_last_42_42_5\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_TUM_GottBERT_base_last_42_42_5\n",
      "Evaluation results for TUM/GottBERT_base_last with 5 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1922639608383179, 'eval_accuracy': 0.803921568627451, 'eval_precision': 0.828454172366621, 'eval_recall': 0.803921568627451, 'eval_f1': 0.80917534477906, 'eval_class_distribution': {0: 40, 1: 43, 2: 70}, 'eval_runtime': 2.2581, 'eval_samples_per_second': 67.755, 'eval_steps_per_second': 34.099, 'epoch': 5.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.73      0.89      0.80        36\n",
      "     Neutral       0.65      0.79      0.71        33\n",
      "     Positiv       0.93      0.76      0.84        84\n",
      "\n",
      "    accuracy                           0.80       153\n",
      "   macro avg       0.77      0.81      0.78       153\n",
      "weighted avg       0.82      0.80      0.80       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 44, 1: 40, 2: 69}\n",
      "Negativ Precision Score: 0.7272727272727273\n",
      "Negativ Recall Score: 0.8888888888888888\n",
      "Negativ F1 Score: 0.8\n",
      "\n",
      "Neutral Precision Score: 0.65\n",
      "Neutral Recall Score: 0.7878787878787878\n",
      "Neutral F1 Score: 0.7123287671232876\n",
      "\n",
      "Positiv Precision Score: 0.927536231884058\n",
      "Positiv Recall Score: 0.7619047619047619\n",
      "Positiv F1 Score: 0.8366013071895425\n",
      "\n",
      "Macro Average Precision Score: 0.7682696530522618\n",
      "Macro Average Recall Score: 0.8128908128908128\n",
      "Macro Average F1 Score: 0.7829766914376101\n",
      "\n",
      "Weighted Average Scores:\n",
      "Weighted Average Precision: 0.8205546513730657\n",
      "Weighted Average Recall: 0.7973856209150327\n",
      "Weighted Average F1: 0.8011853537188893\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/5_epochs/TUM_GottBERT_base_last_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/5_epochs/TUM_GottBERT_base_last_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for distilbert/distilbert-base-german-cased:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 4984.51 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 4678.23 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 4617.95 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for distilbert/distilbert-base-german-cased with 5 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2780' max='2780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2780/2780 02:36, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.822700</td>\n",
       "      <td>0.785686</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.824226</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.788050</td>\n",
       "      <td>{0: 62, 1: 18, 2: 49}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.583800</td>\n",
       "      <td>0.760451</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.832567</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.815965</td>\n",
       "      <td>{0: 54, 1: 24, 2: 51}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.524700</td>\n",
       "      <td>0.789023</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.865685</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.846614</td>\n",
       "      <td>{0: 55, 1: 23, 2: 51}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.288400</td>\n",
       "      <td>0.823489</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.854412</td>\n",
       "      <td>{0: 53, 1: 26, 2: 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.295000</td>\n",
       "      <td>0.829586</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.854412</td>\n",
       "      <td>{0: 53, 1: 26, 2: 50}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_distilbert_distilbert-base-german-cased_42_42_5\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_distilbert_distilbert-base-german-cased_42_42_5\n",
      "Evaluation results for distilbert/distilbert-base-german-cased with 5 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.183458685874939, 'eval_accuracy': 0.7647058823529411, 'eval_precision': 0.7875974685029482, 'eval_recall': 0.7647058823529411, 'eval_f1': 0.7681253712604027, 'eval_class_distribution': {0: 47, 1: 37, 2: 69}, 'eval_runtime': 1.2528, 'eval_samples_per_second': 122.127, 'eval_steps_per_second': 61.463, 'epoch': 5.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.66      0.86      0.75        36\n",
      "     Neutral       0.64      0.64      0.64        33\n",
      "     Positiv       0.90      0.79      0.84        84\n",
      "\n",
      "    accuracy                           0.77       153\n",
      "   macro avg       0.73      0.76      0.74       153\n",
      "weighted avg       0.79      0.77      0.77       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 47, 1: 33, 2: 73}\n",
      "Negativ Precision Score: 0.6595744680851063\n",
      "Negativ Recall Score: 0.8611111111111112\n",
      "Negativ F1 Score: 0.7469879518072289\n",
      "\n",
      "Neutral Precision Score: 0.6363636363636364\n",
      "Neutral Recall Score: 0.6363636363636364\n",
      "Neutral F1 Score: 0.6363636363636364\n",
      "\n",
      "Positiv Precision Score: 0.9041095890410958\n",
      "Positiv Recall Score: 0.7857142857142857\n",
      "Positiv F1 Score: 0.8407643312101911\n",
      "\n",
      "Macro Average Precision Score: 0.7333492311632795\n",
      "Macro Average Recall Score: 0.761063011063011\n",
      "Macro Average F1 Score: 0.7413719731270186\n",
      "\n",
      "Weighted Average Scores:\n",
      "Weighted Average Precision: 0.7888227864739601\n",
      "Weighted Average Recall: 0.7712418300653595\n",
      "Weighted Average F1: 0.7746128763837666\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/5_epochs/distilbert_distilbert-base-german-cased_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/5_epochs/distilbert_distilbert-base-german-cased_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for GerMedBERT/medbert-512:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Device set to use cuda:0\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GerMedBERT/medbert-512 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 3969.44 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3743.39 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 3734.13 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for GerMedBERT/medbert-512 with 5 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2780' max='2780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2780/2780 04:55, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.921500</td>\n",
       "      <td>0.730344</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.801155</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.783977</td>\n",
       "      <td>{0: 55, 1: 22, 2: 52}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.574100</td>\n",
       "      <td>0.756621</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.815845</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.807423</td>\n",
       "      <td>{0: 50, 1: 26, 2: 53}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.515700</td>\n",
       "      <td>1.075526</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.798453</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.782654</td>\n",
       "      <td>{0: 43, 1: 16, 2: 70}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.269600</td>\n",
       "      <td>0.816916</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.829546</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.823608</td>\n",
       "      <td>{0: 47, 1: 28, 2: 54}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.259100</td>\n",
       "      <td>0.815060</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.806847</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.801172</td>\n",
       "      <td>{0: 43, 1: 31, 2: 55}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_GerMedBERT_medbert-512_42_42_5\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_GerMedBERT_medbert-512_42_42_5\n",
      "Evaluation results for GerMedBERT/medbert-512 with 5 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0450433492660522, 'eval_accuracy': 0.7973856209150327, 'eval_precision': 0.8112036512158607, 'eval_recall': 0.7973856209150327, 'eval_f1': 0.7983848696225423, 'eval_class_distribution': {0: 44, 1: 38, 2: 71}, 'eval_runtime': 2.3258, 'eval_samples_per_second': 65.784, 'eval_steps_per_second': 33.107, 'epoch': 5.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.67      0.89      0.76        36\n",
      "     Neutral       0.71      0.67      0.69        33\n",
      "     Positiv       0.88      0.77      0.82        84\n",
      "\n",
      "    accuracy                           0.78       153\n",
      "   macro avg       0.75      0.78      0.76       153\n",
      "weighted avg       0.79      0.78      0.78       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 48, 1: 31, 2: 74}\n",
      "Negativ Precision Score: 0.6666666666666666\n",
      "Negativ Recall Score: 0.8888888888888888\n",
      "Negativ F1 Score: 0.7619047619047619\n",
      "\n",
      "Neutral Precision Score: 0.7096774193548387\n",
      "Neutral Recall Score: 0.6666666666666666\n",
      "Neutral F1 Score: 0.6875\n",
      "\n",
      "Positiv Precision Score: 0.8783783783783784\n",
      "Positiv Recall Score: 0.7738095238095238\n",
      "Positiv F1 Score: 0.8227848101265823\n",
      "\n",
      "Macro Average Precision Score: 0.7515741547999614\n",
      "Macro Average Recall Score: 0.7764550264550264\n",
      "Macro Average F1 Score: 0.757396524010448\n",
      "\n",
      "Weighted Average Scores:\n",
      "Weighted Average Precision: 0.7921773766176043\n",
      "Weighted Average Recall: 0.7777777777777778\n",
      "Weighted Average F1: 0.77928101620395\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/5_epochs/GerMedBERT_medbert-512_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/5_epochs/GerMedBERT_medbert-512_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for deepset/gbert-base:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 3977.73 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3776.36 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 3711.30 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for deepset/gbert-base with 5 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2780' max='2780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2780/2780 04:53, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.815400</td>\n",
       "      <td>0.737219</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.860171</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.859571</td>\n",
       "      <td>{0: 44, 1: 24, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.491800</td>\n",
       "      <td>0.724495</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.844581</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.838060</td>\n",
       "      <td>{0: 49, 1: 23, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.425200</td>\n",
       "      <td>0.811122</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.860171</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.859571</td>\n",
       "      <td>{0: 44, 1: 24, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.219500</td>\n",
       "      <td>0.880146</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.854815</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.853498</td>\n",
       "      <td>{0: 44, 1: 27, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.164500</td>\n",
       "      <td>0.874246</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.861382</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.860856</td>\n",
       "      <td>{0: 43, 1: 27, 2: 59}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_deepset_gbert-base_42_42_5\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_deepset_gbert-base_42_42_5\n",
      "Evaluation results for deepset/gbert-base with 5 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.165304183959961, 'eval_accuracy': 0.8235294117647058, 'eval_precision': 0.8342706313294549, 'eval_recall': 0.8235294117647058, 'eval_f1': 0.826791010385189, 'eval_class_distribution': {0: 35, 1: 40, 2: 78}, 'eval_runtime': 2.332, 'eval_samples_per_second': 65.61, 'eval_steps_per_second': 33.019, 'epoch': 5.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.73      0.92      0.81        36\n",
      "     Neutral       0.62      0.76      0.68        33\n",
      "     Positiv       0.90      0.73      0.80        84\n",
      "\n",
      "    accuracy                           0.78       153\n",
      "   macro avg       0.75      0.80      0.77       153\n",
      "weighted avg       0.80      0.78      0.78       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 45, 1: 40, 2: 68}\n",
      "Negativ Precision Score: 0.7333333333333333\n",
      "Negativ Recall Score: 0.9166666666666666\n",
      "Negativ F1 Score: 0.8148148148148148\n",
      "\n",
      "Neutral Precision Score: 0.625\n",
      "Neutral Recall Score: 0.7575757575757576\n",
      "Neutral F1 Score: 0.684931506849315\n",
      "\n",
      "Positiv Precision Score: 0.8970588235294118\n",
      "Positiv Recall Score: 0.7261904761904762\n",
      "Positiv F1 Score: 0.8026315789473685\n",
      "\n",
      "Macro Average Precision Score: 0.751797385620915\n",
      "Macro Average Recall Score: 0.8001443001443002\n",
      "Macro Average F1 Score: 0.7674593002038327\n",
      "\n",
      "Weighted Average Scores:\n",
      "Weighted Average Precision: 0.7998558246828142\n",
      "Weighted Average Recall: 0.7777777777777778\n",
      "Weighted Average F1: 0.7801119326205207\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/5_epochs/deepset_gbert-base_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/5_epochs/deepset_gbert-base_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(f'training and results for {model}:')\n",
    "    absa_model(data, model, rn1=42, rn2=42, epochs=5, save = True)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33d8b8ec-7fec-4567-a0b5-b00733c044da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 2243.54 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 2313.42 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 2365.43 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for aari1995/German_Sentiment with 5 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2780' max='2780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2780/2780 15:29, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.882300</td>\n",
       "      <td>0.721462</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.888727</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.874627</td>\n",
       "      <td>{0: 51, 1: 19, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.564300</td>\n",
       "      <td>0.483720</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.870841</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.868716</td>\n",
       "      <td>{0: 39, 1: 30, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.506400</td>\n",
       "      <td>0.586305</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.876837</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.876334</td>\n",
       "      <td>{0: 43, 1: 27, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.208600</td>\n",
       "      <td>0.593073</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.886732</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.883650</td>\n",
       "      <td>{0: 47, 1: 24, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.178400</td>\n",
       "      <td>0.725956</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.863998</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.861749</td>\n",
       "      <td>{0: 44, 1: 28, 2: 57}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_aari1995_German_Sentiment_42_42_5\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_aari1995_German_Sentiment_42_42_5\n",
      "Evaluation results for aari1995/German_Sentiment with 5 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8373995423316956, 'eval_accuracy': 0.8496732026143791, 'eval_precision': 0.8689605028614317, 'eval_recall': 0.8496732026143791, 'eval_f1': 0.8543234685178419, 'eval_class_distribution': {0: 33, 1: 44, 2: 76}, 'eval_runtime': 5.6465, 'eval_samples_per_second': 27.096, 'eval_steps_per_second': 13.637, 'epoch': 5.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.91      0.81      0.85        36\n",
      "     Neutral       0.59      0.88      0.71        33\n",
      "     Positiv       0.96      0.82      0.88        84\n",
      "\n",
      "    accuracy                           0.83       153\n",
      "   macro avg       0.82      0.84      0.81       153\n",
      "weighted avg       0.87      0.83      0.84       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 32, 1: 49, 2: 72}\n",
      "Negativ Precision Score: 0.90625\n",
      "Negativ Recall Score: 0.8055555555555556\n",
      "Negativ F1 Score: 0.8529411764705882\n",
      "\n",
      "Neutral Precision Score: 0.5918367346938775\n",
      "Neutral Recall Score: 0.8787878787878788\n",
      "Neutral F1 Score: 0.7073170731707317\n",
      "\n",
      "Positiv Precision Score: 0.9583333333333334\n",
      "Positiv Recall Score: 0.8214285714285714\n",
      "Positiv F1 Score: 0.8846153846153846\n",
      "\n",
      "Macro Average Precision Score: 0.8188066893424036\n",
      "Macro Average Recall Score: 0.8352573352573351\n",
      "Macro Average F1 Score: 0.8149578780855681\n",
      "\n",
      "Weighted Average Scores:\n",
      "Weighted Average Precision: 0.8670301453914899\n",
      "Weighted Average Recall: 0.8300653594771242\n",
      "Weighted Average F1: 0.8389218174854094\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/5_epochs/aari1995_German_Sentiment_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/5_epochs/aari1995_German_Sentiment_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n"
     ]
    }
   ],
   "source": [
    "absa_model(data, \"aari1995/German_Sentiment\", rn1=42, rn2=42, epochs=5, save = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03d80daf-916b-4a67-a205-2a285dde00ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training and results for google-bert/bert-base-german-cased:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 3920.40 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3781.82 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 3706.35 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for google-bert/bert-base-german-cased with 6 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3336' max='3336' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3336/3336 05:50, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.850700</td>\n",
       "      <td>0.872872</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.794676</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.770090</td>\n",
       "      <td>{0: 57, 1: 24, 2: 48}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.503300</td>\n",
       "      <td>0.719870</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.833824</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.823109</td>\n",
       "      <td>{0: 51, 1: 26, 2: 52}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.455900</td>\n",
       "      <td>0.897653</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.822949</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.815203</td>\n",
       "      <td>{0: 50, 1: 24, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.259000</td>\n",
       "      <td>0.848326</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.839475</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.824194</td>\n",
       "      <td>{0: 52, 1: 27, 2: 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.195500</td>\n",
       "      <td>1.000256</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.816432</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.813751</td>\n",
       "      <td>{0: 47, 1: 24, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.116700</td>\n",
       "      <td>1.077784</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.799644</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.798984</td>\n",
       "      <td>{0: 43, 1: 27, 2: 59}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_google-bert_bert-base-german-cased_42_42_6\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_google-bert_bert-base-german-cased_42_42_6\n",
      "Evaluation results for google-bert/bert-base-german-cased with 6 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1823519468307495, 'eval_accuracy': 0.8104575163398693, 'eval_precision': 0.83270987250226, 'eval_recall': 0.8104575163398693, 'eval_f1': 0.8119711042311663, 'eval_class_distribution': {0: 48, 1: 37, 2: 68}, 'eval_runtime': 2.3438, 'eval_samples_per_second': 65.279, 'eval_steps_per_second': 32.853, 'epoch': 6.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.70      0.89      0.78        36\n",
      "     Neutral       0.68      0.76      0.71        33\n",
      "     Positiv       0.93      0.77      0.84        84\n",
      "\n",
      "    accuracy                           0.80       153\n",
      "   macro avg       0.77      0.81      0.78       153\n",
      "weighted avg       0.82      0.80      0.80       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 46, 1: 37, 2: 70}\n",
      "Negativ Precision Score: 0.6956521739130435\n",
      "Negativ Recall Score: 0.8888888888888888\n",
      "Negativ F1 Score: 0.7804878048780488\n",
      "\n",
      "Neutral Precision Score: 0.6756756756756757\n",
      "Neutral Recall Score: 0.7575757575757576\n",
      "Neutral F1 Score: 0.7142857142857143\n",
      "\n",
      "Positiv Precision Score: 0.9285714285714286\n",
      "Positiv Recall Score: 0.7738095238095238\n",
      "Positiv F1 Score: 0.8441558441558441\n",
      "\n",
      "Macro Average Precision Score: 0.7666330927200492\n",
      "Macro Average Recall Score: 0.8067580567580568\n",
      "Macro Average F1 Score: 0.7796431211065357\n",
      "\n",
      "Weighted Average Scores:\n",
      "Weighted Average Precision: 0.8192207552821363\n",
      "Weighted Average Recall: 0.7973856209150327\n",
      "Weighted Average F1: 0.8011639245498643\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/6_epochs/google-bert_bert-base-german-cased_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/6_epochs/google-bert_bert-base-german-cased_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-cased:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 4015.36 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3867.96 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 3839.56 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for dbmdz/bert-base-german-cased with 6 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3336' max='3336' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3336/3336 05:52, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.898400</td>\n",
       "      <td>0.973359</td>\n",
       "      <td>0.751938</td>\n",
       "      <td>0.803143</td>\n",
       "      <td>0.751938</td>\n",
       "      <td>0.753058</td>\n",
       "      <td>{0: 65, 1: 17, 2: 47}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.599300</td>\n",
       "      <td>0.923055</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.786003</td>\n",
       "      <td>{0: 47, 1: 30, 2: 52}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.510800</td>\n",
       "      <td>1.029080</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.808000</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.799121</td>\n",
       "      <td>{0: 51, 1: 23, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.300900</td>\n",
       "      <td>1.030535</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.808141</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.799109</td>\n",
       "      <td>{0: 51, 1: 25, 2: 53}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.256900</td>\n",
       "      <td>0.873975</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.837543</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.836848</td>\n",
       "      <td>{0: 39, 1: 28, 2: 62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.174900</td>\n",
       "      <td>0.928760</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.821210</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.821392</td>\n",
       "      <td>{0: 41, 1: 27, 2: 61}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_dbmdz_bert-base-german-cased_42_42_6\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_dbmdz_bert-base-german-cased_42_42_6\n",
      "Evaluation results for dbmdz/bert-base-german-cased with 6 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2861956357955933, 'eval_accuracy': 0.7516339869281046, 'eval_precision': 0.771012172985136, 'eval_recall': 0.7516339869281046, 'eval_f1': 0.7528386518005895, 'eval_class_distribution': {0: 49, 1: 35, 2: 69}, 'eval_runtime': 2.3445, 'eval_samples_per_second': 65.26, 'eval_steps_per_second': 32.843, 'epoch': 6.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.67      0.86      0.76        36\n",
      "     Neutral       0.69      0.76      0.72        33\n",
      "     Positiv       0.89      0.75      0.81        84\n",
      "\n",
      "    accuracy                           0.78       153\n",
      "   macro avg       0.75      0.79      0.76       153\n",
      "weighted avg       0.80      0.78      0.78       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 46, 1: 36, 2: 71}\n",
      "Negativ Precision Score: 0.6739130434782609\n",
      "Negativ Recall Score: 0.8611111111111112\n",
      "Negativ F1 Score: 0.7560975609756098\n",
      "\n",
      "Neutral Precision Score: 0.6944444444444444\n",
      "Neutral Recall Score: 0.7575757575757576\n",
      "Neutral F1 Score: 0.7246376811594203\n",
      "\n",
      "Positiv Precision Score: 0.8873239436619719\n",
      "Positiv Recall Score: 0.75\n",
      "Positiv F1 Score: 0.8129032258064516\n",
      "\n",
      "Macro Average Precision Score: 0.7518938105282258\n",
      "Macro Average Recall Score: 0.7895622895622895\n",
      "Macro Average F1 Score: 0.7645461559804939\n",
      "\n",
      "Weighted Average Scores:\n",
      "Weighted Average Precision: 0.7955081535914359\n",
      "Weighted Average Recall: 0.7777777777777778\n",
      "Weighted Average F1: 0.7804995205302272\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/6_epochs/dbmdz_bert-base-german-cased_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/6_epochs/dbmdz_bert-base-german-cased_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-uncased:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 3838.76 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3689.17 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 3598.22 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for dbmdz/bert-base-german-uncased with 6 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3336' max='3336' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3336/3336 05:52, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.843200</td>\n",
       "      <td>0.867722</td>\n",
       "      <td>0.775194</td>\n",
       "      <td>0.818401</td>\n",
       "      <td>0.775194</td>\n",
       "      <td>0.776189</td>\n",
       "      <td>{0: 63, 1: 19, 2: 47}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.507200</td>\n",
       "      <td>0.730670</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.807288</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.805480</td>\n",
       "      <td>{0: 44, 1: 23, 2: 62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.527000</td>\n",
       "      <td>0.769214</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.854343</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.852602</td>\n",
       "      <td>{0: 46, 1: 25, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.277400</td>\n",
       "      <td>0.784220</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.854735</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.852079</td>\n",
       "      <td>{0: 46, 1: 23, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.256100</td>\n",
       "      <td>0.759085</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.828607</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.828685</td>\n",
       "      <td>{0: 42, 1: 25, 2: 62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.158200</td>\n",
       "      <td>0.728507</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.861078</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.860522</td>\n",
       "      <td>{0: 40, 1: 28, 2: 61}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_dbmdz_bert-base-german-uncased_42_42_6\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_dbmdz_bert-base-german-uncased_42_42_6\n",
      "Evaluation results for dbmdz/bert-base-german-uncased with 6 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3692032098770142, 'eval_accuracy': 0.7581699346405228, 'eval_precision': 0.7765781922525108, 'eval_recall': 0.7581699346405228, 'eval_f1': 0.762696878732334, 'eval_class_distribution': {0: 41, 1: 40, 2: 72}, 'eval_runtime': 2.3331, 'eval_samples_per_second': 65.579, 'eval_steps_per_second': 33.004, 'epoch': 6.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.80      0.89      0.84        36\n",
      "     Neutral       0.60      0.76      0.67        33\n",
      "     Positiv       0.93      0.79      0.85        84\n",
      "\n",
      "    accuracy                           0.80       153\n",
      "   macro avg       0.77      0.81      0.79       153\n",
      "weighted avg       0.83      0.80      0.81       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 40, 1: 42, 2: 71}\n",
      "Negativ Precision Score: 0.8\n",
      "Negativ Recall Score: 0.8888888888888888\n",
      "Negativ F1 Score: 0.8421052631578947\n",
      "\n",
      "Neutral Precision Score: 0.5952380952380952\n",
      "Neutral Recall Score: 0.7575757575757576\n",
      "Neutral F1 Score: 0.6666666666666666\n",
      "\n",
      "Positiv Precision Score: 0.9295774647887324\n",
      "Positiv Recall Score: 0.7857142857142857\n",
      "Positiv F1 Score: 0.8516129032258064\n",
      "\n",
      "Macro Average Precision Score: 0.7749385200089426\n",
      "Macro Average Recall Score: 0.8107263107263107\n",
      "Macro Average F1 Score: 0.7867949443501225\n",
      "\n",
      "Weighted Average Scores:\n",
      "Weighted Average Precision: 0.8269762365039912\n",
      "Weighted Average Recall: 0.803921568627451\n",
      "Weighted Average F1: 0.8094854466970716\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/6_epochs/dbmdz_bert-base-german-uncased_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/6_epochs/dbmdz_bert-base-german-uncased_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for FacebookAI/xlm-roberta-base:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 4727.56 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3935.48 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 4200.65 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for FacebookAI/xlm-roberta-base with 6 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3336' max='3336' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3336/3336 07:23, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.873900</td>\n",
       "      <td>0.552215</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.848770</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.843999</td>\n",
       "      <td>{0: 49, 1: 23, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.737200</td>\n",
       "      <td>0.797765</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.820183</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.820159</td>\n",
       "      <td>{0: 42, 1: 24, 2: 63}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.737700</td>\n",
       "      <td>0.773387</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.856728</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.851034</td>\n",
       "      <td>{0: 48, 1: 21, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.479400</td>\n",
       "      <td>0.867890</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.850083</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.844866</td>\n",
       "      <td>{0: 49, 1: 24, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.455700</td>\n",
       "      <td>0.914200</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.832768</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.829780</td>\n",
       "      <td>{0: 47, 1: 25, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.364600</td>\n",
       "      <td>0.900340</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.841932</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.837653</td>\n",
       "      <td>{0: 48, 1: 25, 2: 56}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_FacebookAI_xlm-roberta-base_42_42_6\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_FacebookAI_xlm-roberta-base_42_42_6\n",
      "Evaluation results for FacebookAI/xlm-roberta-base with 6 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1698037385940552, 'eval_accuracy': 0.8235294117647058, 'eval_precision': 0.824281805745554, 'eval_recall': 0.8235294117647058, 'eval_f1': 0.8216931313021247, 'eval_class_distribution': {0: 43, 1: 30, 2: 80}, 'eval_runtime': 2.2529, 'eval_samples_per_second': 67.912, 'eval_steps_per_second': 34.178, 'epoch': 6.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.76      0.94      0.84        36\n",
      "     Neutral       0.69      0.61      0.65        33\n",
      "     Positiv       0.91      0.86      0.88        84\n",
      "\n",
      "    accuracy                           0.82       153\n",
      "   macro avg       0.79      0.80      0.79       153\n",
      "weighted avg       0.83      0.82      0.82       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 45, 1: 29, 2: 79}\n",
      "Negativ Precision Score: 0.7555555555555555\n",
      "Negativ Recall Score: 0.9444444444444444\n",
      "Negativ F1 Score: 0.8395061728395061\n",
      "\n",
      "Neutral Precision Score: 0.6896551724137931\n",
      "Neutral Recall Score: 0.6060606060606061\n",
      "Neutral F1 Score: 0.6451612903225806\n",
      "\n",
      "Positiv Precision Score: 0.9113924050632911\n",
      "Positiv Recall Score: 0.8571428571428571\n",
      "Positiv F1 Score: 0.8834355828220859\n",
      "\n",
      "Macro Average Precision Score: 0.7855343776775466\n",
      "Macro Average Recall Score: 0.8025493025493026\n",
      "Macro Average F1 Score: 0.7893676819947242\n",
      "\n",
      "Weighted Average Scores:\n",
      "Weighted Average Precision: 0.8268992334311871\n",
      "Weighted Average Recall: 0.8235294117647058\n",
      "Weighted Average F1: 0.8217067566008013\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/6_epochs/FacebookAI_xlm-roberta-base_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/6_epochs/FacebookAI_xlm-roberta-base_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_best:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at TUM/GottBERT_base_best and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 4416.49 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 4554.04 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 4497.17 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for TUM/GottBERT_base_best with 6 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3336' max='3336' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3336/3336 06:03, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.889700</td>\n",
       "      <td>0.784115</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.851153</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.808713</td>\n",
       "      <td>{0: 60, 1: 14, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.534000</td>\n",
       "      <td>0.685484</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.867948</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.857423</td>\n",
       "      <td>{0: 32, 1: 29, 2: 68}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.519300</td>\n",
       "      <td>0.664688</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.878821</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.875406</td>\n",
       "      <td>{0: 47, 1: 23, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.305300</td>\n",
       "      <td>0.602223</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.891543</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.884078</td>\n",
       "      <td>{0: 50, 1: 24, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.266900</td>\n",
       "      <td>0.559235</td>\n",
       "      <td>0.899225</td>\n",
       "      <td>0.900215</td>\n",
       "      <td>0.899225</td>\n",
       "      <td>0.899631</td>\n",
       "      <td>{0: 42, 1: 28, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.208500</td>\n",
       "      <td>0.548349</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.878873</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.876931</td>\n",
       "      <td>{0: 44, 1: 28, 2: 57}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_TUM_GottBERT_base_best_42_42_6\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_TUM_GottBERT_base_best_42_42_6\n",
      "Evaluation results for TUM/GottBERT_base_best with 6 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1487834453582764, 'eval_accuracy': 0.8431372549019608, 'eval_precision': 0.8580392156862745, 'eval_recall': 0.8431372549019608, 'eval_f1': 0.8467036625971144, 'eval_class_distribution': {0: 36, 1: 42, 2: 75}, 'eval_runtime': 2.2771, 'eval_samples_per_second': 67.191, 'eval_steps_per_second': 33.815, 'epoch': 6.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.84      0.89      0.86        36\n",
      "     Neutral       0.63      0.79      0.70        33\n",
      "     Positiv       0.92      0.81      0.86        84\n",
      "\n",
      "    accuracy                           0.82       153\n",
      "   macro avg       0.80      0.83      0.81       153\n",
      "weighted avg       0.84      0.82      0.83       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 38, 1: 41, 2: 74}\n",
      "Negativ Precision Score: 0.8421052631578947\n",
      "Negativ Recall Score: 0.8888888888888888\n",
      "Negativ F1 Score: 0.8648648648648649\n",
      "\n",
      "Neutral Precision Score: 0.6341463414634146\n",
      "Neutral Recall Score: 0.7878787878787878\n",
      "Neutral F1 Score: 0.7027027027027027\n",
      "\n",
      "Positiv Precision Score: 0.918918918918919\n",
      "Positiv Recall Score: 0.8095238095238095\n",
      "Positiv F1 Score: 0.8607594936708861\n",
      "\n",
      "Macro Average Precision Score: 0.7983901745134094\n",
      "Macro Average Recall Score: 0.8287638287638287\n",
      "Macro Average F1 Score: 0.8094423537461513\n",
      "\n",
      "Weighted Average Scores:\n",
      "Weighted Average Precision: 0.8394235812494515\n",
      "Weighted Average Recall: 0.8235294117647058\n",
      "Weighted Average F1: 0.8276347829586846\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/6_epochs/TUM_GottBERT_base_best_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/6_epochs/TUM_GottBERT_base_best_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_filtered_base_best:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at TUM/GottBERT_filtered_base_best and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 4911.70 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 4468.33 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 4498.97 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for TUM/GottBERT_filtered_base_best with 6 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3336' max='3336' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3336/3336 05:58, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.857000</td>\n",
       "      <td>0.896841</td>\n",
       "      <td>0.775194</td>\n",
       "      <td>0.802215</td>\n",
       "      <td>0.775194</td>\n",
       "      <td>0.776722</td>\n",
       "      <td>{0: 58, 1: 22, 2: 49}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.529200</td>\n",
       "      <td>0.846917</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.861577</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.858477</td>\n",
       "      <td>{0: 38, 1: 24, 2: 67}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.487100</td>\n",
       "      <td>0.587638</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.882450</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.875628</td>\n",
       "      <td>{0: 49, 1: 22, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.299200</td>\n",
       "      <td>0.639291</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.884332</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.883407</td>\n",
       "      <td>{0: 45, 1: 25, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.303800</td>\n",
       "      <td>0.608101</td>\n",
       "      <td>0.899225</td>\n",
       "      <td>0.898668</td>\n",
       "      <td>0.899225</td>\n",
       "      <td>0.898855</td>\n",
       "      <td>{0: 42, 1: 26, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.199200</td>\n",
       "      <td>0.632043</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.883986</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.883606</td>\n",
       "      <td>{0: 44, 1: 26, 2: 59}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_TUM_GottBERT_filtered_base_best_42_42_6\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_TUM_GottBERT_filtered_base_best_42_42_6\n",
      "Evaluation results for TUM/GottBERT_filtered_base_best with 6 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2891265153884888, 'eval_accuracy': 0.8104575163398693, 'eval_precision': 0.8136641700611742, 'eval_recall': 0.8104575163398693, 'eval_f1': 0.8110396752207357, 'eval_class_distribution': {0: 40, 1: 34, 2: 79}, 'eval_runtime': 2.2571, 'eval_samples_per_second': 67.785, 'eval_steps_per_second': 34.114, 'epoch': 6.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.78      0.89      0.83        36\n",
      "     Neutral       0.67      0.67      0.67        33\n",
      "     Positiv       0.87      0.82      0.85        84\n",
      "\n",
      "    accuracy                           0.80       153\n",
      "   macro avg       0.77      0.79      0.78       153\n",
      "weighted avg       0.81      0.80      0.80       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 41, 1: 33, 2: 79}\n",
      "Negativ Precision Score: 0.7804878048780488\n",
      "Negativ Recall Score: 0.8888888888888888\n",
      "Negativ F1 Score: 0.8311688311688312\n",
      "\n",
      "Neutral Precision Score: 0.6666666666666666\n",
      "Neutral Recall Score: 0.6666666666666666\n",
      "Neutral F1 Score: 0.6666666666666666\n",
      "\n",
      "Positiv Precision Score: 0.8734177215189873\n",
      "Positiv Recall Score: 0.8214285714285714\n",
      "Positiv F1 Score: 0.8466257668711656\n",
      "\n",
      "Macro Average Precision Score: 0.7735240643545677\n",
      "Macro Average Recall Score: 0.7923280423280422\n",
      "Macro Average F1 Score: 0.7814870882355546\n",
      "\n",
      "Weighted Average Scores:\n",
      "Weighted Average Precision: 0.8069584940078738\n",
      "Weighted Average Recall: 0.803921568627451\n",
      "Weighted Average F1: 0.8041741329363126\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/6_epochs/TUM_GottBERT_filtered_base_best_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/6_epochs/TUM_GottBERT_filtered_base_best_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_last:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at TUM/GottBERT_base_last were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at TUM/GottBERT_base_last and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 4890.80 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 4449.55 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 4473.41 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for TUM/GottBERT_base_last with 6 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3336' max='3336' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3336/3336 05:56, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.887400</td>\n",
       "      <td>0.931562</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.830926</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.800897</td>\n",
       "      <td>{0: 57, 1: 15, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.587600</td>\n",
       "      <td>0.833820</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.853088</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.852658</td>\n",
       "      <td>{0: 40, 1: 28, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.470200</td>\n",
       "      <td>0.826412</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.870975</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.847282</td>\n",
       "      <td>{0: 54, 1: 16, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.298700</td>\n",
       "      <td>0.767191</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.871894</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.868089</td>\n",
       "      <td>{0: 47, 1: 23, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.249700</td>\n",
       "      <td>0.768104</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.845417</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.842991</td>\n",
       "      <td>{0: 46, 1: 22, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.213300</td>\n",
       "      <td>0.758869</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.863426</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.859381</td>\n",
       "      <td>{0: 47, 1: 22, 2: 60}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_TUM_GottBERT_base_last_42_42_6\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_TUM_GottBERT_base_last_42_42_6\n",
      "Evaluation results for TUM/GottBERT_base_last with 6 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1324610710144043, 'eval_accuracy': 0.8169934640522876, 'eval_precision': 0.8301974214343272, 'eval_recall': 0.8169934640522876, 'eval_f1': 0.81928726927745, 'eval_class_distribution': {0: 40, 1: 40, 2: 73}, 'eval_runtime': 2.2852, 'eval_samples_per_second': 66.954, 'eval_steps_per_second': 33.696, 'epoch': 6.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.76      0.89      0.82        36\n",
      "     Neutral       0.62      0.76      0.68        33\n",
      "     Positiv       0.92      0.77      0.84        84\n",
      "\n",
      "    accuracy                           0.80       153\n",
      "   macro avg       0.77      0.81      0.78       153\n",
      "weighted avg       0.82      0.80      0.80       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 42, 1: 40, 2: 71}\n",
      "Negativ Precision Score: 0.7619047619047619\n",
      "Negativ Recall Score: 0.8888888888888888\n",
      "Negativ F1 Score: 0.8205128205128205\n",
      "\n",
      "Neutral Precision Score: 0.625\n",
      "Neutral Recall Score: 0.7575757575757576\n",
      "Neutral F1 Score: 0.684931506849315\n",
      "\n",
      "Positiv Precision Score: 0.9154929577464789\n",
      "Positiv Recall Score: 0.7738095238095238\n",
      "Positiv F1 Score: 0.8387096774193549\n",
      "\n",
      "Macro Average Precision Score: 0.7674659065504136\n",
      "Macro Average Recall Score: 0.8067580567580568\n",
      "Macro Average F1 Score: 0.7813846682604968\n",
      "\n",
      "Weighted Average Scores:\n",
      "Weighted Average Precision: 0.8166992148972265\n",
      "Weighted Average Recall: 0.7973856209150327\n",
      "Weighted Average F1: 0.801260223318397\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/6_epochs/TUM_GottBERT_base_last_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/6_epochs/TUM_GottBERT_base_last_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for distilbert/distilbert-base-german-cased:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 4984.24 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 4781.12 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 4636.20 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for distilbert/distilbert-base-german-cased with 6 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3336' max='3336' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3336/3336 03:08, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.798800</td>\n",
       "      <td>0.735539</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.824226</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.788050</td>\n",
       "      <td>{0: 62, 1: 18, 2: 49}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.561300</td>\n",
       "      <td>0.695231</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.859105</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.836639</td>\n",
       "      <td>{0: 56, 1: 19, 2: 54}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.505000</td>\n",
       "      <td>0.677091</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.876804</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.862010</td>\n",
       "      <td>{0: 52, 1: 27, 2: 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.279900</td>\n",
       "      <td>0.687710</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.876804</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.862010</td>\n",
       "      <td>{0: 52, 1: 27, 2: 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.251000</td>\n",
       "      <td>0.737269</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.892047</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.877154</td>\n",
       "      <td>{0: 53, 1: 25, 2: 51}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.177500</td>\n",
       "      <td>0.810352</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.858393</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.839439</td>\n",
       "      <td>{0: 52, 1: 29, 2: 48}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_distilbert_distilbert-base-german-cased_42_42_6\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_distilbert_distilbert-base-german-cased_42_42_6\n",
      "Evaluation results for distilbert/distilbert-base-german-cased with 6 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2296180725097656, 'eval_accuracy': 0.7581699346405228, 'eval_precision': 0.7745098039215687, 'eval_recall': 0.7581699346405228, 'eval_f1': 0.7599655246714071, 'eval_class_distribution': {0: 48, 1: 33, 2: 72}, 'eval_runtime': 1.3004, 'eval_samples_per_second': 117.655, 'eval_steps_per_second': 59.212, 'epoch': 6.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.73      0.89      0.80        36\n",
      "     Neutral       0.69      0.67      0.68        33\n",
      "     Positiv       0.88      0.81      0.84        84\n",
      "\n",
      "    accuracy                           0.80       153\n",
      "   macro avg       0.77      0.79      0.77       153\n",
      "weighted avg       0.80      0.80      0.80       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 44, 1: 32, 2: 77}\n",
      "Negativ Precision Score: 0.7272727272727273\n",
      "Negativ Recall Score: 0.8888888888888888\n",
      "Negativ F1 Score: 0.8\n",
      "\n",
      "Neutral Precision Score: 0.6875\n",
      "Neutral Recall Score: 0.6666666666666666\n",
      "Neutral F1 Score: 0.676923076923077\n",
      "\n",
      "Positiv Precision Score: 0.8831168831168831\n",
      "Positiv Recall Score: 0.8095238095238095\n",
      "Positiv F1 Score: 0.84472049689441\n",
      "\n",
      "Macro Average Precision Score: 0.7659632034632035\n",
      "Macro Average Recall Score: 0.7883597883597883\n",
      "Macro Average F1 Score: 0.7738811912724955\n",
      "\n",
      "Weighted Average Scores:\n",
      "Weighted Average Precision: 0.8042557932263814\n",
      "Weighted Average Recall: 0.7973856209150327\n",
      "Weighted Average F1: 0.7980064266509279\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/6_epochs/distilbert_distilbert-base-german-cased_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/6_epochs/distilbert_distilbert-base-german-cased_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for GerMedBERT/medbert-512:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GerMedBERT/medbert-512 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 3944.11 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3738.52 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 3753.87 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for GerMedBERT/medbert-512 with 6 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3336' max='3336' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3336/3336 05:57, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.882400</td>\n",
       "      <td>0.710477</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.781672</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.762594</td>\n",
       "      <td>{0: 51, 1: 16, 2: 62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.544500</td>\n",
       "      <td>1.052178</td>\n",
       "      <td>0.759690</td>\n",
       "      <td>0.758426</td>\n",
       "      <td>0.759690</td>\n",
       "      <td>0.755334</td>\n",
       "      <td>{0: 36, 1: 24, 2: 69}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.499000</td>\n",
       "      <td>0.989582</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.812616</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.803087</td>\n",
       "      <td>{0: 39, 1: 20, 2: 70}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.214800</td>\n",
       "      <td>0.941466</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.813576</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.811673</td>\n",
       "      <td>{0: 46, 1: 22, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.233100</td>\n",
       "      <td>1.158886</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.805212</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.805507</td>\n",
       "      <td>{0: 41, 1: 26, 2: 62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.102600</td>\n",
       "      <td>1.152936</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.815823</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.814685</td>\n",
       "      <td>{0: 43, 1: 28, 2: 58}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_GerMedBERT_medbert-512_42_42_6\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_GerMedBERT_medbert-512_42_42_6\n",
      "Evaluation results for GerMedBERT/medbert-512 with 6 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4708349704742432, 'eval_accuracy': 0.7843137254901961, 'eval_precision': 0.8020066889632107, 'eval_recall': 0.7843137254901961, 'eval_f1': 0.7854564483745569, 'eval_class_distribution': {0: 45, 1: 39, 2: 69}, 'eval_runtime': 2.332, 'eval_samples_per_second': 65.61, 'eval_steps_per_second': 33.019, 'epoch': 6.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.66      0.86      0.75        36\n",
      "     Neutral       0.66      0.70      0.68        33\n",
      "     Positiv       0.89      0.75      0.81        84\n",
      "\n",
      "    accuracy                           0.76       153\n",
      "   macro avg       0.73      0.77      0.75       153\n",
      "weighted avg       0.78      0.76      0.77       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 47, 1: 35, 2: 71}\n",
      "Negativ Precision Score: 0.6595744680851063\n",
      "Negativ Recall Score: 0.8611111111111112\n",
      "Negativ F1 Score: 0.7469879518072289\n",
      "\n",
      "Neutral Precision Score: 0.6571428571428571\n",
      "Neutral Recall Score: 0.696969696969697\n",
      "Neutral F1 Score: 0.6764705882352942\n",
      "\n",
      "Positiv Precision Score: 0.8873239436619719\n",
      "Positiv Recall Score: 0.75\n",
      "Positiv F1 Score: 0.8129032258064516\n",
      "\n",
      "Macro Average Precision Score: 0.7346804229633118\n",
      "Macro Average Recall Score: 0.7693602693602694\n",
      "Macro Average F1 Score: 0.7454539219496582\n",
      "\n",
      "Weighted Average Scores:\n",
      "Weighted Average Precision: 0.7840889307476062\n",
      "Weighted Average Recall: 0.7647058823529411\n",
      "Weighted Average F1: 0.7679671022520711\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/6_epochs/GerMedBERT_medbert-512_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/6_epochs/GerMedBERT_medbert-512_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for deepset/gbert-base:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 3955.86 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3850.53 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 3745.29 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for deepset/gbert-base with 6 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3336' max='3336' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3336/3336 05:51, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.823500</td>\n",
       "      <td>0.771304</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.844654</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.837041</td>\n",
       "      <td>{0: 50, 1: 22, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.548100</td>\n",
       "      <td>0.605326</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.862715</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.860653</td>\n",
       "      <td>{0: 46, 1: 25, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.441000</td>\n",
       "      <td>0.742509</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.870869</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.867459</td>\n",
       "      <td>{0: 48, 1: 24, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.191300</td>\n",
       "      <td>0.610620</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.909670</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.907683</td>\n",
       "      <td>{0: 45, 1: 27, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.159400</td>\n",
       "      <td>0.971854</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.849143</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.845038</td>\n",
       "      <td>{0: 48, 1: 24, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.054900</td>\n",
       "      <td>0.828755</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.873176</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.869614</td>\n",
       "      <td>{0: 46, 1: 27, 2: 56}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_deepset_gbert-base_42_42_6\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_deepset_gbert-base_42_42_6\n",
      "Evaluation results for deepset/gbert-base with 6 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2386518716812134, 'eval_accuracy': 0.8169934640522876, 'eval_precision': 0.8307317934864563, 'eval_recall': 0.8169934640522876, 'eval_f1': 0.8205443519934269, 'eval_class_distribution': {0: 37, 1: 41, 2: 75}, 'eval_runtime': 2.3469, 'eval_samples_per_second': 65.192, 'eval_steps_per_second': 32.809, 'epoch': 6.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.89      0.92      0.90        36\n",
      "     Neutral       0.63      0.79      0.70        33\n",
      "     Positiv       0.89      0.80      0.84        84\n",
      "\n",
      "    accuracy                           0.82       153\n",
      "   macro avg       0.81      0.83      0.82       153\n",
      "weighted avg       0.84      0.82      0.83       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 37, 1: 41, 2: 75}\n",
      "Negativ Precision Score: 0.8918918918918919\n",
      "Negativ Recall Score: 0.9166666666666666\n",
      "Negativ F1 Score: 0.9041095890410958\n",
      "\n",
      "Neutral Precision Score: 0.6341463414634146\n",
      "Neutral Recall Score: 0.7878787878787878\n",
      "Neutral F1 Score: 0.7027027027027027\n",
      "\n",
      "Positiv Precision Score: 0.8933333333333333\n",
      "Positiv Recall Score: 0.7976190476190477\n",
      "Positiv F1 Score: 0.8427672955974843\n",
      "\n",
      "Macro Average Precision Score: 0.8064571888962133\n",
      "Macro Average Recall Score: 0.8340548340548342\n",
      "Macro Average F1 Score: 0.816526529113761\n",
      "\n",
      "Weighted Average Scores:\n",
      "Weighted Average Precision: 0.8370910939634038\n",
      "Weighted Average Recall: 0.8235294117647058\n",
      "Weighted Average F1: 0.826990766175538\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/6_epochs/deepset_gbert-base_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/6_epochs/deepset_gbert-base_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(f'training and results for {model}:')\n",
    "    absa_model(data, model, rn1=42, rn2=42, epochs=6, save = True)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "320cb832-f719-40ae-8c89-781f1b92b991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 3948.55 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3783.46 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 3734.41 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for aari1995/German_Sentiment with 6 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3336' max='3336' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3336/3336 18:09, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.911900</td>\n",
       "      <td>0.623253</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.908965</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.882207</td>\n",
       "      <td>{0: 55, 1: 17, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.510400</td>\n",
       "      <td>0.740861</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.848215</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.839176</td>\n",
       "      <td>{0: 36, 1: 34, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.443600</td>\n",
       "      <td>0.715509</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.870328</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.865894</td>\n",
       "      <td>{0: 47, 1: 21, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.244000</td>\n",
       "      <td>0.627744</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.906579</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.906446</td>\n",
       "      <td>{0: 43, 1: 25, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.185400</td>\n",
       "      <td>0.688010</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.908279</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.906126</td>\n",
       "      <td>{0: 45, 1: 23, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.093500</td>\n",
       "      <td>0.642033</td>\n",
       "      <td>0.922481</td>\n",
       "      <td>0.923643</td>\n",
       "      <td>0.922481</td>\n",
       "      <td>0.922088</td>\n",
       "      <td>{0: 45, 1: 24, 2: 60}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_aari1995_German_Sentiment_42_42_6\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_aari1995_German_Sentiment_42_42_6\n",
      "Evaluation results for aari1995/German_Sentiment with 6 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9785120487213135, 'eval_accuracy': 0.8562091503267973, 'eval_precision': 0.8614384165095456, 'eval_recall': 0.8562091503267973, 'eval_f1': 0.8579112116996729, 'eval_class_distribution': {0: 38, 1: 36, 2: 79}, 'eval_runtime': 7.1423, 'eval_samples_per_second': 21.422, 'eval_steps_per_second': 10.781, 'epoch': 6.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.83      0.94      0.88        36\n",
      "     Neutral       0.64      0.70      0.67        33\n",
      "     Positiv       0.93      0.85      0.89        84\n",
      "\n",
      "    accuracy                           0.84       153\n",
      "   macro avg       0.80      0.83      0.81       153\n",
      "weighted avg       0.85      0.84      0.84       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 41, 1: 36, 2: 76}\n",
      "Negativ Precision Score: 0.8292682926829268\n",
      "Negativ Recall Score: 0.9444444444444444\n",
      "Negativ F1 Score: 0.8831168831168831\n",
      "\n",
      "Neutral Precision Score: 0.6388888888888888\n",
      "Neutral Recall Score: 0.696969696969697\n",
      "Neutral F1 Score: 0.6666666666666666\n",
      "\n",
      "Positiv Precision Score: 0.9342105263157895\n",
      "Positiv Recall Score: 0.8452380952380952\n",
      "Positiv F1 Score: 0.8875\n",
      "\n",
      "Macro Average Precision Score: 0.8007892359625349\n",
      "Macro Average Recall Score: 0.8288840788840789\n",
      "Macro Average F1 Score: 0.8124278499278499\n",
      "\n",
      "Weighted Average Scores:\n",
      "Weighted Average Precision: 0.8458214122904902\n",
      "Weighted Average Recall: 0.8366013071895425\n",
      "Weighted Average F1: 0.8388379594261945\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/6_epochs/aari1995_German_Sentiment_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/6_epochs/aari1995_German_Sentiment_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n"
     ]
    }
   ],
   "source": [
    "absa_model(data, \"aari1995/German_Sentiment\", rn1=42, rn2=42, epochs=6, save = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d0ae1c7-40c0-497a-bf12-c6b45c02e2a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training and results for google-bert/bert-base-german-cased:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 2452.69 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3918.80 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 4015.09 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for google-bert/bert-base-german-cased with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3892' max='3892' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3892/3892 06:49, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.827100</td>\n",
       "      <td>0.933740</td>\n",
       "      <td>0.759690</td>\n",
       "      <td>0.815455</td>\n",
       "      <td>0.759690</td>\n",
       "      <td>0.762571</td>\n",
       "      <td>{0: 65, 1: 17, 2: 47}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.534700</td>\n",
       "      <td>0.612021</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.814447</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.800366</td>\n",
       "      <td>{0: 53, 1: 22, 2: 54}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.461300</td>\n",
       "      <td>1.035336</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.798305</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.790147</td>\n",
       "      <td>{0: 50, 1: 21, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.218200</td>\n",
       "      <td>0.919725</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.808743</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.807006</td>\n",
       "      <td>{0: 45, 1: 26, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.203100</td>\n",
       "      <td>1.046697</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.831635</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.828375</td>\n",
       "      <td>{0: 36, 1: 29, 2: 64}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.139000</td>\n",
       "      <td>1.068112</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.823492</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.822333</td>\n",
       "      <td>{0: 41, 1: 29, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.086200</td>\n",
       "      <td>1.140166</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.832398</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.830607</td>\n",
       "      <td>{0: 42, 1: 29, 2: 58}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_google-bert_bert-base-german-cased_42_42_7\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_google-bert_bert-base-german-cased_42_42_7\n",
      "Evaluation results for google-bert/bert-base-german-cased with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4145169258117676, 'eval_accuracy': 0.7843137254901961, 'eval_precision': 0.8023184540047554, 'eval_recall': 0.7843137254901961, 'eval_f1': 0.7876029162556677, 'eval_class_distribution': {0: 41, 1: 41, 2: 71}, 'eval_runtime': 2.3322, 'eval_samples_per_second': 65.604, 'eval_steps_per_second': 33.017, 'epoch': 7.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.71      0.89      0.79        36\n",
      "     Neutral       0.62      0.70      0.66        33\n",
      "     Positiv       0.89      0.75      0.81        84\n",
      "\n",
      "    accuracy                           0.77       153\n",
      "   macro avg       0.74      0.78      0.75       153\n",
      "weighted avg       0.79      0.77      0.77       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 45, 1: 37, 2: 71}\n",
      "Negativ Precision Score: 0.7111111111111111\n",
      "Negativ Recall Score: 0.8888888888888888\n",
      "Negativ F1 Score: 0.7901234567901234\n",
      "\n",
      "Neutral Precision Score: 0.6216216216216216\n",
      "Neutral Recall Score: 0.696969696969697\n",
      "Neutral F1 Score: 0.6571428571428571\n",
      "\n",
      "Positiv Precision Score: 0.8873239436619719\n",
      "Positiv Recall Score: 0.75\n",
      "Positiv F1 Score: 0.8129032258064516\n",
      "\n",
      "Macro Average Precision Score: 0.7400188921315682\n",
      "Macro Average Recall Score: 0.7786195286195285\n",
      "Macro Average F1 Score: 0.7533898465798107\n",
      "\n",
      "Weighted Average Precision: 0.7885537567393408\n",
      "Weighted Average Recall: 0.7712418300653595\n",
      "Weighted Average F1: 0.7739479065222266\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/7_epochs/google-bert_bert-base-german-cased_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/7_epochs/google-bert_bert-base-german-cased_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-cased:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 3951.23 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3528.74 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 3955.40 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for dbmdz/bert-base-german-cased with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3892' max='3892' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3892/3892 06:51, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.932200</td>\n",
       "      <td>1.065827</td>\n",
       "      <td>0.759690</td>\n",
       "      <td>0.818431</td>\n",
       "      <td>0.759690</td>\n",
       "      <td>0.755759</td>\n",
       "      <td>{0: 66, 1: 13, 2: 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.593300</td>\n",
       "      <td>1.049472</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.741648</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.739688</td>\n",
       "      <td>{0: 39, 1: 22, 2: 68}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.521900</td>\n",
       "      <td>1.068330</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.829688</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.821732</td>\n",
       "      <td>{0: 50, 1: 22, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.332200</td>\n",
       "      <td>0.881616</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.823985</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.809993</td>\n",
       "      <td>{0: 51, 1: 27, 2: 51}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.341200</td>\n",
       "      <td>1.016977</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.827939</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.823577</td>\n",
       "      <td>{0: 42, 1: 31, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.218000</td>\n",
       "      <td>1.035653</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.876655</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.850565</td>\n",
       "      <td>{0: 39, 1: 40, 2: 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.172500</td>\n",
       "      <td>1.035130</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.862300</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.842079</td>\n",
       "      <td>{0: 40, 1: 38, 2: 51}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_dbmdz_bert-base-german-cased_42_42_7\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_dbmdz_bert-base-german-cased_42_42_7\n",
      "Evaluation results for dbmdz/bert-base-german-cased with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4055098295211792, 'eval_accuracy': 0.7843137254901961, 'eval_precision': 0.8106868478385506, 'eval_recall': 0.7843137254901961, 'eval_f1': 0.7901270254211431, 'eval_class_distribution': {0: 38, 1: 45, 2: 70}, 'eval_runtime': 2.3704, 'eval_samples_per_second': 64.545, 'eval_steps_per_second': 32.483, 'epoch': 7.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.74      0.89      0.81        36\n",
      "     Neutral       0.58      0.79      0.67        33\n",
      "     Positiv       0.94      0.73      0.82        84\n",
      "\n",
      "    accuracy                           0.78       153\n",
      "   macro avg       0.75      0.80      0.77       153\n",
      "weighted avg       0.81      0.78      0.78       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 43, 1: 45, 2: 65}\n",
      "Negativ Precision Score: 0.7441860465116279\n",
      "Negativ Recall Score: 0.8888888888888888\n",
      "Negativ F1 Score: 0.810126582278481\n",
      "\n",
      "Neutral Precision Score: 0.5777777777777777\n",
      "Neutral Recall Score: 0.7878787878787878\n",
      "Neutral F1 Score: 0.6666666666666666\n",
      "\n",
      "Positiv Precision Score: 0.9384615384615385\n",
      "Positiv Recall Score: 0.7261904761904762\n",
      "Positiv F1 Score: 0.8187919463087249\n",
      "\n",
      "Macro Average Precision Score: 0.7534751209169813\n",
      "Macro Average Recall Score: 0.8009860509860509\n",
      "Macro Average F1 Score: 0.7651950650846242\n",
      "\n",
      "Weighted Average Precision: 0.81495512138467\n",
      "Weighted Average Recall: 0.7777777777777778\n",
      "Weighted Average F1: 0.7839417023003804\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/7_epochs/dbmdz_bert-base-german-cased_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/7_epochs/dbmdz_bert-base-german-cased_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-uncased:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 3930.50 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3710.07 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 3726.52 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for dbmdz/bert-base-german-uncased with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3892' max='3892' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3892/3892 06:47, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.790999</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.843522</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.820305</td>\n",
       "      <td>{0: 57, 1: 19, 2: 53}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.582800</td>\n",
       "      <td>1.017033</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.764707</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.747105</td>\n",
       "      <td>{0: 37, 1: 39, 2: 53}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.497000</td>\n",
       "      <td>0.689613</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.851761</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.851771</td>\n",
       "      <td>{0: 40, 1: 26, 2: 63}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.301300</td>\n",
       "      <td>0.757878</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.839343</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.832214</td>\n",
       "      <td>{0: 39, 1: 33, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.291200</td>\n",
       "      <td>0.818664</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.827855</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.827817</td>\n",
       "      <td>{0: 39, 1: 26, 2: 64}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.178100</td>\n",
       "      <td>0.936172</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.839243</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.832737</td>\n",
       "      <td>{0: 41, 1: 32, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.115800</td>\n",
       "      <td>0.887976</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.865547</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.862148</td>\n",
       "      <td>{0: 44, 1: 29, 2: 56}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_dbmdz_bert-base-german-uncased_42_42_7\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_dbmdz_bert-base-german-uncased_42_42_7\n",
      "Evaluation results for dbmdz/bert-base-german-uncased with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.603320837020874, 'eval_accuracy': 0.7516339869281046, 'eval_precision': 0.785293336955741, 'eval_recall': 0.7516339869281046, 'eval_f1': 0.7564902099869795, 'eval_class_distribution': {0: 46, 1: 42, 2: 65}, 'eval_runtime': 2.3525, 'eval_samples_per_second': 65.037, 'eval_steps_per_second': 32.731, 'epoch': 7.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.65      0.89      0.75        36\n",
      "     Neutral       0.64      0.82      0.72        33\n",
      "     Positiv       0.95      0.70      0.81        84\n",
      "\n",
      "    accuracy                           0.77       153\n",
      "   macro avg       0.75      0.80      0.76       153\n",
      "weighted avg       0.81      0.77      0.78       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 49, 1: 42, 2: 62}\n",
      "Negativ Precision Score: 0.6530612244897959\n",
      "Negativ Recall Score: 0.8888888888888888\n",
      "Negativ F1 Score: 0.7529411764705882\n",
      "\n",
      "Neutral Precision Score: 0.6428571428571429\n",
      "Neutral Recall Score: 0.8181818181818182\n",
      "Neutral F1 Score: 0.72\n",
      "\n",
      "Positiv Precision Score: 0.9516129032258065\n",
      "Positiv Recall Score: 0.7023809523809523\n",
      "Positiv F1 Score: 0.8082191780821918\n",
      "\n",
      "Macro Average Precision Score: 0.749177090190915\n",
      "Macro Average Recall Score: 0.8031505531505531\n",
      "Macro Average F1 Score: 0.7603867848509266\n",
      "\n",
      "Weighted Average Precision: 0.8147710697182099\n",
      "Weighted Average Recall: 0.7712418300653595\n",
      "Weighted Average F1: 0.7761849236068319\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/7_epochs/dbmdz_bert-base-german-uncased_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/7_epochs/dbmdz_bert-base-german-uncased_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for FacebookAI/xlm-roberta-base:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 4383.31 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 4039.85 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 4249.69 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for FacebookAI/xlm-roberta-base with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3892' max='3892' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3892/3892 08:33, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.921600</td>\n",
       "      <td>0.708911</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.812835</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.805108</td>\n",
       "      <td>{0: 50, 1: 21, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.706100</td>\n",
       "      <td>0.852544</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>{0: 42, 1: 27, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.741500</td>\n",
       "      <td>1.164746</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.819257</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.814667</td>\n",
       "      <td>{0: 48, 1: 24, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.517300</td>\n",
       "      <td>0.945621</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.860207</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.854514</td>\n",
       "      <td>{0: 45, 1: 30, 2: 54}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.475700</td>\n",
       "      <td>0.966865</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.837803</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.837277</td>\n",
       "      <td>{0: 44, 1: 26, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.377600</td>\n",
       "      <td>0.872053</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.873088</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.862747</td>\n",
       "      <td>{0: 39, 1: 35, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.337900</td>\n",
       "      <td>0.859931</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.878529</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.870122</td>\n",
       "      <td>{0: 40, 1: 34, 2: 55}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_FacebookAI_xlm-roberta-base_42_42_7\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_FacebookAI_xlm-roberta-base_42_42_7\n",
      "Evaluation results for FacebookAI/xlm-roberta-base with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2322006225585938, 'eval_accuracy': 0.8169934640522876, 'eval_precision': 0.8249450602391779, 'eval_recall': 0.8169934640522876, 'eval_f1': 0.8192717086834734, 'eval_class_distribution': {0: 39, 1: 37, 2: 77}, 'eval_runtime': 2.2759, 'eval_samples_per_second': 67.225, 'eval_steps_per_second': 33.832, 'epoch': 7.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.83      0.94      0.88        36\n",
      "     Neutral       0.67      0.79      0.72        33\n",
      "     Positiv       0.93      0.81      0.87        84\n",
      "\n",
      "    accuracy                           0.84       153\n",
      "   macro avg       0.81      0.85      0.82       153\n",
      "weighted avg       0.85      0.84      0.84       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 41, 1: 39, 2: 73}\n",
      "Negativ Precision Score: 0.8292682926829268\n",
      "Negativ Recall Score: 0.9444444444444444\n",
      "Negativ F1 Score: 0.8831168831168831\n",
      "\n",
      "Neutral Precision Score: 0.6666666666666666\n",
      "Neutral Recall Score: 0.7878787878787878\n",
      "Neutral F1 Score: 0.7222222222222222\n",
      "\n",
      "Positiv Precision Score: 0.9315068493150684\n",
      "Positiv Recall Score: 0.8095238095238095\n",
      "Positiv F1 Score: 0.8662420382165605\n",
      "\n",
      "Macro Average Precision Score: 0.8091472695548872\n",
      "Macro Average Recall Score: 0.8472823472823473\n",
      "Macro Average F1 Score: 0.8238603811852219\n",
      "\n",
      "Weighted Average Precision: 0.8503283260068699\n",
      "Weighted Average Recall: 0.8366013071895425\n",
      "Weighted Average F1: 0.8391494923904066\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/7_epochs/FacebookAI_xlm-roberta-base_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/7_epochs/FacebookAI_xlm-roberta-base_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_best:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at TUM/GottBERT_base_best and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 5008.11 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 4495.20 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 4507.15 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for TUM/GottBERT_base_best with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3892' max='3892' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3892/3892 06:58, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.864100</td>\n",
       "      <td>0.691972</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.851249</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.788623</td>\n",
       "      <td>{0: 62, 1: 11, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.572400</td>\n",
       "      <td>0.598921</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.864491</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.861585</td>\n",
       "      <td>{0: 46, 1: 26, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.476300</td>\n",
       "      <td>0.626405</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.862384</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.856953</td>\n",
       "      <td>{0: 44, 1: 20, 2: 65}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.346400</td>\n",
       "      <td>0.661666</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.885219</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.869064</td>\n",
       "      <td>{0: 54, 1: 23, 2: 52}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.260300</td>\n",
       "      <td>0.741127</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.850767</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.849997</td>\n",
       "      <td>{0: 41, 1: 23, 2: 65}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.223400</td>\n",
       "      <td>0.864755</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.886164</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.864099</td>\n",
       "      <td>{0: 34, 1: 39, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.165900</td>\n",
       "      <td>0.770394</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.878702</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.871170</td>\n",
       "      <td>{0: 39, 1: 33, 2: 57}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_TUM_GottBERT_base_best_42_42_7\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_TUM_GottBERT_base_best_42_42_7\n",
      "Evaluation results for TUM/GottBERT_base_best with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2199233770370483, 'eval_accuracy': 0.8104575163398693, 'eval_precision': 0.8222825540472599, 'eval_recall': 0.8104575163398693, 'eval_f1': 0.8135454433345665, 'eval_class_distribution': {0: 39, 1: 39, 2: 75}, 'eval_runtime': 2.2536, 'eval_samples_per_second': 67.892, 'eval_steps_per_second': 34.168, 'epoch': 7.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.74      0.89      0.81        36\n",
      "     Neutral       0.65      0.79      0.71        33\n",
      "     Positiv       0.93      0.77      0.84        84\n",
      "\n",
      "    accuracy                           0.80       153\n",
      "   macro avg       0.77      0.82      0.79       153\n",
      "weighted avg       0.83      0.80      0.81       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 43, 1: 40, 2: 70}\n",
      "Negativ Precision Score: 0.7441860465116279\n",
      "Negativ Recall Score: 0.8888888888888888\n",
      "Negativ F1 Score: 0.810126582278481\n",
      "\n",
      "Neutral Precision Score: 0.65\n",
      "Neutral Recall Score: 0.7878787878787878\n",
      "Neutral F1 Score: 0.7123287671232876\n",
      "\n",
      "Positiv Precision Score: 0.9285714285714286\n",
      "Positiv Recall Score: 0.7738095238095238\n",
      "Positiv F1 Score: 0.8441558441558441\n",
      "\n",
      "Macro Average Precision Score: 0.7742524916943522\n",
      "Macro Average Recall Score: 0.8168590668590668\n",
      "Macro Average F1 Score: 0.7888703978525377\n",
      "\n",
      "Weighted Average Precision: 0.8251025991792065\n",
      "Weighted Average Recall: 0.803921568627451\n",
      "Weighted Average F1: 0.8077156678835602\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/7_epochs/TUM_GottBERT_base_best_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/7_epochs/TUM_GottBERT_base_best_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_filtered_base_best:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at TUM/GottBERT_filtered_base_best and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 4910.00 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 4463.53 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 4469.70 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for TUM/GottBERT_filtered_base_best with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3892' max='3892' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3892/3892 06:55, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.825900</td>\n",
       "      <td>0.977278</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.809019</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.769800</td>\n",
       "      <td>{0: 62, 1: 21, 2: 46}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.561300</td>\n",
       "      <td>0.682484</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>{0: 42, 1: 27, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.487900</td>\n",
       "      <td>0.651089</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.894169</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.891106</td>\n",
       "      <td>{0: 46, 1: 23, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.286500</td>\n",
       "      <td>0.699712</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.890875</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.884222</td>\n",
       "      <td>{0: 49, 1: 23, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.292400</td>\n",
       "      <td>0.735913</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.890789</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.891039</td>\n",
       "      <td>{0: 42, 1: 26, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.196500</td>\n",
       "      <td>0.970835</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.864224</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.855692</td>\n",
       "      <td>{0: 42, 1: 33, 2: 54}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.196900</td>\n",
       "      <td>0.851010</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.854655</td>\n",
       "      <td>{0: 45, 1: 30, 2: 54}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_TUM_GottBERT_filtered_base_best_42_42_7\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_TUM_GottBERT_filtered_base_best_42_42_7\n",
      "Evaluation results for TUM/GottBERT_filtered_base_best with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1252208948135376, 'eval_accuracy': 0.7843137254901961, 'eval_precision': 0.7895209365797601, 'eval_recall': 0.7843137254901961, 'eval_f1': 0.7856395013763637, 'eval_class_distribution': {0: 40, 1: 35, 2: 78}, 'eval_runtime': 2.251, 'eval_samples_per_second': 67.971, 'eval_steps_per_second': 34.208, 'epoch': 7.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.76      0.89      0.82        36\n",
      "     Neutral       0.66      0.70      0.68        33\n",
      "     Positiv       0.87      0.79      0.82        84\n",
      "\n",
      "    accuracy                           0.79       153\n",
      "   macro avg       0.76      0.79      0.77       153\n",
      "weighted avg       0.80      0.79      0.79       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 42, 1: 35, 2: 76}\n",
      "Negativ Precision Score: 0.7619047619047619\n",
      "Negativ Recall Score: 0.8888888888888888\n",
      "Negativ F1 Score: 0.8205128205128205\n",
      "\n",
      "Neutral Precision Score: 0.6571428571428571\n",
      "Neutral Recall Score: 0.696969696969697\n",
      "Neutral F1 Score: 0.6764705882352942\n",
      "\n",
      "Positiv Precision Score: 0.868421052631579\n",
      "Positiv Recall Score: 0.7857142857142857\n",
      "Positiv F1 Score: 0.825\n",
      "\n",
      "Macro Average Precision Score: 0.7624895572263993\n",
      "Macro Average Recall Score: 0.7905242905242905\n",
      "Macro Average F1 Score: 0.7739944695827049\n",
      "\n",
      "Weighted Average Precision: 0.7977885891198585\n",
      "Weighted Average Recall: 0.7908496732026143\n",
      "Weighted Average F1: 0.7919084375831781\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/7_epochs/TUM_GottBERT_filtered_base_best_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/7_epochs/TUM_GottBERT_filtered_base_best_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_last:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at TUM/GottBERT_base_last were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at TUM/GottBERT_base_last and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 4730.22 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 4380.00 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 4292.50 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for TUM/GottBERT_base_last with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3892' max='3892' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3892/3892 06:57, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.843000</td>\n",
       "      <td>0.706404</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.837502</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.812199</td>\n",
       "      <td>{0: 56, 1: 17, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.558400</td>\n",
       "      <td>0.677789</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.850767</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.849997</td>\n",
       "      <td>{0: 41, 1: 23, 2: 65}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.489600</td>\n",
       "      <td>0.764616</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.862729</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.850912</td>\n",
       "      <td>{0: 52, 1: 20, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.289300</td>\n",
       "      <td>0.862519</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.852522</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.844393</td>\n",
       "      <td>{0: 51, 1: 23, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.263300</td>\n",
       "      <td>0.980617</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.826867</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.827835</td>\n",
       "      <td>{0: 42, 1: 25, 2: 62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.197300</td>\n",
       "      <td>0.925912</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.835410</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.831433</td>\n",
       "      <td>{0: 40, 1: 31, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.158500</td>\n",
       "      <td>0.996599</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.832803</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.830665</td>\n",
       "      <td>{0: 44, 1: 28, 2: 57}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_TUM_GottBERT_base_last_42_42_7\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_TUM_GottBERT_base_last_42_42_7\n",
      "Evaluation results for TUM/GottBERT_base_last with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9821602702140808, 'eval_accuracy': 0.8366013071895425, 'eval_precision': 0.8400129282482223, 'eval_recall': 0.8366013071895425, 'eval_f1': 0.8369542978296697, 'eval_class_distribution': {0: 40, 1: 35, 2: 78}, 'eval_runtime': 2.2087, 'eval_samples_per_second': 69.272, 'eval_steps_per_second': 34.862, 'epoch': 7.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.76      0.94      0.84        36\n",
      "     Neutral       0.70      0.64      0.67        33\n",
      "     Positiv       0.88      0.82      0.85        84\n",
      "\n",
      "    accuracy                           0.81       153\n",
      "   macro avg       0.78      0.80      0.79       153\n",
      "weighted avg       0.81      0.81      0.81       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 45, 1: 30, 2: 78}\n",
      "Negativ Precision Score: 0.7555555555555555\n",
      "Negativ Recall Score: 0.9444444444444444\n",
      "Negativ F1 Score: 0.8395061728395061\n",
      "\n",
      "Neutral Precision Score: 0.7\n",
      "Neutral Recall Score: 0.6363636363636364\n",
      "Neutral F1 Score: 0.6666666666666666\n",
      "\n",
      "Positiv Precision Score: 0.8846153846153846\n",
      "Positiv Recall Score: 0.8214285714285714\n",
      "Positiv F1 Score: 0.8518518518518519\n",
      "\n",
      "Macro Average Precision Score: 0.78005698005698\n",
      "Macro Average Recall Score: 0.8007455507455509\n",
      "Macro Average F1 Score: 0.7860082304526749\n",
      "\n",
      "Weighted Average Precision: 0.814429361488185\n",
      "Weighted Average Recall: 0.8104575163398693\n",
      "Weighted Average F1: 0.8090050835148874\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/7_epochs/TUM_GottBERT_base_last_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/7_epochs/TUM_GottBERT_base_last_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for distilbert/distilbert-base-german-cased:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 4915.00 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 4677.42 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 4562.04 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for distilbert/distilbert-base-german-cased with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3892' max='3892' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3892/3892 03:39, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.822400</td>\n",
       "      <td>0.630164</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.813384</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.799927</td>\n",
       "      <td>{0: 53, 1: 24, 2: 52}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.545200</td>\n",
       "      <td>0.680577</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.848066</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.824731</td>\n",
       "      <td>{0: 56, 1: 24, 2: 49}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.515000</td>\n",
       "      <td>0.618437</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.841250</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.831894</td>\n",
       "      <td>{0: 48, 1: 29, 2: 52}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.306900</td>\n",
       "      <td>0.636362</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.873897</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.854722</td>\n",
       "      <td>{0: 54, 1: 26, 2: 49}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.284000</td>\n",
       "      <td>0.665883</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.873897</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.854722</td>\n",
       "      <td>{0: 54, 1: 26, 2: 49}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.198000</td>\n",
       "      <td>0.761940</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.853099</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.831978</td>\n",
       "      <td>{0: 51, 1: 31, 2: 47}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.753789</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.879640</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.862112</td>\n",
       "      <td>{0: 53, 1: 27, 2: 49}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_distilbert_distilbert-base-german-cased_42_42_7\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_distilbert_distilbert-base-german-cased_42_42_7\n",
      "Evaluation results for distilbert/distilbert-base-german-cased with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.47126305103302, 'eval_accuracy': 0.738562091503268, 'eval_precision': 0.7675507551163472, 'eval_recall': 0.738562091503268, 'eval_f1': 0.743681635088792, 'eval_class_distribution': {0: 43, 1: 43, 2: 67}, 'eval_runtime': 1.2597, 'eval_samples_per_second': 121.454, 'eval_steps_per_second': 61.124, 'epoch': 7.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.66      0.92      0.77        36\n",
      "     Neutral       0.62      0.70      0.66        33\n",
      "     Positiv       0.89      0.70      0.79        84\n",
      "\n",
      "    accuracy                           0.75       153\n",
      "   macro avg       0.73      0.77      0.74       153\n",
      "weighted avg       0.78      0.75      0.75       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 50, 1: 37, 2: 66}\n",
      "Negativ Precision Score: 0.66\n",
      "Negativ Recall Score: 0.9166666666666666\n",
      "Negativ F1 Score: 0.7674418604651163\n",
      "\n",
      "Neutral Precision Score: 0.6216216216216216\n",
      "Neutral Recall Score: 0.696969696969697\n",
      "Neutral F1 Score: 0.6571428571428571\n",
      "\n",
      "Positiv Precision Score: 0.8939393939393939\n",
      "Positiv Recall Score: 0.7023809523809523\n",
      "Positiv F1 Score: 0.7866666666666666\n",
      "\n",
      "Macro Average Precision Score: 0.7251870051870052\n",
      "Macro Average Recall Score: 0.7720057720057719\n",
      "Macro Average F1 Score: 0.7370837947582133\n",
      "\n",
      "Weighted Average Precision: 0.7801596248655072\n",
      "Weighted Average Recall: 0.7516339869281046\n",
      "Weighted Average F1: 0.7542066749180292\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/7_epochs/distilbert_distilbert-base-german-cased_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/7_epochs/distilbert_distilbert-base-german-cased_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for GerMedBERT/medbert-512:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Device set to use cuda:0\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GerMedBERT/medbert-512 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 3985.99 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3764.69 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 3695.32 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for GerMedBERT/medbert-512 with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3892' max='3892' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3892/3892 06:53, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.872400</td>\n",
       "      <td>0.705863</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.816109</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.789007</td>\n",
       "      <td>{0: 57, 1: 17, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.545600</td>\n",
       "      <td>0.876974</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.790073</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.785352</td>\n",
       "      <td>{0: 42, 1: 31, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.444700</td>\n",
       "      <td>1.099862</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.808525</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.793985</td>\n",
       "      <td>{0: 49, 1: 17, 2: 63}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.227900</td>\n",
       "      <td>0.901028</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.833144</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.822166</td>\n",
       "      <td>{0: 52, 1: 22, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.215600</td>\n",
       "      <td>1.028583</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.822520</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.821889</td>\n",
       "      <td>{0: 44, 1: 26, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.147100</td>\n",
       "      <td>0.996270</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.831414</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.830229</td>\n",
       "      <td>{0: 43, 1: 28, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.114300</td>\n",
       "      <td>1.051120</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.838043</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.837561</td>\n",
       "      <td>{0: 43, 1: 27, 2: 59}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_GerMedBERT_medbert-512_42_42_7\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_GerMedBERT_medbert-512_42_42_7\n",
      "Evaluation results for GerMedBERT/medbert-512 with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.371387243270874, 'eval_accuracy': 0.7908496732026143, 'eval_precision': 0.8091062902702453, 'eval_recall': 0.7908496732026143, 'eval_f1': 0.7925936093439869, 'eval_class_distribution': {0: 47, 1: 36, 2: 70}, 'eval_runtime': 2.341, 'eval_samples_per_second': 65.356, 'eval_steps_per_second': 32.891, 'epoch': 7.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.69      0.94      0.80        36\n",
      "     Neutral       0.67      0.73      0.70        33\n",
      "     Positiv       0.94      0.76      0.84        84\n",
      "\n",
      "    accuracy                           0.80       153\n",
      "   macro avg       0.77      0.81      0.78       153\n",
      "weighted avg       0.82      0.80      0.80       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 49, 1: 36, 2: 68}\n",
      "Negativ Precision Score: 0.6938775510204082\n",
      "Negativ Recall Score: 0.9444444444444444\n",
      "Negativ F1 Score: 0.8\n",
      "\n",
      "Neutral Precision Score: 0.6666666666666666\n",
      "Neutral Recall Score: 0.7272727272727273\n",
      "Neutral F1 Score: 0.6956521739130435\n",
      "\n",
      "Positiv Precision Score: 0.9411764705882353\n",
      "Positiv Recall Score: 0.7619047619047619\n",
      "Positiv F1 Score: 0.8421052631578947\n",
      "\n",
      "Macro Average Precision Score: 0.7672402294251034\n",
      "Macro Average Recall Score: 0.8112073112073112\n",
      "Macro Average F1 Score: 0.7792524790236461\n",
      "\n",
      "Weighted Average Precision: 0.8237804925891926\n",
      "Weighted Average Recall: 0.7973856209150327\n",
      "Weighted Average F1: 0.8006102212051869\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/7_epochs/GerMedBERT_medbert-512_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/7_epochs/GerMedBERT_medbert-512_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for deepset/gbert-base:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 4042.92 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3763.64 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 3721.27 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for deepset/gbert-base with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3892' max='3892' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3892/3892 06:50, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.843000</td>\n",
       "      <td>0.858787</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.859774</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.839021</td>\n",
       "      <td>{0: 52, 1: 16, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.521300</td>\n",
       "      <td>0.723457</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.861265</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.860261</td>\n",
       "      <td>{0: 39, 1: 29, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.487500</td>\n",
       "      <td>1.070793</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.827501</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.828200</td>\n",
       "      <td>{0: 43, 1: 25, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.226300</td>\n",
       "      <td>1.028618</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.827390</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.823698</td>\n",
       "      <td>{0: 45, 1: 28, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.207400</td>\n",
       "      <td>1.090236</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.838175</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.837626</td>\n",
       "      <td>{0: 43, 1: 27, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.128400</td>\n",
       "      <td>1.158467</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.833200</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.831015</td>\n",
       "      <td>{0: 42, 1: 29, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.075400</td>\n",
       "      <td>1.181532</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.831015</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.830156</td>\n",
       "      <td>{0: 42, 1: 28, 2: 59}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_deepset_gbert-base_42_42_7\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_deepset_gbert-base_42_42_7\n",
      "Evaluation results for deepset/gbert-base with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7281306982040405, 'eval_accuracy': 0.8366013071895425, 'eval_precision': 0.8394884269497273, 'eval_recall': 0.8366013071895425, 'eval_f1': 0.8374766867466673, 'eval_class_distribution': {0: 38, 1: 35, 2: 80}, 'eval_runtime': 2.3718, 'eval_samples_per_second': 64.508, 'eval_steps_per_second': 32.465, 'epoch': 7.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.84      0.89      0.86        36\n",
      "     Neutral       0.63      0.73      0.68        33\n",
      "     Positiv       0.91      0.83      0.87        84\n",
      "\n",
      "    accuracy                           0.82       153\n",
      "   macro avg       0.79      0.82      0.80       153\n",
      "weighted avg       0.83      0.82      0.83       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 38, 1: 38, 2: 77}\n",
      "Negativ Precision Score: 0.8421052631578947\n",
      "Negativ Recall Score: 0.8888888888888888\n",
      "Negativ F1 Score: 0.8648648648648649\n",
      "\n",
      "Neutral Precision Score: 0.631578947368421\n",
      "Neutral Recall Score: 0.7272727272727273\n",
      "Neutral F1 Score: 0.676056338028169\n",
      "\n",
      "Positiv Precision Score: 0.9090909090909091\n",
      "Positiv Recall Score: 0.8333333333333334\n",
      "Positiv F1 Score: 0.8695652173913043\n",
      "\n",
      "Macro Average Precision Score: 0.7942583732057416\n",
      "Macro Average Recall Score: 0.8164983164983165\n",
      "Macro Average F1 Score: 0.8034954734281127\n",
      "\n",
      "Weighted Average Precision: 0.8334740594802513\n",
      "Weighted Average Recall: 0.8235294117647058\n",
      "Weighted Average F1: 0.8267220428165639\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/7_epochs/deepset_gbert-base_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/7_epochs/deepset_gbert-base_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(f'training and results for {model}:')\n",
    "    absa_model(data, model, rn1=42, rn2=42, epochs=7, save = True)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1a3f239-80fb-4d04-8010-130ebd7e9c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 3996.77 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3787.01 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 3732.04 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for aari1995/German_Sentiment with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3892' max='3892' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3892/3892 21:08, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.903800</td>\n",
       "      <td>0.656261</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.884589</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.884086</td>\n",
       "      <td>{0: 43, 1: 27, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.546500</td>\n",
       "      <td>0.574743</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.885456</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.870272</td>\n",
       "      <td>{0: 53, 1: 22, 2: 54}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.532700</td>\n",
       "      <td>0.616116</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.884141</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.883155</td>\n",
       "      <td>{0: 44, 1: 24, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.325700</td>\n",
       "      <td>0.765709</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.885395</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.873925</td>\n",
       "      <td>{0: 49, 1: 19, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.228800</td>\n",
       "      <td>0.692132</td>\n",
       "      <td>0.899225</td>\n",
       "      <td>0.901921</td>\n",
       "      <td>0.899225</td>\n",
       "      <td>0.898858</td>\n",
       "      <td>{0: 46, 1: 23, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.185900</td>\n",
       "      <td>0.842588</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.872111</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.869267</td>\n",
       "      <td>{0: 45, 1: 28, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.093700</td>\n",
       "      <td>0.867013</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.885831</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.883819</td>\n",
       "      <td>{0: 46, 1: 25, 2: 58}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_aari1995_German_Sentiment_42_42_7\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_aari1995_German_Sentiment_42_42_7\n",
      "Evaluation results for aari1995/German_Sentiment with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8971391916275024, 'eval_accuracy': 0.8627450980392157, 'eval_precision': 0.8630566438582937, 'eval_recall': 0.8627450980392157, 'eval_f1': 0.8624587035926511, 'eval_class_distribution': {0: 39, 1: 32, 2: 82}, 'eval_runtime': 7.1771, 'eval_samples_per_second': 21.318, 'eval_steps_per_second': 10.729, 'epoch': 7.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.89      0.92      0.90        36\n",
      "     Neutral       0.78      0.76      0.77        33\n",
      "     Positiv       0.92      0.92      0.92        84\n",
      "\n",
      "    accuracy                           0.88       153\n",
      "   macro avg       0.86      0.86      0.86       153\n",
      "weighted avg       0.88      0.88      0.88       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 37, 1: 32, 2: 84}\n",
      "Negativ Precision Score: 0.8918918918918919\n",
      "Negativ Recall Score: 0.9166666666666666\n",
      "Negativ F1 Score: 0.9041095890410958\n",
      "\n",
      "Neutral Precision Score: 0.78125\n",
      "Neutral Recall Score: 0.7575757575757576\n",
      "Neutral F1 Score: 0.7692307692307693\n",
      "\n",
      "Positiv Precision Score: 0.9166666666666666\n",
      "Positiv Recall Score: 0.9166666666666666\n",
      "Positiv F1 Score: 0.9166666666666666\n",
      "\n",
      "Macro Average Precision Score: 0.8632695195195196\n",
      "Macro Average Recall Score: 0.8636363636363636\n",
      "Macro Average F1 Score: 0.8633356749795106\n",
      "\n",
      "Weighted Average Precision: 0.8816297915562621\n",
      "Weighted Average Recall: 0.8823529411764706\n",
      "Weighted Average F1: 0.8819121607195742\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/7_epochs/aari1995_German_Sentiment_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/7_epochs/aari1995_German_Sentiment_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n"
     ]
    }
   ],
   "source": [
    "absa_model(data, \"aari1995/German_Sentiment\", rn1=42, rn2=42, epochs=7, save = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5a1d020-2f0e-4620-a41c-9ec1659f1598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training and results for google-bert/bert-base-german-cased:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 2250.09 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3376.82 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 3457.50 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for google-bert/bert-base-german-cased with 8 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4448' max='4448' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4448/4448 07:48, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.845000</td>\n",
       "      <td>0.864035</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.793056</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.782883</td>\n",
       "      <td>{0: 52, 1: 22, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.543700</td>\n",
       "      <td>0.970465</td>\n",
       "      <td>0.759690</td>\n",
       "      <td>0.783373</td>\n",
       "      <td>0.759690</td>\n",
       "      <td>0.765950</td>\n",
       "      <td>{0: 40, 1: 37, 2: 52}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.459600</td>\n",
       "      <td>1.072917</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.813840</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.813309</td>\n",
       "      <td>{0: 39, 1: 27, 2: 63}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.248000</td>\n",
       "      <td>0.970963</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.798324</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.786356</td>\n",
       "      <td>{0: 49, 1: 29, 2: 51}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.213600</td>\n",
       "      <td>1.317872</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.789348</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.787569</td>\n",
       "      <td>{0: 41, 1: 22, 2: 66}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.137700</td>\n",
       "      <td>1.305402</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.801431</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.799190</td>\n",
       "      <td>{0: 39, 1: 30, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.092400</td>\n",
       "      <td>1.433116</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.814084</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.813789</td>\n",
       "      <td>{0: 40, 1: 28, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.075300</td>\n",
       "      <td>1.440312</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.804440</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.799373</td>\n",
       "      <td>{0: 37, 1: 32, 2: 60}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_google-bert_bert-base-german-cased_42_42_8\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_google-bert_bert-base-german-cased_42_42_8\n",
      "Evaluation results for google-bert/bert-base-german-cased with 8 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7391194105148315, 'eval_accuracy': 0.7647058823529411, 'eval_precision': 0.7755499098864352, 'eval_recall': 0.7647058823529411, 'eval_f1': 0.767150056283583, 'eval_class_distribution': {0: 43, 1: 35, 2: 75}, 'eval_runtime': 2.4178, 'eval_samples_per_second': 63.281, 'eval_steps_per_second': 31.847, 'epoch': 8.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.66      0.81      0.72        36\n",
      "     Neutral       0.60      0.64      0.62        33\n",
      "     Positiv       0.85      0.75      0.80        84\n",
      "\n",
      "    accuracy                           0.74       153\n",
      "   macro avg       0.70      0.73      0.71       153\n",
      "weighted avg       0.75      0.74      0.74       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 44, 1: 35, 2: 74}\n",
      "Negativ Precision Score: 0.6590909090909091\n",
      "Negativ Recall Score: 0.8055555555555556\n",
      "Negativ F1 Score: 0.725\n",
      "\n",
      "Neutral Precision Score: 0.6\n",
      "Neutral Recall Score: 0.6363636363636364\n",
      "Neutral F1 Score: 0.6176470588235294\n",
      "\n",
      "Positiv Precision Score: 0.8513513513513513\n",
      "Positiv Recall Score: 0.75\n",
      "Positiv F1 Score: 0.7974683544303798\n",
      "\n",
      "Macro Average Precision Score: 0.7034807534807536\n",
      "Macro Average Recall Score: 0.7306397306397306\n",
      "Macro Average F1 Score: 0.7133718044179697\n",
      "\n",
      "Weighted Average Precision: 0.7519005636652696\n",
      "Weighted Average Recall: 0.738562091503268\n",
      "Weighted Average F1: 0.7416319915903816\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/8_epochs/google-bert_bert-base-german-cased_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/8_epochs/google-bert_bert-base-german-cased_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-cased:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 3831.18 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3790.11 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 3855.92 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for dbmdz/bert-base-german-cased with 8 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4448' max='4448' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4448/4448 07:46, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.882600</td>\n",
       "      <td>0.738482</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.843440</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.822154</td>\n",
       "      <td>{0: 56, 1: 20, 2: 53}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>0.610201</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.867486</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.848288</td>\n",
       "      <td>{0: 53, 1: 27, 2: 49}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.519300</td>\n",
       "      <td>1.100045</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.835822</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.816300</td>\n",
       "      <td>{0: 50, 1: 16, 2: 63}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.265500</td>\n",
       "      <td>0.770221</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.853570</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.852912</td>\n",
       "      <td>{0: 44, 1: 26, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.260100</td>\n",
       "      <td>0.874548</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.854126</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.852424</td>\n",
       "      <td>{0: 38, 1: 29, 2: 62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.187700</td>\n",
       "      <td>0.893036</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.874928</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.869298</td>\n",
       "      <td>{0: 37, 1: 32, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.116800</td>\n",
       "      <td>0.950542</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.852030</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.851652</td>\n",
       "      <td>{0: 43, 1: 24, 2: 62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.075400</td>\n",
       "      <td>0.967914</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.859173</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.858997</td>\n",
       "      <td>{0: 42, 1: 24, 2: 63}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_dbmdz_bert-base-german-cased_42_42_8\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_dbmdz_bert-base-german-cased_42_42_8\n",
      "Evaluation results for dbmdz/bert-base-german-cased with 8 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.441780686378479, 'eval_accuracy': 0.7712418300653595, 'eval_precision': 0.8038680951530018, 'eval_recall': 0.7712418300653595, 'eval_f1': 0.7793616211916865, 'eval_class_distribution': {0: 34, 1: 48, 2: 71}, 'eval_runtime': 2.3769, 'eval_samples_per_second': 64.371, 'eval_steps_per_second': 32.396, 'epoch': 8.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.83      0.83      0.83        36\n",
      "     Neutral       0.57      0.82      0.68        33\n",
      "     Positiv       0.90      0.75      0.82        84\n",
      "\n",
      "    accuracy                           0.78       153\n",
      "   macro avg       0.77      0.80      0.78       153\n",
      "weighted avg       0.81      0.78      0.79       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 36, 1: 47, 2: 70}\n",
      "Negativ Precision Score: 0.8333333333333334\n",
      "Negativ Recall Score: 0.8333333333333334\n",
      "Negativ F1 Score: 0.8333333333333334\n",
      "\n",
      "Neutral Precision Score: 0.574468085106383\n",
      "Neutral Recall Score: 0.8181818181818182\n",
      "Neutral F1 Score: 0.675\n",
      "\n",
      "Positiv Precision Score: 0.9\n",
      "Positiv Recall Score: 0.75\n",
      "Positiv F1 Score: 0.8181818181818182\n",
      "\n",
      "Macro Average Precision Score: 0.7692671394799054\n",
      "Macro Average Recall Score: 0.8005050505050505\n",
      "Macro Average F1 Score: 0.7755050505050506\n",
      "\n",
      "Weighted Average Precision: 0.8141009595327493\n",
      "Weighted Average Recall: 0.7843137254901961\n",
      "Weighted Average F1: 0.7908645276292335\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/8_epochs/dbmdz_bert-base-german-cased_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/8_epochs/dbmdz_bert-base-german-cased_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-uncased:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 3842.33 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3674.29 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 3632.75 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for dbmdz/bert-base-german-uncased with 8 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4448' max='4448' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4448/4448 07:47, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.847700</td>\n",
       "      <td>0.719345</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.858727</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.844923</td>\n",
       "      <td>{0: 53, 1: 21, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.541800</td>\n",
       "      <td>0.730675</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.867571</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.861635</td>\n",
       "      <td>{0: 48, 1: 27, 2: 54}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.516000</td>\n",
       "      <td>0.845765</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>{0: 42, 1: 27, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.266100</td>\n",
       "      <td>0.893135</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.841489</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.829089</td>\n",
       "      <td>{0: 53, 1: 22, 2: 54}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.203100</td>\n",
       "      <td>0.900852</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.861070</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.860700</td>\n",
       "      <td>{0: 43, 1: 27, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.160800</td>\n",
       "      <td>0.933761</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.857242</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.854129</td>\n",
       "      <td>{0: 44, 1: 29, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.093900</td>\n",
       "      <td>0.891322</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.864385</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.861815</td>\n",
       "      <td>{0: 41, 1: 30, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.050300</td>\n",
       "      <td>0.976547</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.862474</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.861189</td>\n",
       "      <td>{0: 41, 1: 29, 2: 59}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_dbmdz_bert-base-german-uncased_42_42_8\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_dbmdz_bert-base-german-uncased_42_42_8\n",
      "Evaluation results for dbmdz/bert-base-german-uncased with 8 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.917163372039795, 'eval_accuracy': 0.7254901960784313, 'eval_precision': 0.7579185520361991, 'eval_recall': 0.7254901960784313, 'eval_f1': 0.7299436093275224, 'eval_class_distribution': {0: 48, 1: 40, 2: 65}, 'eval_runtime': 2.3786, 'eval_samples_per_second': 64.323, 'eval_steps_per_second': 32.372, 'epoch': 8.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.63      0.86      0.73        36\n",
      "     Neutral       0.61      0.85      0.71        33\n",
      "     Positiv       0.93      0.64      0.76        84\n",
      "\n",
      "    accuracy                           0.74       153\n",
      "   macro avg       0.72      0.78      0.73       153\n",
      "weighted avg       0.79      0.74      0.74       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 49, 1: 46, 2: 58}\n",
      "Negativ Precision Score: 0.6326530612244898\n",
      "Negativ Recall Score: 0.8611111111111112\n",
      "Negativ F1 Score: 0.7294117647058823\n",
      "\n",
      "Neutral Precision Score: 0.6086956521739131\n",
      "Neutral Recall Score: 0.8484848484848485\n",
      "Neutral F1 Score: 0.7088607594936709\n",
      "\n",
      "Positiv Precision Score: 0.9310344827586207\n",
      "Positiv Recall Score: 0.6428571428571429\n",
      "Positiv F1 Score: 0.7605633802816901\n",
      "\n",
      "Macro Average Precision Score: 0.7241277320523412\n",
      "Macro Average Recall Score: 0.7841510341510342\n",
      "Macro Average F1 Score: 0.7329453014937477\n",
      "\n",
      "Weighted Average Precision: 0.7913030279578098\n",
      "Weighted Average Recall: 0.738562091503268\n",
      "Weighted Average F1: 0.742082042721339\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/8_epochs/dbmdz_bert-base-german-uncased_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/8_epochs/dbmdz_bert-base-german-uncased_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for FacebookAI/xlm-roberta-base:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 4560.26 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3915.29 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 4279.02 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for FacebookAI/xlm-roberta-base with 8 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4448' max='4448' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4448/4448 09:58, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.733855</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.796138</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.792435</td>\n",
       "      <td>{0: 46, 1: 27, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.854600</td>\n",
       "      <td>1.031593</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.814601</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.811145</td>\n",
       "      <td>{0: 37, 1: 24, 2: 68}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.783700</td>\n",
       "      <td>1.017649</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.818571</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.812347</td>\n",
       "      <td>{0: 49, 1: 21, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.564300</td>\n",
       "      <td>1.389266</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.777905</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.769491</td>\n",
       "      <td>{0: 48, 1: 29, 2: 52}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.514500</td>\n",
       "      <td>1.104014</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.815302</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.813136</td>\n",
       "      <td>{0: 46, 1: 23, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.439200</td>\n",
       "      <td>1.173627</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.833317</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.830879</td>\n",
       "      <td>{0: 43, 1: 29, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.368100</td>\n",
       "      <td>1.039371</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.847980</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.845873</td>\n",
       "      <td>{0: 45, 1: 27, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.335400</td>\n",
       "      <td>1.040194</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.850306</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.846928</td>\n",
       "      <td>{0: 42, 1: 30, 2: 57}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_FacebookAI_xlm-roberta-base_42_42_8\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_FacebookAI_xlm-roberta-base_42_42_8\n",
      "Evaluation results for FacebookAI/xlm-roberta-base with 8 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9596351981163025, 'eval_accuracy': 0.8496732026143791, 'eval_precision': 0.8603635786298326, 'eval_recall': 0.8496732026143791, 'eval_f1': 0.8525172231054584, 'eval_class_distribution': {0: 38, 1: 39, 2: 76}, 'eval_runtime': 2.2805, 'eval_samples_per_second': 67.089, 'eval_steps_per_second': 33.764, 'epoch': 8.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.74      0.89      0.81        36\n",
      "     Neutral       0.68      0.70      0.69        33\n",
      "     Positiv       0.91      0.82      0.86        84\n",
      "\n",
      "    accuracy                           0.81       153\n",
      "   macro avg       0.78      0.80      0.79       153\n",
      "weighted avg       0.82      0.81      0.81       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 43, 1: 34, 2: 76}\n",
      "Negativ Precision Score: 0.7441860465116279\n",
      "Negativ Recall Score: 0.8888888888888888\n",
      "Negativ F1 Score: 0.810126582278481\n",
      "\n",
      "Neutral Precision Score: 0.6764705882352942\n",
      "Neutral Recall Score: 0.696969696969697\n",
      "Neutral F1 Score: 0.6865671641791045\n",
      "\n",
      "Positiv Precision Score: 0.9078947368421053\n",
      "Positiv Recall Score: 0.8214285714285714\n",
      "Positiv F1 Score: 0.8625\n",
      "\n",
      "Macro Average Precision Score: 0.7761837905296757\n",
      "Macro Average Recall Score: 0.8024290524290524\n",
      "Macro Average F1 Score: 0.7863979154858619\n",
      "\n",
      "Weighted Average Precision: 0.8194600325550337\n",
      "Weighted Average Recall: 0.8104575163398693\n",
      "Weighted Average F1: 0.8122305449669004\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/8_epochs/FacebookAI_xlm-roberta-base_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/8_epochs/FacebookAI_xlm-roberta-base_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_best:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at TUM/GottBERT_base_best and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 5034.22 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 4652.40 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 4675.58 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for TUM/GottBERT_base_best with 8 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4448' max='4448' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4448/4448 07:57, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.879400</td>\n",
       "      <td>0.760487</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.860506</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.827117</td>\n",
       "      <td>{0: 58, 1: 16, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.506600</td>\n",
       "      <td>0.809799</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.846800</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.834453</td>\n",
       "      <td>{0: 39, 1: 35, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.536200</td>\n",
       "      <td>0.629004</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.885124</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.881197</td>\n",
       "      <td>{0: 45, 1: 21, 2: 63}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.318000</td>\n",
       "      <td>0.536448</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.865477</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.858830</td>\n",
       "      <td>{0: 49, 1: 21, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.271500</td>\n",
       "      <td>0.895684</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.847129</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.839765</td>\n",
       "      <td>{0: 39, 1: 20, 2: 70}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.231900</td>\n",
       "      <td>0.761999</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.875031</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.863805</td>\n",
       "      <td>{0: 38, 1: 35, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.193000</td>\n",
       "      <td>0.719269</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.869270</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.868189</td>\n",
       "      <td>{0: 39, 1: 28, 2: 62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.170700</td>\n",
       "      <td>0.866967</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.840784</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.837464</td>\n",
       "      <td>{0: 37, 1: 29, 2: 63}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_TUM_GottBERT_base_best_42_42_8\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_TUM_GottBERT_base_best_42_42_8\n",
      "Evaluation results for TUM/GottBERT_base_best with 8 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0912635326385498, 'eval_accuracy': 0.7973856209150327, 'eval_precision': 0.8099001643890573, 'eval_recall': 0.7973856209150327, 'eval_f1': 0.7985068034526942, 'eval_class_distribution': {0: 46, 1: 34, 2: 73}, 'eval_runtime': 2.3445, 'eval_samples_per_second': 65.258, 'eval_steps_per_second': 32.842, 'epoch': 8.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.72      0.92      0.80        36\n",
      "     Neutral       0.71      0.76      0.74        33\n",
      "     Positiv       0.90      0.77      0.83        84\n",
      "\n",
      "    accuracy                           0.80       153\n",
      "   macro avg       0.78      0.82      0.79       153\n",
      "weighted avg       0.82      0.80      0.81       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 46, 1: 35, 2: 72}\n",
      "Negativ Precision Score: 0.717391304347826\n",
      "Negativ Recall Score: 0.9166666666666666\n",
      "Negativ F1 Score: 0.8048780487804879\n",
      "\n",
      "Neutral Precision Score: 0.7142857142857143\n",
      "Neutral Recall Score: 0.7575757575757576\n",
      "Neutral F1 Score: 0.7352941176470589\n",
      "\n",
      "Positiv Precision Score: 0.9027777777777778\n",
      "Positiv Recall Score: 0.7738095238095238\n",
      "Positiv F1 Score: 0.8333333333333334\n",
      "\n",
      "Macro Average Precision Score: 0.7781515988037727\n",
      "Macro Average Recall Score: 0.816017316017316\n",
      "Macro Average F1 Score: 0.7911684999202934\n",
      "\n",
      "Weighted Average Precision: 0.8185022801391088\n",
      "Weighted Average Recall: 0.803921568627451\n",
      "Weighted Average F1: 0.8054922590748399\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/8_epochs/TUM_GottBERT_base_best_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/8_epochs/TUM_GottBERT_base_best_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_filtered_base_best:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at TUM/GottBERT_filtered_base_best and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 4963.88 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 4379.71 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 4447.58 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for TUM/GottBERT_filtered_base_best with 8 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4448' max='4448' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4448/4448 07:56, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.795200</td>\n",
       "      <td>0.688211</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.861607</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.853744</td>\n",
       "      <td>{0: 50, 1: 24, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.518100</td>\n",
       "      <td>0.684829</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.884455</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.883463</td>\n",
       "      <td>{0: 39, 1: 29, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.458600</td>\n",
       "      <td>0.584417</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.907802</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.907138</td>\n",
       "      <td>{0: 44, 1: 26, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.296900</td>\n",
       "      <td>0.722327</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.878879</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.876812</td>\n",
       "      <td>{0: 45, 1: 27, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.304600</td>\n",
       "      <td>0.705719</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>{0: 42, 1: 27, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.243200</td>\n",
       "      <td>0.817558</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.880171</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.877319</td>\n",
       "      <td>{0: 42, 1: 30, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.214700</td>\n",
       "      <td>0.722536</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.876307</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.875740</td>\n",
       "      <td>{0: 44, 1: 25, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.165600</td>\n",
       "      <td>0.813668</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.879215</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.877052</td>\n",
       "      <td>{0: 43, 1: 29, 2: 57}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_TUM_GottBERT_filtered_base_best_42_42_8\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_TUM_GottBERT_filtered_base_best_42_42_8\n",
      "Evaluation results for TUM/GottBERT_filtered_base_best with 8 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1530835628509521, 'eval_accuracy': 0.8169934640522876, 'eval_precision': 0.8235219586726042, 'eval_recall': 0.8169934640522876, 'eval_f1': 0.8184065069878218, 'eval_class_distribution': {0: 41, 1: 35, 2: 77}, 'eval_runtime': 2.3039, 'eval_samples_per_second': 66.409, 'eval_steps_per_second': 33.421, 'epoch': 8.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.84      0.89      0.86        36\n",
      "     Neutral       0.69      0.76      0.72        33\n",
      "     Positiv       0.91      0.86      0.88        84\n",
      "\n",
      "    accuracy                           0.84       153\n",
      "   macro avg       0.82      0.83      0.82       153\n",
      "weighted avg       0.85      0.84      0.84       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 38, 1: 36, 2: 79}\n",
      "Negativ Precision Score: 0.8421052631578947\n",
      "Negativ Recall Score: 0.8888888888888888\n",
      "Negativ F1 Score: 0.8648648648648649\n",
      "\n",
      "Neutral Precision Score: 0.6944444444444444\n",
      "Neutral Recall Score: 0.7575757575757576\n",
      "Neutral F1 Score: 0.7246376811594203\n",
      "\n",
      "Positiv Precision Score: 0.9113924050632911\n",
      "Positiv Recall Score: 0.8571428571428571\n",
      "Positiv F1 Score: 0.8834355828220859\n",
      "\n",
      "Macro Average Precision Score: 0.8159807042218766\n",
      "Macro Average Recall Score: 0.8345358345358345\n",
      "Macro Average F1 Score: 0.824312709615457\n",
      "\n",
      "Weighted Average Precision: 0.8482968507559955\n",
      "Weighted Average Recall: 0.8431372549019608\n",
      "Weighted Average F1: 0.8448154743166746\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/8_epochs/TUM_GottBERT_filtered_base_best_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/8_epochs/TUM_GottBERT_filtered_base_best_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_last:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at TUM/GottBERT_base_last were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at TUM/GottBERT_base_last and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 4664.30 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 4230.15 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 4190.63 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for TUM/GottBERT_base_last with 8 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4448' max='4448' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4448/4448 07:58, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.908600</td>\n",
       "      <td>0.874375</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.824793</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.787943</td>\n",
       "      <td>{0: 59, 1: 13, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.569700</td>\n",
       "      <td>0.810010</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.846748</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.839653</td>\n",
       "      <td>{0: 38, 1: 33, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.519100</td>\n",
       "      <td>1.082653</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.833942</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.811238</td>\n",
       "      <td>{0: 55, 1: 17, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.310300</td>\n",
       "      <td>0.748966</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.828248</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.828562</td>\n",
       "      <td>{0: 43, 1: 25, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.298300</td>\n",
       "      <td>0.761917</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.851687</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.852115</td>\n",
       "      <td>{0: 42, 1: 26, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.191700</td>\n",
       "      <td>0.913061</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.846540</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.840317</td>\n",
       "      <td>{0: 43, 1: 31, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.190400</td>\n",
       "      <td>0.864859</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.873853</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.870167</td>\n",
       "      <td>{0: 44, 1: 29, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.091100</td>\n",
       "      <td>0.955740</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.867596</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.863049</td>\n",
       "      <td>{0: 43, 1: 30, 2: 56}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_TUM_GottBERT_base_last_42_42_8\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_TUM_GottBERT_base_last_42_42_8\n",
      "Evaluation results for TUM/GottBERT_base_last with 8 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6601247787475586, 'eval_accuracy': 0.7843137254901961, 'eval_precision': 0.8048815770439631, 'eval_recall': 0.7843137254901961, 'eval_f1': 0.7886849318108682, 'eval_class_distribution': {0: 40, 1: 42, 2: 71}, 'eval_runtime': 2.3122, 'eval_samples_per_second': 66.171, 'eval_steps_per_second': 33.302, 'epoch': 8.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.71      0.89      0.79        36\n",
      "     Neutral       0.63      0.79      0.70        33\n",
      "     Positiv       0.94      0.75      0.83        84\n",
      "\n",
      "    accuracy                           0.79       153\n",
      "   macro avg       0.76      0.81      0.78       153\n",
      "weighted avg       0.82      0.79      0.80       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 45, 1: 41, 2: 67}\n",
      "Negativ Precision Score: 0.7111111111111111\n",
      "Negativ Recall Score: 0.8888888888888888\n",
      "Negativ F1 Score: 0.7901234567901234\n",
      "\n",
      "Neutral Precision Score: 0.6341463414634146\n",
      "Neutral Recall Score: 0.7878787878787878\n",
      "Neutral F1 Score: 0.7027027027027027\n",
      "\n",
      "Positiv Precision Score: 0.9402985074626866\n",
      "Positiv Recall Score: 0.75\n",
      "Positiv F1 Score: 0.8344370860927153\n",
      "\n",
      "Macro Average Precision Score: 0.7618519866790708\n",
      "Macro Average Recall Score: 0.8089225589225588\n",
      "Macro Average F1 Score: 0.7757544151951805\n",
      "\n",
      "Weighted Average Precision: 0.8203392411448259\n",
      "Weighted Average Recall: 0.7908496732026143\n",
      "Weighted Average F1: 0.7955970514079851\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/8_epochs/TUM_GottBERT_base_last_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/8_epochs/TUM_GottBERT_base_last_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for distilbert/distilbert-base-german-cased:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 4809.05 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 4400.37 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 4250.31 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for distilbert/distilbert-base-german-cased with 8 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4448' max='4448' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4448/4448 04:06, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.814100</td>\n",
       "      <td>0.742718</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.832345</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.790678</td>\n",
       "      <td>{0: 63, 1: 19, 2: 47}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.568000</td>\n",
       "      <td>0.763324</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.835625</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.816436</td>\n",
       "      <td>{0: 55, 1: 23, 2: 51}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.505500</td>\n",
       "      <td>0.599447</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.887109</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.877011</td>\n",
       "      <td>{0: 51, 1: 25, 2: 53}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.283700</td>\n",
       "      <td>0.762575</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.878638</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.862311</td>\n",
       "      <td>{0: 53, 1: 26, 2: 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.296200</td>\n",
       "      <td>0.776296</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.853919</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.846007</td>\n",
       "      <td>{0: 50, 1: 25, 2: 54}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.188600</td>\n",
       "      <td>0.807323</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.862033</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.853939</td>\n",
       "      <td>{0: 47, 1: 30, 2: 52}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.132100</td>\n",
       "      <td>0.850481</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.876784</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.861919</td>\n",
       "      <td>{0: 53, 1: 25, 2: 51}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.091900</td>\n",
       "      <td>0.851439</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.870176</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.861555</td>\n",
       "      <td>{0: 49, 1: 28, 2: 52}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_distilbert_distilbert-base-german-cased_42_42_8\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_distilbert_distilbert-base-german-cased_42_42_8\n",
      "Evaluation results for distilbert/distilbert-base-german-cased with 8 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0098521709442139, 'eval_accuracy': 0.8169934640522876, 'eval_precision': 0.8173789684729426, 'eval_recall': 0.8169934640522876, 'eval_f1': 0.816770793581566, 'eval_class_distribution': {0: 39, 1: 32, 2: 82}, 'eval_runtime': 1.302, 'eval_samples_per_second': 117.514, 'eval_steps_per_second': 59.141, 'epoch': 8.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.81      0.81      0.81        36\n",
      "     Neutral       0.68      0.58      0.62        33\n",
      "     Positiv       0.83      0.88      0.86        84\n",
      "\n",
      "    accuracy                           0.80       153\n",
      "   macro avg       0.77      0.75      0.76       153\n",
      "weighted avg       0.79      0.80      0.79       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 36, 1: 28, 2: 89}\n",
      "Negativ Precision Score: 0.8055555555555556\n",
      "Negativ Recall Score: 0.8055555555555556\n",
      "Negativ F1 Score: 0.8055555555555556\n",
      "\n",
      "Neutral Precision Score: 0.6785714285714286\n",
      "Neutral Recall Score: 0.5757575757575758\n",
      "Neutral F1 Score: 0.6229508196721312\n",
      "\n",
      "Positiv Precision Score: 0.8314606741573034\n",
      "Positiv Recall Score: 0.8809523809523809\n",
      "Positiv F1 Score: 0.8554913294797688\n",
      "\n",
      "Macro Average Precision Score: 0.7718625527614291\n",
      "Macro Average Recall Score: 0.7540885040885041\n",
      "Macro Average F1 Score: 0.7613325682358184\n",
      "\n",
      "Weighted Average Precision: 0.7923892403403309\n",
      "Weighted Average Recall: 0.7973856209150327\n",
      "Weighted Average F1: 0.7935859393822281\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/8_epochs/distilbert_distilbert-base-german-cased_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/8_epochs/distilbert_distilbert-base-german-cased_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for GerMedBERT/medbert-512:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Device set to use cuda:0\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GerMedBERT/medbert-512 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 3847.20 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3689.63 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 3609.41 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for GerMedBERT/medbert-512 with 8 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4448' max='4448' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4448/4448 07:55, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.903300</td>\n",
       "      <td>0.842962</td>\n",
       "      <td>0.775194</td>\n",
       "      <td>0.780869</td>\n",
       "      <td>0.775194</td>\n",
       "      <td>0.774612</td>\n",
       "      <td>{0: 48, 1: 21, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.557900</td>\n",
       "      <td>1.020309</td>\n",
       "      <td>0.759690</td>\n",
       "      <td>0.768518</td>\n",
       "      <td>0.759690</td>\n",
       "      <td>0.757392</td>\n",
       "      <td>{0: 32, 1: 35, 2: 62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.514300</td>\n",
       "      <td>1.116372</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.805258</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.805649</td>\n",
       "      <td>{0: 42, 1: 26, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.253500</td>\n",
       "      <td>1.255738</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.778941</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.771011</td>\n",
       "      <td>{0: 41, 1: 33, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.259400</td>\n",
       "      <td>1.263882</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.792310</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.791307</td>\n",
       "      <td>{0: 43, 1: 28, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.188100</td>\n",
       "      <td>1.130223</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.824743</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.822403</td>\n",
       "      <td>{0: 44, 1: 29, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.155600</td>\n",
       "      <td>1.288304</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.816409</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.814687</td>\n",
       "      <td>{0: 43, 1: 29, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.083600</td>\n",
       "      <td>1.259637</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.807234</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.806640</td>\n",
       "      <td>{0: 42, 1: 28, 2: 59}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_GerMedBERT_medbert-512_42_42_8\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_GerMedBERT_medbert-512_42_42_8\n",
      "Evaluation results for GerMedBERT/medbert-512 with 8 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1535640954971313, 'eval_accuracy': 0.7777777777777778, 'eval_precision': 0.7928470656741788, 'eval_recall': 0.7777777777777778, 'eval_f1': 0.7796503130084663, 'eval_class_distribution': {0: 43, 1: 39, 2: 71}, 'eval_runtime': 2.3952, 'eval_samples_per_second': 63.879, 'eval_steps_per_second': 32.148, 'epoch': 8.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.74      0.81      0.77        36\n",
      "     Neutral       0.70      0.85      0.77        33\n",
      "     Positiv       0.88      0.77      0.82        84\n",
      "\n",
      "    accuracy                           0.80       153\n",
      "   macro avg       0.77      0.81      0.79       153\n",
      "weighted avg       0.81      0.80      0.80       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 39, 1: 40, 2: 74}\n",
      "Negativ Precision Score: 0.7435897435897436\n",
      "Negativ Recall Score: 0.8055555555555556\n",
      "Negativ F1 Score: 0.7733333333333333\n",
      "\n",
      "Neutral Precision Score: 0.7\n",
      "Neutral Recall Score: 0.8484848484848485\n",
      "Neutral F1 Score: 0.7671232876712328\n",
      "\n",
      "Positiv Precision Score: 0.8783783783783784\n",
      "Positiv Recall Score: 0.7738095238095238\n",
      "Positiv F1 Score: 0.8227848101265823\n",
      "\n",
      "Macro Average Precision Score: 0.773989373989374\n",
      "Macro Average Recall Score: 0.8092833092833093\n",
      "Macro Average F1 Score: 0.7877471437103828\n",
      "\n",
      "Weighted Average Precision: 0.8081896376014024\n",
      "Weighted Average Recall: 0.7973856209150327\n",
      "Weighted Average F1: 0.7991437421162326\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/8_epochs/GerMedBERT_medbert-512_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/8_epochs/GerMedBERT_medbert-512_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for deepset/gbert-base:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 3392.77 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3189.10 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 3184.60 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for deepset/gbert-base with 8 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4448' max='4448' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4448/4448 07:51, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.852800</td>\n",
       "      <td>0.885829</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.822379</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.774095</td>\n",
       "      <td>{0: 60, 1: 12, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.548600</td>\n",
       "      <td>0.501229</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.859302</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.859042</td>\n",
       "      <td>{0: 40, 1: 25, 2: 64}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.437600</td>\n",
       "      <td>0.862168</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.846309</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.844059</td>\n",
       "      <td>{0: 46, 1: 23, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.265300</td>\n",
       "      <td>0.824371</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.839398</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.836834</td>\n",
       "      <td>{0: 47, 1: 24, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.200400</td>\n",
       "      <td>1.082035</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.826926</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.820037</td>\n",
       "      <td>{0: 50, 1: 21, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.108300</td>\n",
       "      <td>0.826940</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.864175</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.860949</td>\n",
       "      <td>{0: 47, 1: 25, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.088500</td>\n",
       "      <td>0.996552</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.855608</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.845859</td>\n",
       "      <td>{0: 51, 1: 25, 2: 53}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.025800</td>\n",
       "      <td>0.939416</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.866030</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.860322</td>\n",
       "      <td>{0: 49, 1: 23, 2: 57}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_deepset_gbert-base_42_42_8\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_deepset_gbert-base_42_42_8\n",
      "Evaluation results for deepset/gbert-base with 8 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.394826889038086, 'eval_accuracy': 0.7843137254901961, 'eval_precision': 0.8034387738835371, 'eval_recall': 0.7843137254901961, 'eval_f1': 0.7871793565911214, 'eval_class_distribution': {0: 41, 1: 42, 2: 70}, 'eval_runtime': 2.3751, 'eval_samples_per_second': 64.419, 'eval_steps_per_second': 32.42, 'epoch': 8.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.78      0.78      0.78        36\n",
      "     Neutral       0.55      0.85      0.67        33\n",
      "     Positiv       0.91      0.71      0.80        84\n",
      "\n",
      "    accuracy                           0.76       153\n",
      "   macro avg       0.75      0.78      0.75       153\n",
      "weighted avg       0.80      0.76      0.77       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 36, 1: 51, 2: 66}\n",
      "Negativ Precision Score: 0.7777777777777778\n",
      "Negativ Recall Score: 0.7777777777777778\n",
      "Negativ F1 Score: 0.7777777777777778\n",
      "\n",
      "Neutral Precision Score: 0.5490196078431373\n",
      "Neutral Recall Score: 0.8484848484848485\n",
      "Neutral F1 Score: 0.6666666666666666\n",
      "\n",
      "Positiv Precision Score: 0.9090909090909091\n",
      "Positiv Recall Score: 0.7142857142857143\n",
      "Positiv F1 Score: 0.8\n",
      "\n",
      "Macro Average Precision Score: 0.7452960982372748\n",
      "Macro Average Recall Score: 0.7801827801827802\n",
      "Macro Average F1 Score: 0.7481481481481481\n",
      "\n",
      "Weighted Average Precision: 0.8005312641990843\n",
      "Weighted Average Recall: 0.7581699346405228\n",
      "Weighted Average F1: 0.7660130718954249\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/8_epochs/deepset_gbert-base_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/8_epochs/deepset_gbert-base_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(f'training and results for {model}:')\n",
    "    absa_model(data, model, rn1=42, rn2=42, epochs=8, save = True)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "591c23d6-e275-4369-8895-12c703e83e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 3928.72 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3724.01 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 3636.41 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for aari1995/German_Sentiment with 8 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4448' max='4448' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4448/4448 24:18, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.897600</td>\n",
       "      <td>0.819189</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.868564</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.823483</td>\n",
       "      <td>{0: 60, 1: 12, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.545900</td>\n",
       "      <td>0.549485</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.889679</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.889848</td>\n",
       "      <td>{0: 43, 1: 24, 2: 62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.471900</td>\n",
       "      <td>0.827644</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.868833</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.866380</td>\n",
       "      <td>{0: 45, 1: 22, 2: 62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.245800</td>\n",
       "      <td>0.690967</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.893065</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.891744</td>\n",
       "      <td>{0: 45, 1: 26, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.221800</td>\n",
       "      <td>0.732186</td>\n",
       "      <td>0.899225</td>\n",
       "      <td>0.899166</td>\n",
       "      <td>0.899225</td>\n",
       "      <td>0.898415</td>\n",
       "      <td>{0: 44, 1: 24, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.089800</td>\n",
       "      <td>0.896576</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.876773</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.876278</td>\n",
       "      <td>{0: 41, 1: 28, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.045300</td>\n",
       "      <td>0.849441</td>\n",
       "      <td>0.899225</td>\n",
       "      <td>0.901475</td>\n",
       "      <td>0.899225</td>\n",
       "      <td>0.897940</td>\n",
       "      <td>{0: 46, 1: 22, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.877132</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.895371</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.890744</td>\n",
       "      <td>{0: 47, 1: 22, 2: 60}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_aari1995_German_Sentiment_42_42_8\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_aari1995_German_Sentiment_42_42_8\n",
      "Evaluation results for aari1995/German_Sentiment with 8 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1299880743026733, 'eval_accuracy': 0.8496732026143791, 'eval_precision': 0.8480319973744039, 'eval_recall': 0.8496732026143791, 'eval_f1': 0.8485100417318726, 'eval_class_distribution': {0: 35, 1: 31, 2: 87}, 'eval_runtime': 7.1668, 'eval_samples_per_second': 21.348, 'eval_steps_per_second': 10.744, 'epoch': 8.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.86      0.86      0.86        36\n",
      "     Neutral       0.77      0.73      0.75        33\n",
      "     Positiv       0.87      0.89      0.88        84\n",
      "\n",
      "    accuracy                           0.85       153\n",
      "   macro avg       0.84      0.83      0.83       153\n",
      "weighted avg       0.85      0.85      0.85       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 36, 1: 31, 2: 86}\n",
      "Negativ Precision Score: 0.8611111111111112\n",
      "Negativ Recall Score: 0.8611111111111112\n",
      "Negativ F1 Score: 0.8611111111111112\n",
      "\n",
      "Neutral Precision Score: 0.7741935483870968\n",
      "Neutral Recall Score: 0.7272727272727273\n",
      "Neutral F1 Score: 0.75\n",
      "\n",
      "Positiv Precision Score: 0.872093023255814\n",
      "Positiv Recall Score: 0.8928571428571429\n",
      "Positiv F1 Score: 0.8823529411764706\n",
      "\n",
      "Macro Average Precision Score: 0.835799227584674\n",
      "Macro Average Recall Score: 0.8270803270803272\n",
      "Macro Average F1 Score: 0.8311546840958606\n",
      "\n",
      "Weighted Average Precision: 0.8483934709167489\n",
      "Weighted Average Recall: 0.8496732026143791\n",
      "Weighted Average F1: 0.8488081507112649\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/8_epochs/aari1995_German_Sentiment_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/8_epochs/aari1995_German_Sentiment_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n"
     ]
    }
   ],
   "source": [
    "absa_model(data, \"aari1995/German_Sentiment\", rn1=42, rn2=42, epochs=8, save = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d6c4d9f6-d9d4-4f2e-844a-f3ae04edfcfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training and results for google-bert/bert-base-german-cased:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 1684.18 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 2415.88 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 2500.53 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for google-bert/bert-base-german-cased with 10 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5560' max='5560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5560/5560 10:40, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.841600</td>\n",
       "      <td>0.846796</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.859764</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.816602</td>\n",
       "      <td>{0: 61, 1: 25, 2: 43}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.552300</td>\n",
       "      <td>0.954318</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.787573</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.787945</td>\n",
       "      <td>{0: 39, 1: 25, 2: 65}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.414700</td>\n",
       "      <td>1.190725</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.807185</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.805427</td>\n",
       "      <td>{0: 44, 1: 23, 2: 62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.231300</td>\n",
       "      <td>1.299271</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.797399</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.790219</td>\n",
       "      <td>{0: 49, 1: 21, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.206400</td>\n",
       "      <td>1.373593</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.797082</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.781495</td>\n",
       "      <td>{0: 51, 1: 18, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.127700</td>\n",
       "      <td>1.275406</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.816278</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.814025</td>\n",
       "      <td>{0: 46, 1: 24, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.130500</td>\n",
       "      <td>1.544113</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.794043</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.791815</td>\n",
       "      <td>{0: 45, 1: 27, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.041600</td>\n",
       "      <td>1.653646</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.801390</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.799613</td>\n",
       "      <td>{0: 42, 1: 29, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>1.651467</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.800454</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.799201</td>\n",
       "      <td>{0: 44, 1: 27, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>1.624203</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.807071</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.806419</td>\n",
       "      <td>{0: 44, 1: 26, 2: 59}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_google-bert_bert-base-german-cased_42_42_10\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_google-bert_bert-base-german-cased_42_42_10\n",
      "Evaluation results for google-bert/bert-base-german-cased with 10 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2085140943527222, 'eval_accuracy': 0.7058823529411765, 'eval_precision': 0.759738431763533, 'eval_recall': 0.7058823529411765, 'eval_f1': 0.7088385714373423, 'eval_class_distribution': {0: 60, 1: 34, 2: 59}, 'eval_runtime': 2.2178, 'eval_samples_per_second': 68.987, 'eval_steps_per_second': 34.719, 'epoch': 10.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.52      0.94      0.67        36\n",
      "     Neutral       0.61      0.58      0.59        33\n",
      "     Positiv       0.93      0.63      0.75        84\n",
      "\n",
      "    accuracy                           0.69       153\n",
      "   macro avg       0.69      0.72      0.67       153\n",
      "weighted avg       0.77      0.69      0.70       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 65, 1: 31, 2: 57}\n",
      "Negativ Precision Score: 0.5230769230769231\n",
      "Negativ Recall Score: 0.9444444444444444\n",
      "Negativ F1 Score: 0.6732673267326733\n",
      "\n",
      "Neutral Precision Score: 0.6129032258064516\n",
      "Neutral Recall Score: 0.5757575757575758\n",
      "Neutral F1 Score: 0.59375\n",
      "\n",
      "Positiv Precision Score: 0.9298245614035088\n",
      "Positiv Recall Score: 0.6309523809523809\n",
      "Positiv F1 Score: 0.75177304964539\n",
      "\n",
      "Macro Average Precision Score: 0.6886015700956278\n",
      "Macro Average Recall Score: 0.717051467051467\n",
      "Macro Average F1 Score: 0.6729301254593545\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/10_epochs/google-bert_bert-base-german-cased_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/10_epochs/google-bert_bert-base-german-cased_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-cased:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 2626.27 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 2438.74 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 2548.88 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for dbmdz/bert-base-german-cased with 10 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5560' max='5560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5560/5560 10:39, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.004200</td>\n",
       "      <td>0.983909</td>\n",
       "      <td>0.759690</td>\n",
       "      <td>0.819145</td>\n",
       "      <td>0.759690</td>\n",
       "      <td>0.754033</td>\n",
       "      <td>{0: 68, 1: 13, 2: 48}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.696200</td>\n",
       "      <td>0.589672</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.833971</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.830337</td>\n",
       "      <td>{0: 47, 1: 26, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.556400</td>\n",
       "      <td>0.829079</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.846518</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.845242</td>\n",
       "      <td>{0: 45, 1: 26, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.332800</td>\n",
       "      <td>0.973666</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.836921</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.823796</td>\n",
       "      <td>{0: 50, 1: 29, 2: 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.345100</td>\n",
       "      <td>1.020653</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.817547</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.815168</td>\n",
       "      <td>{0: 41, 1: 30, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.269100</td>\n",
       "      <td>1.061146</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.814690</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.808853</td>\n",
       "      <td>{0: 41, 1: 32, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.225200</td>\n",
       "      <td>1.044361</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.833691</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.822586</td>\n",
       "      <td>{0: 52, 1: 24, 2: 53}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.180900</td>\n",
       "      <td>1.101380</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.831961</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.829835</td>\n",
       "      <td>{0: 46, 1: 26, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.071200</td>\n",
       "      <td>1.135446</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.829589</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.823768</td>\n",
       "      <td>{0: 42, 1: 32, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.026800</td>\n",
       "      <td>1.174703</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.841889</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.838279</td>\n",
       "      <td>{0: 42, 1: 31, 2: 56}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_dbmdz_bert-base-german-cased_42_42_10\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_dbmdz_bert-base-german-cased_42_42_10\n",
      "Evaluation results for dbmdz/bert-base-german-cased with 10 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1199039220809937, 'eval_accuracy': 0.8104575163398693, 'eval_precision': 0.8183178534571723, 'eval_recall': 0.8104575163398693, 'eval_f1': 0.8108010725657785, 'eval_class_distribution': {0: 45, 1: 32, 2: 76}, 'eval_runtime': 2.159, 'eval_samples_per_second': 70.865, 'eval_steps_per_second': 35.664, 'epoch': 10.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.70      0.89      0.78        36\n",
      "     Neutral       0.70      0.64      0.67        33\n",
      "     Positiv       0.87      0.80      0.83        84\n",
      "\n",
      "    accuracy                           0.78       153\n",
      "   macro avg       0.76      0.77      0.76       153\n",
      "weighted avg       0.79      0.78      0.78       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 46, 1: 30, 2: 77}\n",
      "Negativ Precision Score: 0.6956521739130435\n",
      "Negativ Recall Score: 0.8888888888888888\n",
      "Negativ F1 Score: 0.7804878048780488\n",
      "\n",
      "Neutral Precision Score: 0.7\n",
      "Neutral Recall Score: 0.6363636363636364\n",
      "Neutral F1 Score: 0.6666666666666666\n",
      "\n",
      "Positiv Precision Score: 0.8701298701298701\n",
      "Positiv Recall Score: 0.7976190476190477\n",
      "Positiv F1 Score: 0.8322981366459627\n",
      "\n",
      "Macro Average Precision Score: 0.7552606813476378\n",
      "Macro Average Recall Score: 0.7742905242905241\n",
      "Macro Average F1 Score: 0.7598175360635594\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/10_epochs/dbmdz_bert-base-german-cased_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/10_epochs/dbmdz_bert-base-german-cased_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-uncased:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 2756.97 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 2543.44 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 2606.61 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for dbmdz/bert-base-german-uncased with 10 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5560' max='5560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5560/5560 10:39, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.837300</td>\n",
       "      <td>0.705564</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.856513</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.821713</td>\n",
       "      <td>{0: 59, 1: 17, 2: 53}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.567600</td>\n",
       "      <td>0.799524</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.845273</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.844134</td>\n",
       "      <td>{0: 38, 1: 29, 2: 62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.507600</td>\n",
       "      <td>0.798777</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.860680</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.852662</td>\n",
       "      <td>{0: 50, 1: 22, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.256200</td>\n",
       "      <td>0.702567</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.848547</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.843670</td>\n",
       "      <td>{0: 35, 1: 30, 2: 64}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.233600</td>\n",
       "      <td>0.747054</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.873697</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.860836</td>\n",
       "      <td>{0: 33, 1: 34, 2: 62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.179300</td>\n",
       "      <td>1.042679</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.826929</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.826945</td>\n",
       "      <td>{0: 39, 1: 25, 2: 65}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.139200</td>\n",
       "      <td>1.085772</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.844147</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.844346</td>\n",
       "      <td>{0: 41, 1: 26, 2: 62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.058000</td>\n",
       "      <td>1.128232</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.845772</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.844393</td>\n",
       "      <td>{0: 38, 1: 28, 2: 63}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>1.121340</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.855865</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.848049</td>\n",
       "      <td>{0: 38, 1: 33, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>1.065396</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.860905</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.854956</td>\n",
       "      <td>{0: 38, 1: 32, 2: 59}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_dbmdz_bert-base-german-uncased_42_42_10\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_dbmdz_bert-base-german-uncased_42_42_10\n",
      "Evaluation results for dbmdz/bert-base-german-uncased with 10 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.445467472076416, 'eval_accuracy': 0.7843137254901961, 'eval_precision': 0.8027412533640907, 'eval_recall': 0.7843137254901961, 'eval_f1': 0.7887461903000194, 'eval_class_distribution': {0: 34, 1: 44, 2: 75}, 'eval_runtime': 2.1867, 'eval_samples_per_second': 69.969, 'eval_steps_per_second': 35.213, 'epoch': 10.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.75      0.75      0.75        36\n",
      "     Neutral       0.63      0.82      0.71        33\n",
      "     Positiv       0.89      0.79      0.84        84\n",
      "\n",
      "    accuracy                           0.78       153\n",
      "   macro avg       0.76      0.78      0.77       153\n",
      "weighted avg       0.80      0.78      0.79       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 36, 1: 43, 2: 74}\n",
      "Negativ Precision Score: 0.75\n",
      "Negativ Recall Score: 0.75\n",
      "Negativ F1 Score: 0.75\n",
      "\n",
      "Neutral Precision Score: 0.627906976744186\n",
      "Neutral Recall Score: 0.8181818181818182\n",
      "Neutral F1 Score: 0.7105263157894737\n",
      "\n",
      "Positiv Precision Score: 0.8918918918918919\n",
      "Positiv Recall Score: 0.7857142857142857\n",
      "Positiv F1 Score: 0.8354430379746836\n",
      "\n",
      "Macro Average Precision Score: 0.7565996228786926\n",
      "Macro Average Recall Score: 0.7846320346320347\n",
      "Macro Average F1 Score: 0.7653231179213856\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/10_epochs/dbmdz_bert-base-german-uncased_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/10_epochs/dbmdz_bert-base-german-uncased_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for FacebookAI/xlm-roberta-base:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 3589.44 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3140.72 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 3210.10 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for FacebookAI/xlm-roberta-base with 10 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5560' max='5560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5560/5560 14:33, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.896200</td>\n",
       "      <td>0.815468</td>\n",
       "      <td>0.775194</td>\n",
       "      <td>0.776077</td>\n",
       "      <td>0.775194</td>\n",
       "      <td>0.771644</td>\n",
       "      <td>{0: 44, 1: 20, 2: 65}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.783500</td>\n",
       "      <td>0.871984</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.801309</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.797729</td>\n",
       "      <td>{0: 46, 1: 22, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.822400</td>\n",
       "      <td>0.958059</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.856875</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.843917</td>\n",
       "      <td>{0: 52, 1: 20, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.555700</td>\n",
       "      <td>0.956812</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.809262</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.805945</td>\n",
       "      <td>{0: 47, 1: 23, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.500200</td>\n",
       "      <td>0.898484</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.857430</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.852139</td>\n",
       "      <td>{0: 48, 1: 22, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.418200</td>\n",
       "      <td>1.085667</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.830046</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.808554</td>\n",
       "      <td>{0: 55, 1: 26, 2: 48}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.322300</td>\n",
       "      <td>0.943467</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.865401</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.837937</td>\n",
       "      <td>{0: 58, 1: 20, 2: 51}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.224200</td>\n",
       "      <td>0.960268</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.848129</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.839279</td>\n",
       "      <td>{0: 47, 1: 30, 2: 52}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.162000</td>\n",
       "      <td>0.906566</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.873568</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.863639</td>\n",
       "      <td>{0: 43, 1: 33, 2: 53}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.145600</td>\n",
       "      <td>0.954546</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.866079</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.861853</td>\n",
       "      <td>{0: 46, 1: 28, 2: 55}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_FacebookAI_xlm-roberta-base_42_42_10\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_FacebookAI_xlm-roberta-base_42_42_10\n",
      "Evaluation results for FacebookAI/xlm-roberta-base with 10 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3683611154556274, 'eval_accuracy': 0.8169934640522876, 'eval_precision': 0.829985400827169, 'eval_recall': 0.8169934640522876, 'eval_f1': 0.8190537333886903, 'eval_class_distribution': {0: 39, 1: 41, 2: 73}, 'eval_runtime': 2.0388, 'eval_samples_per_second': 75.042, 'eval_steps_per_second': 37.766, 'epoch': 10.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.84      0.86      0.85        36\n",
      "     Neutral       0.64      0.85      0.73        33\n",
      "     Positiv       0.92      0.79      0.85        84\n",
      "\n",
      "    accuracy                           0.82       153\n",
      "   macro avg       0.80      0.83      0.81       153\n",
      "weighted avg       0.84      0.82      0.82       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 37, 1: 44, 2: 72}\n",
      "Negativ Precision Score: 0.8378378378378378\n",
      "Negativ Recall Score: 0.8611111111111112\n",
      "Negativ F1 Score: 0.8493150684931506\n",
      "\n",
      "Neutral Precision Score: 0.6363636363636364\n",
      "Neutral Recall Score: 0.8484848484848485\n",
      "Neutral F1 Score: 0.7272727272727273\n",
      "\n",
      "Positiv Precision Score: 0.9166666666666666\n",
      "Positiv Recall Score: 0.7857142857142857\n",
      "Positiv F1 Score: 0.8461538461538461\n",
      "\n",
      "Macro Average Precision Score: 0.7969560469560469\n",
      "Macro Average Recall Score: 0.8317700817700818\n",
      "Macro Average F1 Score: 0.8075805473065748\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/10_epochs/FacebookAI_xlm-roberta-base_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/10_epochs/FacebookAI_xlm-roberta-base_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_best:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at TUM/GottBERT_base_best and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 3683.06 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3397.63 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 3249.62 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for TUM/GottBERT_base_best with 10 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5560' max='5560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5560/5560 10:55, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.930300</td>\n",
       "      <td>0.734769</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.868900</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.846236</td>\n",
       "      <td>{0: 55, 1: 19, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.573200</td>\n",
       "      <td>0.848223</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.825883</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.822769</td>\n",
       "      <td>{0: 40, 1: 31, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.838025</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.864537</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.848170</td>\n",
       "      <td>{0: 50, 1: 17, 2: 62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.322600</td>\n",
       "      <td>0.781667</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.869630</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.865522</td>\n",
       "      <td>{0: 47, 1: 21, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.299300</td>\n",
       "      <td>0.854226</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.850493</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.851262</td>\n",
       "      <td>{0: 42, 1: 25, 2: 62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.265600</td>\n",
       "      <td>0.862524</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.839834</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.837637</td>\n",
       "      <td>{0: 46, 1: 25, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.247800</td>\n",
       "      <td>0.916696</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.867940</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.858061</td>\n",
       "      <td>{0: 51, 1: 20, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.207100</td>\n",
       "      <td>0.891070</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.842790</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.842645</td>\n",
       "      <td>{0: 44, 1: 23, 2: 62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.134300</td>\n",
       "      <td>0.964049</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.844167</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.839057</td>\n",
       "      <td>{0: 47, 1: 27, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.088400</td>\n",
       "      <td>1.041490</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.857303</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.852989</td>\n",
       "      <td>{0: 48, 1: 24, 2: 57}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_TUM_GottBERT_base_best_42_42_10\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_TUM_GottBERT_base_best_42_42_10\n",
      "Evaluation results for TUM/GottBERT_base_best with 10 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0864769220352173, 'eval_accuracy': 0.8431372549019608, 'eval_precision': 0.8412104235633648, 'eval_recall': 0.8431372549019608, 'eval_f1': 0.8415303086696702, 'eval_class_distribution': {0: 35, 1: 30, 2: 88}, 'eval_runtime': 2.0531, 'eval_samples_per_second': 74.52, 'eval_steps_per_second': 37.504, 'epoch': 10.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.82      0.92      0.87        36\n",
      "     Neutral       0.69      0.55      0.61        33\n",
      "     Positiv       0.85      0.88      0.87        84\n",
      "\n",
      "    accuracy                           0.82       153\n",
      "   macro avg       0.79      0.78      0.78       153\n",
      "weighted avg       0.81      0.82      0.81       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 40, 1: 26, 2: 87}\n",
      "Negativ Precision Score: 0.825\n",
      "Negativ Recall Score: 0.9166666666666666\n",
      "Negativ F1 Score: 0.868421052631579\n",
      "\n",
      "Neutral Precision Score: 0.6923076923076923\n",
      "Neutral Recall Score: 0.5454545454545454\n",
      "Neutral F1 Score: 0.6101694915254238\n",
      "\n",
      "Positiv Precision Score: 0.8505747126436781\n",
      "Positiv Recall Score: 0.8809523809523809\n",
      "Positiv F1 Score: 0.8654970760233918\n",
      "\n",
      "Macro Average Precision Score: 0.7892941349837902\n",
      "Macro Average Recall Score: 0.781024531024531\n",
      "Macro Average F1 Score: 0.7813625400601314\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/10_epochs/TUM_GottBERT_base_best_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/10_epochs/TUM_GottBERT_base_best_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_filtered_base_best:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at TUM/GottBERT_filtered_base_best and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 3703.67 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3131.51 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 3202.70 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for TUM/GottBERT_filtered_base_best with 10 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5560' max='5560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5560/5560 10:56, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.831800</td>\n",
       "      <td>0.852817</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.816833</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.790920</td>\n",
       "      <td>{0: 58, 1: 19, 2: 52}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.564200</td>\n",
       "      <td>0.576296</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.852431</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.852186</td>\n",
       "      <td>{0: 44, 1: 25, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.472700</td>\n",
       "      <td>0.635316</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.885124</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.881197</td>\n",
       "      <td>{0: 45, 1: 21, 2: 63}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.323600</td>\n",
       "      <td>0.862517</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.867571</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.861635</td>\n",
       "      <td>{0: 48, 1: 27, 2: 54}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.303300</td>\n",
       "      <td>0.696167</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.891362</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.891316</td>\n",
       "      <td>{0: 43, 1: 26, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.217400</td>\n",
       "      <td>0.738092</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.861823</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.854064</td>\n",
       "      <td>{0: 49, 1: 27, 2: 53}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.190700</td>\n",
       "      <td>0.821242</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.869791</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.868493</td>\n",
       "      <td>{0: 45, 1: 26, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.159900</td>\n",
       "      <td>0.885034</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.866550</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.861425</td>\n",
       "      <td>{0: 48, 1: 26, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.077100</td>\n",
       "      <td>0.988218</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.855226</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.846333</td>\n",
       "      <td>{0: 49, 1: 28, 2: 52}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.051300</td>\n",
       "      <td>1.020409</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.860820</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>{0: 49, 1: 26, 2: 54}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_TUM_GottBERT_filtered_base_best_42_42_10\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_TUM_GottBERT_filtered_base_best_42_42_10\n",
      "Evaluation results for TUM/GottBERT_filtered_base_best with 10 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1834323406219482, 'eval_accuracy': 0.7973856209150327, 'eval_precision': 0.7986928104575163, 'eval_recall': 0.7973856209150327, 'eval_f1': 0.7972178173794121, 'eval_class_distribution': {0: 40, 1: 33, 2: 80}, 'eval_runtime': 2.0503, 'eval_samples_per_second': 74.622, 'eval_steps_per_second': 37.555, 'epoch': 10.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.82      0.89      0.85        36\n",
      "     Neutral       0.69      0.67      0.68        33\n",
      "     Positiv       0.87      0.85      0.86        84\n",
      "\n",
      "    accuracy                           0.82       153\n",
      "   macro avg       0.79      0.80      0.80       153\n",
      "weighted avg       0.82      0.82      0.82       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 39, 1: 32, 2: 82}\n",
      "Negativ Precision Score: 0.8205128205128205\n",
      "Negativ Recall Score: 0.8888888888888888\n",
      "Negativ F1 Score: 0.8533333333333334\n",
      "\n",
      "Neutral Precision Score: 0.6875\n",
      "Neutral Recall Score: 0.6666666666666666\n",
      "Neutral F1 Score: 0.676923076923077\n",
      "\n",
      "Positiv Precision Score: 0.8658536585365854\n",
      "Positiv Recall Score: 0.8452380952380952\n",
      "Positiv F1 Score: 0.8554216867469879\n",
      "\n",
      "Macro Average Precision Score: 0.791288826349802\n",
      "Macro Average Recall Score: 0.8002645502645502\n",
      "Macro Average F1 Score: 0.7952260323344661\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/10_epochs/TUM_GottBERT_filtered_base_best_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/10_epochs/TUM_GottBERT_filtered_base_best_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_last:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at TUM/GottBERT_base_last were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at TUM/GottBERT_base_last and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 3636.56 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3202.16 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 3366.43 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for TUM/GottBERT_base_last with 10 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5560' max='5560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5560/5560 10:54, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.907700</td>\n",
       "      <td>0.562201</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.859883</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.851635</td>\n",
       "      <td>{0: 50, 1: 21, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.604200</td>\n",
       "      <td>0.479130</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.893137</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.892083</td>\n",
       "      <td>{0: 43, 1: 28, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.522400</td>\n",
       "      <td>0.871606</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.862877</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>{0: 54, 1: 15, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.307300</td>\n",
       "      <td>0.777478</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.870731</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.861780</td>\n",
       "      <td>{0: 36, 1: 34, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.295000</td>\n",
       "      <td>0.653303</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.876068</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.873864</td>\n",
       "      <td>{0: 45, 1: 22, 2: 62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.254000</td>\n",
       "      <td>0.850213</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.845886</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.839983</td>\n",
       "      <td>{0: 39, 1: 32, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.227700</td>\n",
       "      <td>1.114671</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.822197</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.813928</td>\n",
       "      <td>{0: 51, 1: 23, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.180100</td>\n",
       "      <td>1.013435</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.853630</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.853104</td>\n",
       "      <td>{0: 43, 1: 27, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.121800</td>\n",
       "      <td>0.993790</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.838436</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.832436</td>\n",
       "      <td>{0: 40, 1: 32, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.091800</td>\n",
       "      <td>1.124825</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.837472</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.834978</td>\n",
       "      <td>{0: 47, 1: 22, 2: 60}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_TUM_GottBERT_base_last_42_42_10\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_TUM_GottBERT_base_last_42_42_10\n",
      "Evaluation results for TUM/GottBERT_base_last with 10 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8848168849945068, 'eval_accuracy': 0.8235294117647058, 'eval_precision': 0.8382084340585549, 'eval_recall': 0.8235294117647058, 'eval_f1': 0.8265638870962673, 'eval_class_distribution': {0: 40, 1: 40, 2: 73}, 'eval_runtime': 2.0565, 'eval_samples_per_second': 74.397, 'eval_steps_per_second': 37.441, 'epoch': 10.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.75      0.92      0.82        36\n",
      "     Neutral       0.64      0.76      0.69        33\n",
      "     Positiv       0.91      0.76      0.83        84\n",
      "\n",
      "    accuracy                           0.80       153\n",
      "   macro avg       0.77      0.81      0.78       153\n",
      "weighted avg       0.82      0.80      0.80       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 44, 1: 39, 2: 70}\n",
      "Negativ Precision Score: 0.75\n",
      "Negativ Recall Score: 0.9166666666666666\n",
      "Negativ F1 Score: 0.825\n",
      "\n",
      "Neutral Precision Score: 0.6410256410256411\n",
      "Neutral Recall Score: 0.7575757575757576\n",
      "Neutral F1 Score: 0.6944444444444444\n",
      "\n",
      "Positiv Precision Score: 0.9142857142857143\n",
      "Positiv Recall Score: 0.7619047619047619\n",
      "Positiv F1 Score: 0.8311688311688312\n",
      "\n",
      "Macro Average Precision Score: 0.7684371184371184\n",
      "Macro Average Recall Score: 0.812049062049062\n",
      "Macro Average F1 Score: 0.7835377585377584\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/10_epochs/TUM_GottBERT_base_last_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/10_epochs/TUM_GottBERT_base_last_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for distilbert/distilbert-base-german-cased:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 3732.17 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3125.74 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 3279.08 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for distilbert/distilbert-base-german-cased with 10 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5560' max='5560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5560/5560 05:45, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.830000</td>\n",
       "      <td>0.653218</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.859818</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.840041</td>\n",
       "      <td>{0: 54, 1: 26, 2: 49}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.581300</td>\n",
       "      <td>0.630370</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.831934</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>{0: 50, 1: 24, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.488100</td>\n",
       "      <td>0.643581</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.876949</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.868851</td>\n",
       "      <td>{0: 50, 1: 23, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.281100</td>\n",
       "      <td>0.631425</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.883099</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.869499</td>\n",
       "      <td>{0: 51, 1: 28, 2: 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.293000</td>\n",
       "      <td>0.665700</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.868038</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.867880</td>\n",
       "      <td>{0: 40, 1: 28, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.211100</td>\n",
       "      <td>0.747172</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.880559</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.864461</td>\n",
       "      <td>{0: 45, 1: 34, 2: 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.668056</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.897066</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.884708</td>\n",
       "      <td>{0: 52, 1: 25, 2: 52}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.133300</td>\n",
       "      <td>0.761774</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.881897</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.869636</td>\n",
       "      <td>{0: 51, 1: 27, 2: 51}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.058300</td>\n",
       "      <td>0.859355</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.875606</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.862527</td>\n",
       "      <td>{0: 48, 1: 31, 2: 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.047300</td>\n",
       "      <td>0.864833</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.871148</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.862282</td>\n",
       "      <td>{0: 46, 1: 31, 2: 52}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_distilbert_distilbert-base-german-cased_42_42_10\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_distilbert_distilbert-base-german-cased_42_42_10\n",
      "Evaluation results for distilbert/distilbert-base-german-cased with 10 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3278748989105225, 'eval_accuracy': 0.7843137254901961, 'eval_precision': 0.8022368189812484, 'eval_recall': 0.7843137254901961, 'eval_f1': 0.7874353012445324, 'eval_class_distribution': {0: 44, 1: 38, 2: 71}, 'eval_runtime': 1.2031, 'eval_samples_per_second': 127.166, 'eval_steps_per_second': 63.999, 'epoch': 10.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.67      0.89      0.76        36\n",
      "     Neutral       0.61      0.61      0.61        33\n",
      "     Positiv       0.89      0.76      0.82        84\n",
      "\n",
      "    accuracy                           0.76       153\n",
      "   macro avg       0.72      0.75      0.73       153\n",
      "weighted avg       0.78      0.76      0.76       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 48, 1: 33, 2: 72}\n",
      "Negativ Precision Score: 0.6666666666666666\n",
      "Negativ Recall Score: 0.8888888888888888\n",
      "Negativ F1 Score: 0.7619047619047619\n",
      "\n",
      "Neutral Precision Score: 0.6060606060606061\n",
      "Neutral Recall Score: 0.6060606060606061\n",
      "Neutral F1 Score: 0.6060606060606061\n",
      "\n",
      "Positiv Precision Score: 0.8888888888888888\n",
      "Positiv Recall Score: 0.7619047619047619\n",
      "Positiv F1 Score: 0.8205128205128205\n",
      "\n",
      "Macro Average Precision Score: 0.7205387205387206\n",
      "Macro Average Recall Score: 0.7522847522847522\n",
      "Macro Average F1 Score: 0.7294927294927295\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/10_epochs/distilbert_distilbert-base-german-cased_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/10_epochs/distilbert_distilbert-base-german-cased_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for GerMedBERT/medbert-512:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Device set to use cuda:0\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GerMedBERT/medbert-512 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 2601.53 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 2355.97 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 2396.62 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for GerMedBERT/medbert-512 with 10 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5560' max='5560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5560/5560 10:40, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.890900</td>\n",
       "      <td>0.805563</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.785038</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.768114</td>\n",
       "      <td>{0: 55, 1: 21, 2: 53}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.573600</td>\n",
       "      <td>1.070940</td>\n",
       "      <td>0.751938</td>\n",
       "      <td>0.756547</td>\n",
       "      <td>0.751938</td>\n",
       "      <td>0.741502</td>\n",
       "      <td>{0: 28, 1: 27, 2: 74}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.463500</td>\n",
       "      <td>0.930760</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.832005</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.821458</td>\n",
       "      <td>{0: 52, 1: 22, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.279600</td>\n",
       "      <td>0.974474</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.825690</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.816567</td>\n",
       "      <td>{0: 41, 1: 34, 2: 54}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.247200</td>\n",
       "      <td>1.368894</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.804616</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.804967</td>\n",
       "      <td>{0: 40, 1: 26, 2: 63}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.175200</td>\n",
       "      <td>1.255434</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.768666</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.764427</td>\n",
       "      <td>{0: 34, 1: 31, 2: 64}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.177800</td>\n",
       "      <td>1.243594</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.804972</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.799909</td>\n",
       "      <td>{0: 48, 1: 25, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>1.325993</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.793545</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.791289</td>\n",
       "      <td>{0: 46, 1: 26, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.049700</td>\n",
       "      <td>1.394601</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.783978</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.783384</td>\n",
       "      <td>{0: 42, 1: 28, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.030800</td>\n",
       "      <td>1.347941</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.792757</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.791530</td>\n",
       "      <td>{0: 43, 1: 28, 2: 58}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_GerMedBERT_medbert-512_42_42_10\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_GerMedBERT_medbert-512_42_42_10\n",
      "Evaluation results for GerMedBERT/medbert-512 with 10 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1626139879226685, 'eval_accuracy': 0.803921568627451, 'eval_precision': 0.8156893249177959, 'eval_recall': 0.803921568627451, 'eval_f1': 0.8048216264985952, 'eval_class_distribution': {0: 47, 1: 31, 2: 75}, 'eval_runtime': 2.1774, 'eval_samples_per_second': 70.268, 'eval_steps_per_second': 35.364, 'epoch': 10.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.63      0.89      0.74        36\n",
      "     Neutral       0.71      0.67      0.69        33\n",
      "     Positiv       0.90      0.76      0.83        84\n",
      "\n",
      "    accuracy                           0.77       153\n",
      "   macro avg       0.75      0.77      0.75       153\n",
      "weighted avg       0.80      0.77      0.77       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 51, 1: 31, 2: 71}\n",
      "Negativ Precision Score: 0.6274509803921569\n",
      "Negativ Recall Score: 0.8888888888888888\n",
      "Negativ F1 Score: 0.735632183908046\n",
      "\n",
      "Neutral Precision Score: 0.7096774193548387\n",
      "Neutral Recall Score: 0.6666666666666666\n",
      "Neutral F1 Score: 0.6875\n",
      "\n",
      "Positiv Precision Score: 0.9014084507042254\n",
      "Positiv Recall Score: 0.7619047619047619\n",
      "Positiv F1 Score: 0.8258064516129032\n",
      "\n",
      "Macro Average Precision Score: 0.7461789501504069\n",
      "Macro Average Recall Score: 0.7724867724867724\n",
      "Macro Average F1 Score: 0.7496462118403163\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/10_epochs/GerMedBERT_medbert-512_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/10_epochs/GerMedBERT_medbert-512_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for deepset/gbert-base:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 2684.50 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 2445.74 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 2407.58 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for deepset/gbert-base with 10 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5560' max='5560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5560/5560 10:43, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.817400</td>\n",
       "      <td>0.975716</td>\n",
       "      <td>0.775194</td>\n",
       "      <td>0.813477</td>\n",
       "      <td>0.775194</td>\n",
       "      <td>0.762682</td>\n",
       "      <td>{0: 60, 1: 11, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.501400</td>\n",
       "      <td>0.598750</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.860142</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.859453</td>\n",
       "      <td>{0: 42, 1: 24, 2: 63}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.819698</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.862697</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.859388</td>\n",
       "      <td>{0: 44, 1: 22, 2: 63}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.241200</td>\n",
       "      <td>0.929708</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.831257</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.827164</td>\n",
       "      <td>{0: 47, 1: 21, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.187200</td>\n",
       "      <td>0.892890</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.875319</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.874560</td>\n",
       "      <td>{0: 41, 1: 24, 2: 64}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.105400</td>\n",
       "      <td>1.107060</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.834227</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.830458</td>\n",
       "      <td>{0: 47, 1: 26, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.070700</td>\n",
       "      <td>1.244699</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.847006</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.844875</td>\n",
       "      <td>{0: 46, 1: 24, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>1.229894</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.854815</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.853498</td>\n",
       "      <td>{0: 44, 1: 27, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>1.274283</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.855024</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.853656</td>\n",
       "      <td>{0: 43, 1: 28, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>1.246567</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.861382</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.860856</td>\n",
       "      <td>{0: 43, 1: 27, 2: 59}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_deepset_gbert-base_42_42_10\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_deepset_gbert-base_42_42_10\n",
      "Evaluation results for deepset/gbert-base with 10 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.456703782081604, 'eval_accuracy': 0.7973856209150327, 'eval_precision': 0.8075866899396311, 'eval_recall': 0.7973856209150327, 'eval_f1': 0.8005776859085901, 'eval_class_distribution': {0: 37, 1: 39, 2: 77}, 'eval_runtime': 2.2015, 'eval_samples_per_second': 69.498, 'eval_steps_per_second': 34.976, 'epoch': 10.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.84      0.89      0.86        36\n",
      "     Neutral       0.62      0.73      0.67        33\n",
      "     Positiv       0.88      0.80      0.84        84\n",
      "\n",
      "    accuracy                           0.80       153\n",
      "   macro avg       0.78      0.80      0.79       153\n",
      "weighted avg       0.81      0.80      0.81       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 38, 1: 39, 2: 76}\n",
      "Negativ Precision Score: 0.8421052631578947\n",
      "Negativ Recall Score: 0.8888888888888888\n",
      "Negativ F1 Score: 0.8648648648648649\n",
      "\n",
      "Neutral Precision Score: 0.6153846153846154\n",
      "Neutral Recall Score: 0.7272727272727273\n",
      "Neutral F1 Score: 0.6666666666666666\n",
      "\n",
      "Positiv Precision Score: 0.881578947368421\n",
      "Positiv Recall Score: 0.7976190476190477\n",
      "Positiv F1 Score: 0.8375\n",
      "\n",
      "Macro Average Precision Score: 0.779689608636977\n",
      "Macro Average Recall Score: 0.8045935545935546\n",
      "Macro Average F1 Score: 0.7896771771771771\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/10_epochs/deepset_gbert-base_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/10_epochs/deepset_gbert-base_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(f'training and results for {model}:')\n",
    "    absa_model(data, model, rn1=42, rn2=42, epochs=10, save = True)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c2cf53f-91ef-4709-bfd9-17eff770e28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 2754.01 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 2458.23 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 2512.12 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for aari1995/German_Sentiment with 10 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5560' max='5560' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5560/5560 30:54, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.839500</td>\n",
       "      <td>0.791142</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.865477</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.858830</td>\n",
       "      <td>{0: 49, 1: 21, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.534100</td>\n",
       "      <td>0.854222</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.838044</td>\n",
       "      <td>{0: 36, 1: 33, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.508200</td>\n",
       "      <td>0.742958</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.879837</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.866869</td>\n",
       "      <td>{0: 50, 1: 19, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.274900</td>\n",
       "      <td>0.765735</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.857564</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.854547</td>\n",
       "      <td>{0: 41, 1: 30, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.176400</td>\n",
       "      <td>0.815526</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.879838</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.877259</td>\n",
       "      <td>{0: 40, 1: 30, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.118400</td>\n",
       "      <td>0.767304</td>\n",
       "      <td>0.899225</td>\n",
       "      <td>0.900804</td>\n",
       "      <td>0.899225</td>\n",
       "      <td>0.899732</td>\n",
       "      <td>{0: 44, 1: 27, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.059500</td>\n",
       "      <td>0.658802</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.931396</td>\n",
       "      <td>0.930233</td>\n",
       "      <td>0.929347</td>\n",
       "      <td>{0: 44, 1: 23, 2: 62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.028800</td>\n",
       "      <td>0.727754</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.908350</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.907127</td>\n",
       "      <td>{0: 45, 1: 26, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.718983</td>\n",
       "      <td>0.922481</td>\n",
       "      <td>0.922194</td>\n",
       "      <td>0.922481</td>\n",
       "      <td>0.921549</td>\n",
       "      <td>{0: 43, 1: 24, 2: 62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.717965</td>\n",
       "      <td>0.922481</td>\n",
       "      <td>0.922194</td>\n",
       "      <td>0.922481</td>\n",
       "      <td>0.921549</td>\n",
       "      <td>{0: 43, 1: 24, 2: 62}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_aari1995_German_Sentiment_42_42_10\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_aari1995_German_Sentiment_42_42_10\n",
      "Evaluation results for aari1995/German_Sentiment with 10 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3482502698898315, 'eval_accuracy': 0.8562091503267973, 'eval_precision': 0.854113139508677, 'eval_recall': 0.8562091503267973, 'eval_f1': 0.8546529723000311, 'eval_class_distribution': {0: 36, 1: 30, 2: 87}, 'eval_runtime': 5.6324, 'eval_samples_per_second': 27.164, 'eval_steps_per_second': 13.671, 'epoch': 10.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.89      0.89      0.89        36\n",
      "     Neutral       0.79      0.67      0.72        33\n",
      "     Positiv       0.87      0.92      0.89        84\n",
      "\n",
      "    accuracy                           0.86       153\n",
      "   macro avg       0.85      0.82      0.83       153\n",
      "weighted avg       0.85      0.86      0.85       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 36, 1: 28, 2: 89}\n",
      "Negativ Precision Score: 0.8888888888888888\n",
      "Negativ Recall Score: 0.8888888888888888\n",
      "Negativ F1 Score: 0.8888888888888888\n",
      "\n",
      "Neutral Precision Score: 0.7857142857142857\n",
      "Neutral Recall Score: 0.6666666666666666\n",
      "Neutral F1 Score: 0.7213114754098361\n",
      "\n",
      "Positiv Precision Score: 0.8651685393258427\n",
      "Positiv Recall Score: 0.9166666666666666\n",
      "Positiv F1 Score: 0.8901734104046243\n",
      "\n",
      "Macro Average Precision Score: 0.8465905713096724\n",
      "Macro Average Recall Score: 0.824074074074074\n",
      "Macro Average F1 Score: 0.8334579249011164\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/10_epochs/aari1995_German_Sentiment_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/10_epochs/aari1995_German_Sentiment_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n"
     ]
    }
   ],
   "source": [
    "absa_model(data, \"aari1995/German_Sentiment\", rn1=42, rn2=42, epochs=10, save = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "784b9358-7937-4e8b-8cd9-a56fb005e218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training and results for google-bert/bert-base-german-cased:\n",
      "Training Sentiment label count:  {'positiv': 498, 'neutral': 275, 'negativ': 338}\n",
      "Validation Sentiment label count:  {'positiv': 60, 'neutral': 27, 'negativ': 42}\n",
      "Test Sentiment label count:  {'positiv': 84, 'neutral': 33, 'negativ': 36}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 2252.84 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 2463.61 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 2543.49 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for google-bert/bert-base-german-cased with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2780' max='6672' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2780/6672 05:16 < 07:24, 8.76 it/s, Epoch 5/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.826800</td>\n",
       "      <td>0.856330</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.837679</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.792652</td>\n",
       "      <td>{0: 63, 1: 22, 2: 44}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.535700</td>\n",
       "      <td>0.614490</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.853140</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.840776</td>\n",
       "      <td>{0: 41, 1: 35, 2: 53}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.428600</td>\n",
       "      <td>0.933588</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.828073</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.822346</td>\n",
       "      <td>{0: 49, 1: 24, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.224600</td>\n",
       "      <td>0.911752</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.845803</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.831843</td>\n",
       "      <td>{0: 52, 1: 26, 2: 51}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.193300</td>\n",
       "      <td>1.065856</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.806386</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.805490</td>\n",
       "      <td>{0: 42, 1: 24, 2: 63}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_google-bert_bert-base-german-cased_42_42_12\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_google-bert_bert-base-german-cased_42_42_12\n",
      "Evaluation results for google-bert/bert-base-german-cased with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8268358111381531, 'eval_accuracy': 0.7973856209150327, 'eval_precision': 0.8137133728761873, 'eval_recall': 0.7973856209150327, 'eval_f1': 0.801392227088405, 'eval_class_distribution': {0: 42, 1: 38, 2: 73}, 'eval_runtime': 2.1976, 'eval_samples_per_second': 69.622, 'eval_steps_per_second': 35.038, 'epoch': 5.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.80      0.89      0.84        36\n",
      "     Neutral       0.59      0.73      0.65        33\n",
      "     Positiv       0.93      0.80      0.86        84\n",
      "\n",
      "    accuracy                           0.80       153\n",
      "   macro avg       0.77      0.80      0.78       153\n",
      "weighted avg       0.83      0.80      0.81       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 40, 1: 41, 2: 72}\n",
      "Negativ Precision Score: 0.8\n",
      "Negativ Recall Score: 0.8888888888888888\n",
      "Negativ F1 Score: 0.8421052631578947\n",
      "\n",
      "Neutral Precision Score: 0.5853658536585366\n",
      "Neutral Recall Score: 0.7272727272727273\n",
      "Neutral F1 Score: 0.6486486486486487\n",
      "\n",
      "Positiv Precision Score: 0.9305555555555556\n",
      "Positiv Recall Score: 0.7976190476190477\n",
      "Positiv F1 Score: 0.8589743589743589\n",
      "\n",
      "Macro Average Precision Score: 0.7719738030713641\n",
      "Macro Average Recall Score: 0.8045935545935546\n",
      "Macro Average F1 Score: 0.7832427569269674\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/12_epochs/google-bert_bert-base-german-cased_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/12_epochs/google-bert_bert-base-german-cased_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-cased:\n",
      "Training Sentiment label count:  {'positiv': 498, 'neutral': 275, 'negativ': 338}\n",
      "Validation Sentiment label count:  {'positiv': 60, 'neutral': 27, 'negativ': 42}\n",
      "Test Sentiment label count:  {'positiv': 84, 'neutral': 33, 'negativ': 36}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 2722.64 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 2439.40 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 2505.80 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for dbmdz/bert-base-german-cased with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6672' max='6672' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6672/6672 12:50, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.874600</td>\n",
       "      <td>0.962469</td>\n",
       "      <td>0.775194</td>\n",
       "      <td>0.819495</td>\n",
       "      <td>0.775194</td>\n",
       "      <td>0.766703</td>\n",
       "      <td>{0: 62, 1: 12, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.550600</td>\n",
       "      <td>0.897860</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.813756</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.813489</td>\n",
       "      <td>{0: 44, 1: 25, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.510800</td>\n",
       "      <td>1.098207</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.855367</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.803492</td>\n",
       "      <td>{0: 62, 1: 12, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.316300</td>\n",
       "      <td>0.791952</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.859386</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.853166</td>\n",
       "      <td>{0: 49, 1: 23, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.282400</td>\n",
       "      <td>1.103715</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.831512</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.827072</td>\n",
       "      <td>{0: 36, 1: 25, 2: 68}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.188700</td>\n",
       "      <td>1.175396</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.864026</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.848212</td>\n",
       "      <td>{0: 53, 1: 24, 2: 52}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.117700</td>\n",
       "      <td>0.982043</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.861065</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.858615</td>\n",
       "      <td>{0: 45, 1: 22, 2: 62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.074600</td>\n",
       "      <td>1.205643</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.849633</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.841367</td>\n",
       "      <td>{0: 47, 1: 19, 2: 63}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.017600</td>\n",
       "      <td>0.952554</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.876169</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.875786</td>\n",
       "      <td>{0: 40, 1: 27, 2: 62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>1.071363</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.864774</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.860194</td>\n",
       "      <td>{0: 48, 1: 23, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.108257</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.859831</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.859758</td>\n",
       "      <td>{0: 44, 1: 25, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.119421</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.859831</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.859758</td>\n",
       "      <td>{0: 44, 1: 25, 2: 60}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_dbmdz_bert-base-german-cased_42_42_12\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_dbmdz_bert-base-german-cased_42_42_12\n",
      "Evaluation results for dbmdz/bert-base-german-cased with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.024049758911133, 'eval_accuracy': 0.7450980392156863, 'eval_precision': 0.7647788417692659, 'eval_recall': 0.7450980392156863, 'eval_f1': 0.7512031904807744, 'eval_class_distribution': {0: 35, 1: 43, 2: 75}, 'eval_runtime': 2.1935, 'eval_samples_per_second': 69.753, 'eval_steps_per_second': 35.104, 'epoch': 12.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.86      0.83      0.85        36\n",
      "     Neutral       0.59      0.73      0.65        33\n",
      "     Positiv       0.90      0.82      0.86        84\n",
      "\n",
      "    accuracy                           0.80       153\n",
      "   macro avg       0.78      0.79      0.78       153\n",
      "weighted avg       0.82      0.80      0.81       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 35, 1: 41, 2: 77}\n",
      "Negativ Precision Score: 0.8571428571428571\n",
      "Negativ Recall Score: 0.8333333333333334\n",
      "Negativ F1 Score: 0.8450704225352113\n",
      "\n",
      "Neutral Precision Score: 0.5853658536585366\n",
      "Neutral Recall Score: 0.7272727272727273\n",
      "Neutral F1 Score: 0.6486486486486487\n",
      "\n",
      "Positiv Precision Score: 0.8961038961038961\n",
      "Positiv Recall Score: 0.8214285714285714\n",
      "Positiv F1 Score: 0.8571428571428571\n",
      "\n",
      "Macro Average Precision Score: 0.7795375356350966\n",
      "Macro Average Recall Score: 0.794011544011544\n",
      "Macro Average F1 Score: 0.7836206427755723\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/12_epochs/dbmdz_bert-base-german-cased_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/12_epochs/dbmdz_bert-base-german-cased_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-uncased:\n",
      "Training Sentiment label count:  {'positiv': 498, 'neutral': 275, 'negativ': 338}\n",
      "Validation Sentiment label count:  {'positiv': 60, 'neutral': 27, 'negativ': 42}\n",
      "Test Sentiment label count:  {'positiv': 84, 'neutral': 33, 'negativ': 36}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 2489.03 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 2411.80 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 2483.09 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for dbmdz/bert-base-german-uncased with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4448' max='6672' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4448/6672 08:32 < 04:16, 8.68 it/s, Epoch 8/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.876300</td>\n",
       "      <td>0.650298</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.833099</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.799525</td>\n",
       "      <td>{0: 56, 1: 14, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.521500</td>\n",
       "      <td>0.842318</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.816596</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.812202</td>\n",
       "      <td>{0: 35, 1: 28, 2: 66}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.477200</td>\n",
       "      <td>0.832856</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.818723</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.808880</td>\n",
       "      <td>{0: 49, 1: 18, 2: 62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.272300</td>\n",
       "      <td>0.921269</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.828904</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.817697</td>\n",
       "      <td>{0: 48, 1: 18, 2: 63}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.245900</td>\n",
       "      <td>0.775434</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.861469</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.860882</td>\n",
       "      <td>{0: 42, 1: 28, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.183200</td>\n",
       "      <td>0.934674</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.837863</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.837470</td>\n",
       "      <td>{0: 43, 1: 27, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.148800</td>\n",
       "      <td>1.072342</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.856441</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.853687</td>\n",
       "      <td>{0: 46, 1: 26, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.100600</td>\n",
       "      <td>1.106352</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.853116</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.847472</td>\n",
       "      <td>{0: 40, 1: 32, 2: 57}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_dbmdz_bert-base-german-uncased_42_42_12\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_dbmdz_bert-base-german-uncased_42_42_12\n",
      "Evaluation results for dbmdz/bert-base-german-uncased with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5307726860046387, 'eval_accuracy': 0.7189542483660131, 'eval_precision': 0.7562915368205994, 'eval_recall': 0.7189542483660131, 'eval_f1': 0.720553382023248, 'eval_class_distribution': {0: 49, 1: 43, 2: 61}, 'eval_runtime': 2.1984, 'eval_samples_per_second': 69.597, 'eval_steps_per_second': 35.026, 'epoch': 8.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.64      0.89      0.74        36\n",
      "     Neutral       0.63      0.88      0.73        33\n",
      "     Positiv       0.95      0.64      0.77        84\n",
      "\n",
      "    accuracy                           0.75       153\n",
      "   macro avg       0.74      0.80      0.75       153\n",
      "weighted avg       0.81      0.75      0.75       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 50, 1: 46, 2: 57}\n",
      "Negativ Precision Score: 0.64\n",
      "Negativ Recall Score: 0.8888888888888888\n",
      "Negativ F1 Score: 0.7441860465116279\n",
      "\n",
      "Neutral Precision Score: 0.6304347826086957\n",
      "Neutral Recall Score: 0.8787878787878788\n",
      "Neutral F1 Score: 0.7341772151898734\n",
      "\n",
      "Positiv Precision Score: 0.9473684210526315\n",
      "Positiv Recall Score: 0.6428571428571429\n",
      "Positiv F1 Score: 0.7659574468085106\n",
      "\n",
      "Macro Average Precision Score: 0.7392677345537758\n",
      "Macro Average Recall Score: 0.8035113035113035\n",
      "Macro Average F1 Score: 0.7481069028366706\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/12_epochs/dbmdz_bert-base-german-uncased_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/12_epochs/dbmdz_bert-base-german-uncased_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for FacebookAI/xlm-roberta-base:\n",
      "Training Sentiment label count:  {'positiv': 498, 'neutral': 275, 'negativ': 338}\n",
      "Validation Sentiment label count:  {'positiv': 60, 'neutral': 27, 'negativ': 42}\n",
      "Test Sentiment label count:  {'positiv': 84, 'neutral': 33, 'negativ': 36}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 3705.85 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3135.57 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 3281.12 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for FacebookAI/xlm-roberta-base with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6672' max='6672' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6672/6672 17:28, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.021500</td>\n",
       "      <td>1.070785</td>\n",
       "      <td>0.348837</td>\n",
       "      <td>0.573643</td>\n",
       "      <td>0.348837</td>\n",
       "      <td>0.207087</td>\n",
       "      <td>{0: 126, 1: 0, 2: 3}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.911600</td>\n",
       "      <td>0.779326</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.792021</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.791022</td>\n",
       "      <td>{0: 40, 1: 29, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.839500</td>\n",
       "      <td>1.113744</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.789147</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.789426</td>\n",
       "      <td>{0: 41, 1: 25, 2: 63}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.719000</td>\n",
       "      <td>1.100871</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.796559</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.796857</td>\n",
       "      <td>{0: 44, 1: 24, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.573800</td>\n",
       "      <td>1.387385</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.781519</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.779219</td>\n",
       "      <td>{0: 37, 1: 24, 2: 68}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.583600</td>\n",
       "      <td>1.182464</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.823349</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.815646</td>\n",
       "      <td>{0: 38, 1: 34, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.477700</td>\n",
       "      <td>1.085219</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.824883</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.822435</td>\n",
       "      <td>{0: 46, 1: 26, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.410900</td>\n",
       "      <td>1.135072</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.815073</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.812961</td>\n",
       "      <td>{0: 37, 1: 30, 2: 62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.322100</td>\n",
       "      <td>1.162743</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.831509</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.823597</td>\n",
       "      <td>{0: 38, 1: 34, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.288300</td>\n",
       "      <td>1.222357</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.813320</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.812813</td>\n",
       "      <td>{0: 39, 1: 26, 2: 64}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.240300</td>\n",
       "      <td>1.178664</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.831377</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.830160</td>\n",
       "      <td>{0: 44, 1: 27, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.251300</td>\n",
       "      <td>1.195073</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.831377</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.830160</td>\n",
       "      <td>{0: 44, 1: 27, 2: 58}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_FacebookAI_xlm-roberta-base_42_42_12\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_FacebookAI_xlm-roberta-base_42_42_12\n",
      "Evaluation results for FacebookAI/xlm-roberta-base with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.316672682762146, 'eval_accuracy': 0.8300653594771242, 'eval_precision': 0.8382506345354644, 'eval_recall': 0.8300653594771242, 'eval_f1': 0.8318959162612414, 'eval_class_distribution': {0: 40, 1: 37, 2: 76}, 'eval_runtime': 2.0453, 'eval_samples_per_second': 74.805, 'eval_steps_per_second': 37.647, 'epoch': 12.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.78      0.89      0.83        36\n",
      "     Neutral       0.60      0.79      0.68        33\n",
      "     Positiv       0.91      0.75      0.82        84\n",
      "\n",
      "    accuracy                           0.79       153\n",
      "   macro avg       0.77      0.81      0.78       153\n",
      "weighted avg       0.82      0.79      0.80       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 41, 1: 43, 2: 69}\n",
      "Negativ Precision Score: 0.7804878048780488\n",
      "Negativ Recall Score: 0.8888888888888888\n",
      "Negativ F1 Score: 0.8311688311688312\n",
      "\n",
      "Neutral Precision Score: 0.6046511627906976\n",
      "Neutral Recall Score: 0.7878787878787878\n",
      "Neutral F1 Score: 0.6842105263157895\n",
      "\n",
      "Positiv Precision Score: 0.9130434782608695\n",
      "Positiv Recall Score: 0.75\n",
      "Positiv F1 Score: 0.8235294117647058\n",
      "\n",
      "Macro Average Precision Score: 0.766060815309872\n",
      "Macro Average Recall Score: 0.8089225589225588\n",
      "Macro Average F1 Score: 0.7796362564164422\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/12_epochs/FacebookAI_xlm-roberta-base_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/12_epochs/FacebookAI_xlm-roberta-base_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_best:\n",
      "Training Sentiment label count:  {'positiv': 498, 'neutral': 275, 'negativ': 338}\n",
      "Validation Sentiment label count:  {'positiv': 60, 'neutral': 27, 'negativ': 42}\n",
      "Test Sentiment label count:  {'positiv': 84, 'neutral': 33, 'negativ': 36}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at TUM/GottBERT_base_best and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 3760.30 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3248.80 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 3306.69 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for TUM/GottBERT_base_best with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2780' max='6672' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2780/6672 05:25 < 07:35, 8.54 it/s, Epoch 5/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.891700</td>\n",
       "      <td>0.934055</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.816342</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.788631</td>\n",
       "      <td>{0: 58, 1: 17, 2: 54}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.562300</td>\n",
       "      <td>0.736761</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.863787</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.852160</td>\n",
       "      <td>{0: 52, 1: 21, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.940871</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.843686</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.842311</td>\n",
       "      <td>{0: 44, 1: 22, 2: 63}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.300700</td>\n",
       "      <td>0.966743</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.818203</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.810478</td>\n",
       "      <td>{0: 51, 1: 20, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.329400</td>\n",
       "      <td>0.968592</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.825249</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.818711</td>\n",
       "      <td>{0: 49, 1: 20, 2: 60}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_TUM_GottBERT_base_best_42_42_12\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_TUM_GottBERT_base_best_42_42_12\n",
      "Evaluation results for TUM/GottBERT_base_best with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0387647151947021, 'eval_accuracy': 0.8104575163398693, 'eval_precision': 0.8292497040305368, 'eval_recall': 0.8104575163398693, 'eval_f1': 0.8139436220021332, 'eval_class_distribution': {0: 43, 1: 39, 2: 71}, 'eval_runtime': 2.0508, 'eval_samples_per_second': 74.606, 'eval_steps_per_second': 37.547, 'epoch': 5.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.72      0.92      0.80        36\n",
      "     Neutral       0.68      0.70      0.69        33\n",
      "     Positiv       0.92      0.80      0.85        84\n",
      "\n",
      "    accuracy                           0.80       153\n",
      "   macro avg       0.77      0.80      0.78       153\n",
      "weighted avg       0.82      0.80      0.81       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 46, 1: 34, 2: 73}\n",
      "Negativ Precision Score: 0.717391304347826\n",
      "Negativ Recall Score: 0.9166666666666666\n",
      "Negativ F1 Score: 0.8048780487804879\n",
      "\n",
      "Neutral Precision Score: 0.6764705882352942\n",
      "Neutral Recall Score: 0.696969696969697\n",
      "Neutral F1 Score: 0.6865671641791045\n",
      "\n",
      "Positiv Precision Score: 0.9178082191780822\n",
      "Positiv Recall Score: 0.7976190476190477\n",
      "Positiv F1 Score: 0.8535031847133758\n",
      "\n",
      "Macro Average Precision Score: 0.7705567039204008\n",
      "Macro Average Recall Score: 0.8037518037518039\n",
      "Macro Average F1 Score: 0.7816494658909893\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/12_epochs/TUM_GottBERT_base_best_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/12_epochs/TUM_GottBERT_base_best_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_filtered_base_best:\n",
      "Training Sentiment label count:  {'positiv': 498, 'neutral': 275, 'negativ': 338}\n",
      "Validation Sentiment label count:  {'positiv': 60, 'neutral': 27, 'negativ': 42}\n",
      "Test Sentiment label count:  {'positiv': 84, 'neutral': 33, 'negativ': 36}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at TUM/GottBERT_filtered_base_best and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 3759.05 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3265.84 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 3341.54 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for TUM/GottBERT_filtered_base_best with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3336' max='6672' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3336/6672 06:30 < 06:30, 8.55 it/s, Epoch 6/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.829700</td>\n",
       "      <td>0.934303</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.828243</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.784573</td>\n",
       "      <td>{0: 62, 1: 14, 2: 53}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.571100</td>\n",
       "      <td>0.612250</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.882644</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.882964</td>\n",
       "      <td>{0: 41, 1: 26, 2: 62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.504200</td>\n",
       "      <td>0.571497</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.893850</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.890252</td>\n",
       "      <td>{0: 46, 1: 22, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.328800</td>\n",
       "      <td>0.693923</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.862629</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.852381</td>\n",
       "      <td>{0: 51, 1: 21, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.299900</td>\n",
       "      <td>0.649871</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.887434</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.883974</td>\n",
       "      <td>{0: 47, 1: 24, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.804630</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.857087</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.852938</td>\n",
       "      <td>{0: 48, 1: 25, 2: 56}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_TUM_GottBERT_filtered_base_best_42_42_12\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_TUM_GottBERT_filtered_base_best_42_42_12\n",
      "Evaluation results for TUM/GottBERT_filtered_base_best with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1658645868301392, 'eval_accuracy': 0.7908496732026143, 'eval_precision': 0.7957653649695172, 'eval_recall': 0.7908496732026143, 'eval_f1': 0.7912728312010672, 'eval_class_distribution': {0: 42, 1: 34, 2: 77}, 'eval_runtime': 2.0405, 'eval_samples_per_second': 74.983, 'eval_steps_per_second': 37.736, 'epoch': 6.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.78      0.86      0.82        36\n",
      "     Neutral       0.67      0.73      0.70        33\n",
      "     Positiv       0.87      0.80      0.83        84\n",
      "\n",
      "    accuracy                           0.80       153\n",
      "   macro avg       0.77      0.80      0.78       153\n",
      "weighted avg       0.80      0.80      0.80       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 40, 1: 36, 2: 77}\n",
      "Negativ Precision Score: 0.775\n",
      "Negativ Recall Score: 0.8611111111111112\n",
      "Negativ F1 Score: 0.8157894736842105\n",
      "\n",
      "Neutral Precision Score: 0.6666666666666666\n",
      "Neutral Recall Score: 0.7272727272727273\n",
      "Neutral F1 Score: 0.6956521739130435\n",
      "\n",
      "Positiv Precision Score: 0.8701298701298701\n",
      "Positiv Recall Score: 0.7976190476190477\n",
      "Positiv F1 Score: 0.8322981366459627\n",
      "\n",
      "Macro Average Precision Score: 0.7705988455988456\n",
      "Macro Average Recall Score: 0.7953342953342953\n",
      "Macro Average F1 Score: 0.7812465947477389\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/12_epochs/TUM_GottBERT_filtered_base_best_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/12_epochs/TUM_GottBERT_filtered_base_best_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_last:\n",
      "Training Sentiment label count:  {'positiv': 498, 'neutral': 275, 'negativ': 338}\n",
      "Validation Sentiment label count:  {'positiv': 60, 'neutral': 27, 'negativ': 42}\n",
      "Test Sentiment label count:  {'positiv': 84, 'neutral': 33, 'negativ': 36}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at TUM/GottBERT_base_last were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at TUM/GottBERT_base_last and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 3767.47 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3286.05 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 3325.09 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for TUM/GottBERT_base_last with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2780' max='6672' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2780/6672 05:26 < 07:37, 8.51 it/s, Epoch 5/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.896600</td>\n",
       "      <td>0.734998</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.848089</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.821513</td>\n",
       "      <td>{0: 57, 1: 18, 2: 54}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.542300</td>\n",
       "      <td>0.653417</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.860992</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.860633</td>\n",
       "      <td>{0: 41, 1: 28, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.497700</td>\n",
       "      <td>0.782798</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.856712</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.840051</td>\n",
       "      <td>{0: 52, 1: 17, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.325900</td>\n",
       "      <td>0.778349</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.864224</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.855158</td>\n",
       "      <td>{0: 36, 1: 33, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.278900</td>\n",
       "      <td>1.134474</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.805714</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.803696</td>\n",
       "      <td>{0: 42, 1: 22, 2: 65}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_TUM_GottBERT_base_last_42_42_12\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_TUM_GottBERT_base_last_42_42_12\n",
      "Evaluation results for TUM/GottBERT_base_last with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9622507691383362, 'eval_accuracy': 0.8104575163398693, 'eval_precision': 0.8231703065294397, 'eval_recall': 0.8104575163398693, 'eval_f1': 0.8142358313188288, 'eval_class_distribution': {0: 37, 1: 40, 2: 76}, 'eval_runtime': 2.0565, 'eval_samples_per_second': 74.399, 'eval_steps_per_second': 37.443, 'epoch': 5.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.72      0.86      0.78        36\n",
      "     Neutral       0.59      0.67      0.63        33\n",
      "     Positiv       0.92      0.80      0.85        84\n",
      "\n",
      "    accuracy                           0.78       153\n",
      "   macro avg       0.74      0.78      0.76       153\n",
      "weighted avg       0.80      0.78      0.79       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 43, 1: 37, 2: 73}\n",
      "Negativ Precision Score: 0.7209302325581395\n",
      "Negativ Recall Score: 0.8611111111111112\n",
      "Negativ F1 Score: 0.7848101265822784\n",
      "\n",
      "Neutral Precision Score: 0.5945945945945946\n",
      "Neutral Recall Score: 0.6666666666666666\n",
      "Neutral F1 Score: 0.6285714285714286\n",
      "\n",
      "Positiv Precision Score: 0.9178082191780822\n",
      "Positiv Recall Score: 0.7976190476190477\n",
      "Positiv F1 Score: 0.8535031847133758\n",
      "\n",
      "Macro Average Precision Score: 0.7444443487769389\n",
      "Macro Average Recall Score: 0.775132275132275\n",
      "Macro Average F1 Score: 0.7556282466223609\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/12_epochs/TUM_GottBERT_base_last_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/12_epochs/TUM_GottBERT_base_last_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for distilbert/distilbert-base-german-cased:\n",
      "Training Sentiment label count:  {'positiv': 498, 'neutral': 275, 'negativ': 338}\n",
      "Validation Sentiment label count:  {'positiv': 60, 'neutral': 27, 'negativ': 42}\n",
      "Test Sentiment label count:  {'positiv': 84, 'neutral': 33, 'negativ': 36}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 3870.31 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3261.26 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 3353.95 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for distilbert/distilbert-base-german-cased with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2224' max='6672' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2224/6672 02:17 < 04:34, 16.20 it/s, Epoch 4/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.809900</td>\n",
       "      <td>0.597033</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.864035</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.838656</td>\n",
       "      <td>{0: 57, 1: 24, 2: 48}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.574700</td>\n",
       "      <td>0.615361</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.835170</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.829957</td>\n",
       "      <td>{0: 48, 1: 23, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.494100</td>\n",
       "      <td>0.615135</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.836054</td>\n",
       "      <td>{0: 45, 1: 21, 2: 63}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.286100</td>\n",
       "      <td>0.839471</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.847213</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.822364</td>\n",
       "      <td>{0: 55, 1: 28, 2: 46}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_distilbert_distilbert-base-german-cased_42_42_12\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_distilbert_distilbert-base-german-cased_42_42_12\n",
      "Evaluation results for distilbert/distilbert-base-german-cased with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8538591861724854, 'eval_accuracy': 0.7581699346405228, 'eval_precision': 0.7850672111891964, 'eval_recall': 0.7581699346405228, 'eval_f1': 0.7597698725270837, 'eval_class_distribution': {0: 52, 1: 34, 2: 67}, 'eval_runtime': 1.2053, 'eval_samples_per_second': 126.943, 'eval_steps_per_second': 63.886, 'epoch': 4.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.62      0.97      0.76        36\n",
      "     Neutral       0.68      0.64      0.66        33\n",
      "     Positiv       0.91      0.71      0.80        84\n",
      "\n",
      "    accuracy                           0.76       153\n",
      "   macro avg       0.74      0.77      0.74       153\n",
      "weighted avg       0.79      0.76      0.76       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 56, 1: 31, 2: 66}\n",
      "Negativ Precision Score: 0.625\n",
      "Negativ Recall Score: 0.9722222222222222\n",
      "Negativ F1 Score: 0.7608695652173914\n",
      "\n",
      "Neutral Precision Score: 0.6774193548387096\n",
      "Neutral Recall Score: 0.6363636363636364\n",
      "Neutral F1 Score: 0.65625\n",
      "\n",
      "Positiv Precision Score: 0.9090909090909091\n",
      "Positiv Recall Score: 0.7142857142857143\n",
      "Positiv F1 Score: 0.8\n",
      "\n",
      "Macro Average Precision Score: 0.7371700879765396\n",
      "Macro Average Recall Score: 0.7742905242905244\n",
      "Macro Average F1 Score: 0.7390398550724638\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/12_epochs/distilbert_distilbert-base-german-cased_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/12_epochs/distilbert_distilbert-base-german-cased_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for GerMedBERT/medbert-512:\n",
      "Training Sentiment label count:  {'positiv': 498, 'neutral': 275, 'negativ': 338}\n",
      "Validation Sentiment label count:  {'positiv': 60, 'neutral': 27, 'negativ': 42}\n",
      "Test Sentiment label count:  {'positiv': 84, 'neutral': 33, 'negativ': 36}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Device set to use cuda:0\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GerMedBERT/medbert-512 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 2681.01 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 2422.00 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 2494.79 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for GerMedBERT/medbert-512 with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5004' max='6672' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5004/6672 09:35 < 03:11, 8.70 it/s, Epoch 9/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.878800</td>\n",
       "      <td>0.873218</td>\n",
       "      <td>0.775194</td>\n",
       "      <td>0.777534</td>\n",
       "      <td>0.775194</td>\n",
       "      <td>0.772396</td>\n",
       "      <td>{0: 46, 1: 20, 2: 63}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.555300</td>\n",
       "      <td>0.984977</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.794575</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.787843</td>\n",
       "      <td>{0: 33, 1: 31, 2: 65}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.474100</td>\n",
       "      <td>1.191893</td>\n",
       "      <td>0.775194</td>\n",
       "      <td>0.775666</td>\n",
       "      <td>0.775194</td>\n",
       "      <td>0.771275</td>\n",
       "      <td>{0: 43, 1: 20, 2: 66}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.265400</td>\n",
       "      <td>1.131020</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.789260</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.783659</td>\n",
       "      <td>{0: 49, 1: 25, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.243200</td>\n",
       "      <td>1.283702</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.789147</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.789426</td>\n",
       "      <td>{0: 41, 1: 25, 2: 63}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.160800</td>\n",
       "      <td>1.215056</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.807060</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.806357</td>\n",
       "      <td>{0: 41, 1: 29, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.158400</td>\n",
       "      <td>1.372254</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.798354</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.797200</td>\n",
       "      <td>{0: 39, 1: 25, 2: 65}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.084900</td>\n",
       "      <td>1.407316</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.808251</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.806666</td>\n",
       "      <td>{0: 45, 1: 25, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.059900</td>\n",
       "      <td>1.696144</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.785833</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.770143</td>\n",
       "      <td>{0: 36, 1: 38, 2: 55}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_GerMedBERT_medbert-512_42_42_12\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_GerMedBERT_medbert-512_42_42_12\n",
      "Evaluation results for GerMedBERT/medbert-512 with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.453885793685913, 'eval_accuracy': 0.8169934640522876, 'eval_precision': 0.8192333226385131, 'eval_recall': 0.8169934640522876, 'eval_f1': 0.8168216161720311, 'eval_class_distribution': {0: 41, 1: 33, 2: 79}, 'eval_runtime': 2.1781, 'eval_samples_per_second': 70.245, 'eval_steps_per_second': 35.352, 'epoch': 9.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.73      0.89      0.80        36\n",
      "     Neutral       0.68      0.79      0.73        33\n",
      "     Positiv       0.89      0.75      0.81        84\n",
      "\n",
      "    accuracy                           0.79       153\n",
      "   macro avg       0.77      0.81      0.78       153\n",
      "weighted avg       0.81      0.79      0.79       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 44, 1: 38, 2: 71}\n",
      "Negativ Precision Score: 0.7272727272727273\n",
      "Negativ Recall Score: 0.8888888888888888\n",
      "Negativ F1 Score: 0.8\n",
      "\n",
      "Neutral Precision Score: 0.6842105263157895\n",
      "Neutral Recall Score: 0.7878787878787878\n",
      "Neutral F1 Score: 0.7323943661971831\n",
      "\n",
      "Positiv Precision Score: 0.8873239436619719\n",
      "Positiv Recall Score: 0.75\n",
      "Positiv F1 Score: 0.8129032258064516\n",
      "\n",
      "Macro Average Precision Score: 0.766269065750163\n",
      "Macro Average Recall Score: 0.8089225589225588\n",
      "Macro Average F1 Score: 0.7817658640012116\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/12_epochs/GerMedBERT_medbert-512_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/12_epochs/GerMedBERT_medbert-512_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for deepset/gbert-base:\n",
      "Training Sentiment label count:  {'positiv': 498, 'neutral': 275, 'negativ': 338}\n",
      "Validation Sentiment label count:  {'positiv': 60, 'neutral': 27, 'negativ': 42}\n",
      "Test Sentiment label count:  {'positiv': 84, 'neutral': 33, 'negativ': 36}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 2661.44 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 2451.09 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 2483.02 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for deepset/gbert-base with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2780' max='6672' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2780/6672 05:18 < 07:26, 8.71 it/s, Epoch 5/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.853700</td>\n",
       "      <td>0.772932</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.850111</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.842525</td>\n",
       "      <td>{0: 49, 1: 20, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.535900</td>\n",
       "      <td>0.673803</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>{0: 42, 1: 27, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.485000</td>\n",
       "      <td>0.716973</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.865643</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.864827</td>\n",
       "      <td>{0: 43, 1: 22, 2: 64}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.196800</td>\n",
       "      <td>0.758297</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.863375</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.861308</td>\n",
       "      <td>{0: 45, 1: 27, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.176900</td>\n",
       "      <td>0.988339</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.859291</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.855029</td>\n",
       "      <td>{0: 43, 1: 30, 2: 56}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_deepset_gbert-base_42_42_12\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_deepset_gbert-base_42_42_12\n",
      "Evaluation results for deepset/gbert-base with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8562945127487183, 'eval_accuracy': 0.8169934640522876, 'eval_precision': 0.822554298881415, 'eval_recall': 0.8169934640522876, 'eval_f1': 0.8179301015919039, 'eval_class_distribution': {0: 41, 1: 35, 2: 77}, 'eval_runtime': 2.2069, 'eval_samples_per_second': 69.329, 'eval_steps_per_second': 34.891, 'epoch': 5.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.76      0.89      0.82        36\n",
      "     Neutral       0.66      0.76      0.70        33\n",
      "     Positiv       0.92      0.80      0.85        84\n",
      "\n",
      "    accuracy                           0.81       153\n",
      "   macro avg       0.78      0.81      0.79       153\n",
      "weighted avg       0.83      0.81      0.81       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 42, 1: 38, 2: 73}\n",
      "Negativ Precision Score: 0.7619047619047619\n",
      "Negativ Recall Score: 0.8888888888888888\n",
      "Negativ F1 Score: 0.8205128205128205\n",
      "\n",
      "Neutral Precision Score: 0.6578947368421053\n",
      "Neutral Recall Score: 0.7575757575757576\n",
      "Neutral F1 Score: 0.704225352112676\n",
      "\n",
      "Positiv Precision Score: 0.9178082191780822\n",
      "Positiv Recall Score: 0.7976190476190477\n",
      "Positiv F1 Score: 0.8535031847133758\n",
      "\n",
      "Macro Average Precision Score: 0.7792025726416498\n",
      "Macro Average Recall Score: 0.8146945646945647\n",
      "Macro Average F1 Score: 0.7927471191129575\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/12_epochs/deepset_gbert-base_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/12_epochs/deepset_gbert-base_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(f'training and results for {model}:')\n",
    "    absa_model(data, model, rn1=42, rn2=42, epochs=12, save = True)\n",
    "    print()\n",
    "\n",
    "#early stopping patients = 3, continues when there's any improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "112a2f70-3b25-4d1e-a560-b49801c313f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training and results for google-bert/bert-base-german-cased:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 1676.02 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 2435.17 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 2527.67 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for google-bert/bert-base-german-cased with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6672' max='6672' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6672/6672 12:47, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.855700</td>\n",
       "      <td>0.716623</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.838272</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.825277</td>\n",
       "      <td>{0: 50, 1: 28, 2: 51}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.559500</td>\n",
       "      <td>0.844616</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.824419</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.769514</td>\n",
       "      <td>{0: 64, 1: 25, 2: 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.454400</td>\n",
       "      <td>0.983193</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.813852</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.813603</td>\n",
       "      <td>{0: 43, 1: 25, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.234800</td>\n",
       "      <td>0.940081</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.831297</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.823851</td>\n",
       "      <td>{0: 45, 1: 31, 2: 53}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.218000</td>\n",
       "      <td>1.073637</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.820127</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.815194</td>\n",
       "      <td>{0: 48, 1: 25, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.159200</td>\n",
       "      <td>1.252349</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.806990</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.806249</td>\n",
       "      <td>{0: 40, 1: 29, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.091400</td>\n",
       "      <td>1.338179</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.818806</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.815318</td>\n",
       "      <td>{0: 41, 1: 31, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.065900</td>\n",
       "      <td>1.354868</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.834137</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.830966</td>\n",
       "      <td>{0: 44, 1: 29, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.038900</td>\n",
       "      <td>1.389237</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.844247</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.838833</td>\n",
       "      <td>{0: 46, 1: 29, 2: 54}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>1.463746</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.839788</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.825401</td>\n",
       "      <td>{0: 47, 1: 32, 2: 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>1.542731</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.826207</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.822994</td>\n",
       "      <td>{0: 43, 1: 30, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>1.542705</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.818432</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.815376</td>\n",
       "      <td>{0: 44, 1: 29, 2: 56}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_google-bert_bert-base-german-cased_42_42_12\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_google-bert_bert-base-german-cased_42_42_12\n",
      "Evaluation results for google-bert/bert-base-german-cased with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.006366491317749, 'eval_accuracy': 0.7189542483660131, 'eval_precision': 0.7663681726493292, 'eval_recall': 0.7189542483660131, 'eval_f1': 0.7218794277617807, 'eval_class_distribution': {0: 52, 1: 42, 2: 59}, 'eval_runtime': 2.1847, 'eval_samples_per_second': 70.031, 'eval_steps_per_second': 35.244, 'epoch': 12.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.63      0.92      0.75        36\n",
      "     Neutral       0.64      0.70      0.67        33\n",
      "     Positiv       0.94      0.73      0.82        84\n",
      "\n",
      "    accuracy                           0.76       153\n",
      "   macro avg       0.74      0.78      0.75       153\n",
      "weighted avg       0.80      0.76      0.77       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 52, 1: 36, 2: 65}\n",
      "Negativ Precision Score: 0.6346153846153846\n",
      "Negativ Recall Score: 0.9166666666666666\n",
      "Negativ F1 Score: 0.75\n",
      "\n",
      "Neutral Precision Score: 0.6388888888888888\n",
      "Neutral Recall Score: 0.696969696969697\n",
      "Neutral F1 Score: 0.6666666666666666\n",
      "\n",
      "Positiv Precision Score: 0.9384615384615385\n",
      "Positiv Recall Score: 0.7261904761904762\n",
      "Positiv F1 Score: 0.8187919463087249\n",
      "\n",
      "Macro Average Precision Score: 0.7373219373219374\n",
      "Macro Average Recall Score: 0.77994227994228\n",
      "Macro Average F1 Score: 0.7451528709917971\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/12_epochs/google-bert_bert-base-german-cased_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/12_epochs/google-bert_bert-base-german-cased_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-cased:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 2652.88 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 2456.79 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 2525.91 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for dbmdz/bert-base-german-cased with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3892' max='6672' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3892/6672 07:27 < 05:19, 8.69 it/s, Epoch 7/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.851600</td>\n",
       "      <td>0.803725</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.858408</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.797253</td>\n",
       "      <td>{0: 65, 1: 12, 2: 52}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.612900</td>\n",
       "      <td>0.909515</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.807359</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.803416</td>\n",
       "      <td>{0: 35, 1: 27, 2: 67}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.493500</td>\n",
       "      <td>0.917656</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.848022</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.825901</td>\n",
       "      <td>{0: 55, 1: 17, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.685165</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.859938</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.860107</td>\n",
       "      <td>{0: 43, 1: 26, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.268000</td>\n",
       "      <td>0.898270</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.859042</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.859543</td>\n",
       "      <td>{0: 41, 1: 26, 2: 62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.143700</td>\n",
       "      <td>1.026497</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.859573</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.857790</td>\n",
       "      <td>{0: 46, 1: 22, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.103400</td>\n",
       "      <td>1.122055</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.857593</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.851013</td>\n",
       "      <td>{0: 49, 1: 21, 2: 59}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_dbmdz_bert-base-german-cased_42_42_12\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_dbmdz_bert-base-german-cased_42_42_12\n",
      "Evaluation results for dbmdz/bert-base-german-cased with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3309756517410278, 'eval_accuracy': 0.7908496732026143, 'eval_precision': 0.8278971845148316, 'eval_recall': 0.7908496732026143, 'eval_f1': 0.7959253213868895, 'eval_class_distribution': {0: 40, 1: 48, 2: 65}, 'eval_runtime': 2.2157, 'eval_samples_per_second': 69.051, 'eval_steps_per_second': 34.751, 'epoch': 7.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.79      0.83      0.81        36\n",
      "     Neutral       0.57      0.82      0.68        33\n",
      "     Positiv       0.94      0.76      0.84        84\n",
      "\n",
      "    accuracy                           0.79       153\n",
      "   macro avg       0.77      0.80      0.78       153\n",
      "weighted avg       0.83      0.79      0.80       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 38, 1: 47, 2: 68}\n",
      "Negativ Precision Score: 0.7894736842105263\n",
      "Negativ Recall Score: 0.8333333333333334\n",
      "Negativ F1 Score: 0.8108108108108109\n",
      "\n",
      "Neutral Precision Score: 0.574468085106383\n",
      "Neutral Recall Score: 0.8181818181818182\n",
      "Neutral F1 Score: 0.675\n",
      "\n",
      "Positiv Precision Score: 0.9411764705882353\n",
      "Positiv Recall Score: 0.7619047619047619\n",
      "Positiv F1 Score: 0.8421052631578947\n",
      "\n",
      "Macro Average Precision Score: 0.7683727466350483\n",
      "Macro Average Recall Score: 0.8044733044733045\n",
      "Macro Average F1 Score: 0.7759720246562352\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/12_epochs/dbmdz_bert-base-german-cased_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/12_epochs/dbmdz_bert-base-german-cased_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-uncased:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 2639.90 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 2392.83 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 2449.22 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for dbmdz/bert-base-german-uncased with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6672' max='6672' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6672/6672 12:54, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.869700</td>\n",
       "      <td>0.810844</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.832852</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.828820</td>\n",
       "      <td>{0: 48, 1: 23, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.569800</td>\n",
       "      <td>0.859367</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.839456</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.832531</td>\n",
       "      <td>{0: 42, 1: 32, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.485700</td>\n",
       "      <td>0.811584</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.863299</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.860981</td>\n",
       "      <td>{0: 46, 1: 26, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.329800</td>\n",
       "      <td>1.029312</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.839132</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.813219</td>\n",
       "      <td>{0: 47, 1: 35, 2: 47}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.250700</td>\n",
       "      <td>0.891514</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.844139</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.844246</td>\n",
       "      <td>{0: 43, 1: 25, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.188800</td>\n",
       "      <td>0.904810</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.839428</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.828969</td>\n",
       "      <td>{0: 52, 1: 25, 2: 52}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.123600</td>\n",
       "      <td>0.909692</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.871109</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.868204</td>\n",
       "      <td>{0: 47, 1: 26, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.095600</td>\n",
       "      <td>1.056518</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.863837</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.861626</td>\n",
       "      <td>{0: 43, 1: 29, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.035700</td>\n",
       "      <td>1.221233</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.833507</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.830897</td>\n",
       "      <td>{0: 41, 1: 30, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>1.280209</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.848035</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.839760</td>\n",
       "      <td>{0: 48, 1: 28, 2: 53}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>1.250042</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.841735</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.838424</td>\n",
       "      <td>{0: 46, 1: 27, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>1.267557</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.851717</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.846291</td>\n",
       "      <td>{0: 48, 1: 26, 2: 55}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_dbmdz_bert-base-german-uncased_42_42_12\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_dbmdz_bert-base-german-uncased_42_42_12\n",
      "Evaluation results for dbmdz/bert-base-german-uncased with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7655352354049683, 'eval_accuracy': 0.7320261437908496, 'eval_precision': 0.7672418967587035, 'eval_recall': 0.7320261437908496, 'eval_f1': 0.7363408913013123, 'eval_class_distribution': {0: 49, 1: 40, 2: 64}, 'eval_runtime': 2.1633, 'eval_samples_per_second': 70.726, 'eval_steps_per_second': 35.594, 'epoch': 12.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.62      0.86      0.72        36\n",
      "     Neutral       0.62      0.79      0.69        33\n",
      "     Positiv       0.93      0.68      0.79        84\n",
      "\n",
      "    accuracy                           0.75       153\n",
      "   macro avg       0.72      0.78      0.73       153\n",
      "weighted avg       0.79      0.75      0.75       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 50, 1: 42, 2: 61}\n",
      "Negativ Precision Score: 0.62\n",
      "Negativ Recall Score: 0.8611111111111112\n",
      "Negativ F1 Score: 0.7209302325581395\n",
      "\n",
      "Neutral Precision Score: 0.6190476190476191\n",
      "Neutral Recall Score: 0.7878787878787878\n",
      "Neutral F1 Score: 0.6933333333333334\n",
      "\n",
      "Positiv Precision Score: 0.9344262295081968\n",
      "Positiv Recall Score: 0.6785714285714286\n",
      "Positiv F1 Score: 0.7862068965517242\n",
      "\n",
      "Macro Average Precision Score: 0.7244912828519386\n",
      "Macro Average Recall Score: 0.7758537758537759\n",
      "Macro Average F1 Score: 0.7334901541477322\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/12_epochs/dbmdz_bert-base-german-uncased_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/12_epochs/dbmdz_bert-base-german-uncased_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for FacebookAI/xlm-roberta-base:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 3648.27 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3110.50 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 3215.43 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for FacebookAI/xlm-roberta-base with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6672' max='6672' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6672/6672 17:34, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.935700</td>\n",
       "      <td>0.620074</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.821180</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.775459</td>\n",
       "      <td>{0: 62, 1: 13, 2: 54}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.857400</td>\n",
       "      <td>0.606947</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.838525</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.798129</td>\n",
       "      <td>{0: 61, 1: 16, 2: 52}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.808500</td>\n",
       "      <td>1.137659</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.827962</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.819866</td>\n",
       "      <td>{0: 49, 1: 20, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.541100</td>\n",
       "      <td>1.131197</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.819161</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.813787</td>\n",
       "      <td>{0: 49, 1: 23, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.474100</td>\n",
       "      <td>1.055588</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.823796</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.821870</td>\n",
       "      <td>{0: 46, 1: 25, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.411200</td>\n",
       "      <td>1.040325</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.832080</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.829275</td>\n",
       "      <td>{0: 47, 1: 24, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.338800</td>\n",
       "      <td>1.381436</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.811350</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.797104</td>\n",
       "      <td>{0: 54, 1: 20, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.250200</td>\n",
       "      <td>1.415251</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.830470</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.819454</td>\n",
       "      <td>{0: 32, 1: 33, 2: 64}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.142100</td>\n",
       "      <td>1.174609</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.849488</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.845376</td>\n",
       "      <td>{0: 37, 1: 31, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.137000</td>\n",
       "      <td>1.135929</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.860183</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.859938</td>\n",
       "      <td>{0: 44, 1: 25, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.064300</td>\n",
       "      <td>1.224763</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.860183</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.859938</td>\n",
       "      <td>{0: 44, 1: 25, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.107100</td>\n",
       "      <td>1.183835</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.852366</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.852446</td>\n",
       "      <td>{0: 43, 1: 26, 2: 60}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_FacebookAI_xlm-roberta-base_42_42_12\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_FacebookAI_xlm-roberta-base_42_42_12\n",
      "Evaluation results for FacebookAI/xlm-roberta-base with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3177909851074219, 'eval_accuracy': 0.7777777777777778, 'eval_precision': 0.7908873805932629, 'eval_recall': 0.7777777777777778, 'eval_f1': 0.7824013415924629, 'eval_class_distribution': {0: 35, 1: 40, 2: 78}, 'eval_runtime': 2.0228, 'eval_samples_per_second': 75.638, 'eval_steps_per_second': 38.066, 'epoch': 12.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.83      0.81      0.82        36\n",
      "     Neutral       0.62      0.76      0.68        33\n",
      "     Positiv       0.90      0.83      0.86        84\n",
      "\n",
      "    accuracy                           0.81       153\n",
      "   macro avg       0.78      0.80      0.79       153\n",
      "weighted avg       0.82      0.81      0.81       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 35, 1: 40, 2: 78}\n",
      "Negativ Precision Score: 0.8285714285714286\n",
      "Negativ Recall Score: 0.8055555555555556\n",
      "Negativ F1 Score: 0.8169014084507042\n",
      "\n",
      "Neutral Precision Score: 0.625\n",
      "Neutral Recall Score: 0.7575757575757576\n",
      "Neutral F1 Score: 0.684931506849315\n",
      "\n",
      "Positiv Precision Score: 0.8974358974358975\n",
      "Positiv Recall Score: 0.8333333333333334\n",
      "Positiv F1 Score: 0.8641975308641975\n",
      "\n",
      "Macro Average Precision Score: 0.7836691086691087\n",
      "Macro Average Recall Score: 0.7988215488215489\n",
      "Macro Average F1 Score: 0.7886768153880722\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/12_epochs/FacebookAI_xlm-roberta-base_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/12_epochs/FacebookAI_xlm-roberta-base_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_best:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at TUM/GottBERT_base_best and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 3712.20 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3221.39 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 3272.64 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for TUM/GottBERT_base_best with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6672' max='6672' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6672/6672 13:07, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.891700</td>\n",
       "      <td>0.934055</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.816342</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.788631</td>\n",
       "      <td>{0: 58, 1: 17, 2: 54}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.562300</td>\n",
       "      <td>0.736761</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.863787</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.852160</td>\n",
       "      <td>{0: 52, 1: 21, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.940871</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.843686</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.842311</td>\n",
       "      <td>{0: 44, 1: 22, 2: 63}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.300700</td>\n",
       "      <td>0.966743</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.818203</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.810478</td>\n",
       "      <td>{0: 51, 1: 20, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.329400</td>\n",
       "      <td>0.968592</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.825249</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.818711</td>\n",
       "      <td>{0: 49, 1: 20, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.242200</td>\n",
       "      <td>0.910391</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.847005</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.845773</td>\n",
       "      <td>{0: 43, 1: 28, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.227600</td>\n",
       "      <td>1.197924</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.825419</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.819232</td>\n",
       "      <td>{0: 50, 1: 21, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.202900</td>\n",
       "      <td>0.899163</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.846127</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.838972</td>\n",
       "      <td>{0: 36, 1: 32, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.115700</td>\n",
       "      <td>1.383694</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.836058</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.807359</td>\n",
       "      <td>{0: 36, 1: 41, 2: 52}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.085500</td>\n",
       "      <td>1.106846</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.836862</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.836471</td>\n",
       "      <td>{0: 45, 1: 25, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.046700</td>\n",
       "      <td>1.148554</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.863998</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.861749</td>\n",
       "      <td>{0: 44, 1: 28, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.033800</td>\n",
       "      <td>1.176081</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.854463</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.853318</td>\n",
       "      <td>{0: 44, 1: 27, 2: 58}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_TUM_GottBERT_base_best_42_42_12\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_TUM_GottBERT_base_best_42_42_12\n",
      "Evaluation results for TUM/GottBERT_base_best with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7277506589889526, 'eval_accuracy': 0.7516339869281046, 'eval_precision': 0.7895460121771642, 'eval_recall': 0.7516339869281046, 'eval_f1': 0.7597231758065712, 'eval_class_distribution': {0: 41, 1: 46, 2: 66}, 'eval_runtime': 2.0451, 'eval_samples_per_second': 74.813, 'eval_steps_per_second': 37.651, 'epoch': 12.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.74      0.86      0.79        36\n",
      "     Neutral       0.58      0.76      0.66        33\n",
      "     Positiv       0.91      0.74      0.82        84\n",
      "\n",
      "    accuracy                           0.77       153\n",
      "   macro avg       0.74      0.79      0.76       153\n",
      "weighted avg       0.80      0.77      0.78       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 42, 1: 43, 2: 68}\n",
      "Negativ Precision Score: 0.7380952380952381\n",
      "Negativ Recall Score: 0.8611111111111112\n",
      "Negativ F1 Score: 0.7948717948717948\n",
      "\n",
      "Neutral Precision Score: 0.5813953488372093\n",
      "Neutral Recall Score: 0.7575757575757576\n",
      "Neutral F1 Score: 0.6578947368421053\n",
      "\n",
      "Positiv Precision Score: 0.9117647058823529\n",
      "Positiv Recall Score: 0.7380952380952381\n",
      "Positiv F1 Score: 0.8157894736842105\n",
      "\n",
      "Macro Average Precision Score: 0.7437517642716002\n",
      "Macro Average Recall Score: 0.7855940355940355\n",
      "Macro Average F1 Score: 0.7561853351327036\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/12_epochs/TUM_GottBERT_base_best_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/12_epochs/TUM_GottBERT_base_best_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_filtered_base_best:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at TUM/GottBERT_filtered_base_best and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 3695.60 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3103.33 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 3228.74 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for TUM/GottBERT_filtered_base_best with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6672' max='6672' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6672/6672 13:09, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.893525</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.802395</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.777458</td>\n",
       "      <td>{0: 57, 1: 16, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.535100</td>\n",
       "      <td>0.622440</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>{0: 42, 1: 27, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.505600</td>\n",
       "      <td>0.608511</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.877397</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.873456</td>\n",
       "      <td>{0: 44, 1: 21, 2: 64}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.299600</td>\n",
       "      <td>0.695269</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.886115</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.884297</td>\n",
       "      <td>{0: 45, 1: 27, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.295700</td>\n",
       "      <td>0.800931</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.860653</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.858773</td>\n",
       "      <td>{0: 41, 1: 23, 2: 65}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.231200</td>\n",
       "      <td>0.618526</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.891163</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.891247</td>\n",
       "      <td>{0: 41, 1: 27, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.238500</td>\n",
       "      <td>0.890434</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.860447</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.859088</td>\n",
       "      <td>{0: 43, 1: 23, 2: 63}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.175800</td>\n",
       "      <td>1.060983</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.848106</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.846014</td>\n",
       "      <td>{0: 43, 1: 29, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.113300</td>\n",
       "      <td>0.918313</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.870566</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.862668</td>\n",
       "      <td>{0: 42, 1: 33, 2: 54}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.078500</td>\n",
       "      <td>1.132346</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.846487</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.845227</td>\n",
       "      <td>{0: 45, 1: 26, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.046500</td>\n",
       "      <td>1.207898</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.849487</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.846176</td>\n",
       "      <td>{0: 46, 1: 27, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.042100</td>\n",
       "      <td>1.205743</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.840121</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.837785</td>\n",
       "      <td>{0: 46, 1: 26, 2: 57}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_TUM_GottBERT_filtered_base_best_42_42_12\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_TUM_GottBERT_filtered_base_best_42_42_12\n",
      "Evaluation results for TUM/GottBERT_filtered_base_best with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2134432792663574, 'eval_accuracy': 0.803921568627451, 'eval_precision': 0.8072460563172638, 'eval_recall': 0.803921568627451, 'eval_f1': 0.8050392362148628, 'eval_class_distribution': {0: 38, 1: 35, 2: 80}, 'eval_runtime': 2.1113, 'eval_samples_per_second': 72.466, 'eval_steps_per_second': 36.47, 'epoch': 12.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.84      0.89      0.86        36\n",
      "     Neutral       0.64      0.70      0.67        33\n",
      "     Positiv       0.87      0.82      0.85        84\n",
      "\n",
      "    accuracy                           0.81       153\n",
      "   macro avg       0.78      0.80      0.79       153\n",
      "weighted avg       0.82      0.81      0.81       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 38, 1: 36, 2: 79}\n",
      "Negativ Precision Score: 0.8421052631578947\n",
      "Negativ Recall Score: 0.8888888888888888\n",
      "Negativ F1 Score: 0.8648648648648649\n",
      "\n",
      "Neutral Precision Score: 0.6388888888888888\n",
      "Neutral Recall Score: 0.696969696969697\n",
      "Neutral F1 Score: 0.6666666666666666\n",
      "\n",
      "Positiv Precision Score: 0.8734177215189873\n",
      "Positiv Recall Score: 0.8214285714285714\n",
      "Positiv F1 Score: 0.8466257668711656\n",
      "\n",
      "Macro Average Precision Score: 0.7848039578552569\n",
      "Macro Average Recall Score: 0.8024290524290524\n",
      "Macro Average F1 Score: 0.7927190994675657\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/12_epochs/TUM_GottBERT_filtered_base_best_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/12_epochs/TUM_GottBERT_filtered_base_best_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_last:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at TUM/GottBERT_base_last were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at TUM/GottBERT_base_last and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 3622.04 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3051.66 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 3136.63 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for TUM/GottBERT_base_last with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6672' max='6672' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6672/6672 13:10, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.901800</td>\n",
       "      <td>0.916637</td>\n",
       "      <td>0.759690</td>\n",
       "      <td>0.827061</td>\n",
       "      <td>0.759690</td>\n",
       "      <td>0.750952</td>\n",
       "      <td>{0: 70, 1: 11, 2: 48}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.594300</td>\n",
       "      <td>0.551656</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.831253</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.829784</td>\n",
       "      <td>{0: 45, 1: 25, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.497000</td>\n",
       "      <td>1.007532</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.826873</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.816853</td>\n",
       "      <td>{0: 45, 1: 18, 2: 66}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.295300</td>\n",
       "      <td>0.720128</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.844767</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.844002</td>\n",
       "      <td>{0: 45, 1: 24, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.290900</td>\n",
       "      <td>0.735351</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.844038</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.844293</td>\n",
       "      <td>{0: 41, 1: 26, 2: 62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.258700</td>\n",
       "      <td>0.776919</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.871946</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.862761</td>\n",
       "      <td>{0: 37, 1: 34, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.217300</td>\n",
       "      <td>0.884767</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.855829</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.851981</td>\n",
       "      <td>{0: 48, 1: 23, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.210300</td>\n",
       "      <td>0.851964</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.843051</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.843799</td>\n",
       "      <td>{0: 41, 1: 26, 2: 62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.147900</td>\n",
       "      <td>1.111537</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.875111</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.869887</td>\n",
       "      <td>{0: 41, 1: 32, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.105700</td>\n",
       "      <td>1.210740</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.850041</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.846444</td>\n",
       "      <td>{0: 46, 1: 27, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.055500</td>\n",
       "      <td>1.198847</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.858696</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.854713</td>\n",
       "      <td>{0: 43, 1: 30, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.061600</td>\n",
       "      <td>1.281973</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.850748</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.847005</td>\n",
       "      <td>{0: 44, 1: 29, 2: 56}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_TUM_GottBERT_base_last_42_42_12\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_TUM_GottBERT_base_last_42_42_12\n",
      "Evaluation results for TUM/GottBERT_base_last with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.660540223121643, 'eval_accuracy': 0.8104575163398693, 'eval_precision': 0.843831291218884, 'eval_recall': 0.8104575163398693, 'eval_f1': 0.8161615374626672, 'eval_class_distribution': {0: 39, 1: 47, 2: 67}, 'eval_runtime': 2.0418, 'eval_samples_per_second': 74.934, 'eval_steps_per_second': 37.712, 'epoch': 12.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.74      0.86      0.79        36\n",
      "     Neutral       0.61      0.85      0.71        33\n",
      "     Positiv       0.95      0.74      0.83        84\n",
      "\n",
      "    accuracy                           0.79       153\n",
      "   macro avg       0.77      0.82      0.78       153\n",
      "weighted avg       0.83      0.79      0.80       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 42, 1: 46, 2: 65}\n",
      "Negativ Precision Score: 0.7380952380952381\n",
      "Negativ Recall Score: 0.8611111111111112\n",
      "Negativ F1 Score: 0.7948717948717948\n",
      "\n",
      "Neutral Precision Score: 0.6086956521739131\n",
      "Neutral Recall Score: 0.8484848484848485\n",
      "Neutral F1 Score: 0.7088607594936709\n",
      "\n",
      "Positiv Precision Score: 0.9538461538461539\n",
      "Positiv Recall Score: 0.7380952380952381\n",
      "Positiv F1 Score: 0.8322147651006712\n",
      "\n",
      "Macro Average Precision Score: 0.7668790147051018\n",
      "Macro Average Recall Score: 0.815897065897066\n",
      "Macro Average F1 Score: 0.7786491064887123\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/12_epochs/TUM_GottBERT_base_last_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/12_epochs/TUM_GottBERT_base_last_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for distilbert/distilbert-base-german-cased:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 3690.19 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3206.16 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 3232.25 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for distilbert/distilbert-base-german-cased with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6672' max='6672' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6672/6672 06:54, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.824100</td>\n",
       "      <td>0.651714</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.832567</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.815965</td>\n",
       "      <td>{0: 54, 1: 24, 2: 51}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.597800</td>\n",
       "      <td>0.778695</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.791447</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.789014</td>\n",
       "      <td>{0: 43, 1: 22, 2: 64}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.480200</td>\n",
       "      <td>0.731894</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.839281</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.829628</td>\n",
       "      <td>{0: 50, 1: 21, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.306900</td>\n",
       "      <td>0.756107</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.871737</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.854860</td>\n",
       "      <td>{0: 52, 1: 28, 2: 49}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.283800</td>\n",
       "      <td>0.680210</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.865227</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.860827</td>\n",
       "      <td>{0: 47, 1: 23, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.230100</td>\n",
       "      <td>0.747941</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.825459</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.822867</td>\n",
       "      <td>{0: 42, 1: 30, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.187200</td>\n",
       "      <td>1.083423</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.854538</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.829405</td>\n",
       "      <td>{0: 57, 1: 19, 2: 53}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.107300</td>\n",
       "      <td>0.831728</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.864317</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.861328</td>\n",
       "      <td>{0: 46, 1: 27, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.061700</td>\n",
       "      <td>0.920683</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.844619</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.832717</td>\n",
       "      <td>{0: 47, 1: 31, 2: 51}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.035300</td>\n",
       "      <td>0.975001</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.842061</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.838338</td>\n",
       "      <td>{0: 45, 1: 29, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.020500</td>\n",
       "      <td>1.046519</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.834691</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.830794</td>\n",
       "      <td>{0: 42, 1: 31, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>1.057050</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.834691</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.830794</td>\n",
       "      <td>{0: 42, 1: 31, 2: 56}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_distilbert_distilbert-base-german-cased_42_42_12\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_distilbert_distilbert-base-german-cased_42_42_12\n",
      "Evaluation results for distilbert/distilbert-base-german-cased with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8051081895828247, 'eval_accuracy': 0.7320261437908496, 'eval_precision': 0.7463019938845886, 'eval_recall': 0.7320261437908496, 'eval_f1': 0.7351234336622123, 'eval_class_distribution': {0: 44, 1: 36, 2: 73}, 'eval_runtime': 1.218, 'eval_samples_per_second': 125.612, 'eval_steps_per_second': 63.216, 'epoch': 12.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.60      0.83      0.70        36\n",
      "     Neutral       0.60      0.64      0.62        33\n",
      "     Positiv       0.85      0.69      0.76        84\n",
      "\n",
      "    accuracy                           0.71       153\n",
      "   macro avg       0.68      0.72      0.69       153\n",
      "weighted avg       0.74      0.71      0.72       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 50, 1: 35, 2: 68}\n",
      "Negativ Precision Score: 0.6\n",
      "Negativ Recall Score: 0.8333333333333334\n",
      "Negativ F1 Score: 0.6976744186046512\n",
      "\n",
      "Neutral Precision Score: 0.6\n",
      "Neutral Recall Score: 0.6363636363636364\n",
      "Neutral F1 Score: 0.6176470588235294\n",
      "\n",
      "Positiv Precision Score: 0.8529411764705882\n",
      "Positiv Recall Score: 0.6904761904761905\n",
      "Positiv F1 Score: 0.7631578947368421\n",
      "\n",
      "Macro Average Precision Score: 0.684313725490196\n",
      "Macro Average Recall Score: 0.7200577200577202\n",
      "Macro Average F1 Score: 0.6928264573883408\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/12_epochs/distilbert_distilbert-base-german-cased_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/12_epochs/distilbert_distilbert-base-german-cased_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for GerMedBERT/medbert-512:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Device set to use cuda:0\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GerMedBERT/medbert-512 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 2619.50 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 2377.07 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 2390.58 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for GerMedBERT/medbert-512 with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6672' max='6672' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6672/6672 12:53, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.916500</td>\n",
       "      <td>0.717640</td>\n",
       "      <td>0.775194</td>\n",
       "      <td>0.783074</td>\n",
       "      <td>0.775194</td>\n",
       "      <td>0.775916</td>\n",
       "      <td>{0: 50, 1: 23, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.566900</td>\n",
       "      <td>1.159936</td>\n",
       "      <td>0.775194</td>\n",
       "      <td>0.782902</td>\n",
       "      <td>0.775194</td>\n",
       "      <td>0.772898</td>\n",
       "      <td>{0: 32, 1: 33, 2: 64}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.478500</td>\n",
       "      <td>1.078723</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.812383</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.790531</td>\n",
       "      <td>{0: 44, 1: 15, 2: 70}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.315400</td>\n",
       "      <td>1.460036</td>\n",
       "      <td>0.728682</td>\n",
       "      <td>0.762239</td>\n",
       "      <td>0.728682</td>\n",
       "      <td>0.736847</td>\n",
       "      <td>{0: 39, 1: 40, 2: 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.270400</td>\n",
       "      <td>0.893261</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.824152</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.815751</td>\n",
       "      <td>{0: 50, 1: 25, 2: 54}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.208800</td>\n",
       "      <td>1.010399</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.810039</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.793488</td>\n",
       "      <td>{0: 54, 1: 23, 2: 52}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.207300</td>\n",
       "      <td>1.240560</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.811032</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.807804</td>\n",
       "      <td>{0: 44, 1: 29, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.153500</td>\n",
       "      <td>1.444989</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.830229</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.808636</td>\n",
       "      <td>{0: 34, 1: 40, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.029600</td>\n",
       "      <td>1.500004</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.794636</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.792181</td>\n",
       "      <td>{0: 43, 1: 29, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.027600</td>\n",
       "      <td>1.462218</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.806990</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.806249</td>\n",
       "      <td>{0: 40, 1: 29, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>1.470179</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.814477</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.813644</td>\n",
       "      <td>{0: 39, 1: 29, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.471876</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.814477</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.813644</td>\n",
       "      <td>{0: 39, 1: 29, 2: 61}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_GerMedBERT_medbert-512_42_42_12\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_GerMedBERT_medbert-512_42_42_12\n",
      "Evaluation results for GerMedBERT/medbert-512 with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2331597805023193, 'eval_accuracy': 0.7712418300653595, 'eval_precision': 0.8056298862070228, 'eval_recall': 0.7712418300653595, 'eval_f1': 0.7741878584052047, 'eval_class_distribution': {0: 53, 1: 35, 2: 65}, 'eval_runtime': 2.1632, 'eval_samples_per_second': 70.728, 'eval_steps_per_second': 35.595, 'epoch': 12.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.63      0.94      0.76        36\n",
      "     Neutral       0.75      0.82      0.78        33\n",
      "     Positiv       0.95      0.71      0.82        84\n",
      "\n",
      "    accuracy                           0.79       153\n",
      "   macro avg       0.78      0.83      0.78       153\n",
      "weighted avg       0.83      0.79      0.79       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 54, 1: 36, 2: 63}\n",
      "Negativ Precision Score: 0.6296296296296297\n",
      "Negativ Recall Score: 0.9444444444444444\n",
      "Negativ F1 Score: 0.7555555555555555\n",
      "\n",
      "Neutral Precision Score: 0.75\n",
      "Neutral Recall Score: 0.8181818181818182\n",
      "Neutral F1 Score: 0.782608695652174\n",
      "\n",
      "Positiv Precision Score: 0.9523809523809523\n",
      "Positiv Recall Score: 0.7142857142857143\n",
      "Positiv F1 Score: 0.8163265306122449\n",
      "\n",
      "Macro Average Precision Score: 0.7773368606701941\n",
      "Macro Average Recall Score: 0.8256373256373256\n",
      "Macro Average F1 Score: 0.7848302606066581\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/12_epochs/GerMedBERT_medbert-512_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/12_epochs/GerMedBERT_medbert-512_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for deepset/gbert-base:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 2697.75 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 2428.37 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 2492.78 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for deepset/gbert-base with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6116' max='6672' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6116/6672 11:43 < 01:03, 8.69 it/s, Epoch 11/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.879600</td>\n",
       "      <td>1.028829</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.820040</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.789985</td>\n",
       "      <td>{0: 58, 1: 17, 2: 54}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.555900</td>\n",
       "      <td>0.606031</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.876419</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.875953</td>\n",
       "      <td>{0: 44, 1: 26, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.528900</td>\n",
       "      <td>0.806500</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.861480</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.849033</td>\n",
       "      <td>{0: 48, 1: 18, 2: 63}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.273400</td>\n",
       "      <td>0.748760</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.832803</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.830665</td>\n",
       "      <td>{0: 44, 1: 28, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.233400</td>\n",
       "      <td>0.997604</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.835122</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.835319</td>\n",
       "      <td>{0: 39, 1: 26, 2: 64}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.172900</td>\n",
       "      <td>1.296495</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.819678</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.804576</td>\n",
       "      <td>{0: 42, 1: 35, 2: 52}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.082400</td>\n",
       "      <td>1.102772</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.833598</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.824179</td>\n",
       "      <td>{0: 48, 1: 29, 2: 52}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.059800</td>\n",
       "      <td>1.157991</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.855674</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.851821</td>\n",
       "      <td>{0: 48, 1: 23, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>1.218146</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.856487</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.852531</td>\n",
       "      <td>{0: 48, 1: 24, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.301049</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.854994</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.852463</td>\n",
       "      <td>{0: 47, 1: 25, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.333394</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.854994</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.852463</td>\n",
       "      <td>{0: 47, 1: 25, 2: 57}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_deepset_gbert-base_42_42_12\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_deepset_gbert-base_42_42_12\n",
      "Evaluation results for deepset/gbert-base with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8084350824356079, 'eval_accuracy': 0.7843137254901961, 'eval_precision': 0.8025398405053582, 'eval_recall': 0.7843137254901961, 'eval_f1': 0.7867893626165341, 'eval_class_distribution': {0: 49, 1: 31, 2: 73}, 'eval_runtime': 2.1895, 'eval_samples_per_second': 69.878, 'eval_steps_per_second': 35.167, 'epoch': 11.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.58      0.89      0.70        36\n",
      "     Neutral       0.69      0.76      0.72        33\n",
      "     Positiv       0.90      0.67      0.77        84\n",
      "\n",
      "    accuracy                           0.74       153\n",
      "   macro avg       0.73      0.77      0.73       153\n",
      "weighted avg       0.78      0.74      0.74       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 55, 1: 36, 2: 62}\n",
      "Negativ Precision Score: 0.5818181818181818\n",
      "Negativ Recall Score: 0.8888888888888888\n",
      "Negativ F1 Score: 0.7032967032967034\n",
      "\n",
      "Neutral Precision Score: 0.6944444444444444\n",
      "Neutral Recall Score: 0.7575757575757576\n",
      "Neutral F1 Score: 0.7246376811594203\n",
      "\n",
      "Positiv Precision Score: 0.9032258064516129\n",
      "Positiv Recall Score: 0.6666666666666666\n",
      "Positiv F1 Score: 0.7671232876712328\n",
      "\n",
      "Macro Average Precision Score: 0.7264961442380797\n",
      "Macro Average Recall Score: 0.7710437710437711\n",
      "Macro Average F1 Score: 0.7316858907091189\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/12_epochs/deepset_gbert-base_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/12_epochs/deepset_gbert-base_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(f'training and results for {model}:')\n",
    "    absa_model(data, model, rn1=42, rn2=42, epochs=12, save = True)\n",
    "    print()\n",
    "\n",
    "# v2: early stopping patients = 3, continues when there's any improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a850f860-aced-4518-878c-02ba0c510e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 2243.73 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 2391.09 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 2456.98 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for aari1995/German_Sentiment with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5560' max='6672' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [5560/6672 30:33 < 06:06, 3.03 it/s, Epoch 10/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.849700</td>\n",
       "      <td>0.632475</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>{0: 42, 1: 27, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.571600</td>\n",
       "      <td>0.470746</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.868853</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.868300</td>\n",
       "      <td>{0: 44, 1: 26, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.493200</td>\n",
       "      <td>0.620570</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.885332</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.875285</td>\n",
       "      <td>{0: 51, 1: 21, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.262600</td>\n",
       "      <td>0.663084</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.892821</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.890486</td>\n",
       "      <td>{0: 46, 1: 23, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.251400</td>\n",
       "      <td>1.012527</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.861878</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.861088</td>\n",
       "      <td>{0: 42, 1: 28, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.173300</td>\n",
       "      <td>0.967994</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.872171</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.864105</td>\n",
       "      <td>{0: 39, 1: 33, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.135600</td>\n",
       "      <td>0.689719</td>\n",
       "      <td>0.899225</td>\n",
       "      <td>0.900623</td>\n",
       "      <td>0.899225</td>\n",
       "      <td>0.899837</td>\n",
       "      <td>{0: 42, 1: 28, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.073100</td>\n",
       "      <td>0.741803</td>\n",
       "      <td>0.899225</td>\n",
       "      <td>0.903360</td>\n",
       "      <td>0.899225</td>\n",
       "      <td>0.900654</td>\n",
       "      <td>{0: 41, 1: 30, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.996164</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>{0: 42, 1: 27, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>1.108757</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.884437</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.883982</td>\n",
       "      <td>{0: 41, 1: 28, 2: 60}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_aari1995_German_Sentiment_42_42_12\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_aari1995_German_Sentiment_42_42_12\n",
      "Evaluation results for aari1995/German_Sentiment with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1062209606170654, 'eval_accuracy': 0.8562091503267973, 'eval_precision': 0.8640330576294835, 'eval_recall': 0.8562091503267973, 'eval_f1': 0.8591271587212916, 'eval_class_distribution': {0: 37, 1: 37, 2: 79}, 'eval_runtime': 5.6586, 'eval_samples_per_second': 27.038, 'eval_steps_per_second': 13.608, 'epoch': 10.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.89      0.92      0.90        36\n",
      "     Neutral       0.65      0.73      0.69        33\n",
      "     Positiv       0.92      0.87      0.90        84\n",
      "\n",
      "    accuracy                           0.85       153\n",
      "   macro avg       0.82      0.84      0.83       153\n",
      "weighted avg       0.86      0.85      0.85       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 37, 1: 37, 2: 79}\n",
      "Negativ Precision Score: 0.8918918918918919\n",
      "Negativ Recall Score: 0.9166666666666666\n",
      "Negativ F1 Score: 0.9041095890410958\n",
      "\n",
      "Neutral Precision Score: 0.6486486486486487\n",
      "Neutral Recall Score: 0.7272727272727273\n",
      "Neutral F1 Score: 0.6857142857142857\n",
      "\n",
      "Positiv Precision Score: 0.9240506329113924\n",
      "Positiv Recall Score: 0.8690476190476191\n",
      "Positiv F1 Score: 0.8957055214723927\n",
      "\n",
      "Macro Average Precision Score: 0.8215303911506444\n",
      "Macro Average Recall Score: 0.8376623376623377\n",
      "Macro Average F1 Score: 0.8285097987425915\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/12_epochs/aari1995_German_Sentiment_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/12_epochs/aari1995_German_Sentiment_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n"
     ]
    }
   ],
   "source": [
    "absa_model(data, \"aari1995/German_Sentiment\", rn1=42, rn2=42, epochs=12, save = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45c1c0ac-4bd6-40fc-8f1e-0a6f286da8aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training and results for google-bert/bert-base-german-cased:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 1772.89 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 2565.37 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 2636.81 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for google-bert/bert-base-german-cased with 20 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8340' max='11120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 8340/11120 16:24 < 05:28, 8.47 it/s, Epoch 15/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.874900</td>\n",
       "      <td>0.715817</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.799801</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.776017</td>\n",
       "      <td>{0: 57, 1: 16, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.549200</td>\n",
       "      <td>0.956716</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.790348</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.790180</td>\n",
       "      <td>{0: 42, 1: 25, 2: 62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.441700</td>\n",
       "      <td>0.941463</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.798715</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.796516</td>\n",
       "      <td>{0: 43, 1: 22, 2: 64}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.283400</td>\n",
       "      <td>0.959174</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.842880</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.812816</td>\n",
       "      <td>{0: 58, 1: 17, 2: 54}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.247000</td>\n",
       "      <td>1.418789</td>\n",
       "      <td>0.775194</td>\n",
       "      <td>0.781000</td>\n",
       "      <td>0.775194</td>\n",
       "      <td>0.772407</td>\n",
       "      <td>{0: 49, 1: 19, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.152000</td>\n",
       "      <td>1.385458</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.792307</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.779951</td>\n",
       "      <td>{0: 50, 1: 18, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.127600</td>\n",
       "      <td>1.448598</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.821365</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.807301</td>\n",
       "      <td>{0: 52, 1: 20, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.053900</td>\n",
       "      <td>1.470951</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.822220</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.809309</td>\n",
       "      <td>{0: 52, 1: 23, 2: 54}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.021500</td>\n",
       "      <td>1.950188</td>\n",
       "      <td>0.751938</td>\n",
       "      <td>0.761197</td>\n",
       "      <td>0.751938</td>\n",
       "      <td>0.754659</td>\n",
       "      <td>{0: 44, 1: 31, 2: 54}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.053100</td>\n",
       "      <td>1.655297</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.805118</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.800807</td>\n",
       "      <td>{0: 46, 1: 27, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.029000</td>\n",
       "      <td>1.625990</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.796571</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.787230</td>\n",
       "      <td>{0: 45, 1: 31, 2: 53}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.027800</td>\n",
       "      <td>1.846215</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.809955</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.807518</td>\n",
       "      <td>{0: 45, 1: 27, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.943364</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.799745</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.799018</td>\n",
       "      <td>{0: 42, 1: 28, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.983580</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.799745</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.799018</td>\n",
       "      <td>{0: 42, 1: 28, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.985937</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.799745</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.799018</td>\n",
       "      <td>{0: 42, 1: 28, 2: 59}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_google-bert_bert-base-german-cased_42_42_20\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_google-bert_bert-base-german-cased_42_42_20\n",
      "Evaluation results for google-bert/bert-base-german-cased with 20 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4151344299316406, 'eval_accuracy': 0.7320261437908496, 'eval_precision': 0.7789244352711845, 'eval_recall': 0.7320261437908496, 'eval_f1': 0.7374777868136502, 'eval_class_distribution': {0: 57, 1: 33, 2: 63}, 'eval_runtime': 2.1683, 'eval_samples_per_second': 70.562, 'eval_steps_per_second': 35.511, 'epoch': 15.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.57      0.92      0.70        36\n",
      "     Neutral       0.64      0.64      0.64        33\n",
      "     Positiv       0.92      0.68      0.78        84\n",
      "\n",
      "    accuracy                           0.73       153\n",
      "   macro avg       0.71      0.74      0.71       153\n",
      "weighted avg       0.78      0.73      0.73       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 58, 1: 33, 2: 62}\n",
      "Negativ Precision Score: 0.5689655172413793\n",
      "Negativ Recall Score: 0.9166666666666666\n",
      "Negativ F1 Score: 0.7021276595744681\n",
      "\n",
      "Neutral Precision Score: 0.6363636363636364\n",
      "Neutral Recall Score: 0.6363636363636364\n",
      "Neutral F1 Score: 0.6363636363636364\n",
      "\n",
      "Positiv Precision Score: 0.9193548387096774\n",
      "Positiv Recall Score: 0.6785714285714286\n",
      "Positiv F1 Score: 0.7808219178082192\n",
      "\n",
      "Macro Average Precision Score: 0.7082279974382311\n",
      "Macro Average Recall Score: 0.7438672438672439\n",
      "Macro Average F1 Score: 0.7064377379154413\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/20_epochs/google-bert_bert-base-german-cased_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/20_epochs/google-bert_bert-base-german-cased_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-cased:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 2822.61 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 2561.66 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 2658.79 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for dbmdz/bert-base-german-cased with 20 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8340' max='11120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 8340/11120 16:33 < 05:31, 8.40 it/s, Epoch 15/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.894000</td>\n",
       "      <td>0.976164</td>\n",
       "      <td>0.759690</td>\n",
       "      <td>0.829637</td>\n",
       "      <td>0.759690</td>\n",
       "      <td>0.759899</td>\n",
       "      <td>{0: 69, 1: 15, 2: 45}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.607900</td>\n",
       "      <td>0.543642</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.858722</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.847329</td>\n",
       "      <td>{0: 49, 1: 29, 2: 51}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.537900</td>\n",
       "      <td>1.132337</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.856758</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.827854</td>\n",
       "      <td>{0: 57, 1: 17, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.357600</td>\n",
       "      <td>0.871422</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.837559</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.832973</td>\n",
       "      <td>{0: 43, 1: 20, 2: 66}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.327000</td>\n",
       "      <td>1.041170</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.829314</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.820907</td>\n",
       "      <td>{0: 50, 1: 21, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.253500</td>\n",
       "      <td>0.795151</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.878402</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.871175</td>\n",
       "      <td>{0: 47, 1: 28, 2: 54}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.193700</td>\n",
       "      <td>1.332279</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.842880</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.812816</td>\n",
       "      <td>{0: 58, 1: 17, 2: 54}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.154200</td>\n",
       "      <td>1.244324</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.849976</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.838090</td>\n",
       "      <td>{0: 52, 1: 22, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.069100</td>\n",
       "      <td>1.106597</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.878879</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.876812</td>\n",
       "      <td>{0: 45, 1: 27, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.027900</td>\n",
       "      <td>1.357720</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.824888</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.818919</td>\n",
       "      <td>{0: 47, 1: 20, 2: 62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>1.235643</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.853544</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.849548</td>\n",
       "      <td>{0: 48, 1: 21, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>1.271766</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.879686</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.876415</td>\n",
       "      <td>{0: 47, 1: 25, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.303976</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.881528</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.876640</td>\n",
       "      <td>{0: 48, 1: 24, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.210129</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.876960</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.875282</td>\n",
       "      <td>{0: 46, 1: 24, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.325763</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.874585</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.874970</td>\n",
       "      <td>{0: 43, 1: 25, 2: 61}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_dbmdz_bert-base-german-cased_42_42_20\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_dbmdz_bert-base-german-cased_42_42_20\n",
      "Evaluation results for dbmdz/bert-base-german-cased with 20 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.936912178993225, 'eval_accuracy': 0.7647058823529411, 'eval_precision': 0.8043127619598207, 'eval_recall': 0.7647058823529411, 'eval_f1': 0.7716849671045181, 'eval_class_distribution': {0: 37, 1: 50, 2: 66}, 'eval_runtime': 2.1878, 'eval_samples_per_second': 69.933, 'eval_steps_per_second': 35.195, 'epoch': 15.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.77      0.83      0.80        36\n",
      "     Neutral       0.57      0.88      0.69        33\n",
      "     Positiv       0.94      0.70      0.80        84\n",
      "\n",
      "    accuracy                           0.77       153\n",
      "   macro avg       0.76      0.80      0.76       153\n",
      "weighted avg       0.82      0.77      0.78       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 39, 1: 51, 2: 63}\n",
      "Negativ Precision Score: 0.7692307692307693\n",
      "Negativ Recall Score: 0.8333333333333334\n",
      "Negativ F1 Score: 0.8\n",
      "\n",
      "Neutral Precision Score: 0.5686274509803921\n",
      "Neutral Recall Score: 0.8787878787878788\n",
      "Neutral F1 Score: 0.6904761904761905\n",
      "\n",
      "Positiv Precision Score: 0.9365079365079365\n",
      "Positiv Recall Score: 0.7023809523809523\n",
      "Positiv F1 Score: 0.8027210884353742\n",
      "\n",
      "Macro Average Precision Score: 0.7581220522396993\n",
      "Macro Average Recall Score: 0.8048340548340548\n",
      "Macro Average F1 Score: 0.7643990929705216\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/20_epochs/dbmdz_bert-base-german-cased_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/20_epochs/dbmdz_bert-base-german-cased_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-uncased:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 2792.10 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 2542.11 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 2617.04 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for dbmdz/bert-base-german-uncased with 20 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6116' max='11120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 6116/11120 12:06 < 09:54, 8.41 it/s, Epoch 11/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.808300</td>\n",
       "      <td>0.861836</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.819727</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.784087</td>\n",
       "      <td>{0: 61, 1: 15, 2: 53}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.524400</td>\n",
       "      <td>0.531516</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.854524</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.851045</td>\n",
       "      <td>{0: 37, 1: 25, 2: 67}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.468400</td>\n",
       "      <td>0.760759</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.873754</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.844515</td>\n",
       "      <td>{0: 56, 1: 17, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.258200</td>\n",
       "      <td>0.734496</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.859031</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.851789</td>\n",
       "      <td>{0: 50, 1: 22, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.232100</td>\n",
       "      <td>1.220612</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.838147</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.810177</td>\n",
       "      <td>{0: 27, 1: 34, 2: 68}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.169200</td>\n",
       "      <td>0.887318</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.828936</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.828354</td>\n",
       "      <td>{0: 39, 1: 26, 2: 64}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.121300</td>\n",
       "      <td>1.059194</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.858500</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.853526</td>\n",
       "      <td>{0: 48, 1: 26, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.084600</td>\n",
       "      <td>0.917130</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.871894</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.868089</td>\n",
       "      <td>{0: 47, 1: 23, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>1.136773</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.862556</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.861009</td>\n",
       "      <td>{0: 45, 1: 26, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>1.279904</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.854931</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.851534</td>\n",
       "      <td>{0: 46, 1: 22, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.011800</td>\n",
       "      <td>1.403898</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.836125</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.834393</td>\n",
       "      <td>{0: 42, 1: 22, 2: 65}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_dbmdz_bert-base-german-uncased_42_42_20\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_dbmdz_bert-base-german-uncased_42_42_20\n",
      "Evaluation results for dbmdz/bert-base-german-uncased with 20 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.244220733642578, 'eval_accuracy': 0.7254901960784313, 'eval_precision': 0.7438864291236209, 'eval_recall': 0.7254901960784313, 'eval_f1': 0.7273543734727045, 'eval_class_distribution': {0: 50, 1: 31, 2: 72}, 'eval_runtime': 2.1729, 'eval_samples_per_second': 70.412, 'eval_steps_per_second': 35.436, 'epoch': 11.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.64      0.89      0.74        36\n",
      "     Neutral       0.66      0.64      0.65        33\n",
      "     Positiv       0.90      0.76      0.83        84\n",
      "\n",
      "    accuracy                           0.76       153\n",
      "   macro avg       0.73      0.76      0.74       153\n",
      "weighted avg       0.79      0.76      0.77       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 50, 1: 32, 2: 71}\n",
      "Negativ Precision Score: 0.64\n",
      "Negativ Recall Score: 0.8888888888888888\n",
      "Negativ F1 Score: 0.7441860465116279\n",
      "\n",
      "Neutral Precision Score: 0.65625\n",
      "Neutral Recall Score: 0.6363636363636364\n",
      "Neutral F1 Score: 0.6461538461538462\n",
      "\n",
      "Positiv Precision Score: 0.9014084507042254\n",
      "Positiv Recall Score: 0.7619047619047619\n",
      "Positiv F1 Score: 0.8258064516129032\n",
      "\n",
      "Macro Average Precision Score: 0.7325528169014085\n",
      "Macro Average Recall Score: 0.7623857623857623\n",
      "Macro Average F1 Score: 0.7387154480927923\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/20_epochs/dbmdz_bert-base-german-uncased_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/20_epochs/dbmdz_bert-base-german-uncased_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for FacebookAI/xlm-roberta-base:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 3844.90 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3377.48 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 3464.42 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for FacebookAI/xlm-roberta-base with 20 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6116' max='11120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 6116/11120 16:04 < 13:09, 6.34 it/s, Epoch 11/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.924700</td>\n",
       "      <td>0.521425</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.848854</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.838761</td>\n",
       "      <td>{0: 51, 1: 23, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.773800</td>\n",
       "      <td>0.904179</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.800519</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.776927</td>\n",
       "      <td>{0: 53, 1: 15, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.830500</td>\n",
       "      <td>1.142046</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.834677</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.801752</td>\n",
       "      <td>{0: 60, 1: 16, 2: 53}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.529800</td>\n",
       "      <td>1.083167</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.823026</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.812844</td>\n",
       "      <td>{0: 52, 1: 21, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.466500</td>\n",
       "      <td>1.230084</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.782010</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.782416</td>\n",
       "      <td>{0: 41, 1: 27, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.496700</td>\n",
       "      <td>1.257094</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.820342</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.809644</td>\n",
       "      <td>{0: 49, 1: 28, 2: 52}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>1.277421</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.829018</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.795726</td>\n",
       "      <td>{0: 59, 1: 16, 2: 54}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.317700</td>\n",
       "      <td>0.934092</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.840279</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.838276</td>\n",
       "      <td>{0: 44, 1: 28, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.246400</td>\n",
       "      <td>1.176097</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.842225</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.825926</td>\n",
       "      <td>{0: 42, 1: 36, 2: 51}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.195300</td>\n",
       "      <td>1.267008</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.824883</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.822435</td>\n",
       "      <td>{0: 46, 1: 26, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.185100</td>\n",
       "      <td>1.381958</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.822918</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.815937</td>\n",
       "      <td>{0: 49, 1: 25, 2: 55}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_FacebookAI_xlm-roberta-base_42_42_20\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_FacebookAI_xlm-roberta-base_42_42_20\n",
      "Evaluation results for FacebookAI/xlm-roberta-base with 20 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6734592318534851, 'eval_accuracy': 0.7973856209150327, 'eval_precision': 0.794736441789639, 'eval_recall': 0.7973856209150327, 'eval_f1': 0.7938625979349961, 'eval_class_distribution': {0: 41, 1: 27, 2: 85}, 'eval_runtime': 2.0051, 'eval_samples_per_second': 76.305, 'eval_steps_per_second': 38.402, 'epoch': 11.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.72      0.86      0.78        36\n",
      "     Neutral       0.65      0.52      0.58        33\n",
      "     Positiv       0.86      0.86      0.86        84\n",
      "\n",
      "    accuracy                           0.78       153\n",
      "   macro avg       0.74      0.74      0.74       153\n",
      "weighted avg       0.78      0.78      0.78       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 43, 1: 26, 2: 84}\n",
      "Negativ Precision Score: 0.7209302325581395\n",
      "Negativ Recall Score: 0.8611111111111112\n",
      "Negativ F1 Score: 0.7848101265822784\n",
      "\n",
      "Neutral Precision Score: 0.6538461538461539\n",
      "Neutral Recall Score: 0.5151515151515151\n",
      "Neutral F1 Score: 0.576271186440678\n",
      "\n",
      "Positiv Precision Score: 0.8571428571428571\n",
      "Positiv Recall Score: 0.8571428571428571\n",
      "Positiv F1 Score: 0.8571428571428571\n",
      "\n",
      "Macro Average Precision Score: 0.7439730811823835\n",
      "Macro Average Recall Score: 0.7444684944684945\n",
      "Macro Average F1 Score: 0.7394080567219379\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/20_epochs/FacebookAI_xlm-roberta-base_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/20_epochs/FacebookAI_xlm-roberta-base_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_best:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at TUM/GottBERT_base_best and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 3932.38 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3413.51 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 3490.29 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for TUM/GottBERT_base_best with 20 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11120' max='11120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11120/11120 22:35, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.878400</td>\n",
       "      <td>0.916075</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.830776</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.792119</td>\n",
       "      <td>{0: 60, 1: 14, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.583200</td>\n",
       "      <td>0.810420</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.833879</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.823552</td>\n",
       "      <td>{0: 36, 1: 35, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.521800</td>\n",
       "      <td>0.874525</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.819373</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.818624</td>\n",
       "      <td>{0: 44, 1: 22, 2: 63}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.345200</td>\n",
       "      <td>0.641003</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.876881</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.863263</td>\n",
       "      <td>{0: 51, 1: 27, 2: 51}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.332900</td>\n",
       "      <td>0.922862</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.854126</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.852424</td>\n",
       "      <td>{0: 38, 1: 29, 2: 62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.266400</td>\n",
       "      <td>0.632766</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.869791</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.868493</td>\n",
       "      <td>{0: 45, 1: 26, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.274400</td>\n",
       "      <td>0.925601</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.839627</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.817479</td>\n",
       "      <td>{0: 52, 1: 16, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.252100</td>\n",
       "      <td>0.941017</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.830715</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.827903</td>\n",
       "      <td>{0: 46, 1: 22, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.196600</td>\n",
       "      <td>1.157889</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.809258</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.806662</td>\n",
       "      <td>{0: 38, 1: 30, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.174500</td>\n",
       "      <td>1.037245</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.830995</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.825802</td>\n",
       "      <td>{0: 48, 1: 20, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.141500</td>\n",
       "      <td>0.835880</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.853086</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.852666</td>\n",
       "      <td>{0: 44, 1: 26, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.127700</td>\n",
       "      <td>1.023197</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.839161</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.837824</td>\n",
       "      <td>{0: 40, 1: 29, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.097200</td>\n",
       "      <td>1.232079</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.844062</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.844427</td>\n",
       "      <td>{0: 42, 1: 26, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.051900</td>\n",
       "      <td>1.161217</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.869614</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.868642</td>\n",
       "      <td>{0: 44, 1: 27, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.051200</td>\n",
       "      <td>1.245445</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.844192</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.844273</td>\n",
       "      <td>{0: 43, 1: 25, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.041000</td>\n",
       "      <td>1.558390</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.813638</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.804856</td>\n",
       "      <td>{0: 51, 1: 21, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.034500</td>\n",
       "      <td>1.307361</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.847858</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.839780</td>\n",
       "      <td>{0: 42, 1: 33, 2: 54}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.019800</td>\n",
       "      <td>1.331971</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.849336</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.846278</td>\n",
       "      <td>{0: 45, 1: 28, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.014400</td>\n",
       "      <td>1.393974</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.847199</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.845185</td>\n",
       "      <td>{0: 46, 1: 26, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.005100</td>\n",
       "      <td>1.372101</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.839820</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.837922</td>\n",
       "      <td>{0: 45, 1: 27, 2: 57}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_TUM_GottBERT_base_best_42_42_20\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_TUM_GottBERT_base_best_42_42_20\n",
      "Evaluation results for TUM/GottBERT_base_best with 20 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.010373830795288, 'eval_accuracy': 0.7450980392156863, 'eval_precision': 0.7773233302645067, 'eval_recall': 0.7450980392156863, 'eval_f1': 0.748923840480934, 'eval_class_distribution': {0: 52, 1: 35, 2: 66}, 'eval_runtime': 2.023, 'eval_samples_per_second': 75.629, 'eval_steps_per_second': 38.062, 'epoch': 20.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.62      0.89      0.73        36\n",
      "     Neutral       0.68      0.70      0.69        33\n",
      "     Positiv       0.94      0.75      0.83        84\n",
      "\n",
      "    accuracy                           0.77       153\n",
      "   macro avg       0.74      0.78      0.75       153\n",
      "weighted avg       0.81      0.77      0.78       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 52, 1: 34, 2: 67}\n",
      "Negativ Precision Score: 0.6153846153846154\n",
      "Negativ Recall Score: 0.8888888888888888\n",
      "Negativ F1 Score: 0.7272727272727273\n",
      "\n",
      "Neutral Precision Score: 0.6764705882352942\n",
      "Neutral Recall Score: 0.696969696969697\n",
      "Neutral F1 Score: 0.6865671641791045\n",
      "\n",
      "Positiv Precision Score: 0.9402985074626866\n",
      "Positiv Recall Score: 0.75\n",
      "Positiv F1 Score: 0.8344370860927153\n",
      "\n",
      "Macro Average Precision Score: 0.7440512370275321\n",
      "Macro Average Recall Score: 0.7786195286195285\n",
      "Macro Average F1 Score: 0.7494256591815157\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/20_epochs/TUM_GottBERT_base_best_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/20_epochs/TUM_GottBERT_base_best_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_filtered_base_best:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at TUM/GottBERT_filtered_base_best and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 3906.12 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3383.46 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 3448.13 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for TUM/GottBERT_filtered_base_best with 20 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8896' max='11120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 8896/11120 18:02 < 04:30, 8.22 it/s, Epoch 16/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.827400</td>\n",
       "      <td>1.032586</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.804786</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.770646</td>\n",
       "      <td>{0: 60, 1: 23, 2: 46}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.543900</td>\n",
       "      <td>0.608068</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.883361</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.883164</td>\n",
       "      <td>{0: 42, 1: 25, 2: 62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.515100</td>\n",
       "      <td>0.621424</td>\n",
       "      <td>0.899225</td>\n",
       "      <td>0.899893</td>\n",
       "      <td>0.899225</td>\n",
       "      <td>0.898154</td>\n",
       "      <td>{0: 44, 1: 23, 2: 62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.302700</td>\n",
       "      <td>0.663368</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.878508</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.860882</td>\n",
       "      <td>{0: 52, 1: 19, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.321100</td>\n",
       "      <td>0.704264</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.892073</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.890345</td>\n",
       "      <td>{0: 43, 1: 23, 2: 63}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.244500</td>\n",
       "      <td>0.678609</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.867571</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.861635</td>\n",
       "      <td>{0: 48, 1: 27, 2: 54}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.239800</td>\n",
       "      <td>0.858771</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.866970</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.860743</td>\n",
       "      <td>{0: 49, 1: 23, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.230400</td>\n",
       "      <td>0.781542</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.881229</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.874742</td>\n",
       "      <td>{0: 48, 1: 21, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.155700</td>\n",
       "      <td>0.616346</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.892183</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.890891</td>\n",
       "      <td>{0: 45, 1: 24, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.102100</td>\n",
       "      <td>0.749528</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.891610</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.884926</td>\n",
       "      <td>{0: 49, 1: 25, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.046900</td>\n",
       "      <td>0.754960</td>\n",
       "      <td>0.914729</td>\n",
       "      <td>0.914982</td>\n",
       "      <td>0.914729</td>\n",
       "      <td>0.914437</td>\n",
       "      <td>{0: 44, 1: 25, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.027600</td>\n",
       "      <td>0.715926</td>\n",
       "      <td>0.899225</td>\n",
       "      <td>0.901921</td>\n",
       "      <td>0.899225</td>\n",
       "      <td>0.898858</td>\n",
       "      <td>{0: 46, 1: 23, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.022100</td>\n",
       "      <td>0.750004</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.908279</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.906126</td>\n",
       "      <td>{0: 45, 1: 23, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>0.893561</td>\n",
       "      <td>0.899225</td>\n",
       "      <td>0.900319</td>\n",
       "      <td>0.899225</td>\n",
       "      <td>0.897517</td>\n",
       "      <td>{0: 45, 1: 22, 2: 62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.926917</td>\n",
       "      <td>0.899225</td>\n",
       "      <td>0.901921</td>\n",
       "      <td>0.899225</td>\n",
       "      <td>0.898858</td>\n",
       "      <td>{0: 46, 1: 23, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.863061</td>\n",
       "      <td>0.899225</td>\n",
       "      <td>0.900588</td>\n",
       "      <td>0.899225</td>\n",
       "      <td>0.899274</td>\n",
       "      <td>{0: 45, 1: 25, 2: 59}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_TUM_GottBERT_filtered_base_best_42_42_20\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_TUM_GottBERT_filtered_base_best_42_42_20\n",
      "Evaluation results for TUM/GottBERT_filtered_base_best with 20 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5799249410629272, 'eval_accuracy': 0.8104575163398693, 'eval_precision': 0.8175262664426751, 'eval_recall': 0.8104575163398693, 'eval_f1': 0.8127208440933932, 'eval_class_distribution': {0: 38, 1: 37, 2: 78}, 'eval_runtime': 2.0265, 'eval_samples_per_second': 75.501, 'eval_steps_per_second': 37.997, 'epoch': 16.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.84      0.86      0.85        36\n",
      "     Neutral       0.68      0.76      0.71        33\n",
      "     Positiv       0.91      0.86      0.88        84\n",
      "\n",
      "    accuracy                           0.84       153\n",
      "   macro avg       0.81      0.83      0.82       153\n",
      "weighted avg       0.84      0.84      0.84       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 37, 1: 37, 2: 79}\n",
      "Negativ Precision Score: 0.8378378378378378\n",
      "Negativ Recall Score: 0.8611111111111112\n",
      "Negativ F1 Score: 0.8493150684931506\n",
      "\n",
      "Neutral Precision Score: 0.6756756756756757\n",
      "Neutral Recall Score: 0.7575757575757576\n",
      "Neutral F1 Score: 0.7142857142857143\n",
      "\n",
      "Positiv Precision Score: 0.9113924050632911\n",
      "Positiv Recall Score: 0.8571428571428571\n",
      "Positiv F1 Score: 0.8834355828220859\n",
      "\n",
      "Macro Average Precision Score: 0.8083019728589349\n",
      "Macro Average Recall Score: 0.8252765752765753\n",
      "Macro Average F1 Score: 0.8156787885336504\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/20_epochs/TUM_GottBERT_filtered_base_best_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/20_epochs/TUM_GottBERT_filtered_base_best_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_last:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at TUM/GottBERT_base_last were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at TUM/GottBERT_base_last and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 3937.27 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3408.07 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 3498.70 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for TUM/GottBERT_base_last with 20 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='11120' max='11120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [11120/11120 22:39, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.889800</td>\n",
       "      <td>1.086711</td>\n",
       "      <td>0.736434</td>\n",
       "      <td>0.847252</td>\n",
       "      <td>0.736434</td>\n",
       "      <td>0.708801</td>\n",
       "      <td>{0: 75, 1: 5, 2: 49}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.595500</td>\n",
       "      <td>0.647895</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.861988</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.860612</td>\n",
       "      <td>{0: 39, 1: 29, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.502800</td>\n",
       "      <td>1.264444</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.805407</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.780736</td>\n",
       "      <td>{0: 46, 1: 14, 2: 69}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.356500</td>\n",
       "      <td>0.721889</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.868034</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.868056</td>\n",
       "      <td>{0: 41, 1: 27, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.313900</td>\n",
       "      <td>0.834875</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.848438</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.846226</td>\n",
       "      <td>{0: 44, 1: 28, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.258500</td>\n",
       "      <td>0.838360</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.835613</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.824206</td>\n",
       "      <td>{0: 51, 1: 18, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.256300</td>\n",
       "      <td>1.244473</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.840166</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.801918</td>\n",
       "      <td>{0: 56, 1: 14, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.264800</td>\n",
       "      <td>1.032038</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.823632</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.819476</td>\n",
       "      <td>{0: 47, 1: 21, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.217100</td>\n",
       "      <td>1.075173</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.839470</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.832177</td>\n",
       "      <td>{0: 48, 1: 27, 2: 54}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.220700</td>\n",
       "      <td>1.265244</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.826500</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.808761</td>\n",
       "      <td>{0: 54, 1: 17, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.166200</td>\n",
       "      <td>1.274337</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.833585</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.830935</td>\n",
       "      <td>{0: 41, 1: 30, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.130200</td>\n",
       "      <td>1.108741</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.830423</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.829874</td>\n",
       "      <td>{0: 43, 1: 27, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>1.258711</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.841469</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.833193</td>\n",
       "      <td>{0: 49, 1: 19, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.056800</td>\n",
       "      <td>1.360706</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.828041</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.813499</td>\n",
       "      <td>{0: 48, 1: 16, 2: 65}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.083200</td>\n",
       "      <td>1.341106</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.832226</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.827326</td>\n",
       "      <td>{0: 48, 1: 21, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.039900</td>\n",
       "      <td>1.447014</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.832627</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.816916</td>\n",
       "      <td>{0: 51, 1: 17, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>1.367585</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.830519</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.827236</td>\n",
       "      <td>{0: 48, 1: 22, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.012600</td>\n",
       "      <td>1.506090</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.834607</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.827021</td>\n",
       "      <td>{0: 49, 1: 20, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>1.534783</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.827195</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.809868</td>\n",
       "      <td>{0: 52, 1: 17, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>1.572650</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.827195</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.809868</td>\n",
       "      <td>{0: 52, 1: 17, 2: 60}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_TUM_GottBERT_base_last_42_42_20\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_TUM_GottBERT_base_last_42_42_20\n",
      "Evaluation results for TUM/GottBERT_base_last with 20 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.43964684009552, 'eval_accuracy': 0.7320261437908496, 'eval_precision': 0.7592760180995475, 'eval_recall': 0.7320261437908496, 'eval_f1': 0.7337787004109357, 'eval_class_distribution': {0: 48, 1: 40, 2: 65}, 'eval_runtime': 2.0039, 'eval_samples_per_second': 76.352, 'eval_steps_per_second': 38.425, 'epoch': 20.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.65      0.89      0.75        36\n",
      "     Neutral       0.63      0.73      0.68        33\n",
      "     Positiv       0.89      0.70      0.79        84\n",
      "\n",
      "    accuracy                           0.75       153\n",
      "   macro avg       0.73      0.77      0.74       153\n",
      "weighted avg       0.78      0.75      0.75       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 49, 1: 38, 2: 66}\n",
      "Negativ Precision Score: 0.6530612244897959\n",
      "Negativ Recall Score: 0.8888888888888888\n",
      "Negativ F1 Score: 0.7529411764705882\n",
      "\n",
      "Neutral Precision Score: 0.631578947368421\n",
      "Neutral Recall Score: 0.7272727272727273\n",
      "Neutral F1 Score: 0.676056338028169\n",
      "\n",
      "Positiv Precision Score: 0.8939393939393939\n",
      "Positiv Recall Score: 0.7023809523809523\n",
      "Positiv F1 Score: 0.7866666666666666\n",
      "\n",
      "Macro Average Precision Score: 0.7261931885992037\n",
      "Macro Average Recall Score: 0.7728475228475228\n",
      "Macro Average F1 Score: 0.7385547270551412\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/20_epochs/TUM_GottBERT_base_last_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/20_epochs/TUM_GottBERT_base_last_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for distilbert/distilbert-base-german-cased:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 3972.28 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 3333.88 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 3396.29 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for distilbert/distilbert-base-german-cased with 20 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8340' max='11120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 8340/11120 08:47 < 02:55, 15.82 it/s, Epoch 15/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.821100</td>\n",
       "      <td>0.633758</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.803739</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.783630</td>\n",
       "      <td>{0: 55, 1: 19, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.600200</td>\n",
       "      <td>0.538910</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.850371</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.845734</td>\n",
       "      <td>{0: 48, 1: 25, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.486400</td>\n",
       "      <td>0.568320</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.868555</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.867988</td>\n",
       "      <td>{0: 44, 1: 25, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.289300</td>\n",
       "      <td>0.918813</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.852167</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.815434</td>\n",
       "      <td>{0: 61, 1: 20, 2: 48}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.290900</td>\n",
       "      <td>0.663440</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.863299</td>\n",
       "      <td>0.860465</td>\n",
       "      <td>0.860981</td>\n",
       "      <td>{0: 46, 1: 26, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.212500</td>\n",
       "      <td>0.743646</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.852988</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.846478</td>\n",
       "      <td>{0: 41, 1: 33, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.157800</td>\n",
       "      <td>1.264177</td>\n",
       "      <td>0.775194</td>\n",
       "      <td>0.798626</td>\n",
       "      <td>0.775194</td>\n",
       "      <td>0.774866</td>\n",
       "      <td>{0: 56, 1: 18, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.121900</td>\n",
       "      <td>1.035909</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.820626</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.815359</td>\n",
       "      <td>{0: 42, 1: 32, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.046000</td>\n",
       "      <td>1.070395</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.841354</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.838441</td>\n",
       "      <td>{0: 44, 1: 29, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>1.081289</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.829378</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.829124</td>\n",
       "      <td>{0: 41, 1: 29, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.018900</td>\n",
       "      <td>0.996418</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.845664</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.845248</td>\n",
       "      <td>{0: 43, 1: 27, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>1.062156</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>{0: 42, 1: 27, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>1.112378</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.856112</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.853529</td>\n",
       "      <td>{0: 46, 1: 26, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>1.126050</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.851214</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.846472</td>\n",
       "      <td>{0: 47, 1: 27, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>1.141850</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.842310</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.838130</td>\n",
       "      <td>{0: 43, 1: 31, 2: 55}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_distilbert_distilbert-base-german-cased_42_42_20\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_distilbert_distilbert-base-german-cased_42_42_20\n",
      "Evaluation results for distilbert/distilbert-base-german-cased with 20 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9798324704170227, 'eval_accuracy': 0.803921568627451, 'eval_precision': 0.806424028646251, 'eval_recall': 0.803921568627451, 'eval_f1': 0.8021585186483933, 'eval_class_distribution': {0: 44, 1: 28, 2: 81}, 'eval_runtime': 1.2, 'eval_samples_per_second': 127.5, 'eval_steps_per_second': 64.167, 'epoch': 15.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.74      0.89      0.81        36\n",
      "     Neutral       0.68      0.58      0.62        33\n",
      "     Positiv       0.88      0.86      0.87        84\n",
      "\n",
      "    accuracy                           0.80       153\n",
      "   macro avg       0.77      0.77      0.77       153\n",
      "weighted avg       0.80      0.80      0.80       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 43, 1: 28, 2: 82}\n",
      "Negativ Precision Score: 0.7441860465116279\n",
      "Negativ Recall Score: 0.8888888888888888\n",
      "Negativ F1 Score: 0.810126582278481\n",
      "\n",
      "Neutral Precision Score: 0.6785714285714286\n",
      "Neutral Recall Score: 0.5757575757575758\n",
      "Neutral F1 Score: 0.6229508196721312\n",
      "\n",
      "Positiv Precision Score: 0.8780487804878049\n",
      "Positiv Recall Score: 0.8571428571428571\n",
      "Positiv F1 Score: 0.8674698795180723\n",
      "\n",
      "Macro Average Precision Score: 0.7669354185236205\n",
      "Macro Average Recall Score: 0.7739297739297739\n",
      "Macro Average F1 Score: 0.7668490938228949\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/20_epochs/distilbert_distilbert-base-german-cased_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/20_epochs/distilbert_distilbert-base-german-cased_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for GerMedBERT/medbert-512:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Device set to use cuda:0\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GerMedBERT/medbert-512 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 2825.29 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 2523.67 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 2600.49 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for GerMedBERT/medbert-512 with 20 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9452' max='11120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 9452/11120 18:49 < 03:19, 8.37 it/s, Epoch 17/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.901600</td>\n",
       "      <td>0.974941</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.793225</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.784208</td>\n",
       "      <td>{0: 42, 1: 18, 2: 69}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.555200</td>\n",
       "      <td>1.485358</td>\n",
       "      <td>0.713178</td>\n",
       "      <td>0.730826</td>\n",
       "      <td>0.713178</td>\n",
       "      <td>0.693508</td>\n",
       "      <td>{0: 21, 1: 31, 2: 77}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.536300</td>\n",
       "      <td>1.307692</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.739684</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.741075</td>\n",
       "      <td>{0: 41, 1: 24, 2: 64}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.298800</td>\n",
       "      <td>1.120012</td>\n",
       "      <td>0.751938</td>\n",
       "      <td>0.758253</td>\n",
       "      <td>0.751938</td>\n",
       "      <td>0.750327</td>\n",
       "      <td>{0: 52, 1: 22, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.320300</td>\n",
       "      <td>1.341211</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.748196</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.745918</td>\n",
       "      <td>{0: 42, 1: 29, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.239300</td>\n",
       "      <td>1.265736</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.763956</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.749939</td>\n",
       "      <td>{0: 49, 1: 29, 2: 51}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>1.593361</td>\n",
       "      <td>0.775194</td>\n",
       "      <td>0.798573</td>\n",
       "      <td>0.775194</td>\n",
       "      <td>0.778667</td>\n",
       "      <td>{0: 55, 1: 24, 2: 50}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.161800</td>\n",
       "      <td>1.636195</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.802468</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.787379</td>\n",
       "      <td>{0: 37, 1: 37, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.076600</td>\n",
       "      <td>1.610823</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.801865</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.794811</td>\n",
       "      <td>{0: 43, 1: 31, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.037700</td>\n",
       "      <td>1.459463</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.818622</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.810589</td>\n",
       "      <td>{0: 42, 1: 32, 2: 55}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.021900</td>\n",
       "      <td>1.399294</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.840721</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.831452</td>\n",
       "      <td>{0: 50, 1: 26, 2: 53}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.023400</td>\n",
       "      <td>1.507761</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.804464</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.805073</td>\n",
       "      <td>{0: 40, 1: 27, 2: 62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>1.751983</td>\n",
       "      <td>0.775194</td>\n",
       "      <td>0.771369</td>\n",
       "      <td>0.775194</td>\n",
       "      <td>0.769709</td>\n",
       "      <td>{0: 46, 1: 20, 2: 63}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>1.818859</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.825439</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.805589</td>\n",
       "      <td>{0: 41, 1: 37, 2: 51}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>1.530305</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.807274</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.806200</td>\n",
       "      <td>{0: 45, 1: 25, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.580290</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.798932</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.793638</td>\n",
       "      <td>{0: 42, 1: 31, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.611455</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.798932</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.793638</td>\n",
       "      <td>{0: 42, 1: 31, 2: 56}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_GerMedBERT_medbert-512_42_42_20\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_GerMedBERT_medbert-512_42_42_20\n",
      "Evaluation results for GerMedBERT/medbert-512 with 20 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.0073153972625732, 'eval_accuracy': 0.7777777777777778, 'eval_precision': 0.8028309362960871, 'eval_recall': 0.7777777777777778, 'eval_f1': 0.7806260046083314, 'eval_class_distribution': {0: 49, 1: 36, 2: 68}, 'eval_runtime': 2.1607, 'eval_samples_per_second': 70.812, 'eval_steps_per_second': 35.637, 'epoch': 17.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.62      0.86      0.72        36\n",
      "     Neutral       0.58      0.64      0.61        33\n",
      "     Positiv       0.88      0.70      0.78        84\n",
      "\n",
      "    accuracy                           0.73       153\n",
      "   macro avg       0.69      0.73      0.70       153\n",
      "weighted avg       0.76      0.73      0.73       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 50, 1: 36, 2: 67}\n",
      "Negativ Precision Score: 0.62\n",
      "Negativ Recall Score: 0.8611111111111112\n",
      "Negativ F1 Score: 0.7209302325581395\n",
      "\n",
      "Neutral Precision Score: 0.5833333333333334\n",
      "Neutral Recall Score: 0.6363636363636364\n",
      "Neutral F1 Score: 0.6086956521739131\n",
      "\n",
      "Positiv Precision Score: 0.8805970149253731\n",
      "Positiv Recall Score: 0.7023809523809523\n",
      "Positiv F1 Score: 0.7814569536423841\n",
      "\n",
      "Macro Average Precision Score: 0.6946434494195688\n",
      "Macro Average Recall Score: 0.7332852332852333\n",
      "Macro Average F1 Score: 0.7036942794581456\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/20_epochs/GerMedBERT_medbert-512_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/20_epochs/GerMedBERT_medbert-512_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for deepset/gbert-base:\n",
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 2803.59 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 2552.63 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 2612.57 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for deepset/gbert-base with 20 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9452' max='11120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 9452/11120 18:43 < 03:18, 8.41 it/s, Epoch 17/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.869500</td>\n",
       "      <td>0.827326</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.841133</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.836361</td>\n",
       "      <td>{0: 48, 1: 22, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.537900</td>\n",
       "      <td>0.642612</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.845834</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.845313</td>\n",
       "      <td>{0: 42, 1: 28, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.581000</td>\n",
       "      <td>0.986815</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.828826</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.822037</td>\n",
       "      <td>{0: 49, 1: 22, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.301600</td>\n",
       "      <td>0.907340</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.832306</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.828453</td>\n",
       "      <td>{0: 47, 1: 22, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.252800</td>\n",
       "      <td>0.941541</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.852366</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.852446</td>\n",
       "      <td>{0: 43, 1: 26, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.168100</td>\n",
       "      <td>1.176246</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.836794</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.830554</td>\n",
       "      <td>{0: 49, 1: 24, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.138600</td>\n",
       "      <td>1.192837</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.842360</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.837803</td>\n",
       "      <td>{0: 48, 1: 24, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.081300</td>\n",
       "      <td>1.214781</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.825479</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.823132</td>\n",
       "      <td>{0: 44, 1: 28, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.050500</td>\n",
       "      <td>1.408071</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.824255</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.816017</td>\n",
       "      <td>{0: 49, 1: 27, 2: 53}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.027100</td>\n",
       "      <td>1.474205</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.834032</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.824419</td>\n",
       "      <td>{0: 48, 1: 29, 2: 52}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>1.775272</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.809974</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.795528</td>\n",
       "      <td>{0: 44, 1: 34, 2: 51}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>1.486882</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.846008</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.837633</td>\n",
       "      <td>{0: 50, 1: 22, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.579474</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.827044</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.823021</td>\n",
       "      <td>{0: 47, 1: 26, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.609435</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.834213</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.830514</td>\n",
       "      <td>{0: 47, 1: 25, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.633139</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.834213</td>\n",
       "      <td>0.829457</td>\n",
       "      <td>0.830514</td>\n",
       "      <td>{0: 47, 1: 25, 2: 57}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.715676</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.827044</td>\n",
       "      <td>0.821705</td>\n",
       "      <td>0.823021</td>\n",
       "      <td>{0: 47, 1: 26, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.757733</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.812982</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.808254</td>\n",
       "      <td>{0: 46, 1: 28, 2: 55}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_deepset_gbert-base_42_42_20\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_deepset_gbert-base_42_42_20\n",
      "Evaluation results for deepset/gbert-base with 20 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.168603777885437, 'eval_accuracy': 0.8300653594771242, 'eval_precision': 0.8292870075958311, 'eval_recall': 0.8300653594771242, 'eval_f1': 0.8296025399973829, 'eval_class_distribution': {0: 37, 1: 32, 2: 84}, 'eval_runtime': 2.1808, 'eval_samples_per_second': 70.157, 'eval_steps_per_second': 35.308, 'epoch': 17.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.84      0.86      0.85        36\n",
      "     Neutral       0.68      0.70      0.69        33\n",
      "     Positiv       0.88      0.86      0.87        84\n",
      "\n",
      "    accuracy                           0.82       153\n",
      "   macro avg       0.80      0.81      0.80       153\n",
      "weighted avg       0.83      0.82      0.82       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 37, 1: 34, 2: 82}\n",
      "Negativ Precision Score: 0.8378378378378378\n",
      "Negativ Recall Score: 0.8611111111111112\n",
      "Negativ F1 Score: 0.8493150684931506\n",
      "\n",
      "Neutral Precision Score: 0.6764705882352942\n",
      "Neutral Recall Score: 0.696969696969697\n",
      "Neutral F1 Score: 0.6865671641791045\n",
      "\n",
      "Positiv Precision Score: 0.8780487804878049\n",
      "Positiv Recall Score: 0.8571428571428571\n",
      "Positiv F1 Score: 0.8674698795180723\n",
      "\n",
      "Macro Average Precision Score: 0.797452402186979\n",
      "Macro Average Recall Score: 0.805074555074555\n",
      "Macro Average F1 Score: 0.8011173707301092\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/20_epochs/deepset_gbert-base_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/20_epochs/deepset_gbert-base_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(f'training and results for {model}:')\n",
    "    absa_model(data, model, rn1=42, rn2=42, epochs=20, save = True)\n",
    "    print()\n",
    "\n",
    "# early stopping patients = 3, continues when there's any improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd1b81d2-e3f8-4f13-90ee-1545a764f199",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Sentiment label count:  {'negativ': 338, 'neutral': 275, 'positiv': 498}\n",
      "Validation Sentiment label count:  {'negativ': 42, 'neutral': 27, 'positiv': 60}\n",
      "Test Sentiment label count:  {'negativ': 36, 'neutral': 33, 'positiv': 84}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0957, 1.3467, 0.7436])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1111/1111 [00:00<00:00, 2582.86 examples/s]\n",
      "Map: 100%|██████████| 129/129 [00:00<00:00, 2306.09 examples/s]\n",
      "Map: 100%|██████████| 153/153 [00:00<00:00, 2370.20 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training results for aari1995/German_Sentiment with 20 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8340' max='11120' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 8340/11120 46:15 < 15:25, 3.00 it/s, Epoch 15/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.864200</td>\n",
       "      <td>0.602500</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.886762</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.882243</td>\n",
       "      <td>{0: 48, 1: 22, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.547500</td>\n",
       "      <td>0.718769</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.882680</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.877050</td>\n",
       "      <td>{0: 37, 1: 32, 2: 60}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.552200</td>\n",
       "      <td>0.570527</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.897188</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.890652</td>\n",
       "      <td>{0: 47, 1: 21, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.304600</td>\n",
       "      <td>0.612081</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.872502</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.869262</td>\n",
       "      <td>{0: 46, 1: 27, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.233400</td>\n",
       "      <td>0.659868</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.874395</td>\n",
       "      <td>0.875969</td>\n",
       "      <td>0.873891</td>\n",
       "      <td>{0: 44, 1: 23, 2: 62}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.156200</td>\n",
       "      <td>0.614664</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.900194</td>\n",
       "      <td>0.891473</td>\n",
       "      <td>0.893350</td>\n",
       "      <td>{0: 48, 1: 27, 2: 54}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.080100</td>\n",
       "      <td>0.769258</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.911498</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.906686</td>\n",
       "      <td>{0: 48, 1: 23, 2: 58}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.105500</td>\n",
       "      <td>0.897929</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.876876</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.870811</td>\n",
       "      <td>{0: 41, 1: 32, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.016800</td>\n",
       "      <td>0.818693</td>\n",
       "      <td>0.914729</td>\n",
       "      <td>0.929083</td>\n",
       "      <td>0.914729</td>\n",
       "      <td>0.915143</td>\n",
       "      <td>{0: 52, 1: 21, 2: 56}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.762654</td>\n",
       "      <td>0.922481</td>\n",
       "      <td>0.924614</td>\n",
       "      <td>0.922481</td>\n",
       "      <td>0.921983</td>\n",
       "      <td>{0: 45, 1: 23, 2: 61}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.026400</td>\n",
       "      <td>1.190309</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.888789</td>\n",
       "      <td>0.868217</td>\n",
       "      <td>0.872892</td>\n",
       "      <td>{0: 43, 1: 35, 2: 51}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.019500</td>\n",
       "      <td>0.948967</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.908471</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.907091</td>\n",
       "      <td>{0: 45, 1: 25, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.972488</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.908471</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.907091</td>\n",
       "      <td>{0: 45, 1: 25, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.981026</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.908471</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.907091</td>\n",
       "      <td>{0: 45, 1: 25, 2: 59}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.984718</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.908471</td>\n",
       "      <td>0.906977</td>\n",
       "      <td>0.907091</td>\n",
       "      <td>{0: 45, 1: 25, 2: 59}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/absa_aari1995_German_Sentiment_42_42_20\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/absa_aari1995_German_Sentiment_42_42_20\n",
      "Evaluation results for aari1995/German_Sentiment with 20 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='77' max='77' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [77/77 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.3664731979370117, 'eval_accuracy': 0.8431372549019608, 'eval_precision': 0.8596078431372548, 'eval_recall': 0.8431372549019608, 'eval_f1': 0.8474435812060673, 'eval_class_distribution': {0: 36, 1: 42, 2: 75}, 'eval_runtime': 5.6335, 'eval_samples_per_second': 27.159, 'eval_steps_per_second': 13.668, 'epoch': 15.0}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.84      0.86      0.85        36\n",
      "     Neutral       0.68      0.82      0.74        33\n",
      "     Positiv       0.95      0.86      0.90        84\n",
      "\n",
      "    accuracy                           0.85       153\n",
      "   macro avg       0.82      0.85      0.83       153\n",
      "weighted avg       0.86      0.85      0.85       153\n",
      "\n",
      "True label distribution: {0: 36, 1: 33, 2: 84}\n",
      "Predicted label distribution: {0: 37, 1: 40, 2: 76}\n",
      "Negativ Precision Score: 0.8378378378378378\n",
      "Negativ Recall Score: 0.8611111111111112\n",
      "Negativ F1 Score: 0.8493150684931506\n",
      "\n",
      "Neutral Precision Score: 0.675\n",
      "Neutral Recall Score: 0.8181818181818182\n",
      "Neutral F1 Score: 0.7397260273972602\n",
      "\n",
      "Positiv Precision Score: 0.9473684210526315\n",
      "Positiv Recall Score: 0.8571428571428571\n",
      "Positiv F1 Score: 0.9\n",
      "\n",
      "Macro Average Precision Score: 0.8200687529634898\n",
      "Macro Average Recall Score: 0.8454785954785956\n",
      "Macro Average F1 Score: 0.8296803652968037\n",
      "\n",
      "Confusion Matrix saved at: testresult/BO/absa/20_epochs/aari1995_German_Sentiment_confusion_matrix.png\n",
      "Normalized Confusion Matrix saved at: testresult/BO/absa/20_epochs/aari1995_German_Sentiment_confusion_matrix_normalized.png\n",
      "\n",
      "Training complete. Model directory deleted to free memory.\n"
     ]
    }
   ],
   "source": [
    "absa_model(data, \"aari1995/German_Sentiment\", rn1=42, rn2=42, epochs=20, save = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aac2ce0-e0e6-49ff-b3b5-4a6e25dea9d7",
   "metadata": {},
   "source": [
    "## Cross-Validation to check stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8198323-4b8e-4ca8-9251-1d89c8697c4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Training Fold 1/3\n",
      "==================================================\n",
      "\n",
      "Training Fold 1 Sentiment label count:  {'negativ': 274, 'neutral': 252, 'positiv': 424}\n",
      "Validation Fold 1 Sentiment label count:  {'negativ': 73, 'neutral': 46, 'positiv': 93}\n",
      "Test Fold 1 Sentiment label count:  {'negativ': 69, 'neutral': 37, 'positiv': 125}\n",
      "Class weights for (negative, neutral, positive): tensor([1.1557, 1.2566, 0.7469])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 950/950 [00:00<00:00, 3455.01 examples/s]\n",
      "Map: 100%|██████████| 212/212 [00:00<00:00, 3549.15 examples/s]\n",
      "Map: 100%|██████████| 231/231 [00:00<00:00, 3911.52 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='950' max='950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [950/950 01:45, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.363605</td>\n",
       "      <td>0.533019</td>\n",
       "      <td>0.715617</td>\n",
       "      <td>0.533019</td>\n",
       "      <td>0.439898</td>\n",
       "      <td>{0: 1, 1: 96, 2: 115}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.042400</td>\n",
       "      <td>1.160035</td>\n",
       "      <td>0.688679</td>\n",
       "      <td>0.691718</td>\n",
       "      <td>0.688679</td>\n",
       "      <td>0.688074</td>\n",
       "      <td>{0: 84, 1: 39, 2: 89}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='116' max='116' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [116/116 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.51      0.64      0.57        69\n",
      "     Neutral       0.50      0.43      0.46        37\n",
      "     Positiv       0.85      0.77      0.81       125\n",
      "\n",
      "    accuracy                           0.68       231\n",
      "   macro avg       0.62      0.61      0.61       231\n",
      "weighted avg       0.69      0.68      0.68       231\n",
      "\n",
      "\n",
      "Fold 1 Performance Metrics:\n",
      "GPU: NVIDIA A30\n",
      "Avg epoch: 47.13s\n",
      "Total: 94.26s\n",
      "Peak memory: 2618.0MB\n",
      "Avg batch: 0.0961s\n",
      "\n",
      "==================================================\n",
      "Training Fold 2/3\n",
      "==================================================\n",
      "\n",
      "Training Fold 2 Sentiment label count:  {'negativ': 288, 'neutral': 216, 'positiv': 420}\n",
      "Validation Fold 2 Sentiment label count:  {'negativ': 66, 'neutral': 58, 'positiv': 113}\n",
      "Test Fold 2 Sentiment label count:  {'negativ': 62, 'neutral': 61, 'positiv': 109}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0694, 1.4259, 0.7333])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 924/924 [00:00<00:00, 4107.30 examples/s]\n",
      "Map: 100%|██████████| 237/237 [00:00<00:00, 3775.02 examples/s]\n",
      "Map: 100%|██████████| 232/232 [00:00<00:00, 4209.27 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='924' max='924' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [924/924 01:43, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.594389</td>\n",
       "      <td>0.852321</td>\n",
       "      <td>0.852008</td>\n",
       "      <td>0.852321</td>\n",
       "      <td>0.851061</td>\n",
       "      <td>{0: 59, 1: 58, 2: 120}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.807500</td>\n",
       "      <td>0.782240</td>\n",
       "      <td>0.827004</td>\n",
       "      <td>0.831525</td>\n",
       "      <td>0.827004</td>\n",
       "      <td>0.828223</td>\n",
       "      <td>{0: 72, 1: 60, 2: 105}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='116' max='116' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [116/116 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.62      0.60      0.61        62\n",
      "     Neutral       0.61      0.67      0.64        61\n",
      "     Positiv       0.83      0.80      0.81       109\n",
      "\n",
      "    accuracy                           0.71       232\n",
      "   macro avg       0.69      0.69      0.69       232\n",
      "weighted avg       0.71      0.71      0.71       232\n",
      "\n",
      "\n",
      "Fold 2 Performance Metrics:\n",
      "GPU: NVIDIA A30\n",
      "Avg epoch: 45.46s\n",
      "Total: 90.92s\n",
      "Peak memory: 2614.0MB\n",
      "Avg batch: 0.0957s\n",
      "\n",
      "==================================================\n",
      "Training Fold 3/3\n",
      "==================================================\n",
      "\n",
      "Training Fold 3 Sentiment label count:  {'negativ': 270, 'neutral': 202, 'positiv': 440}\n",
      "Validation Fold 3 Sentiment label count:  {'negativ': 62, 'neutral': 80, 'positiv': 97}\n",
      "Test Fold 3 Sentiment label count:  {'negativ': 84, 'neutral': 53, 'positiv': 105}\n",
      "Class weights for (negative, neutral, positive): tensor([1.1259, 1.5050, 0.6909])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 912/912 [00:00<00:00, 4076.14 examples/s]\n",
      "Map: 100%|██████████| 239/239 [00:00<00:00, 3599.80 examples/s]\n",
      "Map: 100%|██████████| 242/242 [00:00<00:00, 4023.50 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='912' max='912' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [912/912 01:41, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.172984</td>\n",
       "      <td>0.744770</td>\n",
       "      <td>0.766577</td>\n",
       "      <td>0.744770</td>\n",
       "      <td>0.734304</td>\n",
       "      <td>{0: 58, 1: 49, 2: 132}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.782400</td>\n",
       "      <td>1.219372</td>\n",
       "      <td>0.740586</td>\n",
       "      <td>0.750621</td>\n",
       "      <td>0.740586</td>\n",
       "      <td>0.737006</td>\n",
       "      <td>{0: 57, 1: 61, 2: 121}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='121' max='121' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [121/121 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.84      0.83      0.84        84\n",
      "     Neutral       0.76      0.70      0.73        53\n",
      "     Positiv       0.91      0.95      0.93       105\n",
      "\n",
      "    accuracy                           0.86       242\n",
      "   macro avg       0.84      0.83      0.83       242\n",
      "weighted avg       0.85      0.86      0.85       242\n",
      "\n",
      "\n",
      "Fold 3 Performance Metrics:\n",
      "GPU: NVIDIA A30\n",
      "Avg epoch: 44.64s\n",
      "Total: 89.29s\n",
      "Peak memory: 2614.0MB\n",
      "Avg batch: 0.0953s\n",
      "\n",
      "==================================================\n",
      "Cross-Validation Summary\n",
      "==================================================\n",
      "\n",
      "Average Metrics Across Folds:\n",
      "eval_accuracy: 0.7589 ± 0.0666\n",
      "eval_precision: 0.7615 ± 0.0635\n",
      "eval_recall: 0.7589 ± 0.0666\n",
      "eval_f1: 0.7595 ± 0.0654\n",
      "eval_loss: 0.9903 ± 0.1931\n",
      "\n",
      "Overall Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.66      0.70      0.68       215\n",
      "     Neutral       0.64      0.62      0.63       151\n",
      "     Positiv       0.86      0.83      0.85       339\n",
      "\n",
      "    accuracy                           0.75       705\n",
      "   macro avg       0.72      0.72      0.72       705\n",
      "weighted avg       0.75      0.75      0.75       705\n",
      "\n",
      "\n",
      "Weighted Average Scores Across All Folds:\n",
      "Precision: 0.7520\n",
      "Recall: 0.7489\n",
      "F1: 0.7501\n"
     ]
    }
   ],
   "source": [
    "avg_metrics, std_metrics = absa_model_kfold(data, \"dbmdz/bert-base-german-cased\", rn1=42, rn2=42, epochs=2, n_splits=3, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f3f7e62-44bc-4f43-a486-f4ba1e999298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training and results for google-bert/bert-base-german-cased:\n",
      "\n",
      "==================================================\n",
      "Training Fold 1/3\n",
      "==================================================\n",
      "\n",
      "Training Fold 1 Sentiment label count:  {'negativ': 274, 'neutral': 252, 'positiv': 424}\n",
      "Validation Fold 1 Sentiment label count:  {'negativ': 73, 'neutral': 46, 'positiv': 93}\n",
      "Test Fold 1 Sentiment label count:  {'negativ': 69, 'neutral': 37, 'positiv': 125}\n",
      "Class weights for (negative, neutral, positive): tensor([1.1557, 1.2566, 0.7469])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 950/950 [00:00<00:00, 3822.69 examples/s]\n",
      "Map: 100%|██████████| 212/212 [00:00<00:00, 3575.76 examples/s]\n",
      "Map: 100%|██████████| 231/231 [00:00<00:00, 3864.92 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2375' max='2375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2375/2375 04:20, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.777691</td>\n",
       "      <td>0.797170</td>\n",
       "      <td>0.811701</td>\n",
       "      <td>0.797170</td>\n",
       "      <td>0.801479</td>\n",
       "      <td>{0: 66, 1: 58, 2: 88}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.820800</td>\n",
       "      <td>1.135846</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.791074</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.791568</td>\n",
       "      <td>{0: 76, 1: 44, 2: 92}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.466000</td>\n",
       "      <td>1.001936</td>\n",
       "      <td>0.801887</td>\n",
       "      <td>0.802199</td>\n",
       "      <td>0.801887</td>\n",
       "      <td>0.799729</td>\n",
       "      <td>{0: 84, 1: 41, 2: 87}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.346500</td>\n",
       "      <td>1.191324</td>\n",
       "      <td>0.778302</td>\n",
       "      <td>0.778923</td>\n",
       "      <td>0.778302</td>\n",
       "      <td>0.778403</td>\n",
       "      <td>{0: 76, 1: 46, 2: 90}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.195900</td>\n",
       "      <td>1.269362</td>\n",
       "      <td>0.787736</td>\n",
       "      <td>0.795677</td>\n",
       "      <td>0.787736</td>\n",
       "      <td>0.789836</td>\n",
       "      <td>{0: 78, 1: 51, 2: 83}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='116' max='116' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [116/116 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.77      0.80      0.79        69\n",
      "     Neutral       0.55      0.78      0.64        37\n",
      "     Positiv       0.95      0.82      0.88       125\n",
      "\n",
      "    accuracy                           0.81       231\n",
      "   macro avg       0.76      0.80      0.77       231\n",
      "weighted avg       0.83      0.81      0.81       231\n",
      "\n",
      "\n",
      "==================================================\n",
      "Training Fold 2/3\n",
      "==================================================\n",
      "\n",
      "Training Fold 2 Sentiment label count:  {'negativ': 288, 'neutral': 216, 'positiv': 420}\n",
      "Validation Fold 2 Sentiment label count:  {'negativ': 66, 'neutral': 58, 'positiv': 113}\n",
      "Test Fold 2 Sentiment label count:  {'negativ': 62, 'neutral': 61, 'positiv': 109}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0694, 1.4259, 0.7333])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 924/924 [00:00<00:00, 4108.83 examples/s]\n",
      "Map: 100%|██████████| 237/237 [00:00<00:00, 3715.49 examples/s]\n",
      "Map: 100%|██████████| 232/232 [00:00<00:00, 4224.11 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2310' max='2310' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2310/2310 04:17, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.850315</td>\n",
       "      <td>0.797468</td>\n",
       "      <td>0.811282</td>\n",
       "      <td>0.797468</td>\n",
       "      <td>0.799783</td>\n",
       "      <td>{0: 71, 1: 70, 2: 96}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.788400</td>\n",
       "      <td>0.901961</td>\n",
       "      <td>0.805907</td>\n",
       "      <td>0.821133</td>\n",
       "      <td>0.805907</td>\n",
       "      <td>0.804966</td>\n",
       "      <td>{0: 88, 1: 44, 2: 105}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.560800</td>\n",
       "      <td>0.984520</td>\n",
       "      <td>0.789030</td>\n",
       "      <td>0.811445</td>\n",
       "      <td>0.789030</td>\n",
       "      <td>0.793331</td>\n",
       "      <td>{0: 55, 1: 79, 2: 103}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.301400</td>\n",
       "      <td>0.938552</td>\n",
       "      <td>0.818565</td>\n",
       "      <td>0.828272</td>\n",
       "      <td>0.818565</td>\n",
       "      <td>0.814261</td>\n",
       "      <td>{0: 79, 1: 39, 2: 119}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.213700</td>\n",
       "      <td>0.835949</td>\n",
       "      <td>0.831224</td>\n",
       "      <td>0.833137</td>\n",
       "      <td>0.831224</td>\n",
       "      <td>0.831849</td>\n",
       "      <td>{0: 70, 1: 58, 2: 109}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='116' max='116' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [116/116 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.66      0.76      0.71        62\n",
      "     Neutral       0.68      0.62      0.65        61\n",
      "     Positiv       0.83      0.80      0.81       109\n",
      "\n",
      "    accuracy                           0.74       232\n",
      "   macro avg       0.72      0.73      0.72       232\n",
      "weighted avg       0.74      0.74      0.74       232\n",
      "\n",
      "\n",
      "==================================================\n",
      "Training Fold 3/3\n",
      "==================================================\n",
      "\n",
      "Training Fold 3 Sentiment label count:  {'negativ': 270, 'neutral': 202, 'positiv': 440}\n",
      "Validation Fold 3 Sentiment label count:  {'negativ': 62, 'neutral': 80, 'positiv': 97}\n",
      "Test Fold 3 Sentiment label count:  {'negativ': 84, 'neutral': 53, 'positiv': 105}\n",
      "Class weights for (negative, neutral, positive): tensor([1.1259, 1.5050, 0.6909])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 912/912 [00:00<00:00, 3963.89 examples/s]\n",
      "Map: 100%|██████████| 239/239 [00:00<00:00, 3484.59 examples/s]\n",
      "Map: 100%|██████████| 242/242 [00:00<00:00, 4003.90 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2280' max='2280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2280/2280 04:13, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.106438</td>\n",
       "      <td>0.753138</td>\n",
       "      <td>0.770163</td>\n",
       "      <td>0.753138</td>\n",
       "      <td>0.745277</td>\n",
       "      <td>{0: 74, 1: 50, 2: 115}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.793700</td>\n",
       "      <td>1.313978</td>\n",
       "      <td>0.723849</td>\n",
       "      <td>0.730398</td>\n",
       "      <td>0.723849</td>\n",
       "      <td>0.717767</td>\n",
       "      <td>{0: 74, 1: 56, 2: 109}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.482400</td>\n",
       "      <td>1.307499</td>\n",
       "      <td>0.719665</td>\n",
       "      <td>0.720409</td>\n",
       "      <td>0.719665</td>\n",
       "      <td>0.716513</td>\n",
       "      <td>{0: 62, 1: 66, 2: 111}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.326200</td>\n",
       "      <td>1.553217</td>\n",
       "      <td>0.698745</td>\n",
       "      <td>0.697124</td>\n",
       "      <td>0.698745</td>\n",
       "      <td>0.695356</td>\n",
       "      <td>{0: 52, 1: 77, 2: 110}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.160200</td>\n",
       "      <td>1.711333</td>\n",
       "      <td>0.702929</td>\n",
       "      <td>0.701210</td>\n",
       "      <td>0.702929</td>\n",
       "      <td>0.698634</td>\n",
       "      <td>{0: 52, 1: 74, 2: 113}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='121' max='121' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [121/121 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.80      0.88      0.84        84\n",
      "     Neutral       0.76      0.70      0.73        53\n",
      "     Positiv       0.97      0.92      0.95       105\n",
      "\n",
      "    accuracy                           0.86       242\n",
      "   macro avg       0.84      0.83      0.84       242\n",
      "weighted avg       0.86      0.86      0.86       242\n",
      "\n",
      "\n",
      "==================================================\n",
      "Cross-Validation Summary\n",
      "==================================================\n",
      "\n",
      "Average Metrics Across Folds:\n",
      "eval_accuracy: 0.8121 ± 0.0342\n",
      "eval_precision: 0.8254 ± 0.0312\n",
      "eval_recall: 0.8121 ± 0.0342\n",
      "eval_f1: 0.8152 ± 0.0335\n",
      "eval_loss: 0.9095 ± 0.2645\n",
      "\n",
      "Overall Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.75      0.82      0.78       215\n",
      "     Neutral       0.66      0.69      0.67       151\n",
      "     Positiv       0.92      0.84      0.88       339\n",
      "\n",
      "    accuracy                           0.80       705\n",
      "   macro avg       0.77      0.78      0.78       705\n",
      "weighted avg       0.81      0.80      0.81       705\n",
      "\n",
      "\n",
      "Weighted Average Scores Across All Folds:\n",
      "Precision: 0.8102\n",
      "Recall: 0.8028\n",
      "F1: 0.8052\n",
      "\n",
      "training and results for dbmdz/bert-base-german-cased:\n",
      "\n",
      "==================================================\n",
      "Training Fold 1/3\n",
      "==================================================\n",
      "\n",
      "Training Fold 1 Sentiment label count:  {'negativ': 274, 'neutral': 252, 'positiv': 424}\n",
      "Validation Fold 1 Sentiment label count:  {'negativ': 73, 'neutral': 46, 'positiv': 93}\n",
      "Test Fold 1 Sentiment label count:  {'negativ': 69, 'neutral': 37, 'positiv': 125}\n",
      "Class weights for (negative, neutral, positive): tensor([1.1557, 1.2566, 0.7469])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 950/950 [00:00<00:00, 3871.53 examples/s]\n",
      "Map: 100%|██████████| 212/212 [00:00<00:00, 3342.87 examples/s]\n",
      "Map: 100%|██████████| 231/231 [00:00<00:00, 3711.86 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2375' max='2375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2375/2375 04:20, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.946276</td>\n",
       "      <td>0.787736</td>\n",
       "      <td>0.802563</td>\n",
       "      <td>0.787736</td>\n",
       "      <td>0.791936</td>\n",
       "      <td>{0: 75, 1: 56, 2: 81}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.810200</td>\n",
       "      <td>1.025055</td>\n",
       "      <td>0.787736</td>\n",
       "      <td>0.792792</td>\n",
       "      <td>0.787736</td>\n",
       "      <td>0.789454</td>\n",
       "      <td>{0: 67, 1: 50, 2: 95}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.550200</td>\n",
       "      <td>0.864694</td>\n",
       "      <td>0.839623</td>\n",
       "      <td>0.843901</td>\n",
       "      <td>0.839623</td>\n",
       "      <td>0.839212</td>\n",
       "      <td>{0: 84, 1: 44, 2: 84}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.408700</td>\n",
       "      <td>1.077379</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.816118</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.812990</td>\n",
       "      <td>{0: 75, 1: 50, 2: 87}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.257500</td>\n",
       "      <td>1.212649</td>\n",
       "      <td>0.787736</td>\n",
       "      <td>0.803610</td>\n",
       "      <td>0.787736</td>\n",
       "      <td>0.792549</td>\n",
       "      <td>{0: 73, 1: 57, 2: 82}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='116' max='116' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [116/116 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.73      0.96      0.83        69\n",
      "     Neutral       0.72      0.49      0.58        37\n",
      "     Positiv       0.95      0.88      0.91       125\n",
      "\n",
      "    accuracy                           0.84       231\n",
      "   macro avg       0.80      0.77      0.77       231\n",
      "weighted avg       0.85      0.84      0.83       231\n",
      "\n",
      "\n",
      "==================================================\n",
      "Training Fold 2/3\n",
      "==================================================\n",
      "\n",
      "Training Fold 2 Sentiment label count:  {'negativ': 288, 'neutral': 216, 'positiv': 420}\n",
      "Validation Fold 2 Sentiment label count:  {'negativ': 66, 'neutral': 58, 'positiv': 113}\n",
      "Test Fold 2 Sentiment label count:  {'negativ': 62, 'neutral': 61, 'positiv': 109}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0694, 1.4259, 0.7333])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 924/924 [00:00<00:00, 3927.19 examples/s]\n",
      "Map: 100%|██████████| 237/237 [00:00<00:00, 3807.61 examples/s]\n",
      "Map: 100%|██████████| 232/232 [00:00<00:00, 4107.43 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2310' max='2310' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2310/2310 04:14, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.794086</td>\n",
       "      <td>0.835443</td>\n",
       "      <td>0.837959</td>\n",
       "      <td>0.835443</td>\n",
       "      <td>0.836036</td>\n",
       "      <td>{0: 64, 1: 64, 2: 109}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.806300</td>\n",
       "      <td>0.658604</td>\n",
       "      <td>0.852321</td>\n",
       "      <td>0.857694</td>\n",
       "      <td>0.852321</td>\n",
       "      <td>0.852907</td>\n",
       "      <td>{0: 77, 1: 55, 2: 105}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.597600</td>\n",
       "      <td>0.855432</td>\n",
       "      <td>0.839662</td>\n",
       "      <td>0.839898</td>\n",
       "      <td>0.839662</td>\n",
       "      <td>0.839704</td>\n",
       "      <td>{0: 64, 1: 59, 2: 114}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.355400</td>\n",
       "      <td>0.944974</td>\n",
       "      <td>0.839662</td>\n",
       "      <td>0.846381</td>\n",
       "      <td>0.839662</td>\n",
       "      <td>0.841410</td>\n",
       "      <td>{0: 73, 1: 61, 2: 103}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.244700</td>\n",
       "      <td>0.922602</td>\n",
       "      <td>0.831224</td>\n",
       "      <td>0.834008</td>\n",
       "      <td>0.831224</td>\n",
       "      <td>0.832233</td>\n",
       "      <td>{0: 68, 1: 61, 2: 108}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='116' max='116' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [116/116 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.56      0.82      0.67        62\n",
      "     Neutral       0.68      0.56      0.61        61\n",
      "     Positiv       0.93      0.78      0.85       109\n",
      "\n",
      "    accuracy                           0.73       232\n",
      "   macro avg       0.72      0.72      0.71       232\n",
      "weighted avg       0.77      0.73      0.74       232\n",
      "\n",
      "\n",
      "==================================================\n",
      "Training Fold 3/3\n",
      "==================================================\n",
      "\n",
      "Training Fold 3 Sentiment label count:  {'negativ': 270, 'neutral': 202, 'positiv': 440}\n",
      "Validation Fold 3 Sentiment label count:  {'negativ': 62, 'neutral': 80, 'positiv': 97}\n",
      "Test Fold 3 Sentiment label count:  {'negativ': 84, 'neutral': 53, 'positiv': 105}\n",
      "Class weights for (negative, neutral, positive): tensor([1.1259, 1.5050, 0.6909])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 912/912 [00:00<00:00, 4169.11 examples/s]\n",
      "Map: 100%|██████████| 239/239 [00:00<00:00, 3630.20 examples/s]\n",
      "Map: 100%|██████████| 242/242 [00:00<00:00, 4099.47 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2280' max='2280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2280/2280 04:11, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.476761</td>\n",
       "      <td>0.711297</td>\n",
       "      <td>0.748451</td>\n",
       "      <td>0.711297</td>\n",
       "      <td>0.695021</td>\n",
       "      <td>{0: 67, 1: 39, 2: 133}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.769700</td>\n",
       "      <td>1.509264</td>\n",
       "      <td>0.719665</td>\n",
       "      <td>0.737548</td>\n",
       "      <td>0.719665</td>\n",
       "      <td>0.720830</td>\n",
       "      <td>{0: 86, 1: 69, 2: 84}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.529900</td>\n",
       "      <td>1.452126</td>\n",
       "      <td>0.719665</td>\n",
       "      <td>0.740773</td>\n",
       "      <td>0.719665</td>\n",
       "      <td>0.718523</td>\n",
       "      <td>{0: 89, 1: 58, 2: 92}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.379900</td>\n",
       "      <td>1.504852</td>\n",
       "      <td>0.736402</td>\n",
       "      <td>0.738817</td>\n",
       "      <td>0.736402</td>\n",
       "      <td>0.737038</td>\n",
       "      <td>{0: 68, 1: 78, 2: 93}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.219200</td>\n",
       "      <td>1.482222</td>\n",
       "      <td>0.740586</td>\n",
       "      <td>0.740199</td>\n",
       "      <td>0.740586</td>\n",
       "      <td>0.740338</td>\n",
       "      <td>{0: 61, 1: 79, 2: 99}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='121' max='121' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [121/121 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.85      0.73      0.78        84\n",
      "     Neutral       0.63      0.79      0.70        53\n",
      "     Positiv       0.93      0.91      0.92       105\n",
      "\n",
      "    accuracy                           0.82       242\n",
      "   macro avg       0.80      0.81      0.80       242\n",
      "weighted avg       0.84      0.82      0.83       242\n",
      "\n",
      "\n",
      "==================================================\n",
      "Cross-Validation Summary\n",
      "==================================================\n",
      "\n",
      "Average Metrics Across Folds:\n",
      "eval_accuracy: 0.8037 ± 0.0478\n",
      "eval_precision: 0.8158 ± 0.0386\n",
      "eval_recall: 0.8037 ± 0.0478\n",
      "eval_f1: 0.8045 ± 0.0463\n",
      "eval_loss: 0.9353 ± 0.1292\n",
      "\n",
      "Overall Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.70      0.83      0.76       215\n",
      "     Neutral       0.66      0.62      0.64       151\n",
      "     Positiv       0.94      0.86      0.90       339\n",
      "\n",
      "    accuracy                           0.80       705\n",
      "   macro avg       0.77      0.77      0.77       705\n",
      "weighted avg       0.81      0.80      0.80       705\n",
      "\n",
      "\n",
      "Weighted Average Scores Across All Folds:\n",
      "Precision: 0.8077\n",
      "Recall: 0.7986\n",
      "F1: 0.8006\n",
      "\n",
      "training and results for dbmdz/bert-base-german-uncased:\n",
      "\n",
      "==================================================\n",
      "Training Fold 1/3\n",
      "==================================================\n",
      "\n",
      "Training Fold 1 Sentiment label count:  {'negativ': 274, 'neutral': 252, 'positiv': 424}\n",
      "Validation Fold 1 Sentiment label count:  {'negativ': 73, 'neutral': 46, 'positiv': 93}\n",
      "Test Fold 1 Sentiment label count:  {'negativ': 69, 'neutral': 37, 'positiv': 125}\n",
      "Class weights for (negative, neutral, positive): tensor([1.1557, 1.2566, 0.7469])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 950/950 [00:00<00:00, 3992.89 examples/s]\n",
      "Map: 100%|██████████| 212/212 [00:00<00:00, 3662.85 examples/s]\n",
      "Map: 100%|██████████| 231/231 [00:00<00:00, 3885.80 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2375' max='2375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2375/2375 04:20, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.918900</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.797748</td>\n",
       "      <td>{0: 65, 1: 62, 2: 85}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.821600</td>\n",
       "      <td>0.954257</td>\n",
       "      <td>0.820755</td>\n",
       "      <td>0.839581</td>\n",
       "      <td>0.820755</td>\n",
       "      <td>0.825116</td>\n",
       "      <td>{0: 63, 1: 61, 2: 88}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.514100</td>\n",
       "      <td>1.089519</td>\n",
       "      <td>0.797170</td>\n",
       "      <td>0.827101</td>\n",
       "      <td>0.797170</td>\n",
       "      <td>0.804321</td>\n",
       "      <td>{0: 78, 1: 60, 2: 74}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.327200</td>\n",
       "      <td>1.251209</td>\n",
       "      <td>0.797170</td>\n",
       "      <td>0.810078</td>\n",
       "      <td>0.797170</td>\n",
       "      <td>0.800931</td>\n",
       "      <td>{0: 75, 1: 55, 2: 82}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.155900</td>\n",
       "      <td>1.286212</td>\n",
       "      <td>0.801887</td>\n",
       "      <td>0.818466</td>\n",
       "      <td>0.801887</td>\n",
       "      <td>0.806366</td>\n",
       "      <td>{0: 73, 1: 58, 2: 81}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='116' max='116' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [116/116 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.85      0.75      0.80        69\n",
      "     Neutral       0.57      0.76      0.65        37\n",
      "     Positiv       0.93      0.90      0.91       125\n",
      "\n",
      "    accuracy                           0.83       231\n",
      "   macro avg       0.78      0.80      0.79       231\n",
      "weighted avg       0.85      0.83      0.84       231\n",
      "\n",
      "\n",
      "==================================================\n",
      "Training Fold 2/3\n",
      "==================================================\n",
      "\n",
      "Training Fold 2 Sentiment label count:  {'negativ': 288, 'neutral': 216, 'positiv': 420}\n",
      "Validation Fold 2 Sentiment label count:  {'negativ': 66, 'neutral': 58, 'positiv': 113}\n",
      "Test Fold 2 Sentiment label count:  {'negativ': 62, 'neutral': 61, 'positiv': 109}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0694, 1.4259, 0.7333])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 924/924 [00:00<00:00, 3765.80 examples/s]\n",
      "Map: 100%|██████████| 237/237 [00:00<00:00, 3736.92 examples/s]\n",
      "Map: 100%|██████████| 232/232 [00:00<00:00, 3573.92 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2310' max='2310' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2310/2310 04:15, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.653010</td>\n",
       "      <td>0.839662</td>\n",
       "      <td>0.846572</td>\n",
       "      <td>0.839662</td>\n",
       "      <td>0.841577</td>\n",
       "      <td>{0: 71, 1: 63, 2: 103}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.774800</td>\n",
       "      <td>0.762807</td>\n",
       "      <td>0.814346</td>\n",
       "      <td>0.832874</td>\n",
       "      <td>0.814346</td>\n",
       "      <td>0.815937</td>\n",
       "      <td>{0: 88, 1: 47, 2: 102}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.563300</td>\n",
       "      <td>0.765792</td>\n",
       "      <td>0.843882</td>\n",
       "      <td>0.851201</td>\n",
       "      <td>0.843882</td>\n",
       "      <td>0.845991</td>\n",
       "      <td>{0: 71, 1: 63, 2: 103}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.318300</td>\n",
       "      <td>0.807222</td>\n",
       "      <td>0.839662</td>\n",
       "      <td>0.838087</td>\n",
       "      <td>0.839662</td>\n",
       "      <td>0.838703</td>\n",
       "      <td>{0: 67, 1: 55, 2: 115}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.262100</td>\n",
       "      <td>0.768236</td>\n",
       "      <td>0.848101</td>\n",
       "      <td>0.847758</td>\n",
       "      <td>0.848101</td>\n",
       "      <td>0.847902</td>\n",
       "      <td>{0: 67, 1: 57, 2: 113}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='116' max='116' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [116/116 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.60      0.74      0.66        62\n",
      "     Neutral       0.66      0.64      0.65        61\n",
      "     Positiv       0.90      0.79      0.84       109\n",
      "\n",
      "    accuracy                           0.74       232\n",
      "   macro avg       0.72      0.72      0.72       232\n",
      "weighted avg       0.75      0.74      0.74       232\n",
      "\n",
      "\n",
      "==================================================\n",
      "Training Fold 3/3\n",
      "==================================================\n",
      "\n",
      "Training Fold 3 Sentiment label count:  {'negativ': 270, 'neutral': 202, 'positiv': 440}\n",
      "Validation Fold 3 Sentiment label count:  {'negativ': 62, 'neutral': 80, 'positiv': 97}\n",
      "Test Fold 3 Sentiment label count:  {'negativ': 84, 'neutral': 53, 'positiv': 105}\n",
      "Class weights for (negative, neutral, positive): tensor([1.1259, 1.5050, 0.6909])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 912/912 [00:00<00:00, 4096.64 examples/s]\n",
      "Map: 100%|██████████| 239/239 [00:00<00:00, 3598.67 examples/s]\n",
      "Map: 100%|██████████| 242/242 [00:00<00:00, 4049.62 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2280' max='2280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2280/2280 04:13, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.302296</td>\n",
       "      <td>0.715481</td>\n",
       "      <td>0.750745</td>\n",
       "      <td>0.715481</td>\n",
       "      <td>0.716587</td>\n",
       "      <td>{0: 94, 1: 54, 2: 91}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.805900</td>\n",
       "      <td>1.340515</td>\n",
       "      <td>0.736402</td>\n",
       "      <td>0.736682</td>\n",
       "      <td>0.736402</td>\n",
       "      <td>0.735414</td>\n",
       "      <td>{0: 54, 1: 84, 2: 101}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.526600</td>\n",
       "      <td>1.355965</td>\n",
       "      <td>0.753138</td>\n",
       "      <td>0.752845</td>\n",
       "      <td>0.753138</td>\n",
       "      <td>0.751503</td>\n",
       "      <td>{0: 60, 1: 72, 2: 107}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.323800</td>\n",
       "      <td>1.619038</td>\n",
       "      <td>0.728033</td>\n",
       "      <td>0.729507</td>\n",
       "      <td>0.728033</td>\n",
       "      <td>0.726025</td>\n",
       "      <td>{0: 50, 1: 83, 2: 106}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>1.685025</td>\n",
       "      <td>0.707113</td>\n",
       "      <td>0.705488</td>\n",
       "      <td>0.707113</td>\n",
       "      <td>0.704865</td>\n",
       "      <td>{0: 55, 1: 77, 2: 107}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='121' max='121' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [121/121 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.85      0.79      0.81        84\n",
      "     Neutral       0.65      0.74      0.69        53\n",
      "     Positiv       0.94      0.93      0.94       105\n",
      "\n",
      "    accuracy                           0.84       242\n",
      "   macro avg       0.81      0.82      0.81       242\n",
      "weighted avg       0.84      0.84      0.84       242\n",
      "\n",
      "\n",
      "==================================================\n",
      "Cross-Validation Summary\n",
      "==================================================\n",
      "\n",
      "Average Metrics Across Folds:\n",
      "eval_accuracy: 0.8165 ± 0.0473\n",
      "eval_precision: 0.8226 ± 0.0445\n",
      "eval_recall: 0.8165 ± 0.0473\n",
      "eval_f1: 0.8182 ± 0.0465\n",
      "eval_loss: 1.0356 ± 0.3556\n",
      "\n",
      "Overall Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.76      0.76      0.76       215\n",
      "     Neutral       0.63      0.70      0.66       151\n",
      "     Positiv       0.92      0.87      0.90       339\n",
      "\n",
      "    accuracy                           0.80       705\n",
      "   macro avg       0.77      0.78      0.77       705\n",
      "weighted avg       0.81      0.80      0.81       705\n",
      "\n",
      "\n",
      "Weighted Average Scores Across All Folds:\n",
      "Precision: 0.8101\n",
      "Recall: 0.8028\n",
      "F1: 0.8057\n",
      "\n",
      "training and results for FacebookAI/xlm-roberta-base:\n",
      "\n",
      "==================================================\n",
      "Training Fold 1/3\n",
      "==================================================\n",
      "\n",
      "Training Fold 1 Sentiment label count:  {'negativ': 274, 'neutral': 252, 'positiv': 424}\n",
      "Validation Fold 1 Sentiment label count:  {'negativ': 73, 'neutral': 46, 'positiv': 93}\n",
      "Test Fold 1 Sentiment label count:  {'negativ': 69, 'neutral': 37, 'positiv': 125}\n",
      "Class weights for (negative, neutral, positive): tensor([1.1557, 1.2566, 0.7469])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 950/950 [00:00<00:00, 4977.94 examples/s]\n",
      "Map: 100%|██████████| 212/212 [00:00<00:00, 4243.40 examples/s]\n",
      "Map: 100%|██████████| 231/231 [00:00<00:00, 4481.92 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2375' max='2375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2375/2375 05:32, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.940266</td>\n",
       "      <td>0.617925</td>\n",
       "      <td>0.748964</td>\n",
       "      <td>0.617925</td>\n",
       "      <td>0.621562</td>\n",
       "      <td>{0: 30, 1: 110, 2: 72}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.896700</td>\n",
       "      <td>1.401684</td>\n",
       "      <td>0.721698</td>\n",
       "      <td>0.752958</td>\n",
       "      <td>0.721698</td>\n",
       "      <td>0.728561</td>\n",
       "      <td>{0: 57, 1: 67, 2: 88}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.738000</td>\n",
       "      <td>1.121706</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.796388</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.790311</td>\n",
       "      <td>{0: 88, 1: 39, 2: 85}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.645300</td>\n",
       "      <td>1.498908</td>\n",
       "      <td>0.768868</td>\n",
       "      <td>0.765149</td>\n",
       "      <td>0.768868</td>\n",
       "      <td>0.766632</td>\n",
       "      <td>{0: 76, 1: 42, 2: 94}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.554700</td>\n",
       "      <td>1.335152</td>\n",
       "      <td>0.787736</td>\n",
       "      <td>0.797626</td>\n",
       "      <td>0.787736</td>\n",
       "      <td>0.791346</td>\n",
       "      <td>{0: 75, 1: 52, 2: 85}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='116' max='116' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [116/116 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.79      0.88      0.84        69\n",
      "     Neutral       0.68      0.68      0.68        37\n",
      "     Positiv       0.94      0.88      0.91       125\n",
      "\n",
      "    accuracy                           0.85       231\n",
      "   macro avg       0.80      0.81      0.81       231\n",
      "weighted avg       0.85      0.85      0.85       231\n",
      "\n",
      "\n",
      "==================================================\n",
      "Training Fold 2/3\n",
      "==================================================\n",
      "\n",
      "Training Fold 2 Sentiment label count:  {'negativ': 288, 'neutral': 216, 'positiv': 420}\n",
      "Validation Fold 2 Sentiment label count:  {'negativ': 66, 'neutral': 58, 'positiv': 113}\n",
      "Test Fold 2 Sentiment label count:  {'negativ': 62, 'neutral': 61, 'positiv': 109}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0694, 1.4259, 0.7333])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 924/924 [00:00<00:00, 4963.43 examples/s]\n",
      "Map: 100%|██████████| 237/237 [00:00<00:00, 4155.10 examples/s]\n",
      "Map: 100%|██████████| 232/232 [00:00<00:00, 4630.51 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2310' max='2310' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2310/2310 05:22, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.571491</td>\n",
       "      <td>0.848101</td>\n",
       "      <td>0.857421</td>\n",
       "      <td>0.848101</td>\n",
       "      <td>0.846767</td>\n",
       "      <td>{0: 81, 1: 44, 2: 112}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.816300</td>\n",
       "      <td>0.868014</td>\n",
       "      <td>0.843882</td>\n",
       "      <td>0.847045</td>\n",
       "      <td>0.843882</td>\n",
       "      <td>0.838602</td>\n",
       "      <td>{0: 60, 1: 44, 2: 133}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.721500</td>\n",
       "      <td>0.905235</td>\n",
       "      <td>0.848101</td>\n",
       "      <td>0.855942</td>\n",
       "      <td>0.848101</td>\n",
       "      <td>0.847516</td>\n",
       "      <td>{0: 52, 1: 68, 2: 117}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.588900</td>\n",
       "      <td>0.925685</td>\n",
       "      <td>0.843882</td>\n",
       "      <td>0.849904</td>\n",
       "      <td>0.843882</td>\n",
       "      <td>0.837763</td>\n",
       "      <td>{0: 61, 1: 41, 2: 135}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.427300</td>\n",
       "      <td>0.794344</td>\n",
       "      <td>0.856540</td>\n",
       "      <td>0.857140</td>\n",
       "      <td>0.856540</td>\n",
       "      <td>0.856329</td>\n",
       "      <td>{0: 61, 1: 61, 2: 115}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='116' max='116' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [116/116 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.64      0.76      0.69        62\n",
      "     Neutral       0.71      0.75      0.73        61\n",
      "     Positiv       0.91      0.78      0.84       109\n",
      "\n",
      "    accuracy                           0.77       232\n",
      "   macro avg       0.75      0.76      0.75       232\n",
      "weighted avg       0.79      0.77      0.77       232\n",
      "\n",
      "\n",
      "==================================================\n",
      "Training Fold 3/3\n",
      "==================================================\n",
      "\n",
      "Training Fold 3 Sentiment label count:  {'negativ': 270, 'neutral': 202, 'positiv': 440}\n",
      "Validation Fold 3 Sentiment label count:  {'negativ': 62, 'neutral': 80, 'positiv': 97}\n",
      "Test Fold 3 Sentiment label count:  {'negativ': 84, 'neutral': 53, 'positiv': 105}\n",
      "Class weights for (negative, neutral, positive): tensor([1.1259, 1.5050, 0.6909])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 912/912 [00:00<00:00, 3084.61 examples/s]\n",
      "Map: 100%|██████████| 239/239 [00:00<00:00, 2507.65 examples/s]\n",
      "Map: 100%|██████████| 242/242 [00:00<00:00, 2429.80 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2280' max='2280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2280/2280 05:20, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.947346</td>\n",
       "      <td>0.719665</td>\n",
       "      <td>0.750838</td>\n",
       "      <td>0.719665</td>\n",
       "      <td>0.710310</td>\n",
       "      <td>{0: 89, 1: 44, 2: 106}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.846700</td>\n",
       "      <td>1.553150</td>\n",
       "      <td>0.715481</td>\n",
       "      <td>0.711645</td>\n",
       "      <td>0.715481</td>\n",
       "      <td>0.711237</td>\n",
       "      <td>{0: 63, 1: 68, 2: 108}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.765200</td>\n",
       "      <td>1.583897</td>\n",
       "      <td>0.740586</td>\n",
       "      <td>0.746308</td>\n",
       "      <td>0.740586</td>\n",
       "      <td>0.733883</td>\n",
       "      <td>{0: 76, 1: 56, 2: 107}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.647000</td>\n",
       "      <td>1.743541</td>\n",
       "      <td>0.719665</td>\n",
       "      <td>0.719627</td>\n",
       "      <td>0.719665</td>\n",
       "      <td>0.716389</td>\n",
       "      <td>{0: 50, 1: 79, 2: 110}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.437800</td>\n",
       "      <td>1.814499</td>\n",
       "      <td>0.723849</td>\n",
       "      <td>0.724987</td>\n",
       "      <td>0.723849</td>\n",
       "      <td>0.718255</td>\n",
       "      <td>{0: 70, 1: 60, 2: 109}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='121' max='121' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [121/121 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.82      0.77      0.80        84\n",
      "     Neutral       0.68      0.75      0.71        53\n",
      "     Positiv       0.93      0.92      0.93       105\n",
      "\n",
      "    accuracy                           0.83       242\n",
      "   macro avg       0.81      0.82      0.81       242\n",
      "weighted avg       0.84      0.83      0.84       242\n",
      "\n",
      "\n",
      "==================================================\n",
      "Cross-Validation Summary\n",
      "==================================================\n",
      "\n",
      "Average Metrics Across Folds:\n",
      "eval_accuracy: 0.8125 ± 0.0383\n",
      "eval_precision: 0.8196 ± 0.0325\n",
      "eval_recall: 0.8125 ± 0.0383\n",
      "eval_f1: 0.8145 ± 0.0368\n",
      "eval_loss: 1.1257 ± 0.2811\n",
      "\n",
      "Overall Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.75      0.80      0.78       215\n",
      "     Neutral       0.69      0.74      0.71       151\n",
      "     Positiv       0.93      0.86      0.89       339\n",
      "\n",
      "    accuracy                           0.82       705\n",
      "   macro avg       0.79      0.80      0.79       705\n",
      "weighted avg       0.82      0.82      0.82       705\n",
      "\n",
      "\n",
      "Weighted Average Scores Across All Folds:\n",
      "Precision: 0.8242\n",
      "Recall: 0.8170\n",
      "F1: 0.8196\n",
      "\n",
      "training and results for TUM/GottBERT_base_best:\n",
      "\n",
      "==================================================\n",
      "Training Fold 1/3\n",
      "==================================================\n",
      "\n",
      "Training Fold 1 Sentiment label count:  {'negativ': 274, 'neutral': 252, 'positiv': 424}\n",
      "Validation Fold 1 Sentiment label count:  {'negativ': 73, 'neutral': 46, 'positiv': 93}\n",
      "Test Fold 1 Sentiment label count:  {'negativ': 69, 'neutral': 37, 'positiv': 125}\n",
      "Class weights for (negative, neutral, positive): tensor([1.1557, 1.2566, 0.7469])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at TUM/GottBERT_base_best and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 950/950 [00:00<00:00, 5091.72 examples/s]\n",
      "Map: 100%|██████████| 212/212 [00:00<00:00, 4075.39 examples/s]\n",
      "Map: 100%|██████████| 231/231 [00:00<00:00, 3391.30 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2375' max='2375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2375/2375 04:26, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.884847</td>\n",
       "      <td>0.801887</td>\n",
       "      <td>0.831373</td>\n",
       "      <td>0.801887</td>\n",
       "      <td>0.808671</td>\n",
       "      <td>{0: 72, 1: 64, 2: 76}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.858100</td>\n",
       "      <td>1.030374</td>\n",
       "      <td>0.797170</td>\n",
       "      <td>0.799645</td>\n",
       "      <td>0.797170</td>\n",
       "      <td>0.797507</td>\n",
       "      <td>{0: 67, 1: 46, 2: 99}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.545000</td>\n",
       "      <td>0.911507</td>\n",
       "      <td>0.806604</td>\n",
       "      <td>0.812547</td>\n",
       "      <td>0.806604</td>\n",
       "      <td>0.803437</td>\n",
       "      <td>{0: 91, 1: 37, 2: 84}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.391100</td>\n",
       "      <td>0.872582</td>\n",
       "      <td>0.839623</td>\n",
       "      <td>0.845750</td>\n",
       "      <td>0.839623</td>\n",
       "      <td>0.841894</td>\n",
       "      <td>{0: 68, 1: 51, 2: 93}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.268000</td>\n",
       "      <td>0.912570</td>\n",
       "      <td>0.839623</td>\n",
       "      <td>0.847022</td>\n",
       "      <td>0.839623</td>\n",
       "      <td>0.842087</td>\n",
       "      <td>{0: 72, 1: 53, 2: 87}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='116' max='116' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [116/116 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.83      0.86      0.84        69\n",
      "     Neutral       0.66      0.73      0.69        37\n",
      "     Positiv       0.93      0.89      0.91       125\n",
      "\n",
      "    accuracy                           0.85       231\n",
      "   macro avg       0.81      0.82      0.82       231\n",
      "weighted avg       0.86      0.85      0.85       231\n",
      "\n",
      "\n",
      "==================================================\n",
      "Training Fold 2/3\n",
      "==================================================\n",
      "\n",
      "Training Fold 2 Sentiment label count:  {'negativ': 288, 'neutral': 216, 'positiv': 420}\n",
      "Validation Fold 2 Sentiment label count:  {'negativ': 66, 'neutral': 58, 'positiv': 113}\n",
      "Test Fold 2 Sentiment label count:  {'negativ': 62, 'neutral': 61, 'positiv': 109}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0694, 1.4259, 0.7333])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at TUM/GottBERT_base_best and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 924/924 [00:00<00:00, 5078.97 examples/s]\n",
      "Map: 100%|██████████| 237/237 [00:00<00:00, 4244.85 examples/s]\n",
      "Map: 100%|██████████| 232/232 [00:00<00:00, 4662.48 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2310' max='2310' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2310/2310 04:20, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.662607</td>\n",
       "      <td>0.856540</td>\n",
       "      <td>0.857799</td>\n",
       "      <td>0.856540</td>\n",
       "      <td>0.856129</td>\n",
       "      <td>{0: 59, 1: 59, 2: 119}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.776000</td>\n",
       "      <td>0.656891</td>\n",
       "      <td>0.852321</td>\n",
       "      <td>0.860848</td>\n",
       "      <td>0.852321</td>\n",
       "      <td>0.854143</td>\n",
       "      <td>{0: 69, 1: 67, 2: 101}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.508900</td>\n",
       "      <td>0.679287</td>\n",
       "      <td>0.869198</td>\n",
       "      <td>0.871952</td>\n",
       "      <td>0.869198</td>\n",
       "      <td>0.869466</td>\n",
       "      <td>{0: 59, 1: 63, 2: 115}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.319400</td>\n",
       "      <td>0.659168</td>\n",
       "      <td>0.881857</td>\n",
       "      <td>0.882724</td>\n",
       "      <td>0.881857</td>\n",
       "      <td>0.882210</td>\n",
       "      <td>{0: 65, 1: 60, 2: 112}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.292500</td>\n",
       "      <td>0.722814</td>\n",
       "      <td>0.864979</td>\n",
       "      <td>0.868579</td>\n",
       "      <td>0.864979</td>\n",
       "      <td>0.866299</td>\n",
       "      <td>{0: 65, 1: 63, 2: 109}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='116' max='116' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [116/116 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.68      0.84      0.75        62\n",
      "     Neutral       0.69      0.66      0.67        61\n",
      "     Positiv       0.93      0.83      0.88       109\n",
      "\n",
      "    accuracy                           0.79       232\n",
      "   macro avg       0.77      0.78      0.77       232\n",
      "weighted avg       0.80      0.79      0.79       232\n",
      "\n",
      "\n",
      "==================================================\n",
      "Training Fold 3/3\n",
      "==================================================\n",
      "\n",
      "Training Fold 3 Sentiment label count:  {'negativ': 270, 'neutral': 202, 'positiv': 440}\n",
      "Validation Fold 3 Sentiment label count:  {'negativ': 62, 'neutral': 80, 'positiv': 97}\n",
      "Test Fold 3 Sentiment label count:  {'negativ': 84, 'neutral': 53, 'positiv': 105}\n",
      "Class weights for (negative, neutral, positive): tensor([1.1259, 1.5050, 0.6909])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at TUM/GottBERT_base_best and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 912/912 [00:00<00:00, 5145.96 examples/s]\n",
      "Map: 100%|██████████| 239/239 [00:00<00:00, 4311.23 examples/s]\n",
      "Map: 100%|██████████| 242/242 [00:00<00:00, 4775.25 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2280' max='2280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2280/2280 04:18, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.149005</td>\n",
       "      <td>0.744770</td>\n",
       "      <td>0.771746</td>\n",
       "      <td>0.744770</td>\n",
       "      <td>0.730385</td>\n",
       "      <td>{0: 79, 1: 42, 2: 118}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.781000</td>\n",
       "      <td>1.443302</td>\n",
       "      <td>0.748954</td>\n",
       "      <td>0.753595</td>\n",
       "      <td>0.748954</td>\n",
       "      <td>0.750640</td>\n",
       "      <td>{0: 67, 1: 81, 2: 91}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.523300</td>\n",
       "      <td>1.396153</td>\n",
       "      <td>0.744770</td>\n",
       "      <td>0.749106</td>\n",
       "      <td>0.744770</td>\n",
       "      <td>0.741075</td>\n",
       "      <td>{0: 69, 1: 61, 2: 109}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.351500</td>\n",
       "      <td>1.444126</td>\n",
       "      <td>0.732218</td>\n",
       "      <td>0.730262</td>\n",
       "      <td>0.732218</td>\n",
       "      <td>0.727973</td>\n",
       "      <td>{0: 59, 1: 68, 2: 112}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.264600</td>\n",
       "      <td>1.481215</td>\n",
       "      <td>0.736402</td>\n",
       "      <td>0.734360</td>\n",
       "      <td>0.736402</td>\n",
       "      <td>0.732547</td>\n",
       "      <td>{0: 59, 1: 69, 2: 111}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='121' max='121' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [121/121 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.88      0.85      0.86        84\n",
      "     Neutral       0.66      0.83      0.73        53\n",
      "     Positiv       0.98      0.88      0.92       105\n",
      "\n",
      "    accuracy                           0.86       242\n",
      "   macro avg       0.84      0.85      0.84       242\n",
      "weighted avg       0.87      0.86      0.86       242\n",
      "\n",
      "\n",
      "==================================================\n",
      "Cross-Validation Summary\n",
      "==================================================\n",
      "\n",
      "Average Metrics Across Folds:\n",
      "eval_accuracy: 0.8323 ± 0.0339\n",
      "eval_precision: 0.8432 ± 0.0301\n",
      "eval_recall: 0.8323 ± 0.0339\n",
      "eval_f1: 0.8349 ± 0.0342\n",
      "eval_loss: 0.9277 ± 0.2036\n",
      "\n",
      "Overall Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.80      0.85      0.82       215\n",
      "     Neutral       0.67      0.74      0.70       151\n",
      "     Positiv       0.95      0.87      0.90       339\n",
      "\n",
      "    accuracy                           0.83       705\n",
      "   macro avg       0.80      0.82      0.81       705\n",
      "weighted avg       0.84      0.83      0.84       705\n",
      "\n",
      "\n",
      "Weighted Average Scores Across All Folds:\n",
      "Precision: 0.8412\n",
      "Recall: 0.8326\n",
      "F1: 0.8356\n",
      "\n",
      "training and results for TUM/GottBERT_filtered_base_best:\n",
      "\n",
      "==================================================\n",
      "Training Fold 1/3\n",
      "==================================================\n",
      "\n",
      "Training Fold 1 Sentiment label count:  {'negativ': 274, 'neutral': 252, 'positiv': 424}\n",
      "Validation Fold 1 Sentiment label count:  {'negativ': 73, 'neutral': 46, 'positiv': 93}\n",
      "Test Fold 1 Sentiment label count:  {'negativ': 69, 'neutral': 37, 'positiv': 125}\n",
      "Class weights for (negative, neutral, positive): tensor([1.1557, 1.2566, 0.7469])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at TUM/GottBERT_filtered_base_best and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 950/950 [00:00<00:00, 5106.77 examples/s]\n",
      "Map: 100%|██████████| 212/212 [00:00<00:00, 4182.03 examples/s]\n",
      "Map: 100%|██████████| 231/231 [00:00<00:00, 4803.33 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2375' max='2375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2375/2375 04:25, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.069056</td>\n",
       "      <td>0.740566</td>\n",
       "      <td>0.822841</td>\n",
       "      <td>0.740566</td>\n",
       "      <td>0.754755</td>\n",
       "      <td>{0: 49, 1: 86, 2: 77}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.789100</td>\n",
       "      <td>1.029357</td>\n",
       "      <td>0.816038</td>\n",
       "      <td>0.821063</td>\n",
       "      <td>0.816038</td>\n",
       "      <td>0.817919</td>\n",
       "      <td>{0: 69, 1: 51, 2: 92}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.523600</td>\n",
       "      <td>0.882868</td>\n",
       "      <td>0.844340</td>\n",
       "      <td>0.853584</td>\n",
       "      <td>0.844340</td>\n",
       "      <td>0.846439</td>\n",
       "      <td>{0: 77, 1: 53, 2: 82}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.419600</td>\n",
       "      <td>0.875830</td>\n",
       "      <td>0.844340</td>\n",
       "      <td>0.848890</td>\n",
       "      <td>0.844340</td>\n",
       "      <td>0.845346</td>\n",
       "      <td>{0: 78, 1: 49, 2: 85}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.273600</td>\n",
       "      <td>0.990556</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.845305</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.834740</td>\n",
       "      <td>{0: 72, 1: 57, 2: 83}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='116' max='116' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [116/116 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.81      0.90      0.85        69\n",
      "     Neutral       0.74      0.70      0.72        37\n",
      "     Positiv       0.94      0.90      0.92       125\n",
      "\n",
      "    accuracy                           0.87       231\n",
      "   macro avg       0.83      0.83      0.83       231\n",
      "weighted avg       0.87      0.87      0.87       231\n",
      "\n",
      "\n",
      "==================================================\n",
      "Training Fold 2/3\n",
      "==================================================\n",
      "\n",
      "Training Fold 2 Sentiment label count:  {'negativ': 288, 'neutral': 216, 'positiv': 420}\n",
      "Validation Fold 2 Sentiment label count:  {'negativ': 66, 'neutral': 58, 'positiv': 113}\n",
      "Test Fold 2 Sentiment label count:  {'negativ': 62, 'neutral': 61, 'positiv': 109}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0694, 1.4259, 0.7333])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at TUM/GottBERT_filtered_base_best and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 924/924 [00:00<00:00, 5109.91 examples/s]\n",
      "Map: 100%|██████████| 237/237 [00:00<00:00, 4322.95 examples/s]\n",
      "Map: 100%|██████████| 232/232 [00:00<00:00, 4801.56 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2310' max='2310' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2310/2310 04:20, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.579585</td>\n",
       "      <td>0.856540</td>\n",
       "      <td>0.864544</td>\n",
       "      <td>0.856540</td>\n",
       "      <td>0.857732</td>\n",
       "      <td>{0: 58, 1: 70, 2: 109}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.731000</td>\n",
       "      <td>0.457439</td>\n",
       "      <td>0.902954</td>\n",
       "      <td>0.903802</td>\n",
       "      <td>0.902954</td>\n",
       "      <td>0.902892</td>\n",
       "      <td>{0: 70, 1: 54, 2: 113}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.520800</td>\n",
       "      <td>0.850861</td>\n",
       "      <td>0.831224</td>\n",
       "      <td>0.845891</td>\n",
       "      <td>0.831224</td>\n",
       "      <td>0.834282</td>\n",
       "      <td>{0: 58, 1: 74, 2: 105}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.305600</td>\n",
       "      <td>0.609961</td>\n",
       "      <td>0.864979</td>\n",
       "      <td>0.863709</td>\n",
       "      <td>0.864979</td>\n",
       "      <td>0.862949</td>\n",
       "      <td>{0: 68, 1: 50, 2: 119}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.275900</td>\n",
       "      <td>0.780908</td>\n",
       "      <td>0.856540</td>\n",
       "      <td>0.864164</td>\n",
       "      <td>0.856540</td>\n",
       "      <td>0.858755</td>\n",
       "      <td>{0: 65, 1: 67, 2: 105}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='116' max='116' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [116/116 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.67      0.89      0.76        62\n",
      "     Neutral       0.72      0.62      0.67        61\n",
      "     Positiv       0.93      0.83      0.87       109\n",
      "\n",
      "    accuracy                           0.79       232\n",
      "   macro avg       0.77      0.78      0.77       232\n",
      "weighted avg       0.80      0.79      0.79       232\n",
      "\n",
      "\n",
      "==================================================\n",
      "Training Fold 3/3\n",
      "==================================================\n",
      "\n",
      "Training Fold 3 Sentiment label count:  {'negativ': 270, 'neutral': 202, 'positiv': 440}\n",
      "Validation Fold 3 Sentiment label count:  {'negativ': 62, 'neutral': 80, 'positiv': 97}\n",
      "Test Fold 3 Sentiment label count:  {'negativ': 84, 'neutral': 53, 'positiv': 105}\n",
      "Class weights for (negative, neutral, positive): tensor([1.1259, 1.5050, 0.6909])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at TUM/GottBERT_filtered_base_best and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 912/912 [00:00<00:00, 5164.43 examples/s]\n",
      "Map: 100%|██████████| 239/239 [00:00<00:00, 4242.41 examples/s]\n",
      "Map: 100%|██████████| 242/242 [00:00<00:00, 4783.87 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2280' max='2280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2280/2280 04:18, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.141562</td>\n",
       "      <td>0.753138</td>\n",
       "      <td>0.773085</td>\n",
       "      <td>0.753138</td>\n",
       "      <td>0.745097</td>\n",
       "      <td>{0: 88, 1: 50, 2: 101}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.775600</td>\n",
       "      <td>1.143920</td>\n",
       "      <td>0.765690</td>\n",
       "      <td>0.767682</td>\n",
       "      <td>0.765690</td>\n",
       "      <td>0.765960</td>\n",
       "      <td>{0: 56, 1: 85, 2: 98}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.557100</td>\n",
       "      <td>1.289446</td>\n",
       "      <td>0.757322</td>\n",
       "      <td>0.760941</td>\n",
       "      <td>0.757322</td>\n",
       "      <td>0.754018</td>\n",
       "      <td>{0: 75, 1: 63, 2: 101}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.377800</td>\n",
       "      <td>1.432260</td>\n",
       "      <td>0.757322</td>\n",
       "      <td>0.760165</td>\n",
       "      <td>0.757322</td>\n",
       "      <td>0.755672</td>\n",
       "      <td>{0: 57, 1: 70, 2: 112}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.250700</td>\n",
       "      <td>1.377816</td>\n",
       "      <td>0.757322</td>\n",
       "      <td>0.757063</td>\n",
       "      <td>0.757322</td>\n",
       "      <td>0.754975</td>\n",
       "      <td>{0: 62, 1: 69, 2: 108}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='121' max='121' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [121/121 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.88      0.77      0.82        84\n",
      "     Neutral       0.65      0.83      0.73        53\n",
      "     Positiv       0.95      0.90      0.93       105\n",
      "\n",
      "    accuracy                           0.84       242\n",
      "   macro avg       0.83      0.84      0.83       242\n",
      "weighted avg       0.86      0.84      0.85       242\n",
      "\n",
      "\n",
      "==================================================\n",
      "Cross-Validation Summary\n",
      "==================================================\n",
      "\n",
      "Average Metrics Across Folds:\n",
      "eval_accuracy: 0.8395 ± 0.0329\n",
      "eval_precision: 0.8508 ± 0.0258\n",
      "eval_recall: 0.8395 ± 0.0329\n",
      "eval_f1: 0.8408 ± 0.0326\n",
      "eval_loss: 0.8185 ± 0.1097\n",
      "\n",
      "Overall Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.78      0.85      0.81       215\n",
      "     Neutral       0.69      0.72      0.70       151\n",
      "     Positiv       0.94      0.88      0.91       339\n",
      "\n",
      "    accuracy                           0.83       705\n",
      "   macro avg       0.80      0.81      0.81       705\n",
      "weighted avg       0.84      0.83      0.83       705\n",
      "\n",
      "\n",
      "Weighted Average Scores Across All Folds:\n",
      "Precision: 0.8384\n",
      "Recall: 0.8326\n",
      "F1: 0.8345\n",
      "\n",
      "training and results for TUM/GottBERT_base_last:\n",
      "\n",
      "==================================================\n",
      "Training Fold 1/3\n",
      "==================================================\n",
      "\n",
      "Training Fold 1 Sentiment label count:  {'negativ': 274, 'neutral': 252, 'positiv': 424}\n",
      "Validation Fold 1 Sentiment label count:  {'negativ': 73, 'neutral': 46, 'positiv': 93}\n",
      "Test Fold 1 Sentiment label count:  {'negativ': 69, 'neutral': 37, 'positiv': 125}\n",
      "Class weights for (negative, neutral, positive): tensor([1.1557, 1.2566, 0.7469])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at TUM/GottBERT_base_last were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at TUM/GottBERT_base_last and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 950/950 [00:00<00:00, 4381.02 examples/s]\n",
      "Map: 100%|██████████| 212/212 [00:00<00:00, 3694.73 examples/s]\n",
      "Map: 100%|██████████| 231/231 [00:00<00:00, 4455.75 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2375' max='2375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2375/2375 04:25, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.925790</td>\n",
       "      <td>0.783019</td>\n",
       "      <td>0.835194</td>\n",
       "      <td>0.783019</td>\n",
       "      <td>0.794593</td>\n",
       "      <td>{0: 64, 1: 74, 2: 74}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.831300</td>\n",
       "      <td>0.854170</td>\n",
       "      <td>0.816038</td>\n",
       "      <td>0.817813</td>\n",
       "      <td>0.816038</td>\n",
       "      <td>0.816720</td>\n",
       "      <td>{0: 70, 1: 48, 2: 94}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.541300</td>\n",
       "      <td>0.882144</td>\n",
       "      <td>0.820755</td>\n",
       "      <td>0.827651</td>\n",
       "      <td>0.820755</td>\n",
       "      <td>0.821966</td>\n",
       "      <td>{0: 82, 1: 47, 2: 83}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.416300</td>\n",
       "      <td>0.923926</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.835487</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.832232</td>\n",
       "      <td>{0: 72, 1: 51, 2: 89}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.289000</td>\n",
       "      <td>0.879120</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.855818</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.850817</td>\n",
       "      <td>{0: 78, 1: 50, 2: 84}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='116' max='116' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [116/116 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.77      0.87      0.82        69\n",
      "     Neutral       0.71      0.65      0.68        37\n",
      "     Positiv       0.94      0.90      0.92       125\n",
      "\n",
      "    accuracy                           0.85       231\n",
      "   macro avg       0.81      0.80      0.80       231\n",
      "weighted avg       0.85      0.85      0.85       231\n",
      "\n",
      "\n",
      "==================================================\n",
      "Training Fold 2/3\n",
      "==================================================\n",
      "\n",
      "Training Fold 2 Sentiment label count:  {'negativ': 288, 'neutral': 216, 'positiv': 420}\n",
      "Validation Fold 2 Sentiment label count:  {'negativ': 66, 'neutral': 58, 'positiv': 113}\n",
      "Test Fold 2 Sentiment label count:  {'negativ': 62, 'neutral': 61, 'positiv': 109}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0694, 1.4259, 0.7333])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at TUM/GottBERT_base_last were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at TUM/GottBERT_base_last and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 924/924 [00:00<00:00, 4744.64 examples/s]\n",
      "Map: 100%|██████████| 237/237 [00:00<00:00, 4033.20 examples/s]\n",
      "Map: 100%|██████████| 232/232 [00:00<00:00, 4304.06 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2310' max='2310' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2310/2310 04:21, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.610276</td>\n",
       "      <td>0.856540</td>\n",
       "      <td>0.856024</td>\n",
       "      <td>0.856540</td>\n",
       "      <td>0.853725</td>\n",
       "      <td>{0: 63, 1: 49, 2: 125}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.741700</td>\n",
       "      <td>0.651074</td>\n",
       "      <td>0.860759</td>\n",
       "      <td>0.862805</td>\n",
       "      <td>0.860759</td>\n",
       "      <td>0.861388</td>\n",
       "      <td>{0: 69, 1: 60, 2: 108}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.549400</td>\n",
       "      <td>0.798577</td>\n",
       "      <td>0.860759</td>\n",
       "      <td>0.868130</td>\n",
       "      <td>0.860759</td>\n",
       "      <td>0.862660</td>\n",
       "      <td>{0: 62, 1: 68, 2: 107}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.343500</td>\n",
       "      <td>0.651554</td>\n",
       "      <td>0.873418</td>\n",
       "      <td>0.873542</td>\n",
       "      <td>0.873418</td>\n",
       "      <td>0.873402</td>\n",
       "      <td>{0: 68, 1: 57, 2: 112}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.269700</td>\n",
       "      <td>0.720586</td>\n",
       "      <td>0.869198</td>\n",
       "      <td>0.870674</td>\n",
       "      <td>0.869198</td>\n",
       "      <td>0.869194</td>\n",
       "      <td>{0: 60, 1: 61, 2: 116}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='116' max='116' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [116/116 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.66      0.85      0.75        62\n",
      "     Neutral       0.73      0.62      0.67        61\n",
      "     Positiv       0.91      0.83      0.87       109\n",
      "\n",
      "    accuracy                           0.78       232\n",
      "   macro avg       0.77      0.77      0.76       232\n",
      "weighted avg       0.80      0.78      0.79       232\n",
      "\n",
      "\n",
      "==================================================\n",
      "Training Fold 3/3\n",
      "==================================================\n",
      "\n",
      "Training Fold 3 Sentiment label count:  {'negativ': 270, 'neutral': 202, 'positiv': 440}\n",
      "Validation Fold 3 Sentiment label count:  {'negativ': 62, 'neutral': 80, 'positiv': 97}\n",
      "Test Fold 3 Sentiment label count:  {'negativ': 84, 'neutral': 53, 'positiv': 105}\n",
      "Class weights for (negative, neutral, positive): tensor([1.1259, 1.5050, 0.6909])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at TUM/GottBERT_base_last were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at TUM/GottBERT_base_last and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 912/912 [00:00<00:00, 5046.31 examples/s]\n",
      "Map: 100%|██████████| 239/239 [00:00<00:00, 4030.34 examples/s]\n",
      "Map: 100%|██████████| 242/242 [00:00<00:00, 3445.08 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2280' max='2280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2280/2280 04:19, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.029835</td>\n",
       "      <td>0.765690</td>\n",
       "      <td>0.799328</td>\n",
       "      <td>0.765690</td>\n",
       "      <td>0.760032</td>\n",
       "      <td>{0: 89, 1: 47, 2: 103}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.781200</td>\n",
       "      <td>1.316112</td>\n",
       "      <td>0.753138</td>\n",
       "      <td>0.754213</td>\n",
       "      <td>0.753138</td>\n",
       "      <td>0.753593</td>\n",
       "      <td>{0: 64, 1: 80, 2: 95}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.533700</td>\n",
       "      <td>1.322697</td>\n",
       "      <td>0.769874</td>\n",
       "      <td>0.776365</td>\n",
       "      <td>0.769874</td>\n",
       "      <td>0.766997</td>\n",
       "      <td>{0: 72, 1: 61, 2: 106}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.340600</td>\n",
       "      <td>1.332245</td>\n",
       "      <td>0.769874</td>\n",
       "      <td>0.768572</td>\n",
       "      <td>0.769874</td>\n",
       "      <td>0.768977</td>\n",
       "      <td>{0: 63, 1: 76, 2: 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.228700</td>\n",
       "      <td>1.472779</td>\n",
       "      <td>0.753138</td>\n",
       "      <td>0.751839</td>\n",
       "      <td>0.753138</td>\n",
       "      <td>0.751599</td>\n",
       "      <td>{0: 56, 1: 79, 2: 104}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='121' max='121' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [121/121 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.88      0.86      0.87        84\n",
      "     Neutral       0.74      0.81      0.77        53\n",
      "     Positiv       0.96      0.93      0.95       105\n",
      "\n",
      "    accuracy                           0.88       242\n",
      "   macro avg       0.86      0.87      0.86       242\n",
      "weighted avg       0.88      0.88      0.88       242\n",
      "\n",
      "\n",
      "==================================================\n",
      "Cross-Validation Summary\n",
      "==================================================\n",
      "\n",
      "Average Metrics Across Folds:\n",
      "eval_accuracy: 0.8390 ± 0.0447\n",
      "eval_precision: 0.8452 ± 0.0397\n",
      "eval_recall: 0.8390 ± 0.0447\n",
      "eval_f1: 0.8400 ± 0.0446\n",
      "eval_loss: 0.9557 ± 0.2712\n",
      "\n",
      "Overall Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.77      0.86      0.81       215\n",
      "     Neutral       0.73      0.70      0.71       151\n",
      "     Positiv       0.94      0.89      0.91       339\n",
      "\n",
      "    accuracy                           0.84       705\n",
      "   macro avg       0.81      0.81      0.81       705\n",
      "weighted avg       0.84      0.84      0.84       705\n",
      "\n",
      "\n",
      "Weighted Average Scores Across All Folds:\n",
      "Precision: 0.8421\n",
      "Recall: 0.8383\n",
      "F1: 0.8391\n",
      "\n",
      "training and results for distilbert/distilbert-base-german-cased:\n",
      "\n",
      "==================================================\n",
      "Training Fold 1/3\n",
      "==================================================\n",
      "\n",
      "Training Fold 1 Sentiment label count:  {'negativ': 274, 'neutral': 252, 'positiv': 424}\n",
      "Validation Fold 1 Sentiment label count:  {'negativ': 73, 'neutral': 46, 'positiv': 93}\n",
      "Test Fold 1 Sentiment label count:  {'negativ': 69, 'neutral': 37, 'positiv': 125}\n",
      "Class weights for (negative, neutral, positive): tensor([1.1557, 1.2566, 0.7469])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 950/950 [00:00<00:00, 4491.87 examples/s]\n",
      "Map: 100%|██████████| 212/212 [00:00<00:00, 3647.95 examples/s]\n",
      "Map: 100%|██████████| 231/231 [00:00<00:00, 4241.88 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2375' max='2375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2375/2375 02:20, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.822533</td>\n",
       "      <td>0.764151</td>\n",
       "      <td>0.770107</td>\n",
       "      <td>0.764151</td>\n",
       "      <td>0.765735</td>\n",
       "      <td>{0: 66, 1: 53, 2: 93}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.799800</td>\n",
       "      <td>0.954750</td>\n",
       "      <td>0.787736</td>\n",
       "      <td>0.789837</td>\n",
       "      <td>0.787736</td>\n",
       "      <td>0.787589</td>\n",
       "      <td>{0: 66, 1: 46, 2: 100}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.496400</td>\n",
       "      <td>0.885898</td>\n",
       "      <td>0.806604</td>\n",
       "      <td>0.809744</td>\n",
       "      <td>0.806604</td>\n",
       "      <td>0.807134</td>\n",
       "      <td>{0: 79, 1: 47, 2: 86}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.384600</td>\n",
       "      <td>1.127799</td>\n",
       "      <td>0.797170</td>\n",
       "      <td>0.804814</td>\n",
       "      <td>0.797170</td>\n",
       "      <td>0.799864</td>\n",
       "      <td>{0: 68, 1: 53, 2: 91}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.275300</td>\n",
       "      <td>1.118231</td>\n",
       "      <td>0.797170</td>\n",
       "      <td>0.804735</td>\n",
       "      <td>0.797170</td>\n",
       "      <td>0.799902</td>\n",
       "      <td>{0: 69, 1: 53, 2: 90}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='116' max='116' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [116/116 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.68      0.91      0.78        69\n",
      "     Neutral       0.63      0.59      0.61        37\n",
      "     Positiv       0.93      0.78      0.85       125\n",
      "\n",
      "    accuracy                           0.79       231\n",
      "   macro avg       0.75      0.76      0.75       231\n",
      "weighted avg       0.81      0.79      0.79       231\n",
      "\n",
      "\n",
      "==================================================\n",
      "Training Fold 2/3\n",
      "==================================================\n",
      "\n",
      "Training Fold 2 Sentiment label count:  {'negativ': 288, 'neutral': 216, 'positiv': 420}\n",
      "Validation Fold 2 Sentiment label count:  {'negativ': 66, 'neutral': 58, 'positiv': 113}\n",
      "Test Fold 2 Sentiment label count:  {'negativ': 62, 'neutral': 61, 'positiv': 109}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0694, 1.4259, 0.7333])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 924/924 [00:00<00:00, 4994.03 examples/s]\n",
      "Map: 100%|██████████| 237/237 [00:00<00:00, 4095.14 examples/s]\n",
      "Map: 100%|██████████| 232/232 [00:00<00:00, 5055.64 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2310' max='2310' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2310/2310 02:17, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.618776</td>\n",
       "      <td>0.784810</td>\n",
       "      <td>0.783236</td>\n",
       "      <td>0.784810</td>\n",
       "      <td>0.783864</td>\n",
       "      <td>{0: 67, 1: 55, 2: 115}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.723000</td>\n",
       "      <td>0.670976</td>\n",
       "      <td>0.822785</td>\n",
       "      <td>0.828079</td>\n",
       "      <td>0.822785</td>\n",
       "      <td>0.821225</td>\n",
       "      <td>{0: 82, 1: 52, 2: 103}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.516000</td>\n",
       "      <td>0.738165</td>\n",
       "      <td>0.831224</td>\n",
       "      <td>0.840100</td>\n",
       "      <td>0.831224</td>\n",
       "      <td>0.833611</td>\n",
       "      <td>{0: 62, 1: 69, 2: 106}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.299100</td>\n",
       "      <td>0.734327</td>\n",
       "      <td>0.843882</td>\n",
       "      <td>0.843934</td>\n",
       "      <td>0.843882</td>\n",
       "      <td>0.843821</td>\n",
       "      <td>{0: 68, 1: 58, 2: 111}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.236300</td>\n",
       "      <td>0.782170</td>\n",
       "      <td>0.831224</td>\n",
       "      <td>0.838543</td>\n",
       "      <td>0.831224</td>\n",
       "      <td>0.833220</td>\n",
       "      <td>{0: 66, 1: 67, 2: 104}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='116' max='116' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [116/116 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.64      0.79      0.71        62\n",
      "     Neutral       0.74      0.64      0.68        61\n",
      "     Positiv       0.86      0.82      0.84       109\n",
      "\n",
      "    accuracy                           0.76       232\n",
      "   macro avg       0.75      0.75      0.74       232\n",
      "weighted avg       0.77      0.76      0.76       232\n",
      "\n",
      "\n",
      "==================================================\n",
      "Training Fold 3/3\n",
      "==================================================\n",
      "\n",
      "Training Fold 3 Sentiment label count:  {'negativ': 270, 'neutral': 202, 'positiv': 440}\n",
      "Validation Fold 3 Sentiment label count:  {'negativ': 62, 'neutral': 80, 'positiv': 97}\n",
      "Test Fold 3 Sentiment label count:  {'negativ': 84, 'neutral': 53, 'positiv': 105}\n",
      "Class weights for (negative, neutral, positive): tensor([1.1259, 1.5050, 0.6909])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 912/912 [00:00<00:00, 4342.91 examples/s]\n",
      "Map: 100%|██████████| 239/239 [00:00<00:00, 3699.79 examples/s]\n",
      "Map: 100%|██████████| 242/242 [00:00<00:00, 4897.85 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2280' max='2280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2280/2280 02:15, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.149027</td>\n",
       "      <td>0.715481</td>\n",
       "      <td>0.751736</td>\n",
       "      <td>0.715481</td>\n",
       "      <td>0.702072</td>\n",
       "      <td>{0: 66, 1: 41, 2: 132}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.754900</td>\n",
       "      <td>1.281742</td>\n",
       "      <td>0.690377</td>\n",
       "      <td>0.690031</td>\n",
       "      <td>0.690377</td>\n",
       "      <td>0.687325</td>\n",
       "      <td>{0: 66, 1: 66, 2: 107}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.552700</td>\n",
       "      <td>1.447227</td>\n",
       "      <td>0.723849</td>\n",
       "      <td>0.728289</td>\n",
       "      <td>0.723849</td>\n",
       "      <td>0.719065</td>\n",
       "      <td>{0: 70, 1: 59, 2: 110}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.384000</td>\n",
       "      <td>1.671694</td>\n",
       "      <td>0.707113</td>\n",
       "      <td>0.704336</td>\n",
       "      <td>0.707113</td>\n",
       "      <td>0.702295</td>\n",
       "      <td>{0: 52, 1: 74, 2: 113}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.253700</td>\n",
       "      <td>1.762395</td>\n",
       "      <td>0.694561</td>\n",
       "      <td>0.696552</td>\n",
       "      <td>0.694561</td>\n",
       "      <td>0.688007</td>\n",
       "      <td>{0: 55, 1: 63, 2: 121}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='121' max='121' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [121/121 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.81      0.83      0.82        84\n",
      "     Neutral       0.75      0.72      0.73        53\n",
      "     Positiv       0.92      0.92      0.92       105\n",
      "\n",
      "    accuracy                           0.85       242\n",
      "   macro avg       0.83      0.82      0.83       242\n",
      "weighted avg       0.85      0.85      0.85       242\n",
      "\n",
      "\n",
      "==================================================\n",
      "Cross-Validation Summary\n",
      "==================================================\n",
      "\n",
      "Average Metrics Across Folds:\n",
      "eval_accuracy: 0.8080 ± 0.0275\n",
      "eval_precision: 0.8187 ± 0.0228\n",
      "eval_recall: 0.8080 ± 0.0275\n",
      "eval_f1: 0.8100 ± 0.0266\n",
      "eval_loss: 1.0116 ± 0.2606\n",
      "\n",
      "Overall Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.72      0.85      0.78       215\n",
      "     Neutral       0.71      0.66      0.68       151\n",
      "     Positiv       0.91      0.83      0.87       339\n",
      "\n",
      "    accuracy                           0.80       705\n",
      "   macro avg       0.78      0.78      0.78       705\n",
      "weighted avg       0.81      0.80      0.80       705\n",
      "\n",
      "\n",
      "Weighted Average Scores Across All Folds:\n",
      "Precision: 0.8072\n",
      "Recall: 0.8000\n",
      "F1: 0.8010\n",
      "\n",
      "training and results for GerMedBERT/medbert-512:\n",
      "\n",
      "==================================================\n",
      "Training Fold 1/3\n",
      "==================================================\n",
      "\n",
      "Training Fold 1 Sentiment label count:  {'negativ': 274, 'neutral': 252, 'positiv': 424}\n",
      "Validation Fold 1 Sentiment label count:  {'negativ': 73, 'neutral': 46, 'positiv': 93}\n",
      "Test Fold 1 Sentiment label count:  {'negativ': 69, 'neutral': 37, 'positiv': 125}\n",
      "Class weights for (negative, neutral, positive): tensor([1.1557, 1.2566, 0.7469])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Device set to use cuda:0\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GerMedBERT/medbert-512 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 950/950 [00:00<00:00, 3827.58 examples/s]\n",
      "Map: 100%|██████████| 212/212 [00:00<00:00, 3030.56 examples/s]\n",
      "Map: 100%|██████████| 231/231 [00:00<00:00, 3769.95 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2375' max='2375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2375/2375 04:24, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.113644</td>\n",
       "      <td>0.721698</td>\n",
       "      <td>0.739940</td>\n",
       "      <td>0.721698</td>\n",
       "      <td>0.724025</td>\n",
       "      <td>{0: 56, 1: 61, 2: 95}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.856200</td>\n",
       "      <td>1.137417</td>\n",
       "      <td>0.759434</td>\n",
       "      <td>0.764115</td>\n",
       "      <td>0.759434</td>\n",
       "      <td>0.760309</td>\n",
       "      <td>{0: 65, 1: 52, 2: 95}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.562200</td>\n",
       "      <td>1.039343</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.798361</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.794492</td>\n",
       "      <td>{0: 77, 1: 49, 2: 86}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.367900</td>\n",
       "      <td>1.144373</td>\n",
       "      <td>0.783019</td>\n",
       "      <td>0.799265</td>\n",
       "      <td>0.783019</td>\n",
       "      <td>0.788143</td>\n",
       "      <td>{0: 70, 1: 58, 2: 84}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.284500</td>\n",
       "      <td>1.215371</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.814491</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.798388</td>\n",
       "      <td>{0: 71, 1: 61, 2: 80}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='116' max='116' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [116/116 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.69      0.77      0.73        69\n",
      "     Neutral       0.50      0.68      0.57        37\n",
      "     Positiv       0.96      0.80      0.87       125\n",
      "\n",
      "    accuracy                           0.77       231\n",
      "   macro avg       0.72      0.75      0.72       231\n",
      "weighted avg       0.81      0.77      0.78       231\n",
      "\n",
      "\n",
      "==================================================\n",
      "Training Fold 2/3\n",
      "==================================================\n",
      "\n",
      "Training Fold 2 Sentiment label count:  {'negativ': 288, 'neutral': 216, 'positiv': 420}\n",
      "Validation Fold 2 Sentiment label count:  {'negativ': 66, 'neutral': 58, 'positiv': 113}\n",
      "Test Fold 2 Sentiment label count:  {'negativ': 62, 'neutral': 61, 'positiv': 109}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0694, 1.4259, 0.7333])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GerMedBERT/medbert-512 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 924/924 [00:00<00:00, 3556.94 examples/s]\n",
      "Map: 100%|██████████| 237/237 [00:00<00:00, 2672.30 examples/s]\n",
      "Map: 100%|██████████| 232/232 [00:00<00:00, 3366.60 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2310' max='2310' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2310/2310 04:19, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.785198</td>\n",
       "      <td>0.780591</td>\n",
       "      <td>0.796225</td>\n",
       "      <td>0.780591</td>\n",
       "      <td>0.782415</td>\n",
       "      <td>{0: 85, 1: 56, 2: 96}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.824900</td>\n",
       "      <td>0.919566</td>\n",
       "      <td>0.772152</td>\n",
       "      <td>0.774692</td>\n",
       "      <td>0.772152</td>\n",
       "      <td>0.769116</td>\n",
       "      <td>{0: 80, 1: 46, 2: 111}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.580100</td>\n",
       "      <td>1.182793</td>\n",
       "      <td>0.784810</td>\n",
       "      <td>0.797937</td>\n",
       "      <td>0.784810</td>\n",
       "      <td>0.787519</td>\n",
       "      <td>{0: 66, 1: 72, 2: 99}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.303400</td>\n",
       "      <td>1.134372</td>\n",
       "      <td>0.797468</td>\n",
       "      <td>0.807314</td>\n",
       "      <td>0.797468</td>\n",
       "      <td>0.797869</td>\n",
       "      <td>{0: 83, 1: 53, 2: 101}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.271400</td>\n",
       "      <td>1.161903</td>\n",
       "      <td>0.797468</td>\n",
       "      <td>0.799514</td>\n",
       "      <td>0.797468</td>\n",
       "      <td>0.798087</td>\n",
       "      <td>{0: 70, 1: 59, 2: 108}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='116' max='116' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [116/116 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.55      0.66      0.60        62\n",
      "     Neutral       0.60      0.57      0.59        61\n",
      "     Positiv       0.84      0.76      0.80       109\n",
      "\n",
      "    accuracy                           0.69       232\n",
      "   macro avg       0.66      0.67      0.66       232\n",
      "weighted avg       0.70      0.69      0.69       232\n",
      "\n",
      "\n",
      "==================================================\n",
      "Training Fold 3/3\n",
      "==================================================\n",
      "\n",
      "Training Fold 3 Sentiment label count:  {'negativ': 270, 'neutral': 202, 'positiv': 440}\n",
      "Validation Fold 3 Sentiment label count:  {'negativ': 62, 'neutral': 80, 'positiv': 97}\n",
      "Test Fold 3 Sentiment label count:  {'negativ': 84, 'neutral': 53, 'positiv': 105}\n",
      "Class weights for (negative, neutral, positive): tensor([1.1259, 1.5050, 0.6909])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at GerMedBERT/medbert-512 and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 912/912 [00:00<00:00, 4055.59 examples/s]\n",
      "Map: 100%|██████████| 239/239 [00:00<00:00, 3184.51 examples/s]\n",
      "Map: 100%|██████████| 242/242 [00:00<00:00, 3871.00 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2280' max='2280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2280/2280 04:16, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.368158</td>\n",
       "      <td>0.711297</td>\n",
       "      <td>0.751262</td>\n",
       "      <td>0.711297</td>\n",
       "      <td>0.704801</td>\n",
       "      <td>{0: 93, 1: 44, 2: 102}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.817800</td>\n",
       "      <td>1.376052</td>\n",
       "      <td>0.728033</td>\n",
       "      <td>0.730225</td>\n",
       "      <td>0.728033</td>\n",
       "      <td>0.727853</td>\n",
       "      <td>{0: 70, 1: 72, 2: 97}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.550900</td>\n",
       "      <td>1.699784</td>\n",
       "      <td>0.698745</td>\n",
       "      <td>0.706768</td>\n",
       "      <td>0.698745</td>\n",
       "      <td>0.689244</td>\n",
       "      <td>{0: 76, 1: 51, 2: 112}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.375200</td>\n",
       "      <td>1.701387</td>\n",
       "      <td>0.686192</td>\n",
       "      <td>0.682413</td>\n",
       "      <td>0.686192</td>\n",
       "      <td>0.683444</td>\n",
       "      <td>{0: 57, 1: 77, 2: 105}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.183600</td>\n",
       "      <td>1.815511</td>\n",
       "      <td>0.677824</td>\n",
       "      <td>0.673042</td>\n",
       "      <td>0.677824</td>\n",
       "      <td>0.672434</td>\n",
       "      <td>{0: 59, 1: 68, 2: 112}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='121' max='121' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [121/121 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.85      0.79      0.81        84\n",
      "     Neutral       0.63      0.77      0.69        53\n",
      "     Positiv       0.94      0.89      0.91       105\n",
      "\n",
      "    accuracy                           0.83       242\n",
      "   macro avg       0.81      0.82      0.81       242\n",
      "weighted avg       0.84      0.83      0.83       242\n",
      "\n",
      "\n",
      "==================================================\n",
      "Cross-Validation Summary\n",
      "==================================================\n",
      "\n",
      "Average Metrics Across Folds:\n",
      "eval_accuracy: 0.7549 ± 0.0537\n",
      "eval_precision: 0.7709 ± 0.0509\n",
      "eval_recall: 0.7549 ± 0.0537\n",
      "eval_f1: 0.7601 ± 0.0529\n",
      "eval_loss: 1.2710 ± 0.3454\n",
      "\n",
      "Overall Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.70      0.74      0.72       215\n",
      "     Neutral       0.58      0.67      0.62       151\n",
      "     Positiv       0.91      0.81      0.86       339\n",
      "\n",
      "    accuracy                           0.76       705\n",
      "   macro avg       0.73      0.74      0.73       705\n",
      "weighted avg       0.78      0.76      0.77       705\n",
      "\n",
      "\n",
      "Weighted Average Scores Across All Folds:\n",
      "Precision: 0.7766\n",
      "Recall: 0.7617\n",
      "F1: 0.7669\n",
      "\n",
      "training and results for deepset/gbert-base:\n",
      "\n",
      "==================================================\n",
      "Training Fold 1/3\n",
      "==================================================\n",
      "\n",
      "Training Fold 1 Sentiment label count:  {'negativ': 274, 'neutral': 252, 'positiv': 424}\n",
      "Validation Fold 1 Sentiment label count:  {'negativ': 73, 'neutral': 46, 'positiv': 93}\n",
      "Test Fold 1 Sentiment label count:  {'negativ': 69, 'neutral': 37, 'positiv': 125}\n",
      "Class weights for (negative, neutral, positive): tensor([1.1557, 1.2566, 0.7469])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 950/950 [00:00<00:00, 4050.06 examples/s]\n",
      "Map: 100%|██████████| 212/212 [00:00<00:00, 3294.21 examples/s]\n",
      "Map: 100%|██████████| 231/231 [00:00<00:00, 3856.69 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2375' max='2375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2375/2375 04:22, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.894189</td>\n",
       "      <td>0.787736</td>\n",
       "      <td>0.826328</td>\n",
       "      <td>0.787736</td>\n",
       "      <td>0.797341</td>\n",
       "      <td>{0: 64, 1: 69, 2: 79}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.750400</td>\n",
       "      <td>0.805046</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.842594</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.834185</td>\n",
       "      <td>{0: 73, 1: 55, 2: 84}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.509800</td>\n",
       "      <td>0.867564</td>\n",
       "      <td>0.839623</td>\n",
       "      <td>0.850348</td>\n",
       "      <td>0.839623</td>\n",
       "      <td>0.842031</td>\n",
       "      <td>{0: 78, 1: 53, 2: 81}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.345600</td>\n",
       "      <td>1.002077</td>\n",
       "      <td>0.825472</td>\n",
       "      <td>0.833519</td>\n",
       "      <td>0.825472</td>\n",
       "      <td>0.828122</td>\n",
       "      <td>{0: 75, 1: 52, 2: 85}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.223100</td>\n",
       "      <td>1.047652</td>\n",
       "      <td>0.825472</td>\n",
       "      <td>0.838496</td>\n",
       "      <td>0.825472</td>\n",
       "      <td>0.829214</td>\n",
       "      <td>{0: 75, 1: 55, 2: 82}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='116' max='116' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [116/116 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Fold 1:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.83      0.86      0.84        69\n",
      "     Neutral       0.70      0.76      0.73        37\n",
      "     Positiv       0.94      0.90      0.92       125\n",
      "\n",
      "    accuracy                           0.87       231\n",
      "   macro avg       0.82      0.84      0.83       231\n",
      "weighted avg       0.87      0.87      0.87       231\n",
      "\n",
      "\n",
      "==================================================\n",
      "Training Fold 2/3\n",
      "==================================================\n",
      "\n",
      "Training Fold 2 Sentiment label count:  {'negativ': 288, 'neutral': 216, 'positiv': 420}\n",
      "Validation Fold 2 Sentiment label count:  {'negativ': 66, 'neutral': 58, 'positiv': 113}\n",
      "Test Fold 2 Sentiment label count:  {'negativ': 62, 'neutral': 61, 'positiv': 109}\n",
      "Class weights for (negative, neutral, positive): tensor([1.0694, 1.4259, 0.7333])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 924/924 [00:00<00:00, 3979.40 examples/s]\n",
      "Map: 100%|██████████| 237/237 [00:00<00:00, 3323.36 examples/s]\n",
      "Map: 100%|██████████| 232/232 [00:00<00:00, 3886.36 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2310' max='2310' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2310/2310 04:15, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.660488</td>\n",
       "      <td>0.856540</td>\n",
       "      <td>0.860974</td>\n",
       "      <td>0.856540</td>\n",
       "      <td>0.856169</td>\n",
       "      <td>{0: 55, 1: 64, 2: 118}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.756400</td>\n",
       "      <td>0.568352</td>\n",
       "      <td>0.848101</td>\n",
       "      <td>0.851781</td>\n",
       "      <td>0.848101</td>\n",
       "      <td>0.849282</td>\n",
       "      <td>{0: 63, 1: 64, 2: 110}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.509300</td>\n",
       "      <td>0.672660</td>\n",
       "      <td>0.869198</td>\n",
       "      <td>0.874764</td>\n",
       "      <td>0.869198</td>\n",
       "      <td>0.871051</td>\n",
       "      <td>{0: 67, 1: 64, 2: 106}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.277800</td>\n",
       "      <td>0.681783</td>\n",
       "      <td>0.860759</td>\n",
       "      <td>0.863870</td>\n",
       "      <td>0.860759</td>\n",
       "      <td>0.861918</td>\n",
       "      <td>{0: 68, 1: 61, 2: 108}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.224900</td>\n",
       "      <td>0.724932</td>\n",
       "      <td>0.873418</td>\n",
       "      <td>0.876072</td>\n",
       "      <td>0.873418</td>\n",
       "      <td>0.874344</td>\n",
       "      <td>{0: 68, 1: 61, 2: 108}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='116' max='116' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [116/116 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Fold 2:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.72      0.81      0.76        62\n",
      "     Neutral       0.70      0.74      0.72        61\n",
      "     Positiv       0.93      0.84      0.88       109\n",
      "\n",
      "    accuracy                           0.81       232\n",
      "   macro avg       0.79      0.80      0.79       232\n",
      "weighted avg       0.82      0.81      0.81       232\n",
      "\n",
      "\n",
      "==================================================\n",
      "Training Fold 3/3\n",
      "==================================================\n",
      "\n",
      "Training Fold 3 Sentiment label count:  {'negativ': 270, 'neutral': 202, 'positiv': 440}\n",
      "Validation Fold 3 Sentiment label count:  {'negativ': 62, 'neutral': 80, 'positiv': 97}\n",
      "Test Fold 3 Sentiment label count:  {'negativ': 84, 'neutral': 53, 'positiv': 105}\n",
      "Class weights for (negative, neutral, positive): tensor([1.1259, 1.5050, 0.6909])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 912/912 [00:00<00:00, 4054.19 examples/s]\n",
      "Map: 100%|██████████| 239/239 [00:00<00:00, 3414.98 examples/s]\n",
      "Map: 100%|██████████| 242/242 [00:00<00:00, 3892.67 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2280' max='2280' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2280/2280 04:13, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Class Distribution</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.090109</td>\n",
       "      <td>0.774059</td>\n",
       "      <td>0.775709</td>\n",
       "      <td>0.774059</td>\n",
       "      <td>0.769561</td>\n",
       "      <td>{0: 69, 1: 62, 2: 108}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.745600</td>\n",
       "      <td>1.292890</td>\n",
       "      <td>0.778243</td>\n",
       "      <td>0.791338</td>\n",
       "      <td>0.778243</td>\n",
       "      <td>0.780771</td>\n",
       "      <td>{0: 56, 1: 97, 2: 86}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.484800</td>\n",
       "      <td>1.434442</td>\n",
       "      <td>0.765690</td>\n",
       "      <td>0.773320</td>\n",
       "      <td>0.765690</td>\n",
       "      <td>0.761216</td>\n",
       "      <td>{0: 71, 1: 58, 2: 110}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.312300</td>\n",
       "      <td>1.409014</td>\n",
       "      <td>0.782427</td>\n",
       "      <td>0.793514</td>\n",
       "      <td>0.782427</td>\n",
       "      <td>0.784368</td>\n",
       "      <td>{0: 52, 1: 95, 2: 92}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>1.463964</td>\n",
       "      <td>0.782427</td>\n",
       "      <td>0.781518</td>\n",
       "      <td>0.782427</td>\n",
       "      <td>0.781596</td>\n",
       "      <td>{0: 59, 1: 78, 2: 102}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='121' max='121' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [121/121 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report for Fold 3:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.85      0.76      0.81        84\n",
      "     Neutral       0.63      0.83      0.72        53\n",
      "     Positiv       0.98      0.90      0.94       105\n",
      "\n",
      "    accuracy                           0.84       242\n",
      "   macro avg       0.82      0.83      0.82       242\n",
      "weighted avg       0.86      0.84      0.84       242\n",
      "\n",
      "\n",
      "==================================================\n",
      "Cross-Validation Summary\n",
      "==================================================\n",
      "\n",
      "Average Metrics Across Folds:\n",
      "eval_accuracy: 0.8398 ± 0.0160\n",
      "eval_precision: 0.8474 ± 0.0130\n",
      "eval_recall: 0.8398 ± 0.0160\n",
      "eval_f1: 0.8414 ± 0.0159\n",
      "eval_loss: 0.9507 ± 0.2044\n",
      "\n",
      "Overall Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Negativ       0.80      0.80      0.80       215\n",
      "     Neutral       0.67      0.77      0.72       151\n",
      "     Positiv       0.95      0.88      0.92       339\n",
      "\n",
      "    accuracy                           0.84       705\n",
      "   macro avg       0.81      0.82      0.81       705\n",
      "weighted avg       0.85      0.84      0.84       705\n",
      "\n",
      "\n",
      "Weighted Average Scores Across All Folds:\n",
      "Precision: 0.8459\n",
      "Recall: 0.8369\n",
      "F1: 0.8401\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_model_metrics = {}\n",
    "\n",
    "for model in models:\n",
    "    print(f'training and results for {model}:')\n",
    "    avg_metrics, std_metrics = absa_model_kfold(data, model, rn1=42, rn2=42, epochs=5, n_splits=3, save=False)\n",
    "    \n",
    "    # Store both metrics together under the model name\n",
    "    all_model_metrics[model] = {\n",
    "        'avg_metrics': avg_metrics,\n",
    "        'std_metrics': std_metrics\n",
    "    }\n",
    "    \n",
    "    print()\n",
    "\n",
    "# Access:\n",
    "# all_model_metrics['model_name']['avg_metrics']\n",
    "# all_model_metrics['model_name']['std_metrics']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ABSA-Check",
   "language": "python",
   "name": "absa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
