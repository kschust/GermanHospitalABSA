{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08100a32-8406-4e51-8408-c470ef7fb9ff",
   "metadata": {},
   "source": [
    "## Aspect Term Extraction (ATE) Training and Fine Tuning for Large Language Models on German hospital reviews using OBI-Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc914b81-7682-4ecf-b22b-1b61e87ea6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sc.uni-leipzig.de/ch31qoni/venv/absa/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "import spacy\n",
    "import ast  # To safely evaluate strings as Python objects\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import evaluate\n",
    "\n",
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# We need the sys package to load modules from another directory:\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from functions.ate_model_train import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48155d44-b615-452a-b5dd-c791e26e41bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA available: True\n",
      "CUDA version: 12.6\n",
      "GPU device name: NVIDIA A30\n"
     ]
    }
   ],
   "source": [
    "print(\"Is CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"GPU device name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "519fbd0b-1cde-49d9-84e6-a7c998bd8c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset into a DataFrame\n",
    "data = pd.read_csv(\"./data/hospitalABSA/patient_review_labels_absa.csv\")\n",
    "data_ano = pd.read_csv(\"./data/hospitalABSA/patient_review_labels_absa_ano.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe97d396-d00b-4db6-8ee4-676b94a02f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"google-bert/bert-base-german-cased\",\"dbmdz/bert-base-german-cased\", \"dbmdz/bert-base-german-uncased\",\n",
    "          \"FacebookAI/xlm-roberta-base\", \"TUM/GottBERT_base_best\", \"TUM/GottBERT_filtered_base_best\", \"TUM/GottBERT_base_last\",\n",
    "          \"distilbert/distilbert-base-german-cased\", \"GerMedBERT/medbert-512\", \"deepset/gbert-base\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13de6a5f-2304-4699-816f-5c15f7bbc392",
   "metadata": {},
   "source": [
    "### 1. standard ATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f90f73bc-9d11-49f2-b105-cead82285b64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training and results for google-bert/bert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 3621.40 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4797.18 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-ASPECT' 'O' 'B-ASPECT']\n",
      "{0: 21.94744744744745, 1: 0.3725025484199796, 2: 3.705196451204056}\n",
      "Training results for google-bert/bert-base-german-cased with 10 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4040' max='4040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4040/4040 04:56, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.174199</td>\n",
       "      <td>0.773756</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.751648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.228000</td>\n",
       "      <td>0.170873</td>\n",
       "      <td>0.816143</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.796499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.103200</td>\n",
       "      <td>0.275012</td>\n",
       "      <td>0.793860</td>\n",
       "      <td>0.773504</td>\n",
       "      <td>0.783550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.034100</td>\n",
       "      <td>0.270710</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.786325</td>\n",
       "      <td>0.789700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.018700</td>\n",
       "      <td>0.392381</td>\n",
       "      <td>0.815315</td>\n",
       "      <td>0.773504</td>\n",
       "      <td>0.793860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.018700</td>\n",
       "      <td>0.472495</td>\n",
       "      <td>0.766393</td>\n",
       "      <td>0.799145</td>\n",
       "      <td>0.782427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>0.460692</td>\n",
       "      <td>0.795745</td>\n",
       "      <td>0.799145</td>\n",
       "      <td>0.797441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.482626</td>\n",
       "      <td>0.788793</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.785408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.488393</td>\n",
       "      <td>0.801802</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.780702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.491477</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.784314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4446.81 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.83      0.75      0.79       268\n",
      "\n",
      "   micro avg       0.83      0.75      0.79       268\n",
      "   macro avg       0.83      0.75      0.79       268\n",
      "weighted avg       0.83      0.75      0.79       268\n",
      "\n",
      "Precision Score: 0.8347107438016529\n",
      "Recall Score: 0.753731343283582\n",
      "F1 Score: 0.792156862745098\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/10_epochs/google-bert_bert-base-german-cased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/10_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5948.64 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4872.11 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-ASPECT' 'O' 'B-ASPECT']\n",
      "{0: 21.94744744744745, 1: 0.3725025484199796, 2: 3.705196451204056}\n",
      "Training results for dbmdz/bert-base-german-cased with 10 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4040' max='4040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4040/4040 04:54, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.181845</td>\n",
       "      <td>0.748936</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.760259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.241500</td>\n",
       "      <td>0.197786</td>\n",
       "      <td>0.756198</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>0.778723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.116300</td>\n",
       "      <td>0.265555</td>\n",
       "      <td>0.759494</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.774194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.046900</td>\n",
       "      <td>0.308310</td>\n",
       "      <td>0.715909</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.768293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.029000</td>\n",
       "      <td>0.387184</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.780702</td>\n",
       "      <td>0.760684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.029000</td>\n",
       "      <td>0.396562</td>\n",
       "      <td>0.789954</td>\n",
       "      <td>0.758772</td>\n",
       "      <td>0.774049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>0.440614</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>0.776316</td>\n",
       "      <td>0.786667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.424229</td>\n",
       "      <td>0.758475</td>\n",
       "      <td>0.785088</td>\n",
       "      <td>0.771552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.453511</td>\n",
       "      <td>0.756410</td>\n",
       "      <td>0.776316</td>\n",
       "      <td>0.766234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.463390</td>\n",
       "      <td>0.748954</td>\n",
       "      <td>0.785088</td>\n",
       "      <td>0.766595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4403.29 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.85      0.74      0.80       261\n",
      "\n",
      "   micro avg       0.85      0.74      0.80       261\n",
      "   macro avg       0.85      0.74      0.80       261\n",
      "weighted avg       0.85      0.74      0.80       261\n",
      "\n",
      "Precision Score: 0.8546255506607929\n",
      "Recall Score: 0.7432950191570882\n",
      "F1 Score: 0.7950819672131147\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/10_epochs/dbmdz_bert-base-german-cased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/10_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-uncased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5627.64 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4764.70 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-ASPECT' 'O' 'B-ASPECT']\n",
      "{0: 21.94744744744745, 1: 0.3725025484199796, 2: 3.705196451204056}\n",
      "Training results for dbmdz/bert-base-german-uncased with 10 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4040' max='4040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4040/4040 04:53, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.174619</td>\n",
       "      <td>0.747788</td>\n",
       "      <td>0.747788</td>\n",
       "      <td>0.747788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.233700</td>\n",
       "      <td>0.213093</td>\n",
       "      <td>0.800926</td>\n",
       "      <td>0.765487</td>\n",
       "      <td>0.782805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.115400</td>\n",
       "      <td>0.239687</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.761062</td>\n",
       "      <td>0.780045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.048200</td>\n",
       "      <td>0.278641</td>\n",
       "      <td>0.723849</td>\n",
       "      <td>0.765487</td>\n",
       "      <td>0.744086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.027300</td>\n",
       "      <td>0.321366</td>\n",
       "      <td>0.748918</td>\n",
       "      <td>0.765487</td>\n",
       "      <td>0.757112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.027300</td>\n",
       "      <td>0.365935</td>\n",
       "      <td>0.770563</td>\n",
       "      <td>0.787611</td>\n",
       "      <td>0.778993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>0.427991</td>\n",
       "      <td>0.755459</td>\n",
       "      <td>0.765487</td>\n",
       "      <td>0.760440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.453464</td>\n",
       "      <td>0.782407</td>\n",
       "      <td>0.747788</td>\n",
       "      <td>0.764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.465730</td>\n",
       "      <td>0.779817</td>\n",
       "      <td>0.752212</td>\n",
       "      <td>0.765766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.450496</td>\n",
       "      <td>0.765217</td>\n",
       "      <td>0.778761</td>\n",
       "      <td>0.771930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4507.91 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.86      0.70      0.77       267\n",
      "\n",
      "   micro avg       0.86      0.70      0.77       267\n",
      "   macro avg       0.86      0.70      0.77       267\n",
      "weighted avg       0.86      0.70      0.77       267\n",
      "\n",
      "Precision Score: 0.8611111111111112\n",
      "Recall Score: 0.6966292134831461\n",
      "F1 Score: 0.7701863354037267\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/10_epochs/dbmdz_bert-base-german-uncased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/10_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for FacebookAI/xlm-roberta-base:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5685.16 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4931.14 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-ASPECT' 'O' 'B-ASPECT']\n",
      "{0: 21.94744744744745, 1: 0.3725025484199796, 2: 3.705196451204056}\n",
      "Training results for FacebookAI/xlm-roberta-base with 10 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4040' max='4040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4040/4040 08:08, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.175791</td>\n",
       "      <td>0.786260</td>\n",
       "      <td>0.792308</td>\n",
       "      <td>0.789272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.269100</td>\n",
       "      <td>0.204412</td>\n",
       "      <td>0.751825</td>\n",
       "      <td>0.792308</td>\n",
       "      <td>0.771536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.175600</td>\n",
       "      <td>0.175286</td>\n",
       "      <td>0.770909</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>0.792523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.110000</td>\n",
       "      <td>0.202577</td>\n",
       "      <td>0.767606</td>\n",
       "      <td>0.838462</td>\n",
       "      <td>0.801471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.081100</td>\n",
       "      <td>0.283526</td>\n",
       "      <td>0.779720</td>\n",
       "      <td>0.857692</td>\n",
       "      <td>0.816850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.081100</td>\n",
       "      <td>0.289111</td>\n",
       "      <td>0.769759</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.813067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.047500</td>\n",
       "      <td>0.330556</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.803571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.030400</td>\n",
       "      <td>0.331324</td>\n",
       "      <td>0.777385</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.810313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.016300</td>\n",
       "      <td>0.355234</td>\n",
       "      <td>0.775862</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>0.352818</td>\n",
       "      <td>0.762712</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.810811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4535.39 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.77      0.79      0.78       294\n",
      "\n",
      "   micro avg       0.77      0.79      0.78       294\n",
      "   macro avg       0.77      0.79      0.78       294\n",
      "weighted avg       0.77      0.79      0.78       294\n",
      "\n",
      "Precision Score: 0.7715231788079471\n",
      "Recall Score: 0.7925170068027211\n",
      "F1 Score: 0.7818791946308725\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/10_epochs/FacebookAI_xlm-roberta-base_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/10_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_best:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6309.43 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4876.65 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-ASPECT' 'O' 'B-ASPECT']\n",
      "{0: 21.94744744744745, 1: 0.3725025484199796, 2: 3.705196451204056}\n",
      "Training results for TUM/GottBERT_base_best with 10 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4040' max='4040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4040/4040 05:23, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.242694</td>\n",
       "      <td>0.742105</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.733700</td>\n",
       "      <td>0.181759</td>\n",
       "      <td>0.787709</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.772603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.188100</td>\n",
       "      <td>0.255710</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.776860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.087900</td>\n",
       "      <td>0.283692</td>\n",
       "      <td>0.741627</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.784810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.054000</td>\n",
       "      <td>0.380063</td>\n",
       "      <td>0.768844</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.794805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.054000</td>\n",
       "      <td>0.423698</td>\n",
       "      <td>0.745098</td>\n",
       "      <td>0.817204</td>\n",
       "      <td>0.779487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.023200</td>\n",
       "      <td>0.423066</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.784615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>0.524198</td>\n",
       "      <td>0.755000</td>\n",
       "      <td>0.811828</td>\n",
       "      <td>0.782383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>0.562123</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.769634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.574963</td>\n",
       "      <td>0.758974</td>\n",
       "      <td>0.795699</td>\n",
       "      <td>0.776903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.decoder.weight', 'lm_head.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4734.71 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.79      0.79      0.79       229\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       229\n",
      "   macro avg       0.79      0.79      0.79       229\n",
      "weighted avg       0.79      0.79      0.79       229\n",
      "\n",
      "Precision Score: 0.7947598253275109\n",
      "Recall Score: 0.7947598253275109\n",
      "F1 Score: 0.7947598253275109\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/10_epochs/TUM_GottBERT_base_best_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/10_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_filtered_base_best:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6446.67 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4948.02 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-ASPECT' 'O' 'B-ASPECT']\n",
      "{0: 21.94744744744745, 1: 0.3725025484199796, 2: 3.705196451204056}\n",
      "Training results for TUM/GottBERT_filtered_base_best with 10 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4040' max='4040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4040/4040 05:21, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.276601</td>\n",
       "      <td>0.797101</td>\n",
       "      <td>0.591398</td>\n",
       "      <td>0.679012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.665300</td>\n",
       "      <td>0.207075</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.779661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.174200</td>\n",
       "      <td>0.218857</td>\n",
       "      <td>0.820652</td>\n",
       "      <td>0.811828</td>\n",
       "      <td>0.816216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.087900</td>\n",
       "      <td>0.241436</td>\n",
       "      <td>0.762791</td>\n",
       "      <td>0.881720</td>\n",
       "      <td>0.817955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.048300</td>\n",
       "      <td>0.314045</td>\n",
       "      <td>0.781421</td>\n",
       "      <td>0.768817</td>\n",
       "      <td>0.775068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.048300</td>\n",
       "      <td>0.424234</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.817204</td>\n",
       "      <td>0.787565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>0.504661</td>\n",
       "      <td>0.815476</td>\n",
       "      <td>0.736559</td>\n",
       "      <td>0.774011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>0.525661</td>\n",
       "      <td>0.773684</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.781915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.486074</td>\n",
       "      <td>0.774359</td>\n",
       "      <td>0.811828</td>\n",
       "      <td>0.792651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.488192</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.817204</td>\n",
       "      <td>0.795812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.decoder.weight', 'lm_head.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4620.33 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.73      0.77      0.75       229\n",
      "\n",
      "   micro avg       0.73      0.77      0.75       229\n",
      "   macro avg       0.73      0.77      0.75       229\n",
      "weighted avg       0.73      0.77      0.75       229\n",
      "\n",
      "Precision Score: 0.731404958677686\n",
      "Recall Score: 0.7729257641921398\n",
      "F1 Score: 0.7515923566878981\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/10_epochs/TUM_GottBERT_filtered_base_best_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/10_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_last:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at TUM/GottBERT_base_last were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of the model checkpoint at TUM/GottBERT_base_last were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6354.59 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4906.70 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-ASPECT' 'O' 'B-ASPECT']\n",
      "{0: 21.94744744744745, 1: 0.3725025484199796, 2: 3.705196451204056}\n",
      "Training results for TUM/GottBERT_base_last with 10 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4040' max='4040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4040/4040 05:21, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.329046</td>\n",
       "      <td>0.812950</td>\n",
       "      <td>0.607527</td>\n",
       "      <td>0.695385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.737100</td>\n",
       "      <td>0.187419</td>\n",
       "      <td>0.796512</td>\n",
       "      <td>0.736559</td>\n",
       "      <td>0.765363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.259836</td>\n",
       "      <td>0.823899</td>\n",
       "      <td>0.704301</td>\n",
       "      <td>0.759420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.095200</td>\n",
       "      <td>0.211095</td>\n",
       "      <td>0.747706</td>\n",
       "      <td>0.876344</td>\n",
       "      <td>0.806931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.061700</td>\n",
       "      <td>0.370675</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.791878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.061700</td>\n",
       "      <td>0.412819</td>\n",
       "      <td>0.756219</td>\n",
       "      <td>0.817204</td>\n",
       "      <td>0.785530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.021700</td>\n",
       "      <td>0.444019</td>\n",
       "      <td>0.771574</td>\n",
       "      <td>0.817204</td>\n",
       "      <td>0.793734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>0.497182</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.535993</td>\n",
       "      <td>0.765000</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.792746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.522426</td>\n",
       "      <td>0.759804</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.794872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.decoder.weight', 'lm_head.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4632.08 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.75      0.80      0.77       229\n",
      "\n",
      "   micro avg       0.75      0.80      0.77       229\n",
      "   macro avg       0.75      0.80      0.77       229\n",
      "weighted avg       0.75      0.80      0.77       229\n",
      "\n",
      "Precision Score: 0.75\n",
      "Recall Score: 0.7991266375545851\n",
      "F1 Score: 0.7737843551797039\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/10_epochs/TUM_GottBERT_base_last_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/10_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for distilbert/distilbert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6415.77 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5200.66 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-ASPECT' 'O' 'B-ASPECT']\n",
      "{0: 21.94744744744745, 1: 0.3725025484199796, 2: 3.705196451204056}\n",
      "Training results for distilbert/distilbert-base-german-cased with 10 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4040' max='4040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4040/4040 02:44, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.172492</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.776316</td>\n",
       "      <td>0.771242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.258400</td>\n",
       "      <td>0.181641</td>\n",
       "      <td>0.768182</td>\n",
       "      <td>0.741228</td>\n",
       "      <td>0.754464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.129800</td>\n",
       "      <td>0.225262</td>\n",
       "      <td>0.799087</td>\n",
       "      <td>0.767544</td>\n",
       "      <td>0.782998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.061900</td>\n",
       "      <td>0.254332</td>\n",
       "      <td>0.763485</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.784648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.041300</td>\n",
       "      <td>0.318700</td>\n",
       "      <td>0.747036</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.785863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.041300</td>\n",
       "      <td>0.338674</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.786026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.018500</td>\n",
       "      <td>0.358271</td>\n",
       "      <td>0.771186</td>\n",
       "      <td>0.798246</td>\n",
       "      <td>0.784483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.008700</td>\n",
       "      <td>0.397171</td>\n",
       "      <td>0.738956</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.771488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>0.399300</td>\n",
       "      <td>0.759494</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.774194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.397510</td>\n",
       "      <td>0.774468</td>\n",
       "      <td>0.798246</td>\n",
       "      <td>0.786177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4891.93 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.81      0.75      0.78       261\n",
      "\n",
      "   micro avg       0.81      0.75      0.78       261\n",
      "   macro avg       0.81      0.75      0.78       261\n",
      "weighted avg       0.81      0.75      0.78       261\n",
      "\n",
      "Precision Score: 0.8091286307053942\n",
      "Recall Score: 0.7471264367816092\n",
      "F1 Score: 0.7768924302788845\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/10_epochs/distilbert_distilbert-base-german-cased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/10_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for GerMedBERT/medbert-512:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5776.50 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4632.82 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-ASPECT' 'O' 'B-ASPECT']\n",
      "{0: 21.94744744744745, 1: 0.3725025484199796, 2: 3.705196451204056}\n",
      "Training results for GerMedBERT/medbert-512 with 10 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4040' max='4040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4040/4040 04:59, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.189749</td>\n",
       "      <td>0.756906</td>\n",
       "      <td>0.665049</td>\n",
       "      <td>0.708010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.039400</td>\n",
       "      <td>0.178356</td>\n",
       "      <td>0.748768</td>\n",
       "      <td>0.737864</td>\n",
       "      <td>0.743276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.190800</td>\n",
       "      <td>0.214708</td>\n",
       "      <td>0.790576</td>\n",
       "      <td>0.733010</td>\n",
       "      <td>0.760705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.083500</td>\n",
       "      <td>0.253717</td>\n",
       "      <td>0.746341</td>\n",
       "      <td>0.742718</td>\n",
       "      <td>0.744526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.045600</td>\n",
       "      <td>0.436221</td>\n",
       "      <td>0.693694</td>\n",
       "      <td>0.747573</td>\n",
       "      <td>0.719626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.045600</td>\n",
       "      <td>0.373632</td>\n",
       "      <td>0.728643</td>\n",
       "      <td>0.703883</td>\n",
       "      <td>0.716049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.023700</td>\n",
       "      <td>0.479751</td>\n",
       "      <td>0.723810</td>\n",
       "      <td>0.737864</td>\n",
       "      <td>0.730769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>0.480134</td>\n",
       "      <td>0.732673</td>\n",
       "      <td>0.718447</td>\n",
       "      <td>0.725490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.493200</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>0.713592</td>\n",
       "      <td>0.733167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.503710</td>\n",
       "      <td>0.747525</td>\n",
       "      <td>0.733010</td>\n",
       "      <td>0.740196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4295.20 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.79      0.65      0.71       234\n",
      "\n",
      "   micro avg       0.79      0.65      0.71       234\n",
      "   macro avg       0.79      0.65      0.71       234\n",
      "weighted avg       0.79      0.65      0.71       234\n",
      "\n",
      "Precision Score: 0.7905759162303665\n",
      "Recall Score: 0.6452991452991453\n",
      "F1 Score: 0.7105882352941176\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/10_epochs/GerMedBERT_medbert-512_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/10_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for deepset/gbert-base:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5844.07 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4724.58 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-ASPECT' 'O' 'B-ASPECT']\n",
      "{0: 21.94744744744745, 1: 0.3725025484199796, 2: 3.705196451204056}\n",
      "Training results for deepset/gbert-base with 10 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4040' max='4040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4040/4040 05:00, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.252091</td>\n",
       "      <td>0.753363</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.745011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.611200</td>\n",
       "      <td>0.206167</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.802548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.175900</td>\n",
       "      <td>0.289843</td>\n",
       "      <td>0.792035</td>\n",
       "      <td>0.785088</td>\n",
       "      <td>0.788546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.074300</td>\n",
       "      <td>0.253312</td>\n",
       "      <td>0.788136</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.801724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.050900</td>\n",
       "      <td>0.346724</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.807018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.050900</td>\n",
       "      <td>0.440677</td>\n",
       "      <td>0.821101</td>\n",
       "      <td>0.785088</td>\n",
       "      <td>0.802691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.021500</td>\n",
       "      <td>0.445545</td>\n",
       "      <td>0.795745</td>\n",
       "      <td>0.820175</td>\n",
       "      <td>0.807775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>0.500903</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.811404</td>\n",
       "      <td>0.807860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.520252</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.807018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.526721</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.811404</td>\n",
       "      <td>0.807860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4359.72 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.85      0.74      0.80       261\n",
      "\n",
      "   micro avg       0.85      0.74      0.80       261\n",
      "   macro avg       0.85      0.74      0.80       261\n",
      "weighted avg       0.85      0.74      0.80       261\n",
      "\n",
      "Precision Score: 0.8546255506607929\n",
      "Recall Score: 0.7432950191570882\n",
      "F1 Score: 0.7950819672131147\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/10_epochs/deepset_gbert-base_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/10_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(f'training and results for {model}:')\n",
    "    ate_model(data, model, rn1=42, rn2=42, epochs=10)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad75b56-c7c5-4c75-b9f3-a27104cf2384",
   "metadata": {},
   "source": [
    "Model training with 5 epochs and f1 to load the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03ffc452-78e2-43dd-b7ca-13bc528b0375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training and results for google-bert/bert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 2979.62 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 3753.38 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-ASPECT' 'I-ASPECT']\n",
      "{0: 0.3725025484199796, 1: 3.705196451204056, 2: 21.94744744744745}\n",
      "Training results for google-bert/bert-base-german-cased with 5 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 02:20, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.165580</td>\n",
       "      <td>0.769912</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.756522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.231200</td>\n",
       "      <td>0.170855</td>\n",
       "      <td>0.781116</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.779443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.107000</td>\n",
       "      <td>0.242393</td>\n",
       "      <td>0.780172</td>\n",
       "      <td>0.773504</td>\n",
       "      <td>0.776824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.032100</td>\n",
       "      <td>0.280931</td>\n",
       "      <td>0.775424</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.778723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.018700</td>\n",
       "      <td>0.319572</td>\n",
       "      <td>0.756198</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.768908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 3327.34 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.82      0.78      0.80       268\n",
      "\n",
      "   micro avg       0.82      0.78      0.80       268\n",
      "   macro avg       0.82      0.78      0.80       268\n",
      "weighted avg       0.82      0.78      0.80       268\n",
      "\n",
      "Precision Score: 0.8221343873517787\n",
      "Recall Score: 0.7761194029850746\n",
      "F1 Score: 0.7984644913627639\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/5_epochs/google-bert_bert-base-german-cased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/5_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 4569.19 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 3782.67 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-ASPECT' 'I-ASPECT']\n",
      "{0: 0.3725025484199796, 1: 3.705196451204056, 2: 21.94744744744745}\n",
      "Training results for dbmdz/bert-base-german-cased with 5 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 02:20, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.163810</td>\n",
       "      <td>0.762931</td>\n",
       "      <td>0.776316</td>\n",
       "      <td>0.769565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.248800</td>\n",
       "      <td>0.159659</td>\n",
       "      <td>0.776423</td>\n",
       "      <td>0.837719</td>\n",
       "      <td>0.805907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.124800</td>\n",
       "      <td>0.241545</td>\n",
       "      <td>0.745020</td>\n",
       "      <td>0.820175</td>\n",
       "      <td>0.780793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.055600</td>\n",
       "      <td>0.270153</td>\n",
       "      <td>0.771186</td>\n",
       "      <td>0.798246</td>\n",
       "      <td>0.784483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>0.308753</td>\n",
       "      <td>0.760331</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.782979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 3568.22 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.82      0.75      0.78       261\n",
      "\n",
      "   micro avg       0.82      0.75      0.78       261\n",
      "   macro avg       0.82      0.75      0.78       261\n",
      "weighted avg       0.82      0.75      0.78       261\n",
      "\n",
      "Precision Score: 0.819327731092437\n",
      "Recall Score: 0.7471264367816092\n",
      "F1 Score: 0.781563126252505\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/5_epochs/dbmdz_bert-base-german-cased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/5_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-uncased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 3994.50 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 3540.47 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-ASPECT' 'I-ASPECT']\n",
      "{0: 0.3725025484199796, 1: 3.705196451204056, 2: 21.94744744744745}\n",
      "Training results for dbmdz/bert-base-german-uncased with 5 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 02:20, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.170243</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.743363</td>\n",
       "      <td>0.758465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.230900</td>\n",
       "      <td>0.186659</td>\n",
       "      <td>0.838235</td>\n",
       "      <td>0.756637</td>\n",
       "      <td>0.795349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.113600</td>\n",
       "      <td>0.246048</td>\n",
       "      <td>0.822430</td>\n",
       "      <td>0.778761</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.045400</td>\n",
       "      <td>0.264298</td>\n",
       "      <td>0.776786</td>\n",
       "      <td>0.769912</td>\n",
       "      <td>0.773333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.277863</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.778761</td>\n",
       "      <td>0.789238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 3086.41 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.90      0.69      0.78       267\n",
      "\n",
      "   micro avg       0.90      0.69      0.78       267\n",
      "   macro avg       0.90      0.69      0.78       267\n",
      "weighted avg       0.90      0.69      0.78       267\n",
      "\n",
      "Precision Score: 0.9024390243902439\n",
      "Recall Score: 0.6928838951310862\n",
      "F1 Score: 0.7838983050847458\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/5_epochs/dbmdz_bert-base-german-uncased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/5_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for FacebookAI/xlm-roberta-base:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 4252.34 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 3769.20 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-ASPECT' 'I-ASPECT']\n",
      "{0: 0.3725025484199796, 1: 3.705196451204056, 2: 21.94744744744745}\n",
      "Training results for FacebookAI/xlm-roberta-base with 5 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 03:44, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.186593</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.787645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.275800</td>\n",
       "      <td>0.179816</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.780769</td>\n",
       "      <td>0.782274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.203222</td>\n",
       "      <td>0.804000</td>\n",
       "      <td>0.773077</td>\n",
       "      <td>0.788235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.102200</td>\n",
       "      <td>0.204244</td>\n",
       "      <td>0.785965</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.822018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>0.223930</td>\n",
       "      <td>0.796992</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>0.806084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 3573.08 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.76      0.80      0.78       294\n",
      "\n",
      "   micro avg       0.76      0.80      0.78       294\n",
      "   macro avg       0.76      0.80      0.78       294\n",
      "weighted avg       0.76      0.80      0.78       294\n",
      "\n",
      "Precision Score: 0.762214983713355\n",
      "Recall Score: 0.7959183673469388\n",
      "F1 Score: 0.778702163061564\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/5_epochs/FacebookAI_xlm-roberta-base_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/5_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_best:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 4353.78 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 3401.49 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-ASPECT' 'I-ASPECT']\n",
      "{0: 0.3725025484199796, 1: 3.705196451204056, 2: 21.94744744744745}\n",
      "Training results for TUM/GottBERT_base_best with 5 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 02:33, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.240714</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.746000</td>\n",
       "      <td>0.198866</td>\n",
       "      <td>0.762162</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.760108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.192300</td>\n",
       "      <td>0.215613</td>\n",
       "      <td>0.783784</td>\n",
       "      <td>0.779570</td>\n",
       "      <td>0.781671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.087500</td>\n",
       "      <td>0.244708</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.810000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.053500</td>\n",
       "      <td>0.293393</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.793893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.decoder.weight', 'lm_head.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 3600.17 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.77      0.77      0.77       229\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       229\n",
      "   macro avg       0.77      0.77      0.77       229\n",
      "weighted avg       0.77      0.77      0.77       229\n",
      "\n",
      "Precision Score: 0.7685589519650655\n",
      "Recall Score: 0.7685589519650655\n",
      "F1 Score: 0.7685589519650655\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/5_epochs/TUM_GottBERT_base_best_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/5_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_filtered_base_best:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 4415.38 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 3145.95 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-ASPECT' 'I-ASPECT']\n",
      "{0: 0.3725025484199796, 1: 3.705196451204056, 2: 21.94744744744745}\n",
      "Training results for TUM/GottBERT_filtered_base_best with 5 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 02:33, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.212647</td>\n",
       "      <td>0.764368</td>\n",
       "      <td>0.715054</td>\n",
       "      <td>0.738889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.664000</td>\n",
       "      <td>0.188561</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.795699</td>\n",
       "      <td>0.797844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.171700</td>\n",
       "      <td>0.190545</td>\n",
       "      <td>0.806122</td>\n",
       "      <td>0.849462</td>\n",
       "      <td>0.827225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.075400</td>\n",
       "      <td>0.218402</td>\n",
       "      <td>0.781095</td>\n",
       "      <td>0.844086</td>\n",
       "      <td>0.811370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.263866</td>\n",
       "      <td>0.802083</td>\n",
       "      <td>0.827957</td>\n",
       "      <td>0.814815</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.decoder.weight', 'lm_head.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 3442.96 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.76      0.78      0.77       229\n",
      "\n",
      "   micro avg       0.76      0.78      0.77       229\n",
      "   macro avg       0.76      0.78      0.77       229\n",
      "weighted avg       0.76      0.78      0.77       229\n",
      "\n",
      "Precision Score: 0.7584745762711864\n",
      "Recall Score: 0.7816593886462883\n",
      "F1 Score: 0.7698924731182795\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/5_epochs/TUM_GottBERT_filtered_base_best_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/5_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_last:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at TUM/GottBERT_base_last were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of the model checkpoint at TUM/GottBERT_base_last were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 4482.84 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 3696.55 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-ASPECT' 'I-ASPECT']\n",
      "{0: 0.3725025484199796, 1: 3.705196451204056, 2: 21.94744744744745}\n",
      "Training results for TUM/GottBERT_base_last with 5 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 02:33, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.284252</td>\n",
       "      <td>0.809211</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.727811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.757000</td>\n",
       "      <td>0.193124</td>\n",
       "      <td>0.770950</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.756164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.190100</td>\n",
       "      <td>0.205109</td>\n",
       "      <td>0.776042</td>\n",
       "      <td>0.801075</td>\n",
       "      <td>0.788360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.088900</td>\n",
       "      <td>0.196000</td>\n",
       "      <td>0.790576</td>\n",
       "      <td>0.811828</td>\n",
       "      <td>0.801061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.058200</td>\n",
       "      <td>0.258856</td>\n",
       "      <td>0.769608</td>\n",
       "      <td>0.844086</td>\n",
       "      <td>0.805128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.decoder.weight', 'lm_head.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 3259.97 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.80      0.78      0.79       229\n",
      "\n",
      "   micro avg       0.80      0.78      0.79       229\n",
      "   macro avg       0.80      0.78      0.79       229\n",
      "weighted avg       0.80      0.78      0.79       229\n",
      "\n",
      "Precision Score: 0.8026905829596412\n",
      "Recall Score: 0.7816593886462883\n",
      "F1 Score: 0.7920353982300885\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/5_epochs/TUM_GottBERT_base_last_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/5_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for distilbert/distilbert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 4796.58 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 3805.57 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-ASPECT' 'I-ASPECT']\n",
      "{0: 0.3725025484199796, 1: 3.705196451204056, 2: 21.94744744744745}\n",
      "Training results for distilbert/distilbert-base-german-cased with 5 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 01:20, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.172081</td>\n",
       "      <td>0.770213</td>\n",
       "      <td>0.793860</td>\n",
       "      <td>0.781857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.264400</td>\n",
       "      <td>0.181659</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.761062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.136100</td>\n",
       "      <td>0.207040</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.767544</td>\n",
       "      <td>0.781250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.071000</td>\n",
       "      <td>0.232414</td>\n",
       "      <td>0.792952</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.791209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.054700</td>\n",
       "      <td>0.238745</td>\n",
       "      <td>0.797357</td>\n",
       "      <td>0.793860</td>\n",
       "      <td>0.795604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 3649.31 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.83      0.75      0.79       261\n",
      "\n",
      "   micro avg       0.83      0.75      0.79       261\n",
      "   macro avg       0.83      0.75      0.79       261\n",
      "weighted avg       0.83      0.75      0.79       261\n",
      "\n",
      "Precision Score: 0.8305084745762712\n",
      "Recall Score: 0.7509578544061303\n",
      "F1 Score: 0.7887323943661971\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/5_epochs/distilbert_distilbert-base-german-cased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/5_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for GerMedBERT/medbert-512:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 4380.83 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 3487.40 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-ASPECT' 'I-ASPECT']\n",
      "{0: 0.3725025484199796, 1: 3.705196451204056, 2: 21.94744744744745}\n",
      "Training results for GerMedBERT/medbert-512 with 5 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 02:25, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.185691</td>\n",
       "      <td>0.727749</td>\n",
       "      <td>0.674757</td>\n",
       "      <td>0.700252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.058000</td>\n",
       "      <td>0.192995</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.776699</td>\n",
       "      <td>0.751174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.194400</td>\n",
       "      <td>0.217908</td>\n",
       "      <td>0.767677</td>\n",
       "      <td>0.737864</td>\n",
       "      <td>0.752475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.082800</td>\n",
       "      <td>0.253167</td>\n",
       "      <td>0.756477</td>\n",
       "      <td>0.708738</td>\n",
       "      <td>0.731830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.051900</td>\n",
       "      <td>0.308834</td>\n",
       "      <td>0.766497</td>\n",
       "      <td>0.733010</td>\n",
       "      <td>0.749380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 3343.38 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.80      0.72      0.76       234\n",
      "\n",
      "   micro avg       0.80      0.72      0.76       234\n",
      "   macro avg       0.80      0.72      0.76       234\n",
      "weighted avg       0.80      0.72      0.76       234\n",
      "\n",
      "Precision Score: 0.8\n",
      "Recall Score: 0.717948717948718\n",
      "F1 Score: 0.7567567567567569\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/5_epochs/GerMedBERT_medbert-512_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/5_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for deepset/gbert-base:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 4443.42 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 3615.56 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-ASPECT' 'I-ASPECT']\n",
      "{0: 0.3725025484199796, 1: 3.705196451204056, 2: 21.94744744744745}\n",
      "Training results for deepset/gbert-base with 5 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 02:25, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.257658</td>\n",
       "      <td>0.719828</td>\n",
       "      <td>0.732456</td>\n",
       "      <td>0.726087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.619300</td>\n",
       "      <td>0.225630</td>\n",
       "      <td>0.764228</td>\n",
       "      <td>0.824561</td>\n",
       "      <td>0.793249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.174400</td>\n",
       "      <td>0.246719</td>\n",
       "      <td>0.792952</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.791209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.075100</td>\n",
       "      <td>0.251072</td>\n",
       "      <td>0.788793</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>0.795652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.055900</td>\n",
       "      <td>0.319447</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.810458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 3471.77 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.83      0.72      0.77       261\n",
      "\n",
      "   micro avg       0.83      0.72      0.77       261\n",
      "   macro avg       0.83      0.72      0.77       261\n",
      "weighted avg       0.83      0.72      0.77       261\n",
      "\n",
      "Precision Score: 0.8289473684210527\n",
      "Recall Score: 0.7241379310344828\n",
      "F1 Score: 0.7730061349693252\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/5_epochs/deepset_gbert-base_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/5_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(f'training and results for {model}:')\n",
    "    ate_model(data, model, rn1=42, rn2=42, epochs=5)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3337ee2b-a5ae-4fd7-9064-bc7368d84ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training and results for google-bert/bert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5774.07 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4642.36 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-ASPECT' 'O' 'B-ASPECT']\n",
      "{0: 21.94744744744745, 1: 0.3725025484199796, 2: 3.705196451204056}\n",
      "Training results for google-bert/bert-base-german-cased with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2828' max='2828' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2828/2828 03:25, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.181461</td>\n",
       "      <td>0.781659</td>\n",
       "      <td>0.764957</td>\n",
       "      <td>0.773218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.233300</td>\n",
       "      <td>0.188964</td>\n",
       "      <td>0.766129</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.788382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.105400</td>\n",
       "      <td>0.256114</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.797468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.032300</td>\n",
       "      <td>0.287511</td>\n",
       "      <td>0.772532</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.770878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.389646</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.782051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.018100</td>\n",
       "      <td>0.412960</td>\n",
       "      <td>0.744856</td>\n",
       "      <td>0.773504</td>\n",
       "      <td>0.758910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.427830</td>\n",
       "      <td>0.760331</td>\n",
       "      <td>0.786325</td>\n",
       "      <td>0.773109</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4380.56 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.80      0.75      0.77       268\n",
      "\n",
      "   micro avg       0.80      0.75      0.77       268\n",
      "   macro avg       0.80      0.75      0.77       268\n",
      "weighted avg       0.80      0.75      0.77       268\n",
      "\n",
      "Precision Score: 0.7976190476190477\n",
      "Recall Score: 0.75\n",
      "F1 Score: 0.7730769230769232\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/7_epochs/google-bert_bert-base-german-cased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/7_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5874.66 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4715.95 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-ASPECT' 'O' 'B-ASPECT']\n",
      "{0: 21.94744744744745, 1: 0.3725025484199796, 2: 3.705196451204056}\n",
      "Training results for dbmdz/bert-base-german-cased with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2828' max='2828' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2828/2828 03:26, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.173228</td>\n",
       "      <td>0.738956</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.771488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.246900</td>\n",
       "      <td>0.173769</td>\n",
       "      <td>0.784483</td>\n",
       "      <td>0.798246</td>\n",
       "      <td>0.791304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.124500</td>\n",
       "      <td>0.201311</td>\n",
       "      <td>0.795833</td>\n",
       "      <td>0.837719</td>\n",
       "      <td>0.816239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.053400</td>\n",
       "      <td>0.260093</td>\n",
       "      <td>0.745174</td>\n",
       "      <td>0.846491</td>\n",
       "      <td>0.792608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.032400</td>\n",
       "      <td>0.311122</td>\n",
       "      <td>0.764228</td>\n",
       "      <td>0.824561</td>\n",
       "      <td>0.793249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.032400</td>\n",
       "      <td>0.334307</td>\n",
       "      <td>0.774590</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.800847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.016300</td>\n",
       "      <td>0.345661</td>\n",
       "      <td>0.784232</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.805970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4499.76 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.83      0.77      0.80       261\n",
      "\n",
      "   micro avg       0.83      0.77      0.80       261\n",
      "   macro avg       0.83      0.77      0.80       261\n",
      "weighted avg       0.83      0.77      0.80       261\n",
      "\n",
      "Precision Score: 0.8264462809917356\n",
      "Recall Score: 0.7662835249042146\n",
      "F1 Score: 0.7952286282306162\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/7_epochs/dbmdz_bert-base-german-cased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/7_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-uncased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5604.30 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4624.47 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-ASPECT' 'O' 'B-ASPECT']\n",
      "{0: 21.94744744744745, 1: 0.3725025484199796, 2: 3.705196451204056}\n",
      "Training results for dbmdz/bert-base-german-uncased with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2828' max='2828' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2828/2828 03:25, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.177574</td>\n",
       "      <td>0.755656</td>\n",
       "      <td>0.738938</td>\n",
       "      <td>0.747204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.230200</td>\n",
       "      <td>0.187400</td>\n",
       "      <td>0.816038</td>\n",
       "      <td>0.765487</td>\n",
       "      <td>0.789954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.109600</td>\n",
       "      <td>0.243596</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.756637</td>\n",
       "      <td>0.784404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.043100</td>\n",
       "      <td>0.250718</td>\n",
       "      <td>0.789954</td>\n",
       "      <td>0.765487</td>\n",
       "      <td>0.777528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.024700</td>\n",
       "      <td>0.318618</td>\n",
       "      <td>0.770925</td>\n",
       "      <td>0.774336</td>\n",
       "      <td>0.772627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.024700</td>\n",
       "      <td>0.364562</td>\n",
       "      <td>0.779817</td>\n",
       "      <td>0.752212</td>\n",
       "      <td>0.765766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.383791</td>\n",
       "      <td>0.785388</td>\n",
       "      <td>0.761062</td>\n",
       "      <td>0.773034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4466.50 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.87      0.74      0.80       267\n",
      "\n",
      "   micro avg       0.87      0.74      0.80       267\n",
      "   macro avg       0.87      0.74      0.80       267\n",
      "weighted avg       0.87      0.74      0.80       267\n",
      "\n",
      "Precision Score: 0.8716814159292036\n",
      "Recall Score: 0.7378277153558053\n",
      "F1 Score: 0.799188640973631\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/7_epochs/dbmdz_bert-base-german-uncased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/7_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for FacebookAI/xlm-roberta-base:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5704.30 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4951.61 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-ASPECT' 'O' 'B-ASPECT']\n",
      "{0: 21.94744744744745, 1: 0.3725025484199796, 2: 3.705196451204056}\n",
      "Training results for FacebookAI/xlm-roberta-base with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2828' max='2828' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2828/2828 05:39, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.200126</td>\n",
       "      <td>0.790123</td>\n",
       "      <td>0.738462</td>\n",
       "      <td>0.763419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.285700</td>\n",
       "      <td>0.216824</td>\n",
       "      <td>0.746324</td>\n",
       "      <td>0.780769</td>\n",
       "      <td>0.763158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.189100</td>\n",
       "      <td>0.206973</td>\n",
       "      <td>0.776515</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.782443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.119200</td>\n",
       "      <td>0.197361</td>\n",
       "      <td>0.785441</td>\n",
       "      <td>0.788462</td>\n",
       "      <td>0.786948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.081400</td>\n",
       "      <td>0.235169</td>\n",
       "      <td>0.751701</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.797834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.081400</td>\n",
       "      <td>0.238651</td>\n",
       "      <td>0.792115</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.820037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.051900</td>\n",
       "      <td>0.252218</td>\n",
       "      <td>0.788530</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.816327</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4448.06 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.81      0.75      0.78       294\n",
      "\n",
      "   micro avg       0.81      0.75      0.78       294\n",
      "   macro avg       0.81      0.75      0.78       294\n",
      "weighted avg       0.81      0.75      0.78       294\n",
      "\n",
      "Precision Score: 0.8125\n",
      "Recall Score: 0.7517006802721088\n",
      "F1 Score: 0.7809187279151942\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/7_epochs/FacebookAI_xlm-roberta-base_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/7_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_best:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6382.33 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4945.36 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-ASPECT' 'O' 'B-ASPECT']\n",
      "{0: 21.94744744744745, 1: 0.3725025484199796, 2: 3.705196451204056}\n",
      "Training results for TUM/GottBERT_base_best with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2828' max='2828' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2828/2828 03:45, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.266336</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.768000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.724600</td>\n",
       "      <td>0.184548</td>\n",
       "      <td>0.789773</td>\n",
       "      <td>0.747312</td>\n",
       "      <td>0.767956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.184900</td>\n",
       "      <td>0.196833</td>\n",
       "      <td>0.770053</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.772118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.082800</td>\n",
       "      <td>0.215874</td>\n",
       "      <td>0.784038</td>\n",
       "      <td>0.897849</td>\n",
       "      <td>0.837093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.049900</td>\n",
       "      <td>0.315540</td>\n",
       "      <td>0.775229</td>\n",
       "      <td>0.908602</td>\n",
       "      <td>0.836634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.049900</td>\n",
       "      <td>0.312912</td>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.815385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>0.340441</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.816754</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.decoder.weight', 'lm_head.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4601.19 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.79      0.79      0.79       229\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       229\n",
      "   macro avg       0.79      0.79      0.79       229\n",
      "weighted avg       0.79      0.79      0.79       229\n",
      "\n",
      "Precision Score: 0.793859649122807\n",
      "Recall Score: 0.7903930131004366\n",
      "F1 Score: 0.7921225382932167\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/7_epochs/TUM_GottBERT_base_best_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/7_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_filtered_base_best:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6487.29 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4916.15 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-ASPECT' 'O' 'B-ASPECT']\n",
      "{0: 21.94744744744745, 1: 0.3725025484199796, 2: 3.705196451204056}\n",
      "Training results for TUM/GottBERT_filtered_base_best with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2828' max='2828' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2828/2828 03:45, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.245944</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.698925</td>\n",
       "      <td>0.732394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.658800</td>\n",
       "      <td>0.184877</td>\n",
       "      <td>0.841808</td>\n",
       "      <td>0.801075</td>\n",
       "      <td>0.820937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.176300</td>\n",
       "      <td>0.209376</td>\n",
       "      <td>0.760563</td>\n",
       "      <td>0.870968</td>\n",
       "      <td>0.812030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.080700</td>\n",
       "      <td>0.190812</td>\n",
       "      <td>0.755760</td>\n",
       "      <td>0.881720</td>\n",
       "      <td>0.813896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.044500</td>\n",
       "      <td>0.300964</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.827957</td>\n",
       "      <td>0.791774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.044500</td>\n",
       "      <td>0.362863</td>\n",
       "      <td>0.777202</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.791557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.023400</td>\n",
       "      <td>0.377163</td>\n",
       "      <td>0.773684</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.781915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.decoder.weight', 'lm_head.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4740.32 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.86      0.73      0.79       229\n",
      "\n",
      "   micro avg       0.86      0.73      0.79       229\n",
      "   macro avg       0.86      0.73      0.79       229\n",
      "weighted avg       0.86      0.73      0.79       229\n",
      "\n",
      "Precision Score: 0.8615384615384616\n",
      "Recall Score: 0.7336244541484717\n",
      "F1 Score: 0.7924528301886793\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/7_epochs/TUM_GottBERT_filtered_base_best_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/7_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_last:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at TUM/GottBERT_base_last were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of the model checkpoint at TUM/GottBERT_base_last were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6412.06 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4915.30 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-ASPECT' 'O' 'B-ASPECT']\n",
      "{0: 21.94744744744745, 1: 0.3725025484199796, 2: 3.705196451204056}\n",
      "Training results for TUM/GottBERT_base_last with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2828' max='2828' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2828/2828 03:45, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.229832</td>\n",
       "      <td>0.760234</td>\n",
       "      <td>0.698925</td>\n",
       "      <td>0.728291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.746900</td>\n",
       "      <td>0.179568</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.770053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.192000</td>\n",
       "      <td>0.219577</td>\n",
       "      <td>0.776119</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.806202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.094900</td>\n",
       "      <td>0.244077</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.803109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.054800</td>\n",
       "      <td>0.366791</td>\n",
       "      <td>0.756098</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.792839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.054800</td>\n",
       "      <td>0.374622</td>\n",
       "      <td>0.766497</td>\n",
       "      <td>0.811828</td>\n",
       "      <td>0.788512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.019000</td>\n",
       "      <td>0.401523</td>\n",
       "      <td>0.763819</td>\n",
       "      <td>0.817204</td>\n",
       "      <td>0.789610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.decoder.weight', 'lm_head.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4660.13 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.83      0.79      0.81       229\n",
      "\n",
      "   micro avg       0.83      0.79      0.81       229\n",
      "   macro avg       0.83      0.79      0.81       229\n",
      "weighted avg       0.83      0.79      0.81       229\n",
      "\n",
      "Precision Score: 0.8256880733944955\n",
      "Recall Score: 0.7860262008733624\n",
      "F1 Score: 0.8053691275167785\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/7_epochs/TUM_GottBERT_base_last_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/7_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for distilbert/distilbert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6512.07 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5138.21 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-ASPECT' 'O' 'B-ASPECT']\n",
      "{0: 21.94744744744745, 1: 0.3725025484199796, 2: 3.705196451204056}\n",
      "Training results for distilbert/distilbert-base-german-cased with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2828' max='2828' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2828/2828 01:55, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.177223</td>\n",
       "      <td>0.755365</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.763557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.257800</td>\n",
       "      <td>0.181633</td>\n",
       "      <td>0.779736</td>\n",
       "      <td>0.776316</td>\n",
       "      <td>0.778022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.133200</td>\n",
       "      <td>0.220919</td>\n",
       "      <td>0.816901</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.789116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.065100</td>\n",
       "      <td>0.240712</td>\n",
       "      <td>0.816514</td>\n",
       "      <td>0.780702</td>\n",
       "      <td>0.798206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.045200</td>\n",
       "      <td>0.264957</td>\n",
       "      <td>0.802752</td>\n",
       "      <td>0.767544</td>\n",
       "      <td>0.784753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.045200</td>\n",
       "      <td>0.283065</td>\n",
       "      <td>0.805430</td>\n",
       "      <td>0.780702</td>\n",
       "      <td>0.792873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.022400</td>\n",
       "      <td>0.292062</td>\n",
       "      <td>0.786667</td>\n",
       "      <td>0.776316</td>\n",
       "      <td>0.781457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4791.24 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.81      0.71      0.76       261\n",
      "\n",
      "   micro avg       0.81      0.71      0.76       261\n",
      "   macro avg       0.81      0.71      0.76       261\n",
      "weighted avg       0.81      0.71      0.76       261\n",
      "\n",
      "Precision Score: 0.8149779735682819\n",
      "Recall Score: 0.7088122605363985\n",
      "F1 Score: 0.7581967213114754\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/7_epochs/distilbert_distilbert-base-german-cased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/7_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for GerMedBERT/medbert-512:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5729.62 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4574.93 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-ASPECT' 'O' 'B-ASPECT']\n",
      "{0: 21.94744744744745, 1: 0.3725025484199796, 2: 3.705196451204056}\n",
      "Training results for GerMedBERT/medbert-512 with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2828' max='2828' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2828/2828 03:31, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.189177</td>\n",
       "      <td>0.755435</td>\n",
       "      <td>0.674757</td>\n",
       "      <td>0.712821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.047700</td>\n",
       "      <td>0.191705</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.776699</td>\n",
       "      <td>0.765550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.195100</td>\n",
       "      <td>0.220584</td>\n",
       "      <td>0.773399</td>\n",
       "      <td>0.762136</td>\n",
       "      <td>0.767726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.082300</td>\n",
       "      <td>0.248508</td>\n",
       "      <td>0.754902</td>\n",
       "      <td>0.747573</td>\n",
       "      <td>0.751220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.044900</td>\n",
       "      <td>0.361298</td>\n",
       "      <td>0.769608</td>\n",
       "      <td>0.762136</td>\n",
       "      <td>0.765854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.044900</td>\n",
       "      <td>0.397020</td>\n",
       "      <td>0.781421</td>\n",
       "      <td>0.694175</td>\n",
       "      <td>0.735219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.021600</td>\n",
       "      <td>0.423888</td>\n",
       "      <td>0.774869</td>\n",
       "      <td>0.718447</td>\n",
       "      <td>0.745592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4219.29 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.79      0.70      0.74       234\n",
      "\n",
      "   micro avg       0.79      0.70      0.74       234\n",
      "   macro avg       0.79      0.70      0.74       234\n",
      "weighted avg       0.79      0.70      0.74       234\n",
      "\n",
      "Precision Score: 0.7912621359223301\n",
      "Recall Score: 0.6965811965811965\n",
      "F1 Score: 0.7409090909090909\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/7_epochs/GerMedBERT_medbert-512_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/7_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for deepset/gbert-base:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5761.48 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4772.43 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-ASPECT' 'O' 'B-ASPECT']\n",
      "{0: 21.94744744744745, 1: 0.3725025484199796, 2: 3.705196451204056}\n",
      "Training results for deepset/gbert-base with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2828' max='2828' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2828/2828 03:32, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.252348</td>\n",
       "      <td>0.721311</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.745763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.622400</td>\n",
       "      <td>0.235447</td>\n",
       "      <td>0.771300</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.762749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.173400</td>\n",
       "      <td>0.284240</td>\n",
       "      <td>0.783186</td>\n",
       "      <td>0.776316</td>\n",
       "      <td>0.779736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.072400</td>\n",
       "      <td>0.307109</td>\n",
       "      <td>0.785088</td>\n",
       "      <td>0.785088</td>\n",
       "      <td>0.785088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.057100</td>\n",
       "      <td>0.390860</td>\n",
       "      <td>0.791111</td>\n",
       "      <td>0.780702</td>\n",
       "      <td>0.785872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.057100</td>\n",
       "      <td>0.407471</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.798246</td>\n",
       "      <td>0.793028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.023100</td>\n",
       "      <td>0.448715</td>\n",
       "      <td>0.796460</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.792952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4458.91 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.84      0.73      0.78       261\n",
      "\n",
      "   micro avg       0.84      0.73      0.78       261\n",
      "   macro avg       0.84      0.73      0.78       261\n",
      "weighted avg       0.84      0.73      0.78       261\n",
      "\n",
      "Precision Score: 0.8377192982456141\n",
      "Recall Score: 0.7318007662835249\n",
      "F1 Score: 0.7811860940695297\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/7_epochs/deepset_gbert-base_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/7_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(f'training and results for {model}:')\n",
    "    ate_model(data, model, rn1=42, rn2=42, epochs=7)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e70742da-6be7-4ae4-849e-3a8598aec684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training and results for google-bert/bert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5718.76 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4592.44 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-ASPECT' 'O' 'B-ASPECT']\n",
      "{0: 21.94744744744745, 1: 0.3725025484199796, 2: 3.705196451204056}\n",
      "Training results for google-bert/bert-base-german-cased with 8 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3232' max='3232' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3232/3232 03:57, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.170733</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.760684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.228800</td>\n",
       "      <td>0.175184</td>\n",
       "      <td>0.809735</td>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.795652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0.257495</td>\n",
       "      <td>0.749035</td>\n",
       "      <td>0.829060</td>\n",
       "      <td>0.787018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.032600</td>\n",
       "      <td>0.294443</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.789144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>0.402445</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.752137</td>\n",
       "      <td>0.775330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>0.421581</td>\n",
       "      <td>0.784483</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.781116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.459147</td>\n",
       "      <td>0.797297</td>\n",
       "      <td>0.756410</td>\n",
       "      <td>0.776316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.459163</td>\n",
       "      <td>0.798206</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.778993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4340.83 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.81      0.74      0.77       268\n",
      "\n",
      "   micro avg       0.81      0.74      0.77       268\n",
      "   macro avg       0.81      0.74      0.77       268\n",
      "weighted avg       0.81      0.74      0.77       268\n",
      "\n",
      "Precision Score: 0.8089430894308943\n",
      "Recall Score: 0.7425373134328358\n",
      "F1 Score: 0.77431906614786\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/8_epochs/google-bert_bert-base-german-cased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/8_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5645.81 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4705.90 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-ASPECT' 'O' 'B-ASPECT']\n",
      "{0: 21.94744744744745, 1: 0.3725025484199796, 2: 3.705196451204056}\n",
      "Training results for dbmdz/bert-base-german-cased with 8 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3232' max='3232' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3232/3232 03:56, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.172412</td>\n",
       "      <td>0.744856</td>\n",
       "      <td>0.793860</td>\n",
       "      <td>0.768577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.241300</td>\n",
       "      <td>0.184421</td>\n",
       "      <td>0.767932</td>\n",
       "      <td>0.798246</td>\n",
       "      <td>0.782796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.119200</td>\n",
       "      <td>0.255241</td>\n",
       "      <td>0.799127</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>0.800875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.046100</td>\n",
       "      <td>0.286976</td>\n",
       "      <td>0.736000</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.769874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.025100</td>\n",
       "      <td>0.369435</td>\n",
       "      <td>0.719231</td>\n",
       "      <td>0.820175</td>\n",
       "      <td>0.766393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.025100</td>\n",
       "      <td>0.395934</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.723684</td>\n",
       "      <td>0.753425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>0.388833</td>\n",
       "      <td>0.775330</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.773626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.381444</td>\n",
       "      <td>0.756303</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.772532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4444.60 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.85      0.74      0.79       261\n",
      "\n",
      "   micro avg       0.85      0.74      0.79       261\n",
      "   macro avg       0.85      0.74      0.79       261\n",
      "weighted avg       0.85      0.74      0.79       261\n",
      "\n",
      "Precision Score: 0.8458149779735683\n",
      "Recall Score: 0.735632183908046\n",
      "F1 Score: 0.7868852459016393\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/8_epochs/dbmdz_bert-base-german-cased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/8_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-uncased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5467.17 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4506.89 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-ASPECT' 'O' 'B-ASPECT']\n",
      "{0: 21.94744744744745, 1: 0.3725025484199796, 2: 3.705196451204056}\n",
      "Training results for dbmdz/bert-base-german-uncased with 8 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3232' max='3232' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3232/3232 03:55, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.170334</td>\n",
       "      <td>0.770642</td>\n",
       "      <td>0.743363</td>\n",
       "      <td>0.756757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.227700</td>\n",
       "      <td>0.189060</td>\n",
       "      <td>0.792627</td>\n",
       "      <td>0.761062</td>\n",
       "      <td>0.776524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.115100</td>\n",
       "      <td>0.262753</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.778761</td>\n",
       "      <td>0.803653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.047300</td>\n",
       "      <td>0.270339</td>\n",
       "      <td>0.789238</td>\n",
       "      <td>0.778761</td>\n",
       "      <td>0.783964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>0.329700</td>\n",
       "      <td>0.776744</td>\n",
       "      <td>0.738938</td>\n",
       "      <td>0.757370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>0.371579</td>\n",
       "      <td>0.784753</td>\n",
       "      <td>0.774336</td>\n",
       "      <td>0.779510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>0.376573</td>\n",
       "      <td>0.772926</td>\n",
       "      <td>0.783186</td>\n",
       "      <td>0.778022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.003600</td>\n",
       "      <td>0.373185</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.805310</td>\n",
       "      <td>0.791304</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4416.56 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.89      0.70      0.78       267\n",
      "\n",
      "   micro avg       0.89      0.70      0.78       267\n",
      "   macro avg       0.89      0.70      0.78       267\n",
      "weighted avg       0.89      0.70      0.78       267\n",
      "\n",
      "Precision Score: 0.8867924528301887\n",
      "Recall Score: 0.704119850187266\n",
      "F1 Score: 0.7849686847599165\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/8_epochs/dbmdz_bert-base-german-uncased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/8_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for FacebookAI/xlm-roberta-base:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5741.87 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4931.03 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-ASPECT' 'O' 'B-ASPECT']\n",
      "{0: 21.94744744744745, 1: 0.3725025484199796, 2: 3.705196451204056}\n",
      "Training results for FacebookAI/xlm-roberta-base with 8 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3232' max='3232' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3232/3232 06:28, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.195258</td>\n",
       "      <td>0.760456</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.764818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.262500</td>\n",
       "      <td>0.174126</td>\n",
       "      <td>0.786477</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.817006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.171000</td>\n",
       "      <td>0.196249</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>0.807619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.107500</td>\n",
       "      <td>0.234222</td>\n",
       "      <td>0.780576</td>\n",
       "      <td>0.834615</td>\n",
       "      <td>0.806691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.071900</td>\n",
       "      <td>0.274170</td>\n",
       "      <td>0.787770</td>\n",
       "      <td>0.842308</td>\n",
       "      <td>0.814126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.071900</td>\n",
       "      <td>0.324814</td>\n",
       "      <td>0.794466</td>\n",
       "      <td>0.773077</td>\n",
       "      <td>0.783626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.039400</td>\n",
       "      <td>0.341685</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.803846</td>\n",
       "      <td>0.797710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.022300</td>\n",
       "      <td>0.338770</td>\n",
       "      <td>0.781022</td>\n",
       "      <td>0.823077</td>\n",
       "      <td>0.801498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4487.91 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.75      0.77      0.76       294\n",
      "\n",
      "   micro avg       0.75      0.77      0.76       294\n",
      "   macro avg       0.75      0.77      0.76       294\n",
      "weighted avg       0.75      0.77      0.76       294\n",
      "\n",
      "Precision Score: 0.7475083056478405\n",
      "Recall Score: 0.7653061224489796\n",
      "F1 Score: 0.7563025210084033\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/8_epochs/FacebookAI_xlm-roberta-base_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/8_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_best:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5823.48 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4935.74 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-ASPECT' 'O' 'B-ASPECT']\n",
      "{0: 21.94744744744745, 1: 0.3725025484199796, 2: 3.705196451204056}\n",
      "Training results for TUM/GottBERT_base_best with 8 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3232' max='3232' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3232/3232 04:17, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.254853</td>\n",
       "      <td>0.807453</td>\n",
       "      <td>0.698925</td>\n",
       "      <td>0.749280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.715300</td>\n",
       "      <td>0.197798</td>\n",
       "      <td>0.797688</td>\n",
       "      <td>0.741935</td>\n",
       "      <td>0.768802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.184700</td>\n",
       "      <td>0.218726</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.784000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.086200</td>\n",
       "      <td>0.254850</td>\n",
       "      <td>0.753363</td>\n",
       "      <td>0.903226</td>\n",
       "      <td>0.821516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.056400</td>\n",
       "      <td>0.373603</td>\n",
       "      <td>0.751220</td>\n",
       "      <td>0.827957</td>\n",
       "      <td>0.787724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.056400</td>\n",
       "      <td>0.379446</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.860215</td>\n",
       "      <td>0.804020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.020500</td>\n",
       "      <td>0.422208</td>\n",
       "      <td>0.770732</td>\n",
       "      <td>0.849462</td>\n",
       "      <td>0.808184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.426926</td>\n",
       "      <td>0.781095</td>\n",
       "      <td>0.844086</td>\n",
       "      <td>0.811370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.decoder.weight', 'lm_head.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4666.90 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.76      0.78      0.77       229\n",
      "\n",
      "   micro avg       0.76      0.78      0.77       229\n",
      "   macro avg       0.76      0.78      0.77       229\n",
      "weighted avg       0.76      0.78      0.77       229\n",
      "\n",
      "Precision Score: 0.7639484978540773\n",
      "Recall Score: 0.777292576419214\n",
      "F1 Score: 0.7705627705627706\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/8_epochs/TUM_GottBERT_base_best_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/8_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_filtered_base_best:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6381.78 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4876.59 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-ASPECT' 'O' 'B-ASPECT']\n",
      "{0: 21.94744744744745, 1: 0.3725025484199796, 2: 3.705196451204056}\n",
      "Training results for TUM/GottBERT_filtered_base_best with 8 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3232' max='3232' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3232/3232 04:18, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.252846</td>\n",
       "      <td>0.802817</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.695122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.661900</td>\n",
       "      <td>0.187913</td>\n",
       "      <td>0.815476</td>\n",
       "      <td>0.736559</td>\n",
       "      <td>0.774011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.174200</td>\n",
       "      <td>0.212021</td>\n",
       "      <td>0.752427</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.790816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.089500</td>\n",
       "      <td>0.203339</td>\n",
       "      <td>0.745283</td>\n",
       "      <td>0.849462</td>\n",
       "      <td>0.793970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.043600</td>\n",
       "      <td>0.360286</td>\n",
       "      <td>0.763819</td>\n",
       "      <td>0.817204</td>\n",
       "      <td>0.789610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.043600</td>\n",
       "      <td>0.368892</td>\n",
       "      <td>0.753769</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.779221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>0.432983</td>\n",
       "      <td>0.762626</td>\n",
       "      <td>0.811828</td>\n",
       "      <td>0.786458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.009700</td>\n",
       "      <td>0.475443</td>\n",
       "      <td>0.776042</td>\n",
       "      <td>0.801075</td>\n",
       "      <td>0.788360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.decoder.weight', 'lm_head.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4710.26 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.75      0.78      0.76       229\n",
      "\n",
      "   micro avg       0.75      0.78      0.76       229\n",
      "   macro avg       0.75      0.78      0.76       229\n",
      "weighted avg       0.75      0.78      0.76       229\n",
      "\n",
      "Precision Score: 0.7489539748953975\n",
      "Recall Score: 0.7816593886462883\n",
      "F1 Score: 0.7649572649572649\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/8_epochs/TUM_GottBERT_filtered_base_best_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/8_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_last:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at TUM/GottBERT_base_last were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of the model checkpoint at TUM/GottBERT_base_last were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6447.74 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4848.24 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-ASPECT' 'O' 'B-ASPECT']\n",
      "{0: 21.94744744744745, 1: 0.3725025484199796, 2: 3.705196451204056}\n",
      "Training results for TUM/GottBERT_base_last with 8 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3232' max='3232' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3232/3232 04:17, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.274411</td>\n",
       "      <td>0.801471</td>\n",
       "      <td>0.586022</td>\n",
       "      <td>0.677019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.735400</td>\n",
       "      <td>0.174878</td>\n",
       "      <td>0.742424</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.765625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.192600</td>\n",
       "      <td>0.231019</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.817204</td>\n",
       "      <td>0.812834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.087700</td>\n",
       "      <td>0.241931</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.860215</td>\n",
       "      <td>0.808081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.056200</td>\n",
       "      <td>0.368433</td>\n",
       "      <td>0.768473</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.802057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.056200</td>\n",
       "      <td>0.397673</td>\n",
       "      <td>0.778947</td>\n",
       "      <td>0.795699</td>\n",
       "      <td>0.787234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.020500</td>\n",
       "      <td>0.423944</td>\n",
       "      <td>0.764423</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.807107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.011100</td>\n",
       "      <td>0.434345</td>\n",
       "      <td>0.777228</td>\n",
       "      <td>0.844086</td>\n",
       "      <td>0.809278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.decoder.weight', 'lm_head.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4665.88 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.81      0.77      0.79       229\n",
      "\n",
      "   micro avg       0.81      0.77      0.79       229\n",
      "   macro avg       0.81      0.77      0.79       229\n",
      "weighted avg       0.81      0.77      0.79       229\n",
      "\n",
      "Precision Score: 0.8082191780821918\n",
      "Recall Score: 0.7729257641921398\n",
      "F1 Score: 0.7901785714285714\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/8_epochs/TUM_GottBERT_base_last_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/8_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for distilbert/distilbert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6514.51 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5246.58 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-ASPECT' 'O' 'B-ASPECT']\n",
      "{0: 21.94744744744745, 1: 0.3725025484199796, 2: 3.705196451204056}\n",
      "Training results for distilbert/distilbert-base-german-cased with 8 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3232' max='3232' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3232/3232 02:12, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.181537</td>\n",
       "      <td>0.752137</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.258900</td>\n",
       "      <td>0.188958</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.745614</td>\n",
       "      <td>0.757238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.132200</td>\n",
       "      <td>0.225596</td>\n",
       "      <td>0.789954</td>\n",
       "      <td>0.758772</td>\n",
       "      <td>0.774049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.064500</td>\n",
       "      <td>0.243682</td>\n",
       "      <td>0.773504</td>\n",
       "      <td>0.793860</td>\n",
       "      <td>0.783550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.045400</td>\n",
       "      <td>0.283247</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.798246</td>\n",
       "      <td>0.793028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.045400</td>\n",
       "      <td>0.298365</td>\n",
       "      <td>0.783550</td>\n",
       "      <td>0.793860</td>\n",
       "      <td>0.788671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.022200</td>\n",
       "      <td>0.320788</td>\n",
       "      <td>0.794760</td>\n",
       "      <td>0.798246</td>\n",
       "      <td>0.796499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.013100</td>\n",
       "      <td>0.325516</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.802632</td>\n",
       "      <td>0.797386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4865.62 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.81      0.75      0.78       261\n",
      "\n",
      "   micro avg       0.81      0.75      0.78       261\n",
      "   macro avg       0.81      0.75      0.78       261\n",
      "weighted avg       0.81      0.75      0.78       261\n",
      "\n",
      "Precision Score: 0.8106995884773662\n",
      "Recall Score: 0.7547892720306514\n",
      "F1 Score: 0.7817460317460319\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/8_epochs/distilbert_distilbert-base-german-cased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/8_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for GerMedBERT/medbert-512:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5728.29 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4571.72 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-ASPECT' 'O' 'B-ASPECT']\n",
      "{0: 21.94744744744745, 1: 0.3725025484199796, 2: 3.705196451204056}\n",
      "Training results for GerMedBERT/medbert-512 with 8 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3232' max='3232' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3232/3232 04:01, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.191483</td>\n",
       "      <td>0.751381</td>\n",
       "      <td>0.660194</td>\n",
       "      <td>0.702842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.044100</td>\n",
       "      <td>0.187153</td>\n",
       "      <td>0.736364</td>\n",
       "      <td>0.786408</td>\n",
       "      <td>0.760563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.194000</td>\n",
       "      <td>0.228407</td>\n",
       "      <td>0.771028</td>\n",
       "      <td>0.800971</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.083100</td>\n",
       "      <td>0.257542</td>\n",
       "      <td>0.732673</td>\n",
       "      <td>0.718447</td>\n",
       "      <td>0.725490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.046400</td>\n",
       "      <td>0.416212</td>\n",
       "      <td>0.726027</td>\n",
       "      <td>0.771845</td>\n",
       "      <td>0.748235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.046400</td>\n",
       "      <td>0.379000</td>\n",
       "      <td>0.773196</td>\n",
       "      <td>0.728155</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.024200</td>\n",
       "      <td>0.439008</td>\n",
       "      <td>0.757426</td>\n",
       "      <td>0.742718</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.457236</td>\n",
       "      <td>0.741463</td>\n",
       "      <td>0.737864</td>\n",
       "      <td>0.739659</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Unexpected prediction 21380 found. Assigning 'O'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4277.38 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.79      0.74      0.76       234\n",
      "\n",
      "   micro avg       0.79      0.74      0.76       234\n",
      "   macro avg       0.79      0.74      0.76       234\n",
      "weighted avg       0.79      0.74      0.76       234\n",
      "\n",
      "Precision Score: 0.7853881278538812\n",
      "Recall Score: 0.7350427350427351\n",
      "F1 Score: 0.7593818984547461\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/8_epochs/GerMedBERT_medbert-512_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/8_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for deepset/gbert-base:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5721.92 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4602.72 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-ASPECT' 'O' 'B-ASPECT']\n",
      "{0: 21.94744744744745, 1: 0.3725025484199796, 2: 3.705196451204056}\n",
      "Training results for deepset/gbert-base with 8 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3232' max='3232' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3232/3232 04:02, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.240540</td>\n",
       "      <td>0.738739</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.728889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.614500</td>\n",
       "      <td>0.228364</td>\n",
       "      <td>0.748000</td>\n",
       "      <td>0.820175</td>\n",
       "      <td>0.782427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.170300</td>\n",
       "      <td>0.240929</td>\n",
       "      <td>0.796537</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.801743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.071400</td>\n",
       "      <td>0.246625</td>\n",
       "      <td>0.798283</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.806941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.043100</td>\n",
       "      <td>0.346854</td>\n",
       "      <td>0.786008</td>\n",
       "      <td>0.837719</td>\n",
       "      <td>0.811040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.043100</td>\n",
       "      <td>0.375973</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.811404</td>\n",
       "      <td>0.807860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.018400</td>\n",
       "      <td>0.431386</td>\n",
       "      <td>0.817778</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.812362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.437655</td>\n",
       "      <td>0.802575</td>\n",
       "      <td>0.820175</td>\n",
       "      <td>0.811280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4398.26 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.85      0.72      0.78       261\n",
      "\n",
      "   micro avg       0.85      0.72      0.78       261\n",
      "   macro avg       0.85      0.72      0.78       261\n",
      "weighted avg       0.85      0.72      0.78       261\n",
      "\n",
      "Precision Score: 0.8506787330316742\n",
      "Recall Score: 0.7203065134099617\n",
      "F1 Score: 0.7800829875518672\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/8_epochs/deepset_gbert-base_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/8_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(f'training and results for {model}:')\n",
    "    ate_model(data, model, rn1=42, rn2=42, epochs=8)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcdc148d-8938-407d-b3be-21d89a6fa261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training and results for google-bert/bert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 4358.65 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 3509.38 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-ASPECT' 'I-ASPECT']\n",
      "{0: 0.3725025484199796, 1: 3.705196451204056, 2: 21.94744744744745}\n",
      "Training results for google-bert/bert-base-german-cased with 6 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2424' max='2424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2424/2424 02:51, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.176338</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.767932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.231300</td>\n",
       "      <td>0.175735</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.807692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.108800</td>\n",
       "      <td>0.222077</td>\n",
       "      <td>0.787149</td>\n",
       "      <td>0.837607</td>\n",
       "      <td>0.811594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.034500</td>\n",
       "      <td>0.249603</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.800847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.335527</td>\n",
       "      <td>0.800885</td>\n",
       "      <td>0.773504</td>\n",
       "      <td>0.786957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.343859</td>\n",
       "      <td>0.792035</td>\n",
       "      <td>0.764957</td>\n",
       "      <td>0.778261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 3058.21 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.82      0.76      0.79       268\n",
      "\n",
      "   micro avg       0.82      0.76      0.79       268\n",
      "   macro avg       0.82      0.76      0.79       268\n",
      "weighted avg       0.82      0.76      0.79       268\n",
      "\n",
      "Precision Score: 0.8192771084337349\n",
      "Recall Score: 0.7611940298507462\n",
      "F1 Score: 0.7891682785299807\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/6_epochs/google-bert_bert-base-german-cased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/6_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 4437.65 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 3698.26 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-ASPECT' 'I-ASPECT']\n",
      "{0: 0.3725025484199796, 1: 3.705196451204056, 2: 21.94744744744745}\n",
      "Training results for dbmdz/bert-base-german-cased with 6 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2424' max='2424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2424/2424 02:50, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.167944</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.776316</td>\n",
       "      <td>0.771242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.241600</td>\n",
       "      <td>0.174428</td>\n",
       "      <td>0.757322</td>\n",
       "      <td>0.793860</td>\n",
       "      <td>0.775161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.119400</td>\n",
       "      <td>0.237688</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.786325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.049000</td>\n",
       "      <td>0.263297</td>\n",
       "      <td>0.730924</td>\n",
       "      <td>0.798246</td>\n",
       "      <td>0.763103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.030600</td>\n",
       "      <td>0.357499</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.798246</td>\n",
       "      <td>0.769556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.030600</td>\n",
       "      <td>0.365126</td>\n",
       "      <td>0.742739</td>\n",
       "      <td>0.785088</td>\n",
       "      <td>0.763326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 3145.47 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.83      0.75      0.79       261\n",
      "\n",
      "   micro avg       0.83      0.75      0.79       261\n",
      "   macro avg       0.83      0.75      0.79       261\n",
      "weighted avg       0.83      0.75      0.79       261\n",
      "\n",
      "Precision Score: 0.8340425531914893\n",
      "Recall Score: 0.7509578544061303\n",
      "F1 Score: 0.7903225806451614\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/6_epochs/dbmdz_bert-base-german-cased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/6_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-uncased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 3892.63 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 3356.93 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-ASPECT' 'I-ASPECT']\n",
      "{0: 0.3725025484199796, 1: 3.705196451204056, 2: 21.94744744744745}\n",
      "Training results for dbmdz/bert-base-german-uncased with 6 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2424' max='2424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2424/2424 02:50, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.182595</td>\n",
       "      <td>0.756637</td>\n",
       "      <td>0.756637</td>\n",
       "      <td>0.756637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.233800</td>\n",
       "      <td>0.197348</td>\n",
       "      <td>0.778281</td>\n",
       "      <td>0.761062</td>\n",
       "      <td>0.769575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.117300</td>\n",
       "      <td>0.233480</td>\n",
       "      <td>0.784753</td>\n",
       "      <td>0.774336</td>\n",
       "      <td>0.779510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.043600</td>\n",
       "      <td>0.256252</td>\n",
       "      <td>0.725410</td>\n",
       "      <td>0.783186</td>\n",
       "      <td>0.753191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>0.337623</td>\n",
       "      <td>0.761261</td>\n",
       "      <td>0.747788</td>\n",
       "      <td>0.754464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.029900</td>\n",
       "      <td>0.350670</td>\n",
       "      <td>0.747826</td>\n",
       "      <td>0.761062</td>\n",
       "      <td>0.754386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 3423.81 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.88      0.72      0.79       267\n",
      "\n",
      "   micro avg       0.88      0.72      0.79       267\n",
      "   macro avg       0.88      0.72      0.79       267\n",
      "weighted avg       0.88      0.72      0.79       267\n",
      "\n",
      "Precision Score: 0.8807339449541285\n",
      "Recall Score: 0.7191011235955056\n",
      "F1 Score: 0.7917525773195877\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/6_epochs/dbmdz_bert-base-german-uncased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/6_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for FacebookAI/xlm-roberta-base:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 4144.66 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 3237.09 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-ASPECT' 'I-ASPECT']\n",
      "{0: 0.3725025484199796, 1: 3.705196451204056, 2: 21.94744744744745}\n",
      "Training results for FacebookAI/xlm-roberta-base with 6 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2424' max='2424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2424/2424 04:31, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.167060</td>\n",
       "      <td>0.759124</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.779026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.268900</td>\n",
       "      <td>0.185781</td>\n",
       "      <td>0.772388</td>\n",
       "      <td>0.796154</td>\n",
       "      <td>0.784091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.177000</td>\n",
       "      <td>0.177962</td>\n",
       "      <td>0.771127</td>\n",
       "      <td>0.842308</td>\n",
       "      <td>0.805147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.101700</td>\n",
       "      <td>0.206347</td>\n",
       "      <td>0.738983</td>\n",
       "      <td>0.838462</td>\n",
       "      <td>0.785586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.079700</td>\n",
       "      <td>0.233393</td>\n",
       "      <td>0.779783</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>0.804469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.079700</td>\n",
       "      <td>0.252703</td>\n",
       "      <td>0.779359</td>\n",
       "      <td>0.842308</td>\n",
       "      <td>0.809612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 3381.70 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.78      0.74      0.76       294\n",
      "\n",
      "   micro avg       0.78      0.74      0.76       294\n",
      "   macro avg       0.78      0.74      0.76       294\n",
      "weighted avg       0.78      0.74      0.76       294\n",
      "\n",
      "Precision Score: 0.7833935018050542\n",
      "Recall Score: 0.7380952380952381\n",
      "F1 Score: 0.7600700525394045\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/6_epochs/FacebookAI_xlm-roberta-base_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/6_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_best:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 4471.20 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 3650.46 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-ASPECT' 'I-ASPECT']\n",
      "{0: 0.3725025484199796, 1: 3.705196451204056, 2: 21.94744744744745}\n",
      "Training results for TUM/GottBERT_base_best with 6 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2424' max='2424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2424/2424 03:02, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.214263</td>\n",
       "      <td>0.717073</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.751918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.740700</td>\n",
       "      <td>0.210448</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.731183</td>\n",
       "      <td>0.743169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.222889</td>\n",
       "      <td>0.809249</td>\n",
       "      <td>0.752688</td>\n",
       "      <td>0.779944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.077100</td>\n",
       "      <td>0.226247</td>\n",
       "      <td>0.742081</td>\n",
       "      <td>0.881720</td>\n",
       "      <td>0.805897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.046500</td>\n",
       "      <td>0.330229</td>\n",
       "      <td>0.747619</td>\n",
       "      <td>0.844086</td>\n",
       "      <td>0.792929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.046500</td>\n",
       "      <td>0.357830</td>\n",
       "      <td>0.733010</td>\n",
       "      <td>0.811828</td>\n",
       "      <td>0.770408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.decoder.weight', 'lm_head.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 3564.27 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.81      0.77      0.79       229\n",
      "\n",
      "   micro avg       0.81      0.77      0.79       229\n",
      "   macro avg       0.81      0.77      0.79       229\n",
      "weighted avg       0.81      0.77      0.79       229\n",
      "\n",
      "Precision Score: 0.8082191780821918\n",
      "Recall Score: 0.7729257641921398\n",
      "F1 Score: 0.7901785714285714\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/6_epochs/TUM_GottBERT_base_best_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/6_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_filtered_base_best:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 4517.80 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 3656.13 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-ASPECT' 'I-ASPECT']\n",
      "{0: 0.3725025484199796, 1: 3.705196451204056, 2: 21.94744744744745}\n",
      "Training results for TUM/GottBERT_filtered_base_best with 6 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2424' max='2424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2424/2424 03:03, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.294401</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.639785</td>\n",
       "      <td>0.714715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.666200</td>\n",
       "      <td>0.209947</td>\n",
       "      <td>0.789189</td>\n",
       "      <td>0.784946</td>\n",
       "      <td>0.787062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.177900</td>\n",
       "      <td>0.216284</td>\n",
       "      <td>0.791878</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.814621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.081600</td>\n",
       "      <td>0.231700</td>\n",
       "      <td>0.753425</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.814815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.041400</td>\n",
       "      <td>0.355718</td>\n",
       "      <td>0.737327</td>\n",
       "      <td>0.860215</td>\n",
       "      <td>0.794045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.041400</td>\n",
       "      <td>0.351964</td>\n",
       "      <td>0.751196</td>\n",
       "      <td>0.844086</td>\n",
       "      <td>0.794937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.decoder.weight', 'lm_head.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 3587.79 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.75      0.77      0.76       229\n",
      "\n",
      "   micro avg       0.75      0.77      0.76       229\n",
      "   macro avg       0.75      0.77      0.76       229\n",
      "weighted avg       0.75      0.77      0.76       229\n",
      "\n",
      "Precision Score: 0.75\n",
      "Recall Score: 0.7729257641921398\n",
      "F1 Score: 0.7612903225806452\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/6_epochs/TUM_GottBERT_filtered_base_best_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/6_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_last:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at TUM/GottBERT_base_last were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of the model checkpoint at TUM/GottBERT_base_last were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 4482.37 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 3570.49 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-ASPECT' 'I-ASPECT']\n",
      "{0: 0.3725025484199796, 1: 3.705196451204056, 2: 21.94744744744745}\n",
      "Training results for TUM/GottBERT_base_last with 6 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2424' max='2424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2424/2424 03:03, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.259857</td>\n",
       "      <td>0.766082</td>\n",
       "      <td>0.704301</td>\n",
       "      <td>0.733894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.206259</td>\n",
       "      <td>0.751351</td>\n",
       "      <td>0.747312</td>\n",
       "      <td>0.749326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.181500</td>\n",
       "      <td>0.257704</td>\n",
       "      <td>0.807229</td>\n",
       "      <td>0.720430</td>\n",
       "      <td>0.761364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.083000</td>\n",
       "      <td>0.222824</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.052600</td>\n",
       "      <td>0.325440</td>\n",
       "      <td>0.773399</td>\n",
       "      <td>0.844086</td>\n",
       "      <td>0.807198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.052600</td>\n",
       "      <td>0.347636</td>\n",
       "      <td>0.777228</td>\n",
       "      <td>0.844086</td>\n",
       "      <td>0.809278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.decoder.weight', 'lm_head.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 3511.12 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.80      0.76      0.78       229\n",
      "\n",
      "   micro avg       0.80      0.76      0.78       229\n",
      "   macro avg       0.80      0.76      0.78       229\n",
      "weighted avg       0.80      0.76      0.78       229\n",
      "\n",
      "Precision Score: 0.7981651376146789\n",
      "Recall Score: 0.759825327510917\n",
      "F1 Score: 0.7785234899328859\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/6_epochs/TUM_GottBERT_base_last_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/6_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for distilbert/distilbert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 4796.99 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 3762.34 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-ASPECT' 'I-ASPECT']\n",
      "{0: 0.3725025484199796, 1: 3.705196451204056, 2: 21.94744744744745}\n",
      "Training results for distilbert/distilbert-base-german-cased with 6 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2424' max='2424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2424/2424 01:36, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.178517</td>\n",
       "      <td>0.772321</td>\n",
       "      <td>0.758772</td>\n",
       "      <td>0.765487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.256700</td>\n",
       "      <td>0.178241</td>\n",
       "      <td>0.753304</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.751648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.131700</td>\n",
       "      <td>0.219524</td>\n",
       "      <td>0.775785</td>\n",
       "      <td>0.758772</td>\n",
       "      <td>0.767184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.065200</td>\n",
       "      <td>0.248030</td>\n",
       "      <td>0.780172</td>\n",
       "      <td>0.793860</td>\n",
       "      <td>0.786957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.272421</td>\n",
       "      <td>0.791111</td>\n",
       "      <td>0.780702</td>\n",
       "      <td>0.785872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.283957</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.798246</td>\n",
       "      <td>0.793028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 3628.23 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.83      0.77      0.80       261\n",
      "\n",
      "   micro avg       0.83      0.77      0.80       261\n",
      "   macro avg       0.83      0.77      0.80       261\n",
      "weighted avg       0.83      0.77      0.80       261\n",
      "\n",
      "Precision Score: 0.8271604938271605\n",
      "Recall Score: 0.7701149425287356\n",
      "F1 Score: 0.7976190476190476\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/6_epochs/distilbert_distilbert-base-german-cased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/6_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for GerMedBERT/medbert-512:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 4149.00 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 3513.57 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-ASPECT' 'I-ASPECT']\n",
      "{0: 0.3725025484199796, 1: 3.705196451204056, 2: 21.94744744744745}\n",
      "Training results for GerMedBERT/medbert-512 with 6 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2424' max='2424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2424/2424 02:54, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.187720</td>\n",
       "      <td>0.738220</td>\n",
       "      <td>0.684466</td>\n",
       "      <td>0.710327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.052400</td>\n",
       "      <td>0.186301</td>\n",
       "      <td>0.747664</td>\n",
       "      <td>0.776699</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.193000</td>\n",
       "      <td>0.214645</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.752427</td>\n",
       "      <td>0.773067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.081700</td>\n",
       "      <td>0.247427</td>\n",
       "      <td>0.743961</td>\n",
       "      <td>0.747573</td>\n",
       "      <td>0.745763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.047700</td>\n",
       "      <td>0.365210</td>\n",
       "      <td>0.753623</td>\n",
       "      <td>0.757282</td>\n",
       "      <td>0.755448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.047700</td>\n",
       "      <td>0.368026</td>\n",
       "      <td>0.769608</td>\n",
       "      <td>0.762136</td>\n",
       "      <td>0.765854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 3179.63 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.81      0.67      0.73       234\n",
      "\n",
      "   micro avg       0.81      0.67      0.73       234\n",
      "   macro avg       0.81      0.67      0.73       234\n",
      "weighted avg       0.81      0.67      0.73       234\n",
      "\n",
      "Precision Score: 0.8051282051282052\n",
      "Recall Score: 0.6709401709401709\n",
      "F1 Score: 0.7319347319347319\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/6_epochs/GerMedBERT_medbert-512_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/6_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for deepset/gbert-base:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 4465.67 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 3541.69 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-ASPECT' 'I-ASPECT']\n",
      "{0: 0.3725025484199796, 1: 3.705196451204056, 2: 21.94744744744745}\n",
      "Training results for deepset/gbert-base with 6 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2424' max='2424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2424/2424 02:54, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.243179</td>\n",
       "      <td>0.735426</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.621300</td>\n",
       "      <td>0.223387</td>\n",
       "      <td>0.762115</td>\n",
       "      <td>0.758772</td>\n",
       "      <td>0.760440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.171800</td>\n",
       "      <td>0.256678</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.767544</td>\n",
       "      <td>0.781250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.074500</td>\n",
       "      <td>0.243001</td>\n",
       "      <td>0.796537</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.801743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.363324</td>\n",
       "      <td>0.794643</td>\n",
       "      <td>0.780702</td>\n",
       "      <td>0.787611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.044000</td>\n",
       "      <td>0.388545</td>\n",
       "      <td>0.809091</td>\n",
       "      <td>0.780702</td>\n",
       "      <td>0.794643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 3409.03 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.80      0.74      0.77       261\n",
      "\n",
      "   micro avg       0.80      0.74      0.77       261\n",
      "   macro avg       0.80      0.74      0.77       261\n",
      "weighted avg       0.80      0.74      0.77       261\n",
      "\n",
      "Precision Score: 0.8\n",
      "Recall Score: 0.735632183908046\n",
      "F1 Score: 0.7664670658682634\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/6_epochs/deepset_gbert-base_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/6_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(f'training and results for {model}:')\n",
    "    ate_model(data, model, rn1=42, rn2=42, epochs=6)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33b523b8-83f4-4794-882e-04fdd8daffcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training and results for google-bert/bert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5762.51 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4603.77 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-ASPECT' 'O' 'B-ASPECT']\n",
      "{0: 21.94744744744745, 1: 0.3725025484199796, 2: 3.705196451204056}\n",
      "Training results for google-bert/bert-base-german-cased with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4848' max='4848' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4848/4848 05:53, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.182900</td>\n",
       "      <td>0.774336</td>\n",
       "      <td>0.747863</td>\n",
       "      <td>0.760870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.227500</td>\n",
       "      <td>0.184631</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.792952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.100900</td>\n",
       "      <td>0.264567</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.811475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>0.325516</td>\n",
       "      <td>0.754167</td>\n",
       "      <td>0.773504</td>\n",
       "      <td>0.763713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.420455</td>\n",
       "      <td>0.793860</td>\n",
       "      <td>0.773504</td>\n",
       "      <td>0.783550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.018000</td>\n",
       "      <td>0.445054</td>\n",
       "      <td>0.799107</td>\n",
       "      <td>0.764957</td>\n",
       "      <td>0.781659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>0.478515</td>\n",
       "      <td>0.790393</td>\n",
       "      <td>0.773504</td>\n",
       "      <td>0.781857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.464537</td>\n",
       "      <td>0.787611</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.773913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.485570</td>\n",
       "      <td>0.801802</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.780702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.521621</td>\n",
       "      <td>0.776824</td>\n",
       "      <td>0.773504</td>\n",
       "      <td>0.775161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.504347</td>\n",
       "      <td>0.776824</td>\n",
       "      <td>0.773504</td>\n",
       "      <td>0.775161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.517838</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.774194</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4197.35 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.82      0.78      0.80       268\n",
      "\n",
      "   micro avg       0.82      0.78      0.80       268\n",
      "   macro avg       0.82      0.78      0.80       268\n",
      "weighted avg       0.82      0.78      0.80       268\n",
      "\n",
      "Precision Score: 0.8221343873517787\n",
      "Recall Score: 0.7761194029850746\n",
      "F1 Score: 0.7984644913627639\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/12_epochs/google-bert_bert-base-german-cased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/12_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5649.50 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4748.84 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-ASPECT' 'O' 'B-ASPECT']\n",
      "{0: 21.94744744744745, 1: 0.3725025484199796, 2: 3.705196451204056}\n",
      "Training results for dbmdz/bert-base-german-cased with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4848' max='4848' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4848/4848 05:53, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.175790</td>\n",
       "      <td>0.782805</td>\n",
       "      <td>0.758772</td>\n",
       "      <td>0.770601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.243900</td>\n",
       "      <td>0.185718</td>\n",
       "      <td>0.779661</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.793103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.123700</td>\n",
       "      <td>0.235898</td>\n",
       "      <td>0.757812</td>\n",
       "      <td>0.850877</td>\n",
       "      <td>0.801653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.049500</td>\n",
       "      <td>0.238581</td>\n",
       "      <td>0.750943</td>\n",
       "      <td>0.872807</td>\n",
       "      <td>0.807302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.031900</td>\n",
       "      <td>0.318879</td>\n",
       "      <td>0.729008</td>\n",
       "      <td>0.837719</td>\n",
       "      <td>0.779592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.031900</td>\n",
       "      <td>0.339503</td>\n",
       "      <td>0.804444</td>\n",
       "      <td>0.793860</td>\n",
       "      <td>0.799117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>0.394532</td>\n",
       "      <td>0.776860</td>\n",
       "      <td>0.824561</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>0.404207</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.811159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.404046</td>\n",
       "      <td>0.768595</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.791489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.424459</td>\n",
       "      <td>0.778243</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.796574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.436464</td>\n",
       "      <td>0.782979</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.794816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.427199</td>\n",
       "      <td>0.774590</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.800847</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4438.88 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.83      0.76      0.79       261\n",
      "\n",
      "   micro avg       0.83      0.76      0.79       261\n",
      "   macro avg       0.83      0.76      0.79       261\n",
      "weighted avg       0.83      0.76      0.79       261\n",
      "\n",
      "Precision Score: 0.8319327731092437\n",
      "Recall Score: 0.7586206896551724\n",
      "F1 Score: 0.7935871743486974\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/12_epochs/dbmdz_bert-base-german-cased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/12_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-uncased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5346.81 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4490.45 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-ASPECT' 'O' 'B-ASPECT']\n",
      "{0: 21.94744744744745, 1: 0.3725025484199796, 2: 3.705196451204056}\n",
      "Training results for dbmdz/bert-base-german-uncased with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4848' max='4848' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4848/4848 05:55, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.166190</td>\n",
       "      <td>0.764192</td>\n",
       "      <td>0.774336</td>\n",
       "      <td>0.769231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.230700</td>\n",
       "      <td>0.203475</td>\n",
       "      <td>0.796380</td>\n",
       "      <td>0.778761</td>\n",
       "      <td>0.787472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.115400</td>\n",
       "      <td>0.254972</td>\n",
       "      <td>0.776256</td>\n",
       "      <td>0.752212</td>\n",
       "      <td>0.764045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.041700</td>\n",
       "      <td>0.327320</td>\n",
       "      <td>0.770925</td>\n",
       "      <td>0.774336</td>\n",
       "      <td>0.772627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.026500</td>\n",
       "      <td>0.361629</td>\n",
       "      <td>0.747826</td>\n",
       "      <td>0.761062</td>\n",
       "      <td>0.754386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.026500</td>\n",
       "      <td>0.429090</td>\n",
       "      <td>0.789954</td>\n",
       "      <td>0.765487</td>\n",
       "      <td>0.777528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>0.473046</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.778761</td>\n",
       "      <td>0.755365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.474429</td>\n",
       "      <td>0.744589</td>\n",
       "      <td>0.761062</td>\n",
       "      <td>0.752735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.485442</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.752212</td>\n",
       "      <td>0.762332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.496603</td>\n",
       "      <td>0.744770</td>\n",
       "      <td>0.787611</td>\n",
       "      <td>0.765591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.485831</td>\n",
       "      <td>0.766520</td>\n",
       "      <td>0.769912</td>\n",
       "      <td>0.768212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.504105</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.769912</td>\n",
       "      <td>0.766520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4352.71 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.85      0.74      0.79       267\n",
      "\n",
      "   micro avg       0.85      0.74      0.79       267\n",
      "   macro avg       0.85      0.74      0.79       267\n",
      "weighted avg       0.85      0.74      0.79       267\n",
      "\n",
      "Precision Score: 0.8454935622317596\n",
      "Recall Score: 0.7378277153558053\n",
      "F1 Score: 0.7879999999999999\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/12_epochs/dbmdz_bert-base-german-uncased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/12_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for FacebookAI/xlm-roberta-base:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5691.39 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4650.21 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-ASPECT' 'O' 'B-ASPECT']\n",
      "{0: 21.94744744744745, 1: 0.3725025484199796, 2: 3.705196451204056}\n",
      "Training results for FacebookAI/xlm-roberta-base with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4848' max='4848' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4848/4848 09:53, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.181880</td>\n",
       "      <td>0.748276</td>\n",
       "      <td>0.834615</td>\n",
       "      <td>0.789091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.259400</td>\n",
       "      <td>0.228498</td>\n",
       "      <td>0.801653</td>\n",
       "      <td>0.746154</td>\n",
       "      <td>0.772908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.176600</td>\n",
       "      <td>0.188888</td>\n",
       "      <td>0.786765</td>\n",
       "      <td>0.823077</td>\n",
       "      <td>0.804511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.099200</td>\n",
       "      <td>0.212885</td>\n",
       "      <td>0.771626</td>\n",
       "      <td>0.857692</td>\n",
       "      <td>0.812386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.077300</td>\n",
       "      <td>0.248682</td>\n",
       "      <td>0.798587</td>\n",
       "      <td>0.869231</td>\n",
       "      <td>0.832413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.077300</td>\n",
       "      <td>0.285703</td>\n",
       "      <td>0.803704</td>\n",
       "      <td>0.834615</td>\n",
       "      <td>0.818868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.041800</td>\n",
       "      <td>0.303892</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.865385</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.029600</td>\n",
       "      <td>0.356714</td>\n",
       "      <td>0.821012</td>\n",
       "      <td>0.811538</td>\n",
       "      <td>0.816248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.019700</td>\n",
       "      <td>0.352624</td>\n",
       "      <td>0.801394</td>\n",
       "      <td>0.884615</td>\n",
       "      <td>0.840951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>0.358789</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.835821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>0.354702</td>\n",
       "      <td>0.810526</td>\n",
       "      <td>0.888462</td>\n",
       "      <td>0.847706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>0.356508</td>\n",
       "      <td>0.810526</td>\n",
       "      <td>0.888462</td>\n",
       "      <td>0.847706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4398.04 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.77      0.77      0.77       294\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       294\n",
      "   macro avg       0.77      0.77      0.77       294\n",
      "weighted avg       0.77      0.77      0.77       294\n",
      "\n",
      "Precision Score: 0.7713310580204779\n",
      "Recall Score: 0.7687074829931972\n",
      "F1 Score: 0.7700170357751277\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/12_epochs/FacebookAI_xlm-roberta-base_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/12_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_best:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6210.98 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4831.16 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-ASPECT' 'O' 'B-ASPECT']\n",
      "{0: 21.94744744744745, 1: 0.3725025484199796, 2: 3.705196451204056}\n",
      "Training results for TUM/GottBERT_base_best with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4848' max='4848' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4848/4848 06:24, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.332554</td>\n",
       "      <td>0.783217</td>\n",
       "      <td>0.602151</td>\n",
       "      <td>0.680851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.724700</td>\n",
       "      <td>0.197943</td>\n",
       "      <td>0.748691</td>\n",
       "      <td>0.768817</td>\n",
       "      <td>0.758621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.194500</td>\n",
       "      <td>0.208874</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.731183</td>\n",
       "      <td>0.768362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.091400</td>\n",
       "      <td>0.225158</td>\n",
       "      <td>0.753425</td>\n",
       "      <td>0.887097</td>\n",
       "      <td>0.814815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.056100</td>\n",
       "      <td>0.369419</td>\n",
       "      <td>0.739535</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.793017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.056100</td>\n",
       "      <td>0.378145</td>\n",
       "      <td>0.762376</td>\n",
       "      <td>0.827957</td>\n",
       "      <td>0.793814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.023800</td>\n",
       "      <td>0.362827</td>\n",
       "      <td>0.761421</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.783290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>0.486202</td>\n",
       "      <td>0.752475</td>\n",
       "      <td>0.817204</td>\n",
       "      <td>0.783505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.573122</td>\n",
       "      <td>0.761421</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.783290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.619228</td>\n",
       "      <td>0.772973</td>\n",
       "      <td>0.768817</td>\n",
       "      <td>0.770889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.599137</td>\n",
       "      <td>0.760204</td>\n",
       "      <td>0.801075</td>\n",
       "      <td>0.780105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.591393</td>\n",
       "      <td>0.752577</td>\n",
       "      <td>0.784946</td>\n",
       "      <td>0.768421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.decoder.weight', 'lm_head.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4612.21 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.80      0.78      0.79       229\n",
      "\n",
      "   micro avg       0.80      0.78      0.79       229\n",
      "   macro avg       0.80      0.78      0.79       229\n",
      "weighted avg       0.80      0.78      0.79       229\n",
      "\n",
      "Precision Score: 0.7982062780269058\n",
      "Recall Score: 0.777292576419214\n",
      "F1 Score: 0.7876106194690267\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/12_epochs/TUM_GottBERT_base_best_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/12_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_filtered_base_best:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6395.77 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4800.17 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-ASPECT' 'O' 'B-ASPECT']\n",
      "{0: 21.94744744744745, 1: 0.3725025484199796, 2: 3.705196451204056}\n",
      "Training results for TUM/GottBERT_filtered_base_best with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4848' max='4848' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4848/4848 06:22, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.270717</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.703704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.669800</td>\n",
       "      <td>0.189723</td>\n",
       "      <td>0.834254</td>\n",
       "      <td>0.811828</td>\n",
       "      <td>0.822888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.180500</td>\n",
       "      <td>0.222736</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.790323</td>\n",
       "      <td>0.798913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.092800</td>\n",
       "      <td>0.236305</td>\n",
       "      <td>0.725225</td>\n",
       "      <td>0.865591</td>\n",
       "      <td>0.789216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.052800</td>\n",
       "      <td>0.332976</td>\n",
       "      <td>0.746341</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.052800</td>\n",
       "      <td>0.426769</td>\n",
       "      <td>0.782828</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.807292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>0.473810</td>\n",
       "      <td>0.752475</td>\n",
       "      <td>0.817204</td>\n",
       "      <td>0.783505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.011400</td>\n",
       "      <td>0.509127</td>\n",
       "      <td>0.792553</td>\n",
       "      <td>0.801075</td>\n",
       "      <td>0.796791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>0.592428</td>\n",
       "      <td>0.789744</td>\n",
       "      <td>0.827957</td>\n",
       "      <td>0.808399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.611152</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.806452</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.636904</td>\n",
       "      <td>0.773869</td>\n",
       "      <td>0.827957</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.647092</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.827957</td>\n",
       "      <td>0.802083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.decoder.weight', 'lm_head.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4414.46 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.87      0.71      0.78       229\n",
      "\n",
      "   micro avg       0.87      0.71      0.78       229\n",
      "   macro avg       0.87      0.71      0.78       229\n",
      "weighted avg       0.87      0.71      0.78       229\n",
      "\n",
      "Precision Score: 0.8716577540106952\n",
      "Recall Score: 0.7117903930131004\n",
      "F1 Score: 0.7836538461538461\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/12_epochs/TUM_GottBERT_filtered_base_best_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/12_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_last:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at TUM/GottBERT_base_last were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of the model checkpoint at TUM/GottBERT_base_last were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6153.53 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4753.42 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-ASPECT' 'O' 'B-ASPECT']\n",
      "{0: 21.94744744744745, 1: 0.3725025484199796, 2: 3.705196451204056}\n",
      "Training results for TUM/GottBERT_base_last with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4848' max='4848' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4848/4848 06:24, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.250728</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.768817</td>\n",
       "      <td>0.750656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.739900</td>\n",
       "      <td>0.200275</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.779570</td>\n",
       "      <td>0.771277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.184100</td>\n",
       "      <td>0.231351</td>\n",
       "      <td>0.829412</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.792135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.086300</td>\n",
       "      <td>0.210530</td>\n",
       "      <td>0.731818</td>\n",
       "      <td>0.865591</td>\n",
       "      <td>0.793103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.052800</td>\n",
       "      <td>0.376041</td>\n",
       "      <td>0.734300</td>\n",
       "      <td>0.817204</td>\n",
       "      <td>0.773537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.052800</td>\n",
       "      <td>0.503252</td>\n",
       "      <td>0.741463</td>\n",
       "      <td>0.817204</td>\n",
       "      <td>0.777494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>0.455758</td>\n",
       "      <td>0.741463</td>\n",
       "      <td>0.817204</td>\n",
       "      <td>0.777494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.010100</td>\n",
       "      <td>0.561049</td>\n",
       "      <td>0.732673</td>\n",
       "      <td>0.795699</td>\n",
       "      <td>0.762887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.582488</td>\n",
       "      <td>0.748792</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.788804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.627763</td>\n",
       "      <td>0.770408</td>\n",
       "      <td>0.811828</td>\n",
       "      <td>0.790576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.002100</td>\n",
       "      <td>0.609565</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.822581</td>\n",
       "      <td>0.784615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.606185</td>\n",
       "      <td>0.751220</td>\n",
       "      <td>0.827957</td>\n",
       "      <td>0.787724</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.decoder.weight', 'lm_head.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4543.82 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.74      0.81      0.78       229\n",
      "\n",
      "   micro avg       0.74      0.81      0.78       229\n",
      "   macro avg       0.74      0.81      0.78       229\n",
      "weighted avg       0.74      0.81      0.78       229\n",
      "\n",
      "Precision Score: 0.744\n",
      "Recall Score: 0.8122270742358079\n",
      "F1 Score: 0.7766179540709811\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/12_epochs/TUM_GottBERT_base_last_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/12_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for distilbert/distilbert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6156.85 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5031.83 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-ASPECT' 'O' 'B-ASPECT']\n",
      "{0: 21.94744744744745, 1: 0.3725025484199796, 2: 3.705196451204056}\n",
      "Training results for distilbert/distilbert-base-german-cased with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4848' max='4848' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4848/4848 03:18, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.168544</td>\n",
       "      <td>0.753191</td>\n",
       "      <td>0.776316</td>\n",
       "      <td>0.764579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.260500</td>\n",
       "      <td>0.182833</td>\n",
       "      <td>0.787037</td>\n",
       "      <td>0.745614</td>\n",
       "      <td>0.765766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.127900</td>\n",
       "      <td>0.215014</td>\n",
       "      <td>0.767932</td>\n",
       "      <td>0.798246</td>\n",
       "      <td>0.782796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.059300</td>\n",
       "      <td>0.237890</td>\n",
       "      <td>0.816038</td>\n",
       "      <td>0.758772</td>\n",
       "      <td>0.786364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.039200</td>\n",
       "      <td>0.285450</td>\n",
       "      <td>0.742063</td>\n",
       "      <td>0.820175</td>\n",
       "      <td>0.779167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.039200</td>\n",
       "      <td>0.322810</td>\n",
       "      <td>0.772926</td>\n",
       "      <td>0.776316</td>\n",
       "      <td>0.774617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.017400</td>\n",
       "      <td>0.357822</td>\n",
       "      <td>0.744939</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.774737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>0.363007</td>\n",
       "      <td>0.787611</td>\n",
       "      <td>0.780702</td>\n",
       "      <td>0.784141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.367792</td>\n",
       "      <td>0.759036</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.792453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.377506</td>\n",
       "      <td>0.766949</td>\n",
       "      <td>0.793860</td>\n",
       "      <td>0.780172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.382109</td>\n",
       "      <td>0.778761</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.775330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.385964</td>\n",
       "      <td>0.783186</td>\n",
       "      <td>0.776316</td>\n",
       "      <td>0.779736</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4822.72 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.81      0.79      0.80       261\n",
      "\n",
      "   micro avg       0.81      0.79      0.80       261\n",
      "   macro avg       0.81      0.79      0.80       261\n",
      "weighted avg       0.81      0.79      0.80       261\n",
      "\n",
      "Precision Score: 0.8054474708171206\n",
      "Recall Score: 0.7931034482758621\n",
      "F1 Score: 0.7992277992277992\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/12_epochs/distilbert_distilbert-base-german-cased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/12_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for GerMedBERT/medbert-512:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5700.16 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4592.14 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-ASPECT' 'O' 'B-ASPECT']\n",
      "{0: 21.94744744744745, 1: 0.3725025484199796, 2: 3.705196451204056}\n",
      "Training results for GerMedBERT/medbert-512 with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4848' max='4848' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4848/4848 06:00, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.198532</td>\n",
       "      <td>0.757225</td>\n",
       "      <td>0.635922</td>\n",
       "      <td>0.691293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.036500</td>\n",
       "      <td>0.175390</td>\n",
       "      <td>0.776119</td>\n",
       "      <td>0.757282</td>\n",
       "      <td>0.766585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.193900</td>\n",
       "      <td>0.231344</td>\n",
       "      <td>0.765258</td>\n",
       "      <td>0.791262</td>\n",
       "      <td>0.778043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.080100</td>\n",
       "      <td>0.246968</td>\n",
       "      <td>0.731343</td>\n",
       "      <td>0.713592</td>\n",
       "      <td>0.722359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.049100</td>\n",
       "      <td>0.444121</td>\n",
       "      <td>0.731959</td>\n",
       "      <td>0.689320</td>\n",
       "      <td>0.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.049100</td>\n",
       "      <td>0.368511</td>\n",
       "      <td>0.731959</td>\n",
       "      <td>0.689320</td>\n",
       "      <td>0.710000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.024800</td>\n",
       "      <td>0.401871</td>\n",
       "      <td>0.725664</td>\n",
       "      <td>0.796117</td>\n",
       "      <td>0.759259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>0.468312</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.742718</td>\n",
       "      <td>0.740920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>0.482595</td>\n",
       "      <td>0.745000</td>\n",
       "      <td>0.723301</td>\n",
       "      <td>0.733990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.521337</td>\n",
       "      <td>0.766839</td>\n",
       "      <td>0.718447</td>\n",
       "      <td>0.741855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.541462</td>\n",
       "      <td>0.752475</td>\n",
       "      <td>0.737864</td>\n",
       "      <td>0.745098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.542736</td>\n",
       "      <td>0.752525</td>\n",
       "      <td>0.723301</td>\n",
       "      <td>0.737624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4229.13 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.76      0.74      0.75       234\n",
      "\n",
      "   micro avg       0.76      0.74      0.75       234\n",
      "   macro avg       0.76      0.74      0.75       234\n",
      "weighted avg       0.76      0.74      0.75       234\n",
      "\n",
      "Precision Score: 0.7577092511013216\n",
      "Recall Score: 0.7350427350427351\n",
      "F1 Score: 0.7462039045553145\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/12_epochs/GerMedBERT_medbert-512_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/12_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for deepset/gbert-base:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5754.61 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4603.32 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_v2.py:416: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-ASPECT' 'O' 'B-ASPECT']\n",
      "{0: 21.94744744744745, 1: 0.3725025484199796, 2: 3.705196451204056}\n",
      "Training results for deepset/gbert-base with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4848' max='4848' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4848/4848 06:01, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.243553</td>\n",
       "      <td>0.742489</td>\n",
       "      <td>0.758772</td>\n",
       "      <td>0.750542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.612200</td>\n",
       "      <td>0.226384</td>\n",
       "      <td>0.753138</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.770878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.178900</td>\n",
       "      <td>0.259738</td>\n",
       "      <td>0.780172</td>\n",
       "      <td>0.793860</td>\n",
       "      <td>0.786957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.071500</td>\n",
       "      <td>0.279910</td>\n",
       "      <td>0.797414</td>\n",
       "      <td>0.811404</td>\n",
       "      <td>0.804348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.049100</td>\n",
       "      <td>0.356831</td>\n",
       "      <td>0.784232</td>\n",
       "      <td>0.828947</td>\n",
       "      <td>0.805970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.049100</td>\n",
       "      <td>0.445217</td>\n",
       "      <td>0.807339</td>\n",
       "      <td>0.771930</td>\n",
       "      <td>0.789238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.017000</td>\n",
       "      <td>0.477910</td>\n",
       "      <td>0.781893</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.806794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>0.492423</td>\n",
       "      <td>0.809955</td>\n",
       "      <td>0.785088</td>\n",
       "      <td>0.797327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>0.541927</td>\n",
       "      <td>0.806867</td>\n",
       "      <td>0.824561</td>\n",
       "      <td>0.815618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.550221</td>\n",
       "      <td>0.773279</td>\n",
       "      <td>0.837719</td>\n",
       "      <td>0.804211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.589599</td>\n",
       "      <td>0.778689</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.805085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.590759</td>\n",
       "      <td>0.798319</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.815451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4383.53 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1, 2}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.86      0.75      0.80       261\n",
      "\n",
      "   micro avg       0.86      0.75      0.80       261\n",
      "   macro avg       0.86      0.75      0.80       261\n",
      "weighted avg       0.86      0.75      0.80       261\n",
      "\n",
      "Precision Score: 0.8558951965065502\n",
      "Recall Score: 0.7509578544061303\n",
      "F1 Score: 0.8\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/12_epochs/deepset_gbert-base_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/12_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(f'training and results for {model}:')\n",
    "    ate_model(data, model, rn1=42, rn2=42, epochs=12)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c288ffeb-8c03-48a5-84b6-4a2ce22c7508",
   "metadata": {},
   "source": [
    "### 2. category-aware ATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b2885df7-6714-4e0e-923f-b40ffbfed98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training and results for google-bert/bert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 575/575 [00:00<00:00, 5833.23 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:00<00:00, 3904.81 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/model_train_v2.py:669: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-anderer Service' 'B-anderer Service' 'B-mediz. Service' 'I-Personal'\n",
      " 'O' 'I-Pflegepersonal' 'B-Krankenhaus' 'B-Arzt' 'I-mediz. Service'\n",
      " 'I-Arzt' 'B-Pflegepersonal' 'B-Personal' 'I-Krankenhaus']\n",
      "{0: np.float64(78.56153846153846), 1: np.float64(5.651909241837299), 2: np.float64(2.846432552954292), 3: np.float64(71.41958041958041), 4: np.float64(0.08550450420280634), 5: np.float64(261.87179487179486), 6: np.float64(3.9280769230769232), 7: np.float64(5.493813878429263), 8: np.float64(23.806526806526808), 9: np.float64(18.705128205128204), 10: np.float64(9.465245597775718), 11: np.float64(13.545092838196286), 12: np.float64(29.096866096866098)}\n",
      "Training google-bert/bert-base-german-cased for 5 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1440' max='1440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1440/1440 01:49, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.328237</td>\n",
       "      <td>0.637584</td>\n",
       "      <td>0.519126</td>\n",
       "      <td>0.572289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.371000</td>\n",
       "      <td>0.357443</td>\n",
       "      <td>0.669014</td>\n",
       "      <td>0.519126</td>\n",
       "      <td>0.584615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.371000</td>\n",
       "      <td>0.468612</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.650273</td>\n",
       "      <td>0.589109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.110700</td>\n",
       "      <td>0.480588</td>\n",
       "      <td>0.649425</td>\n",
       "      <td>0.617486</td>\n",
       "      <td>0.633053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.110700</td>\n",
       "      <td>0.508611</td>\n",
       "      <td>0.623596</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.614958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:00<00:00, 3490.81 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {np.int64(0), np.int64(3), np.int64(5), np.int64(6), np.int64(7), np.int64(9), np.int64(11), np.int64(13)}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.55      0.41      0.47        29\n",
      "    Krankenhaus       0.68      0.74      0.71        43\n",
      "       Personal       0.71      0.71      0.71         7\n",
      " Pflegepersonal       1.00      0.90      0.95        10\n",
      "anderer Service       0.45      0.28      0.34        18\n",
      " mediz. Service       0.71      0.65      0.68        37\n",
      "\n",
      "      micro avg       0.67      0.60      0.64       144\n",
      "      macro avg       0.68      0.62      0.64       144\n",
      "   weighted avg       0.66      0.60      0.62       144\n",
      "\n",
      "Precision Score: 0.6692307692307692\n",
      "Recall Score: 0.6041666666666666\n",
      "F1 Score: 0.635036496350365\n",
      "Tokens     : ['Ich', 'habe', 'jeden', 'Tag', 'die', 'StationsÃ¤rztin', 'gesehen', ',', 'hier', 'nochmal', 'vielen', 'Dank', 'fÃ¼r', 'die', 'Geduld', 'und', 'die', 'fachliche', 'Betreuung', 'und', 'die', 'Empathie', 'die', 'mir', 'entgegengebracht', 'wurde', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'B-Arzt', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'B-anderer Service', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Ich', 'bin', 'seit', 'Juni', '2023', 'in', 'der', 'Uni', 'in', 'Behandlung', 'wegen', 'Brustkrebs', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Krankenhaus', 'O', 'B-mediz. Service', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Krankenhaus', 'O', 'B-mediz. Service', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate_cat/5_epochs/google-bert_bert-base-german-cased_ate_cat_test_results.txt\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 575/575 [00:00<00:00, 5665.46 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:00<00:00, 3112.17 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/model_train_v2.py:669: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-anderer Service' 'B-anderer Service' 'B-mediz. Service' 'I-Personal'\n",
      " 'O' 'I-Pflegepersonal' 'B-Krankenhaus' 'B-Arzt' 'I-mediz. Service'\n",
      " 'I-Arzt' 'B-Pflegepersonal' 'B-Personal' 'I-Krankenhaus']\n",
      "{0: np.float64(78.56153846153846), 1: np.float64(5.651909241837299), 2: np.float64(2.846432552954292), 3: np.float64(71.41958041958041), 4: np.float64(0.08550450420280634), 5: np.float64(261.87179487179486), 6: np.float64(3.9280769230769232), 7: np.float64(5.493813878429263), 8: np.float64(23.806526806526808), 9: np.float64(18.705128205128204), 10: np.float64(9.465245597775718), 11: np.float64(13.545092838196286), 12: np.float64(29.096866096866098)}\n",
      "Training dbmdz/bert-base-german-cased for 5 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1440' max='1440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1440/1440 01:54, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.335056</td>\n",
       "      <td>0.593750</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.574018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.351706</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.543860</td>\n",
       "      <td>0.596154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.405000</td>\n",
       "      <td>0.416945</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.595041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.134700</td>\n",
       "      <td>0.443570</td>\n",
       "      <td>0.593220</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.603448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.134700</td>\n",
       "      <td>0.471154</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.583333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:00<00:00, 3845.58 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {np.int64(0), np.int64(3), np.int64(5), np.int64(6), np.int64(7), np.int64(9), np.int64(11), np.int64(13)}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.57      0.55      0.56        31\n",
      "    Krankenhaus       0.74      0.69      0.72        42\n",
      "       Personal       0.44      0.50      0.47         8\n",
      " Pflegepersonal       1.00      0.90      0.95        10\n",
      "anderer Service       0.29      0.28      0.29        18\n",
      " mediz. Service       0.70      0.55      0.62        38\n",
      "\n",
      "      micro avg       0.63      0.58      0.60       147\n",
      "      macro avg       0.62      0.58      0.60       147\n",
      "   weighted avg       0.64      0.58      0.61       147\n",
      "\n",
      "Precision Score: 0.6343283582089553\n",
      "Recall Score: 0.5782312925170068\n",
      "F1 Score: 0.6049822064056939\n",
      "Tokens     : ['Ich', 'habe', 'jeden', 'Tag', 'die', 'StationsÃ¤rztin', 'gesehen', ',', 'hier', 'nochmal', 'vielen', 'Dank', 'fÃ¼r', 'die', 'Geduld', 'und', 'die', 'fachliche', 'Betreuung', 'und', 'die', 'Empathie', 'die', 'mir', 'entgegengebracht', 'wurde', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'B-Arzt', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'B-anderer Service', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'B-Personal', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Ich', 'bin', 'seit', 'Juni', '2023', 'in', 'der', 'Uni', 'in', 'Behandlung', 'wegen', 'Brustkrebs', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Krankenhaus', 'O', 'B-mediz. Service', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate_cat/5_epochs/dbmdz_bert-base-german-cased_ate_cat_test_results.txt\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-uncased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 575/575 [00:00<00:00, 5601.87 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:00<00:00, 3921.03 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/model_train_v2.py:669: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-anderer Service' 'B-anderer Service' 'B-mediz. Service' 'I-Personal'\n",
      " 'O' 'I-Pflegepersonal' 'B-Krankenhaus' 'B-Arzt' 'I-mediz. Service'\n",
      " 'I-Arzt' 'B-Pflegepersonal' 'B-Personal' 'I-Krankenhaus']\n",
      "{0: np.float64(78.56153846153846), 1: np.float64(5.651909241837299), 2: np.float64(2.846432552954292), 3: np.float64(71.41958041958041), 4: np.float64(0.08550450420280634), 5: np.float64(261.87179487179486), 6: np.float64(3.9280769230769232), 7: np.float64(5.493813878429263), 8: np.float64(23.806526806526808), 9: np.float64(18.705128205128204), 10: np.float64(9.465245597775718), 11: np.float64(13.545092838196286), 12: np.float64(29.096866096866098)}\n",
      "Training dbmdz/bert-base-german-uncased for 5 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1440' max='1440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1440/1440 01:50, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.326593</td>\n",
       "      <td>0.654135</td>\n",
       "      <td>0.520958</td>\n",
       "      <td>0.580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.347663</td>\n",
       "      <td>0.643939</td>\n",
       "      <td>0.508982</td>\n",
       "      <td>0.568562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.469372</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>0.586826</td>\n",
       "      <td>0.501279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.130200</td>\n",
       "      <td>0.462696</td>\n",
       "      <td>0.589404</td>\n",
       "      <td>0.532934</td>\n",
       "      <td>0.559748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.130200</td>\n",
       "      <td>0.480155</td>\n",
       "      <td>0.545977</td>\n",
       "      <td>0.568862</td>\n",
       "      <td>0.557185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:00<00:00, 3784.24 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {np.int64(0), np.int64(3), np.int64(5), np.int64(6), np.int64(7), np.int64(9), np.int64(11), np.int64(13)}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.54      0.74      0.62        34\n",
      "    Krankenhaus       0.75      0.57      0.65        42\n",
      "       Personal       0.67      0.25      0.36         8\n",
      " Pflegepersonal       1.00      0.88      0.93         8\n",
      "anderer Service       1.00      0.06      0.12        16\n",
      " mediz. Service       0.72      0.54      0.62        39\n",
      "\n",
      "      micro avg       0.68      0.54      0.60       147\n",
      "      macro avg       0.78      0.51      0.55       147\n",
      "   weighted avg       0.73      0.54      0.58       147\n",
      "\n",
      "Precision Score: 0.6779661016949152\n",
      "Recall Score: 0.54421768707483\n",
      "F1 Score: 0.6037735849056604\n",
      "Tokens     : ['Ich', 'habe', 'jeden', 'Tag', 'die', 'StationsÃ¤rztin', 'gesehen', ',', 'hier', 'nochmal', 'vielen', 'Dank', 'fÃ¼r', 'die', 'Geduld', 'und', 'die', 'fachliche', 'Betreuung', 'und', 'die', 'Empathie', 'die', 'mir', 'entgegengebracht', 'wurde', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'B-Arzt', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'B-anderer Service', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'B-Arzt', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Ich', 'bin', 'seit', 'Juni', '2023', 'in', 'der', 'Uni', 'in', 'Behandlung', 'wegen', 'Brustkrebs', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Krankenhaus', 'O', 'B-mediz. Service', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate_cat/5_epochs/dbmdz_bert-base-german-uncased_ate_cat_test_results.txt\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for FacebookAI/xlm-roberta-base:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 575/575 [00:00<00:00, 5774.19 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:00<00:00, 3593.32 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/model_train_v2.py:669: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-anderer Service' 'B-anderer Service' 'B-mediz. Service' 'I-Personal'\n",
      " 'O' 'I-Pflegepersonal' 'B-Krankenhaus' 'B-Arzt' 'I-mediz. Service'\n",
      " 'I-Arzt' 'B-Pflegepersonal' 'B-Personal' 'I-Krankenhaus']\n",
      "{0: np.float64(78.56153846153846), 1: np.float64(5.651909241837299), 2: np.float64(2.846432552954292), 3: np.float64(71.41958041958041), 4: np.float64(0.08550450420280634), 5: np.float64(261.87179487179486), 6: np.float64(3.9280769230769232), 7: np.float64(5.493813878429263), 8: np.float64(23.806526806526808), 9: np.float64(18.705128205128204), 10: np.float64(9.465245597775718), 11: np.float64(13.545092838196286), 12: np.float64(29.096866096866098)}\n",
      "Training FacebookAI/xlm-roberta-base for 5 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1440' max='1440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1440/1440 02:59, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.428879</td>\n",
       "      <td>0.460870</td>\n",
       "      <td>0.258537</td>\n",
       "      <td>0.331250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.488600</td>\n",
       "      <td>0.343836</td>\n",
       "      <td>0.655405</td>\n",
       "      <td>0.473171</td>\n",
       "      <td>0.549575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.488600</td>\n",
       "      <td>0.387170</td>\n",
       "      <td>0.589862</td>\n",
       "      <td>0.624390</td>\n",
       "      <td>0.606635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.226100</td>\n",
       "      <td>0.431481</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.604878</td>\n",
       "      <td>0.606357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.226100</td>\n",
       "      <td>0.454515</td>\n",
       "      <td>0.606635</td>\n",
       "      <td>0.624390</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:00<00:00, 4174.53 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {np.int64(0), np.int64(3), np.int64(5), np.int64(6), np.int64(7), np.int64(9), np.int64(11), np.int64(13)}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.62      0.69      0.66        36\n",
      "    Krankenhaus       0.73      0.73      0.73        45\n",
      "       Personal       0.75      0.55      0.63        11\n",
      " Pflegepersonal       0.85      0.92      0.88        12\n",
      "anderer Service       0.53      0.41      0.46        22\n",
      " mediz. Service       0.80      0.66      0.73        50\n",
      "\n",
      "      micro avg       0.71      0.66      0.69       176\n",
      "      macro avg       0.71      0.66      0.68       176\n",
      "   weighted avg       0.71      0.66      0.69       176\n",
      "\n",
      "Precision Score: 0.7134146341463414\n",
      "Recall Score: 0.6647727272727273\n",
      "F1 Score: 0.6882352941176471\n",
      "Tokens     : ['Ich', 'habe', 'jeden', 'Tag', 'die', 'StationsÃ¤rztin', 'gesehen', ',', 'hier', 'nochmal', 'vielen', 'Dank', 'fÃ¼r', 'die', 'Geduld', 'und', 'die', 'fachliche', 'Betreuung', 'und', 'die', 'Empathie', 'die', 'mir', 'entgegengebracht', 'wurde', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'B-Arzt', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'B-anderer Service', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'B-Arzt', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Ich', 'bin', 'seit', 'Juni', '2023', 'in', 'der', 'Uni', 'in', 'Behandlung', 'wegen', 'Brustkrebs', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Krankenhaus', 'O', 'B-mediz. Service', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Krankenhaus', 'O', 'B-mediz. Service', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate_cat/5_epochs/FacebookAI_xlm-roberta-base_ate_cat_test_results.txt\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_best:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 575/575 [00:00<00:00, 6020.67 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:00<00:00, 3779.13 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/model_train_v2.py:669: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-anderer Service' 'B-anderer Service' 'B-mediz. Service' 'I-Personal'\n",
      " 'O' 'I-Pflegepersonal' 'B-Krankenhaus' 'B-Arzt' 'I-mediz. Service'\n",
      " 'I-Arzt' 'B-Pflegepersonal' 'B-Personal' 'I-Krankenhaus']\n",
      "{0: np.float64(78.56153846153846), 1: np.float64(5.651909241837299), 2: np.float64(2.846432552954292), 3: np.float64(71.41958041958041), 4: np.float64(0.08550450420280634), 5: np.float64(261.87179487179486), 6: np.float64(3.9280769230769232), 7: np.float64(5.493813878429263), 8: np.float64(23.806526806526808), 9: np.float64(18.705128205128204), 10: np.float64(9.465245597775718), 11: np.float64(13.545092838196286), 12: np.float64(29.096866096866098)}\n",
      "Training TUM/GottBERT_base_best for 5 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1440' max='1440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1440/1440 02:03, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.424025</td>\n",
       "      <td>0.493750</td>\n",
       "      <td>0.519737</td>\n",
       "      <td>0.506410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.740200</td>\n",
       "      <td>0.319288</td>\n",
       "      <td>0.602837</td>\n",
       "      <td>0.559211</td>\n",
       "      <td>0.580205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.740200</td>\n",
       "      <td>0.421500</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.651316</td>\n",
       "      <td>0.613003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.211400</td>\n",
       "      <td>0.535966</td>\n",
       "      <td>0.593333</td>\n",
       "      <td>0.585526</td>\n",
       "      <td>0.589404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.211400</td>\n",
       "      <td>0.613212</td>\n",
       "      <td>0.622517</td>\n",
       "      <td>0.618421</td>\n",
       "      <td>0.620462</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.decoder.weight', 'lm_head.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:00<00:00, 4262.14 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Unexpected prediction 206 found. Assigning 'O'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O_missing seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {np.int64(0), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(9), np.int64(11), np.int64(13), np.int64(206)}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
      "Warning: Unexpected prediction 206 found. Assigning 'O_missing'.\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.62      0.64      0.63        25\n",
      "    Krankenhaus       0.74      0.61      0.67        41\n",
      "       Personal       0.67      0.57      0.62         7\n",
      " Pflegepersonal       0.58      0.88      0.70         8\n",
      "anderer Service       0.23      0.27      0.25        11\n",
      " mediz. Service       0.71      0.67      0.69        30\n",
      "\n",
      "      micro avg       0.63      0.61      0.62       122\n",
      "      macro avg       0.59      0.61      0.59       122\n",
      "   weighted avg       0.65      0.61      0.63       122\n",
      "\n",
      "Precision Score: 0.6302521008403361\n",
      "Recall Score: 0.6147540983606558\n",
      "F1 Score: 0.6224066390041495\n",
      "Tokens     : ['Ich', 'habe', 'jeden', 'Tag', 'die', 'StationsÃ¤rztin', 'gesehen', ',', 'hier', 'nochmal', 'vielen', 'Dank', 'fÃ¼r', 'die', 'Geduld', 'und', 'die', 'fachliche', 'Betreuung', 'und', 'die', 'Empathie', 'die', 'mir', 'entgegengebracht', 'wurde', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'B-Arzt', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'B-anderer Service', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'B-Arzt', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Ich', 'bin', 'seit', 'Juni', '2023', 'in', 'der', 'Uni', 'in', 'Behandlung', 'wegen', 'Brustkrebs', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Krankenhaus', 'O', 'B-mediz. Service', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Krankenhaus', 'O', 'B-mediz. Service', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate_cat/5_epochs/TUM_GottBERT_base_best_ate_cat_test_results.txt\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_filtered_base_best:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 575/575 [00:00<00:00, 6059.64 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:00<00:00, 3994.31 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/model_train_v2.py:669: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-anderer Service' 'B-anderer Service' 'B-mediz. Service' 'I-Personal'\n",
      " 'O' 'I-Pflegepersonal' 'B-Krankenhaus' 'B-Arzt' 'I-mediz. Service'\n",
      " 'I-Arzt' 'B-Pflegepersonal' 'B-Personal' 'I-Krankenhaus']\n",
      "{0: np.float64(78.56153846153846), 1: np.float64(5.651909241837299), 2: np.float64(2.846432552954292), 3: np.float64(71.41958041958041), 4: np.float64(0.08550450420280634), 5: np.float64(261.87179487179486), 6: np.float64(3.9280769230769232), 7: np.float64(5.493813878429263), 8: np.float64(23.806526806526808), 9: np.float64(18.705128205128204), 10: np.float64(9.465245597775718), 11: np.float64(13.545092838196286), 12: np.float64(29.096866096866098)}\n",
      "Training TUM/GottBERT_filtered_base_best for 5 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1440' max='1440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1440/1440 02:00, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.392108</td>\n",
       "      <td>0.585106</td>\n",
       "      <td>0.361842</td>\n",
       "      <td>0.447154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.594000</td>\n",
       "      <td>0.394694</td>\n",
       "      <td>0.569620</td>\n",
       "      <td>0.592105</td>\n",
       "      <td>0.580645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.594000</td>\n",
       "      <td>0.534113</td>\n",
       "      <td>0.598485</td>\n",
       "      <td>0.519737</td>\n",
       "      <td>0.556338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.168300</td>\n",
       "      <td>0.573898</td>\n",
       "      <td>0.618705</td>\n",
       "      <td>0.565789</td>\n",
       "      <td>0.591065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.168300</td>\n",
       "      <td>0.653187</td>\n",
       "      <td>0.601266</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.612903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Unexpected prediction 360 found. Assigning 'O'.\n",
      "Warning: Unexpected prediction 1081 found. Assigning 'O'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.decoder.weight', 'lm_head.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:00<00:00, 4256.08 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {np.int64(0), np.int64(3), np.int64(5), np.int64(6), np.int64(7), np.int64(9), np.int64(10), np.int64(11), np.int64(13)}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.65      0.52      0.58        25\n",
      "    Krankenhaus       0.70      0.73      0.71        41\n",
      "       Personal       0.50      0.71      0.59         7\n",
      " Pflegepersonal       1.00      0.88      0.93         8\n",
      "anderer Service       0.38      0.27      0.32        11\n",
      " mediz. Service       0.57      0.40      0.47        30\n",
      "\n",
      "      micro avg       0.64      0.57      0.61       122\n",
      "      macro avg       0.63      0.59      0.60       122\n",
      "   weighted avg       0.64      0.57      0.60       122\n",
      "\n",
      "Precision Score: 0.6422018348623854\n",
      "Recall Score: 0.5737704918032787\n",
      "F1 Score: 0.606060606060606\n",
      "Tokens     : ['Ich', 'habe', 'jeden', 'Tag', 'die', 'StationsÃ¤rztin', 'gesehen', ',', 'hier', 'nochmal', 'vielen', 'Dank', 'fÃ¼r', 'die', 'Geduld', 'und', 'die', 'fachliche', 'Betreuung', 'und', 'die', 'Empathie', 'die', 'mir', 'entgegengebracht', 'wurde', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'B-Arzt', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'B-anderer Service', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'B-Personal', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Ich', 'bin', 'seit', 'Juni', '2023', 'in', 'der', 'Uni', 'in', 'Behandlung', 'wegen', 'Brustkrebs', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Krankenhaus', 'O', 'B-mediz. Service', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Krankenhaus', 'O', 'B-Krankenhaus', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate_cat/5_epochs/TUM_GottBERT_filtered_base_best_ate_cat_test_results.txt\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_last:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at TUM/GottBERT_base_last were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of the model checkpoint at TUM/GottBERT_base_last were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 575/575 [00:00<00:00, 6155.12 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:00<00:00, 4056.99 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/model_train_v2.py:669: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-anderer Service' 'B-anderer Service' 'B-mediz. Service' 'I-Personal'\n",
      " 'O' 'I-Pflegepersonal' 'B-Krankenhaus' 'B-Arzt' 'I-mediz. Service'\n",
      " 'I-Arzt' 'B-Pflegepersonal' 'B-Personal' 'I-Krankenhaus']\n",
      "{0: np.float64(78.56153846153846), 1: np.float64(5.651909241837299), 2: np.float64(2.846432552954292), 3: np.float64(71.41958041958041), 4: np.float64(0.08550450420280634), 5: np.float64(261.87179487179486), 6: np.float64(3.9280769230769232), 7: np.float64(5.493813878429263), 8: np.float64(23.806526806526808), 9: np.float64(18.705128205128204), 10: np.float64(9.465245597775718), 11: np.float64(13.545092838196286), 12: np.float64(29.096866096866098)}\n",
      "Training TUM/GottBERT_base_last for 5 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1440' max='1440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1440/1440 02:03, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.415237</td>\n",
       "      <td>0.517986</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.494845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.730100</td>\n",
       "      <td>0.390912</td>\n",
       "      <td>0.631944</td>\n",
       "      <td>0.598684</td>\n",
       "      <td>0.614865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.730100</td>\n",
       "      <td>0.459400</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.575342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.169100</td>\n",
       "      <td>0.669077</td>\n",
       "      <td>0.634483</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.619529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.169100</td>\n",
       "      <td>0.769484</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.602740</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Unexpected prediction 240 found. Assigning 'O'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.decoder.weight', 'lm_head.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:00<00:00, 4354.14 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {np.int64(0), np.int64(2), np.int64(3), np.int64(5), np.int64(6), np.int64(7), np.int64(9), np.int64(11), np.int64(13)}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.65      0.60      0.63        25\n",
      "    Krankenhaus       0.76      0.63      0.69        41\n",
      "       Personal       0.67      0.57      0.62         7\n",
      " Pflegepersonal       0.88      0.88      0.88         8\n",
      "anderer Service       0.17      0.27      0.21        11\n",
      " mediz. Service       0.70      0.53      0.60        30\n",
      "\n",
      "      micro avg       0.63      0.58      0.61       122\n",
      "      macro avg       0.64      0.58      0.60       122\n",
      "   weighted avg       0.67      0.58      0.62       122\n",
      "\n",
      "Precision Score: 0.6339285714285714\n",
      "Recall Score: 0.5819672131147541\n",
      "F1 Score: 0.6068376068376068\n",
      "Tokens     : ['Ich', 'habe', 'jeden', 'Tag', 'die', 'StationsÃ¤rztin', 'gesehen', ',', 'hier', 'nochmal', 'vielen', 'Dank', 'fÃ¼r', 'die', 'Geduld', 'und', 'die', 'fachliche', 'Betreuung', 'und', 'die', 'Empathie', 'die', 'mir', 'entgegengebracht', 'wurde', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'B-Arzt', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'B-anderer Service', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'B-Arzt', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Ich', 'bin', 'seit', 'Juni', '2023', 'in', 'der', 'Uni', 'in', 'Behandlung', 'wegen', 'Brustkrebs', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Krankenhaus', 'O', 'B-mediz. Service', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate_cat/5_epochs/TUM_GottBERT_base_last_ate_cat_test_results.txt\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for distilbert/distilbert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 575/575 [00:00<00:00, 6735.97 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:00<00:00, 4313.46 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/model_train_v2.py:669: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-anderer Service' 'B-anderer Service' 'B-mediz. Service' 'I-Personal'\n",
      " 'O' 'I-Pflegepersonal' 'B-Krankenhaus' 'B-Arzt' 'I-mediz. Service'\n",
      " 'I-Arzt' 'B-Pflegepersonal' 'B-Personal' 'I-Krankenhaus']\n",
      "{0: np.float64(78.56153846153846), 1: np.float64(5.651909241837299), 2: np.float64(2.846432552954292), 3: np.float64(71.41958041958041), 4: np.float64(0.08550450420280634), 5: np.float64(261.87179487179486), 6: np.float64(3.9280769230769232), 7: np.float64(5.493813878429263), 8: np.float64(23.806526806526808), 9: np.float64(18.705128205128204), 10: np.float64(9.465245597775718), 11: np.float64(13.545092838196286), 12: np.float64(29.096866096866098)}\n",
      "Training distilbert/distilbert-base-german-cased for 5 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1440' max='1440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1440/1440 01:03, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.382121</td>\n",
       "      <td>0.544776</td>\n",
       "      <td>0.426901</td>\n",
       "      <td>0.478689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.478400</td>\n",
       "      <td>0.327016</td>\n",
       "      <td>0.573333</td>\n",
       "      <td>0.502924</td>\n",
       "      <td>0.535826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.478400</td>\n",
       "      <td>0.360440</td>\n",
       "      <td>0.495000</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.533693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.178900</td>\n",
       "      <td>0.386078</td>\n",
       "      <td>0.524590</td>\n",
       "      <td>0.561404</td>\n",
       "      <td>0.542373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.178900</td>\n",
       "      <td>0.389224</td>\n",
       "      <td>0.513966</td>\n",
       "      <td>0.538012</td>\n",
       "      <td>0.525714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:00<00:00, 3965.05 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {np.int64(0), np.int64(3), np.int64(5), np.int64(6), np.int64(7), np.int64(9), np.int64(11), np.int64(13)}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.55      0.52      0.53        31\n",
      "    Krankenhaus       0.72      0.67      0.69        42\n",
      "       Personal       0.67      0.50      0.57         8\n",
      " Pflegepersonal       0.82      0.90      0.86        10\n",
      "anderer Service       0.29      0.11      0.16        18\n",
      " mediz. Service       0.65      0.58      0.61        38\n",
      "\n",
      "      micro avg       0.64      0.55      0.59       147\n",
      "      macro avg       0.61      0.55      0.57       147\n",
      "   weighted avg       0.62      0.55      0.58       147\n",
      "\n",
      "Precision Score: 0.6428571428571429\n",
      "Recall Score: 0.5510204081632653\n",
      "F1 Score: 0.5934065934065934\n",
      "Tokens     : ['Ich', 'habe', 'jeden', 'Tag', 'die', 'StationsÃ¤rztin', 'gesehen', ',', 'hier', 'nochmal', 'vielen', 'Dank', 'fÃ¼r', 'die', 'Geduld', 'und', 'die', 'fachliche', 'Betreuung', 'und', 'die', 'Empathie', 'die', 'mir', 'entgegengebracht', 'wurde', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'B-Arzt', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'B-anderer Service', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Ich', 'bin', 'seit', 'Juni', '2023', 'in', 'der', 'Uni', 'in', 'Behandlung', 'wegen', 'Brustkrebs', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Krankenhaus', 'O', 'B-mediz. Service', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'B-mediz. Service', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate_cat/5_epochs/distilbert_distilbert-base-german-cased_ate_cat_test_results.txt\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for GerMedBERT/medbert-512:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 575/575 [00:00<00:00, 5948.59 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:00<00:00, 3898.50 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/model_train_v2.py:669: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-anderer Service' 'B-anderer Service' 'B-mediz. Service' 'I-Personal'\n",
      " 'O' 'I-Pflegepersonal' 'B-Krankenhaus' 'B-Arzt' 'I-mediz. Service'\n",
      " 'I-Arzt' 'B-Pflegepersonal' 'B-Personal' 'I-Krankenhaus']\n",
      "{0: np.float64(78.56153846153846), 1: np.float64(5.651909241837299), 2: np.float64(2.846432552954292), 3: np.float64(71.41958041958041), 4: np.float64(0.08550450420280634), 5: np.float64(261.87179487179486), 6: np.float64(3.9280769230769232), 7: np.float64(5.493813878429263), 8: np.float64(23.806526806526808), 9: np.float64(18.705128205128204), 10: np.float64(9.465245597775718), 11: np.float64(13.545092838196286), 12: np.float64(29.096866096866098)}\n",
      "Training GerMedBERT/medbert-512 for 5 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1440' max='1440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1440/1440 01:53, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.564667</td>\n",
       "      <td>0.338983</td>\n",
       "      <td>0.372671</td>\n",
       "      <td>0.355030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.451800</td>\n",
       "      <td>0.410399</td>\n",
       "      <td>0.564885</td>\n",
       "      <td>0.459627</td>\n",
       "      <td>0.506849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.451800</td>\n",
       "      <td>0.458173</td>\n",
       "      <td>0.502703</td>\n",
       "      <td>0.577640</td>\n",
       "      <td>0.537572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.205300</td>\n",
       "      <td>0.514803</td>\n",
       "      <td>0.662162</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.634304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.205300</td>\n",
       "      <td>0.548273</td>\n",
       "      <td>0.616352</td>\n",
       "      <td>0.608696</td>\n",
       "      <td>0.612500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:00<00:00, 4009.85 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {np.int64(0), np.int64(3), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(11), np.int64(13)}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.52      0.58      0.55        24\n",
      "    Krankenhaus       0.86      0.80      0.83        45\n",
      "       Personal       0.67      0.75      0.71         8\n",
      " Pflegepersonal       0.91      0.91      0.91        11\n",
      "anderer Service       0.33      0.38      0.35        16\n",
      " mediz. Service       0.56      0.32      0.41        31\n",
      "\n",
      "      micro avg       0.66      0.61      0.63       135\n",
      "      macro avg       0.64      0.62      0.63       135\n",
      "   weighted avg       0.66      0.61      0.62       135\n",
      "\n",
      "Precision Score: 0.656\n",
      "Recall Score: 0.6074074074074074\n",
      "F1 Score: 0.6307692307692309\n",
      "Tokens     : ['Ich', 'habe', 'jeden', 'Tag', 'die', 'StationsÃ¤rztin', 'gesehen', ',', 'hier', 'nochmal', 'vielen', 'Dank', 'fÃ¼r', 'die', 'Geduld', 'und', 'die', 'fachliche', 'Betreuung', 'und', 'die', 'Empathie', 'die', 'mir', 'entgegengebracht', 'wurde', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'B-Arzt', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'B-anderer Service', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'B-Arzt', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Ich', 'bin', 'seit', 'Juni', '2023', 'in', 'der', 'Uni', 'in', 'Behandlung', 'wegen', 'Brustkrebs', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Krankenhaus', 'O', 'B-mediz. Service', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Krankenhaus', 'O', 'B-mediz. Service', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate_cat/5_epochs/GerMedBERT_medbert-512_ate_cat_test_results.txt\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(f'training and results for {model}:')\n",
    "    ate_cat_model(data, model, rn1=42, rn2=42, epochs=5)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb35fc00-deac-48e7-aad1-d3c4c189bcc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training and results for google-bert/bert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 575/575 [00:00<00:00, 5617.60 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:00<00:00, 3823.09 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/model_train_v2.py:669: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-anderer Service' 'B-anderer Service' 'B-mediz. Service' 'I-Personal'\n",
      " 'O' 'I-Pflegepersonal' 'B-Krankenhaus' 'B-Arzt' 'I-mediz. Service'\n",
      " 'I-Arzt' 'B-Pflegepersonal' 'B-Personal' 'I-Krankenhaus']\n",
      "{0: np.float64(78.56153846153846), 1: np.float64(5.651909241837299), 2: np.float64(2.846432552954292), 3: np.float64(71.41958041958041), 4: np.float64(0.08550450420280634), 5: np.float64(261.87179487179486), 6: np.float64(3.9280769230769232), 7: np.float64(5.493813878429263), 8: np.float64(23.806526806526808), 9: np.float64(18.705128205128204), 10: np.float64(9.465245597775718), 11: np.float64(13.545092838196286), 12: np.float64(29.096866096866098)}\n",
      "Training google-bert/bert-base-german-cased for 10 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2880' max='2880' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2880/2880 03:36, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.314145</td>\n",
       "      <td>0.626506</td>\n",
       "      <td>0.568306</td>\n",
       "      <td>0.595989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.357200</td>\n",
       "      <td>0.363651</td>\n",
       "      <td>0.700680</td>\n",
       "      <td>0.562842</td>\n",
       "      <td>0.624242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.357200</td>\n",
       "      <td>0.464200</td>\n",
       "      <td>0.578199</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.619289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>0.512544</td>\n",
       "      <td>0.618785</td>\n",
       "      <td>0.612022</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.108000</td>\n",
       "      <td>0.580289</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.612022</td>\n",
       "      <td>0.602151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.031400</td>\n",
       "      <td>0.583369</td>\n",
       "      <td>0.639535</td>\n",
       "      <td>0.601093</td>\n",
       "      <td>0.619718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.617354</td>\n",
       "      <td>0.596774</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.601626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.654113</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.601093</td>\n",
       "      <td>0.623229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.647009</td>\n",
       "      <td>0.619318</td>\n",
       "      <td>0.595628</td>\n",
       "      <td>0.607242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.656684</td>\n",
       "      <td>0.626437</td>\n",
       "      <td>0.595628</td>\n",
       "      <td>0.610644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:00<00:00, 3981.51 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {np.int64(0), np.int64(3), np.int64(5), np.int64(6), np.int64(7), np.int64(9), np.int64(11), np.int64(13)}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.57      0.59      0.58        29\n",
      "    Krankenhaus       0.78      0.67      0.72        43\n",
      "       Personal       0.75      0.43      0.55         7\n",
      " Pflegepersonal       1.00      0.90      0.95        10\n",
      "anderer Service       0.42      0.28      0.33        18\n",
      " mediz. Service       0.88      0.57      0.69        37\n",
      "\n",
      "      micro avg       0.72      0.58      0.65       144\n",
      "      macro avg       0.73      0.57      0.64       144\n",
      "   weighted avg       0.73      0.58      0.64       144\n",
      "\n",
      "Precision Score: 0.7241379310344828\n",
      "Recall Score: 0.5833333333333334\n",
      "F1 Score: 0.6461538461538462\n",
      "Tokens     : ['Ich', 'habe', 'jeden', 'Tag', 'die', 'StationsÃ¤rztin', 'gesehen', ',', 'hier', 'nochmal', 'vielen', 'Dank', 'fÃ¼r', 'die', 'Geduld', 'und', 'die', 'fachliche', 'Betreuung', 'und', 'die', 'Empathie', 'die', 'mir', 'entgegengebracht', 'wurde', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'B-Arzt', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'B-anderer Service', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Ich', 'bin', 'seit', 'Juni', '2023', 'in', 'der', 'Uni', 'in', 'Behandlung', 'wegen', 'Brustkrebs', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Krankenhaus', 'O', 'B-mediz. Service', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Krankenhaus', 'O', 'B-mediz. Service', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate_cat/10_epochs/google-bert_bert-base-german-cased_ate_cat_test_results.txt\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 575/575 [00:00<00:00, 6058.24 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:00<00:00, 4032.61 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/model_train_v2.py:669: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-anderer Service' 'B-anderer Service' 'B-mediz. Service' 'I-Personal'\n",
      " 'O' 'I-Pflegepersonal' 'B-Krankenhaus' 'B-Arzt' 'I-mediz. Service'\n",
      " 'I-Arzt' 'B-Pflegepersonal' 'B-Personal' 'I-Krankenhaus']\n",
      "{0: np.float64(78.56153846153846), 1: np.float64(5.651909241837299), 2: np.float64(2.846432552954292), 3: np.float64(71.41958041958041), 4: np.float64(0.08550450420280634), 5: np.float64(261.87179487179486), 6: np.float64(3.9280769230769232), 7: np.float64(5.493813878429263), 8: np.float64(23.806526806526808), 9: np.float64(18.705128205128204), 10: np.float64(9.465245597775718), 11: np.float64(13.545092838196286), 12: np.float64(29.096866096866098)}\n",
      "Training dbmdz/bert-base-german-cased for 10 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2880' max='2880' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2880/2880 03:27, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.340263</td>\n",
       "      <td>0.564417</td>\n",
       "      <td>0.538012</td>\n",
       "      <td>0.550898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.386000</td>\n",
       "      <td>0.315173</td>\n",
       "      <td>0.612676</td>\n",
       "      <td>0.508772</td>\n",
       "      <td>0.555911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.386000</td>\n",
       "      <td>0.459173</td>\n",
       "      <td>0.602210</td>\n",
       "      <td>0.637427</td>\n",
       "      <td>0.619318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.125900</td>\n",
       "      <td>0.486373</td>\n",
       "      <td>0.586592</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.125900</td>\n",
       "      <td>0.550674</td>\n",
       "      <td>0.569892</td>\n",
       "      <td>0.619883</td>\n",
       "      <td>0.593838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.050200</td>\n",
       "      <td>0.630320</td>\n",
       "      <td>0.598870</td>\n",
       "      <td>0.619883</td>\n",
       "      <td>0.609195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>0.672255</td>\n",
       "      <td>0.601156</td>\n",
       "      <td>0.608187</td>\n",
       "      <td>0.604651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>0.692469</td>\n",
       "      <td>0.559585</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.593407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>0.699506</td>\n",
       "      <td>0.562162</td>\n",
       "      <td>0.608187</td>\n",
       "      <td>0.584270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>0.696316</td>\n",
       "      <td>0.564516</td>\n",
       "      <td>0.614035</td>\n",
       "      <td>0.588235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:00<00:00, 4141.78 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {np.int64(0), np.int64(3), np.int64(5), np.int64(6), np.int64(7), np.int64(9), np.int64(11), np.int64(13)}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.68      0.55      0.61        31\n",
      "    Krankenhaus       0.74      0.48      0.58        42\n",
      "       Personal       0.71      0.62      0.67         8\n",
      " Pflegepersonal       0.47      0.90      0.62        10\n",
      "anderer Service       0.22      0.28      0.24        18\n",
      " mediz. Service       0.61      0.61      0.61        38\n",
      "\n",
      "      micro avg       0.57      0.54      0.55       147\n",
      "      macro avg       0.57      0.57      0.55       147\n",
      "   weighted avg       0.61      0.54      0.56       147\n",
      "\n",
      "Precision Score: 0.5683453237410072\n",
      "Recall Score: 0.5374149659863946\n",
      "F1 Score: 0.5524475524475525\n",
      "Tokens     : ['Ich', 'habe', 'jeden', 'Tag', 'die', 'StationsÃ¤rztin', 'gesehen', ',', 'hier', 'nochmal', 'vielen', 'Dank', 'fÃ¼r', 'die', 'Geduld', 'und', 'die', 'fachliche', 'Betreuung', 'und', 'die', 'Empathie', 'die', 'mir', 'entgegengebracht', 'wurde', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'B-Arzt', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'B-anderer Service', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'B-Pflegepersonal', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Ich', 'bin', 'seit', 'Juni', '2023', 'in', 'der', 'Uni', 'in', 'Behandlung', 'wegen', 'Brustkrebs', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Krankenhaus', 'O', 'B-mediz. Service', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Krankenhaus', 'O', 'B-mediz. Service', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate_cat/10_epochs/dbmdz_bert-base-german-cased_ate_cat_test_results.txt\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-uncased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 575/575 [00:00<00:00, 5886.09 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:00<00:00, 3900.27 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/model_train_v2.py:669: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-anderer Service' 'B-anderer Service' 'B-mediz. Service' 'I-Personal'\n",
      " 'O' 'I-Pflegepersonal' 'B-Krankenhaus' 'B-Arzt' 'I-mediz. Service'\n",
      " 'I-Arzt' 'B-Pflegepersonal' 'B-Personal' 'I-Krankenhaus']\n",
      "{0: np.float64(78.56153846153846), 1: np.float64(5.651909241837299), 2: np.float64(2.846432552954292), 3: np.float64(71.41958041958041), 4: np.float64(0.08550450420280634), 5: np.float64(261.87179487179486), 6: np.float64(3.9280769230769232), 7: np.float64(5.493813878429263), 8: np.float64(23.806526806526808), 9: np.float64(18.705128205128204), 10: np.float64(9.465245597775718), 11: np.float64(13.545092838196286), 12: np.float64(29.096866096866098)}\n",
      "Training dbmdz/bert-base-german-uncased for 10 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2880' max='2880' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2880/2880 03:28, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.319907</td>\n",
       "      <td>0.611511</td>\n",
       "      <td>0.508982</td>\n",
       "      <td>0.555556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.366300</td>\n",
       "      <td>0.376197</td>\n",
       "      <td>0.576642</td>\n",
       "      <td>0.473054</td>\n",
       "      <td>0.519737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.366300</td>\n",
       "      <td>0.481974</td>\n",
       "      <td>0.486772</td>\n",
       "      <td>0.550898</td>\n",
       "      <td>0.516854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.124400</td>\n",
       "      <td>0.527617</td>\n",
       "      <td>0.546512</td>\n",
       "      <td>0.562874</td>\n",
       "      <td>0.554572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.124400</td>\n",
       "      <td>0.593346</td>\n",
       "      <td>0.583893</td>\n",
       "      <td>0.520958</td>\n",
       "      <td>0.550633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.042100</td>\n",
       "      <td>0.644776</td>\n",
       "      <td>0.546512</td>\n",
       "      <td>0.562874</td>\n",
       "      <td>0.554572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>0.704451</td>\n",
       "      <td>0.527174</td>\n",
       "      <td>0.580838</td>\n",
       "      <td>0.552707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>0.721638</td>\n",
       "      <td>0.558282</td>\n",
       "      <td>0.544910</td>\n",
       "      <td>0.551515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.754043</td>\n",
       "      <td>0.521978</td>\n",
       "      <td>0.568862</td>\n",
       "      <td>0.544413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.753562</td>\n",
       "      <td>0.552941</td>\n",
       "      <td>0.562874</td>\n",
       "      <td>0.557864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:00<00:00, 4063.10 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {np.int64(0), np.int64(3), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(10), np.int64(11), np.int64(13)}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.57      0.59      0.58        34\n",
      "    Krankenhaus       0.81      0.71      0.76        42\n",
      "       Personal       0.71      0.62      0.67         8\n",
      " Pflegepersonal       0.58      0.88      0.70         8\n",
      "anderer Service       0.21      0.25      0.23        16\n",
      " mediz. Service       0.76      0.56      0.65        39\n",
      "\n",
      "      micro avg       0.63      0.60      0.62       147\n",
      "      macro avg       0.61      0.60      0.60       147\n",
      "   weighted avg       0.66      0.60      0.62       147\n",
      "\n",
      "Precision Score: 0.6330935251798561\n",
      "Recall Score: 0.5986394557823129\n",
      "F1 Score: 0.6153846153846154\n",
      "Tokens     : ['Ich', 'habe', 'jeden', 'Tag', 'die', 'StationsÃ¤rztin', 'gesehen', ',', 'hier', 'nochmal', 'vielen', 'Dank', 'fÃ¼r', 'die', 'Geduld', 'und', 'die', 'fachliche', 'Betreuung', 'und', 'die', 'Empathie', 'die', 'mir', 'entgegengebracht', 'wurde', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'B-Arzt', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'B-anderer Service', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'B-Pflegepersonal', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Ich', 'bin', 'seit', 'Juni', '2023', 'in', 'der', 'Uni', 'in', 'Behandlung', 'wegen', 'Brustkrebs', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Krankenhaus', 'O', 'B-mediz. Service', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate_cat/10_epochs/dbmdz_bert-base-german-uncased_ate_cat_test_results.txt\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for FacebookAI/xlm-roberta-base:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 575/575 [00:00<00:00, 4656.14 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:00<00:00, 3259.01 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/model_train_v2.py:669: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-anderer Service' 'B-anderer Service' 'B-mediz. Service' 'I-Personal'\n",
      " 'O' 'I-Pflegepersonal' 'B-Krankenhaus' 'B-Arzt' 'I-mediz. Service'\n",
      " 'I-Arzt' 'B-Pflegepersonal' 'B-Personal' 'I-Krankenhaus']\n",
      "{0: np.float64(78.56153846153846), 1: np.float64(5.651909241837299), 2: np.float64(2.846432552954292), 3: np.float64(71.41958041958041), 4: np.float64(0.08550450420280634), 5: np.float64(261.87179487179486), 6: np.float64(3.9280769230769232), 7: np.float64(5.493813878429263), 8: np.float64(23.806526806526808), 9: np.float64(18.705128205128204), 10: np.float64(9.465245597775718), 11: np.float64(13.545092838196286), 12: np.float64(29.096866096866098)}\n",
      "Training FacebookAI/xlm-roberta-base for 10 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2880' max='2880' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2880/2880 05:56, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.404620</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.336585</td>\n",
       "      <td>0.416918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.508600</td>\n",
       "      <td>0.324651</td>\n",
       "      <td>0.728682</td>\n",
       "      <td>0.458537</td>\n",
       "      <td>0.562874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.508600</td>\n",
       "      <td>0.330159</td>\n",
       "      <td>0.683616</td>\n",
       "      <td>0.590244</td>\n",
       "      <td>0.633508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.238600</td>\n",
       "      <td>0.431061</td>\n",
       "      <td>0.702703</td>\n",
       "      <td>0.507317</td>\n",
       "      <td>0.589235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.238600</td>\n",
       "      <td>0.483945</td>\n",
       "      <td>0.568720</td>\n",
       "      <td>0.585366</td>\n",
       "      <td>0.576923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.149500</td>\n",
       "      <td>0.507345</td>\n",
       "      <td>0.520833</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.561798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.080800</td>\n",
       "      <td>0.566223</td>\n",
       "      <td>0.570776</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.589623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.080800</td>\n",
       "      <td>0.605235</td>\n",
       "      <td>0.576037</td>\n",
       "      <td>0.609756</td>\n",
       "      <td>0.592417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.047400</td>\n",
       "      <td>0.630347</td>\n",
       "      <td>0.575221</td>\n",
       "      <td>0.634146</td>\n",
       "      <td>0.603248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.047400</td>\n",
       "      <td>0.647925</td>\n",
       "      <td>0.558442</td>\n",
       "      <td>0.629268</td>\n",
       "      <td>0.591743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:00<00:00, 4293.96 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {np.int64(0), np.int64(3), np.int64(5), np.int64(6), np.int64(7), np.int64(9), np.int64(11), np.int64(13)}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.67      0.72      0.69        36\n",
      "    Krankenhaus       0.82      0.62      0.71        45\n",
      "       Personal       0.40      0.18      0.25        11\n",
      " Pflegepersonal       0.61      0.92      0.73        12\n",
      "anderer Service       0.38      0.45      0.42        22\n",
      " mediz. Service       0.83      0.50      0.62        50\n",
      "\n",
      "      micro avg       0.67      0.58      0.62       176\n",
      "      macro avg       0.62      0.57      0.57       176\n",
      "   weighted avg       0.70      0.58      0.62       176\n",
      "\n",
      "Precision Score: 0.6710526315789473\n",
      "Recall Score: 0.5795454545454546\n",
      "F1 Score: 0.6219512195121951\n",
      "Tokens     : ['Ich', 'habe', 'jeden', 'Tag', 'die', 'StationsÃ¤rztin', 'gesehen', ',', 'hier', 'nochmal', 'vielen', 'Dank', 'fÃ¼r', 'die', 'Geduld', 'und', 'die', 'fachliche', 'Betreuung', 'und', 'die', 'Empathie', 'die', 'mir', 'entgegengebracht', 'wurde', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'B-Arzt', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'B-anderer Service', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'B-Personal', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Ich', 'bin', 'seit', 'Juni', '2023', 'in', 'der', 'Uni', 'in', 'Behandlung', 'wegen', 'Brustkrebs', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Krankenhaus', 'O', 'B-mediz. Service', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Krankenhaus', 'O', 'B-mediz. Service', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate_cat/10_epochs/FacebookAI_xlm-roberta-base_ate_cat_test_results.txt\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_best:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 575/575 [00:00<00:00, 5843.55 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:00<00:00, 3883.46 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/model_train_v2.py:669: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-anderer Service' 'B-anderer Service' 'B-mediz. Service' 'I-Personal'\n",
      " 'O' 'I-Pflegepersonal' 'B-Krankenhaus' 'B-Arzt' 'I-mediz. Service'\n",
      " 'I-Arzt' 'B-Pflegepersonal' 'B-Personal' 'I-Krankenhaus']\n",
      "{0: np.float64(78.56153846153846), 1: np.float64(5.651909241837299), 2: np.float64(2.846432552954292), 3: np.float64(71.41958041958041), 4: np.float64(0.08550450420280634), 5: np.float64(261.87179487179486), 6: np.float64(3.9280769230769232), 7: np.float64(5.493813878429263), 8: np.float64(23.806526806526808), 9: np.float64(18.705128205128204), 10: np.float64(9.465245597775718), 11: np.float64(13.545092838196286), 12: np.float64(29.096866096866098)}\n",
      "Training TUM/GottBERT_base_best for 10 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2880' max='2880' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2880/2880 04:02, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.429805</td>\n",
       "      <td>0.448087</td>\n",
       "      <td>0.539474</td>\n",
       "      <td>0.489552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.743900</td>\n",
       "      <td>0.432371</td>\n",
       "      <td>0.468293</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.537815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.743900</td>\n",
       "      <td>0.420159</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.520548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.225700</td>\n",
       "      <td>0.478080</td>\n",
       "      <td>0.560510</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.569579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.225700</td>\n",
       "      <td>0.662139</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.113900</td>\n",
       "      <td>1.028739</td>\n",
       "      <td>0.574713</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.613497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.041700</td>\n",
       "      <td>1.091422</td>\n",
       "      <td>0.576687</td>\n",
       "      <td>0.618421</td>\n",
       "      <td>0.596825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.041700</td>\n",
       "      <td>1.079843</td>\n",
       "      <td>0.604790</td>\n",
       "      <td>0.664474</td>\n",
       "      <td>0.633229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>1.113201</td>\n",
       "      <td>0.607595</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.619355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>1.145341</td>\n",
       "      <td>0.598802</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.626959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Unexpected prediction 40350 found. Assigning 'O'.\n",
      "Warning: Unexpected prediction 240 found. Assigning 'O'.\n",
      "Warning: Unexpected prediction 3063 found. Assigning 'O'.\n",
      "Warning: Unexpected prediction 266 found. Assigning 'O'.\n",
      "Warning: Unexpected prediction 40350 found. Assigning 'O'.\n",
      "Warning: Unexpected prediction 240 found. Assigning 'O'.\n",
      "Warning: Unexpected prediction 3063 found. Assigning 'O'.\n",
      "Warning: Unexpected prediction 40350 found. Assigning 'O'.\n",
      "Warning: Unexpected prediction 240 found. Assigning 'O'.\n",
      "Warning: Unexpected prediction 3063 found. Assigning 'O'.\n",
      "Warning: Unexpected prediction 40350 found. Assigning 'O'.\n",
      "Warning: Unexpected prediction 240 found. Assigning 'O'.\n",
      "Warning: Unexpected prediction 3063 found. Assigning 'O'.\n",
      "Warning: Unexpected prediction 40350 found. Assigning 'O'.\n",
      "Warning: Unexpected prediction 240 found. Assigning 'O'.\n",
      "Warning: Unexpected prediction 3063 found. Assigning 'O'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.decoder.weight', 'lm_head.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:00<00:00, 4303.26 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Unexpected prediction 149 found. Assigning 'O'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O_missing seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {np.int64(0), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(9), np.int64(11), np.int64(13), np.int64(149)}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
      "Warning: Unexpected prediction 149 found. Assigning 'O_missing'.\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.60      0.72      0.65        25\n",
      "    Krankenhaus       0.71      0.59      0.64        41\n",
      "       Personal       0.62      0.71      0.67         7\n",
      " Pflegepersonal       0.78      0.88      0.82         8\n",
      "anderer Service       0.21      0.27      0.24        11\n",
      " mediz. Service       0.54      0.67      0.60        30\n",
      "\n",
      "      micro avg       0.58      0.63      0.61       122\n",
      "      macro avg       0.58      0.64      0.60       122\n",
      "   weighted avg       0.60      0.63      0.61       122\n",
      "\n",
      "Precision Score: 0.5833333333333334\n",
      "Recall Score: 0.6311475409836066\n",
      "F1 Score: 0.6062992125984252\n",
      "Tokens     : ['Ich', 'habe', 'jeden', 'Tag', 'die', 'StationsÃ¤rztin', 'gesehen', ',', 'hier', 'nochmal', 'vielen', 'Dank', 'fÃ¼r', 'die', 'Geduld', 'und', 'die', 'fachliche', 'Betreuung', 'und', 'die', 'Empathie', 'die', 'mir', 'entgegengebracht', 'wurde', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'B-Arzt', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'B-anderer Service', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'B-Arzt', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Ich', 'bin', 'seit', 'Juni', '2023', 'in', 'der', 'Uni', 'in', 'Behandlung', 'wegen', 'Brustkrebs', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Krankenhaus', 'O', 'B-mediz. Service', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Krankenhaus', 'O', 'B-mediz. Service', 'O', 'B-mediz. Service', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate_cat/10_epochs/TUM_GottBERT_base_best_ate_cat_test_results.txt\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_filtered_base_best:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 575/575 [00:00<00:00, 6424.81 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:00<00:00, 4116.66 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/model_train_v2.py:669: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-anderer Service' 'B-anderer Service' 'B-mediz. Service' 'I-Personal'\n",
      " 'O' 'I-Pflegepersonal' 'B-Krankenhaus' 'B-Arzt' 'I-mediz. Service'\n",
      " 'I-Arzt' 'B-Pflegepersonal' 'B-Personal' 'I-Krankenhaus']\n",
      "{0: np.float64(78.56153846153846), 1: np.float64(5.651909241837299), 2: np.float64(2.846432552954292), 3: np.float64(71.41958041958041), 4: np.float64(0.08550450420280634), 5: np.float64(261.87179487179486), 6: np.float64(3.9280769230769232), 7: np.float64(5.493813878429263), 8: np.float64(23.806526806526808), 9: np.float64(18.705128205128204), 10: np.float64(9.465245597775718), 11: np.float64(13.545092838196286), 12: np.float64(29.096866096866098)}\n",
      "Training TUM/GottBERT_filtered_base_best for 10 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2880' max='2880' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2880/2880 03:58, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.399965</td>\n",
       "      <td>0.504202</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.442804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.582200</td>\n",
       "      <td>0.467780</td>\n",
       "      <td>0.497297</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.545994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.582200</td>\n",
       "      <td>0.535172</td>\n",
       "      <td>0.598639</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.588629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.181200</td>\n",
       "      <td>0.651366</td>\n",
       "      <td>0.579882</td>\n",
       "      <td>0.644737</td>\n",
       "      <td>0.610592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.181200</td>\n",
       "      <td>0.797268</td>\n",
       "      <td>0.613139</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.581315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.076800</td>\n",
       "      <td>0.944462</td>\n",
       "      <td>0.603659</td>\n",
       "      <td>0.651316</td>\n",
       "      <td>0.626582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>1.024025</td>\n",
       "      <td>0.593023</td>\n",
       "      <td>0.671053</td>\n",
       "      <td>0.629630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>1.049350</td>\n",
       "      <td>0.582353</td>\n",
       "      <td>0.651316</td>\n",
       "      <td>0.614907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>1.123064</td>\n",
       "      <td>0.582857</td>\n",
       "      <td>0.671053</td>\n",
       "      <td>0.623853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.009100</td>\n",
       "      <td>1.098065</td>\n",
       "      <td>0.601190</td>\n",
       "      <td>0.664474</td>\n",
       "      <td>0.631250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Unexpected prediction 360 found. Assigning 'O'.\n",
      "Warning: Unexpected prediction 48924 found. Assigning 'O'.\n",
      "Warning: Unexpected prediction 360 found. Assigning 'O'.\n",
      "Warning: Unexpected prediction 48924 found. Assigning 'O'.\n",
      "Warning: Unexpected prediction 1081 found. Assigning 'O'.\n",
      "Warning: Unexpected prediction 11939 found. Assigning 'O'.\n",
      "Warning: Unexpected prediction 48924 found. Assigning 'O'.\n",
      "Warning: Unexpected prediction 1081 found. Assigning 'O'.\n",
      "Warning: Unexpected prediction 48924 found. Assigning 'O'.\n",
      "Warning: Unexpected prediction 1081 found. Assigning 'O'.\n",
      "Warning: Unexpected prediction 11939 found. Assigning 'O'.\n",
      "Warning: Unexpected prediction 48924 found. Assigning 'O'.\n",
      "Warning: Unexpected prediction 1081 found. Assigning 'O'.\n",
      "Warning: Unexpected prediction 11939 found. Assigning 'O'.\n",
      "Warning: Unexpected prediction 257 found. Assigning 'O'.\n",
      "Warning: Unexpected prediction 3063 found. Assigning 'O'.\n",
      "Warning: Unexpected prediction 48924 found. Assigning 'O'.\n",
      "Warning: Unexpected prediction 1081 found. Assigning 'O'.\n",
      "Warning: Unexpected prediction 257 found. Assigning 'O'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.decoder.weight', 'lm_head.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:00<00:00, 4189.47 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {np.int64(0), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(10), np.int64(11), np.int64(13)}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.76      0.64      0.70        25\n",
      "    Krankenhaus       0.85      0.80      0.83        41\n",
      "       Personal       0.50      0.71      0.59         7\n",
      " Pflegepersonal       0.88      0.88      0.88         8\n",
      "anderer Service       0.38      0.27      0.32        11\n",
      " mediz. Service       0.56      0.60      0.58        30\n",
      "\n",
      "      micro avg       0.69      0.67      0.68       122\n",
      "      macro avg       0.65      0.65      0.65       122\n",
      "   weighted avg       0.70      0.67      0.68       122\n",
      "\n",
      "Precision Score: 0.6949152542372882\n",
      "Recall Score: 0.6721311475409836\n",
      "F1 Score: 0.6833333333333333\n",
      "Tokens     : ['Ich', 'habe', 'jeden', 'Tag', 'die', 'StationsÃ¤rztin', 'gesehen', ',', 'hier', 'nochmal', 'vielen', 'Dank', 'fÃ¼r', 'die', 'Geduld', 'und', 'die', 'fachliche', 'Betreuung', 'und', 'die', 'Empathie', 'die', 'mir', 'entgegengebracht', 'wurde', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'B-Arzt', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'B-anderer Service', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'B-Personal', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Ich', 'bin', 'seit', 'Juni', '2023', 'in', 'der', 'Uni', 'in', 'Behandlung', 'wegen', 'Brustkrebs', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Krankenhaus', 'O', 'B-mediz. Service', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Krankenhaus', 'O', 'B-mediz. Service', 'O', 'B-mediz. Service', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate_cat/10_epochs/TUM_GottBERT_filtered_base_best_ate_cat_test_results.txt\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_last:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at TUM/GottBERT_base_last were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of the model checkpoint at TUM/GottBERT_base_last were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 575/575 [00:00<00:00, 6045.70 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:00<00:00, 3889.97 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/model_train_v2.py:669: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-anderer Service' 'B-anderer Service' 'B-mediz. Service' 'I-Personal'\n",
      " 'O' 'I-Pflegepersonal' 'B-Krankenhaus' 'B-Arzt' 'I-mediz. Service'\n",
      " 'I-Arzt' 'B-Pflegepersonal' 'B-Personal' 'I-Krankenhaus']\n",
      "{0: np.float64(78.56153846153846), 1: np.float64(5.651909241837299), 2: np.float64(2.846432552954292), 3: np.float64(71.41958041958041), 4: np.float64(0.08550450420280634), 5: np.float64(261.87179487179486), 6: np.float64(3.9280769230769232), 7: np.float64(5.493813878429263), 8: np.float64(23.806526806526808), 9: np.float64(18.705128205128204), 10: np.float64(9.465245597775718), 11: np.float64(13.545092838196286), 12: np.float64(29.096866096866098)}\n",
      "Training TUM/GottBERT_base_last for 10 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2880' max='2880' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2880/2880 04:01, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.436968</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.540541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.726900</td>\n",
       "      <td>0.447421</td>\n",
       "      <td>0.591549</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.726900</td>\n",
       "      <td>0.523774</td>\n",
       "      <td>0.575949</td>\n",
       "      <td>0.598684</td>\n",
       "      <td>0.587097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>0.846363</td>\n",
       "      <td>0.603774</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.617363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>0.964704</td>\n",
       "      <td>0.633094</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.604811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.075400</td>\n",
       "      <td>1.235551</td>\n",
       "      <td>0.554913</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.590769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>1.251128</td>\n",
       "      <td>0.585526</td>\n",
       "      <td>0.585526</td>\n",
       "      <td>0.585526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>1.329724</td>\n",
       "      <td>0.603896</td>\n",
       "      <td>0.611842</td>\n",
       "      <td>0.607843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>1.314530</td>\n",
       "      <td>0.603896</td>\n",
       "      <td>0.611842</td>\n",
       "      <td>0.607843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>1.305345</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.613333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Unexpected prediction 18924 found. Assigning 'O'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.decoder.weight', 'lm_head.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:00<00:00, 3923.68 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {np.int64(0), np.int64(3), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(10), np.int64(11), np.int64(13)}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.62      0.64      0.63        25\n",
      "    Krankenhaus       0.78      0.68      0.73        41\n",
      "       Personal       0.60      0.43      0.50         7\n",
      " Pflegepersonal       0.78      0.88      0.82         8\n",
      "anderer Service       0.25      0.27      0.26        11\n",
      " mediz. Service       0.67      0.60      0.63        30\n",
      "\n",
      "      micro avg       0.65      0.61      0.63       122\n",
      "      macro avg       0.61      0.58      0.60       122\n",
      "   weighted avg       0.66      0.61      0.63       122\n",
      "\n",
      "Precision Score: 0.6521739130434783\n",
      "Recall Score: 0.6147540983606558\n",
      "F1 Score: 0.6329113924050632\n",
      "Tokens     : ['Ich', 'habe', 'jeden', 'Tag', 'die', 'StationsÃ¤rztin', 'gesehen', ',', 'hier', 'nochmal', 'vielen', 'Dank', 'fÃ¼r', 'die', 'Geduld', 'und', 'die', 'fachliche', 'Betreuung', 'und', 'die', 'Empathie', 'die', 'mir', 'entgegengebracht', 'wurde', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'B-Arzt', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'B-anderer Service', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'B-Arzt', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Ich', 'bin', 'seit', 'Juni', '2023', 'in', 'der', 'Uni', 'in', 'Behandlung', 'wegen', 'Brustkrebs', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Krankenhaus', 'O', 'B-mediz. Service', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Krankenhaus', 'O', 'B-mediz. Service', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate_cat/10_epochs/TUM_GottBERT_base_last_ate_cat_test_results.txt\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for distilbert/distilbert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 575/575 [00:00<00:00, 6500.59 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:00<00:00, 4412.61 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/model_train_v2.py:669: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-anderer Service' 'B-anderer Service' 'B-mediz. Service' 'I-Personal'\n",
      " 'O' 'I-Pflegepersonal' 'B-Krankenhaus' 'B-Arzt' 'I-mediz. Service'\n",
      " 'I-Arzt' 'B-Pflegepersonal' 'B-Personal' 'I-Krankenhaus']\n",
      "{0: np.float64(78.56153846153846), 1: np.float64(5.651909241837299), 2: np.float64(2.846432552954292), 3: np.float64(71.41958041958041), 4: np.float64(0.08550450420280634), 5: np.float64(261.87179487179486), 6: np.float64(3.9280769230769232), 7: np.float64(5.493813878429263), 8: np.float64(23.806526806526808), 9: np.float64(18.705128205128204), 10: np.float64(9.465245597775718), 11: np.float64(13.545092838196286), 12: np.float64(29.096866096866098)}\n",
      "Training distilbert/distilbert-base-german-cased for 10 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2880' max='2880' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2880/2880 02:05, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.376311</td>\n",
       "      <td>0.482558</td>\n",
       "      <td>0.485380</td>\n",
       "      <td>0.483965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.448200</td>\n",
       "      <td>0.308758</td>\n",
       "      <td>0.661538</td>\n",
       "      <td>0.502924</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.448200</td>\n",
       "      <td>0.327499</td>\n",
       "      <td>0.603550</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.164300</td>\n",
       "      <td>0.386752</td>\n",
       "      <td>0.602484</td>\n",
       "      <td>0.567251</td>\n",
       "      <td>0.584337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.164300</td>\n",
       "      <td>0.417542</td>\n",
       "      <td>0.551913</td>\n",
       "      <td>0.590643</td>\n",
       "      <td>0.570621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.074800</td>\n",
       "      <td>0.445919</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.573099</td>\n",
       "      <td>0.578171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.039900</td>\n",
       "      <td>0.475213</td>\n",
       "      <td>0.575581</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.577259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.039900</td>\n",
       "      <td>0.496147</td>\n",
       "      <td>0.577640</td>\n",
       "      <td>0.543860</td>\n",
       "      <td>0.560241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.023400</td>\n",
       "      <td>0.508502</td>\n",
       "      <td>0.556818</td>\n",
       "      <td>0.573099</td>\n",
       "      <td>0.564841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.023400</td>\n",
       "      <td>0.514116</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>0.561404</td>\n",
       "      <td>0.559767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:00<00:00, 4002.68 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {np.int64(0), np.int64(3), np.int64(5), np.int64(6), np.int64(7), np.int64(9), np.int64(11), np.int64(13)}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.61      0.61      0.61        31\n",
      "    Krankenhaus       0.71      0.57      0.63        42\n",
      "       Personal       0.60      0.38      0.46         8\n",
      " Pflegepersonal       0.60      0.90      0.72        10\n",
      "anderer Service       0.20      0.11      0.14        18\n",
      " mediz. Service       0.69      0.66      0.68        38\n",
      "\n",
      "      micro avg       0.63      0.56      0.59       147\n",
      "      macro avg       0.57      0.54      0.54       147\n",
      "   weighted avg       0.61      0.56      0.58       147\n",
      "\n",
      "Precision Score: 0.6259541984732825\n",
      "Recall Score: 0.5578231292517006\n",
      "F1 Score: 0.5899280575539567\n",
      "Tokens     : ['Ich', 'habe', 'jeden', 'Tag', 'die', 'StationsÃ¤rztin', 'gesehen', ',', 'hier', 'nochmal', 'vielen', 'Dank', 'fÃ¼r', 'die', 'Geduld', 'und', 'die', 'fachliche', 'Betreuung', 'und', 'die', 'Empathie', 'die', 'mir', 'entgegengebracht', 'wurde', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'B-Arzt', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'B-anderer Service', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Ich', 'bin', 'seit', 'Juni', '2023', 'in', 'der', 'Uni', 'in', 'Behandlung', 'wegen', 'Brustkrebs', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Krankenhaus', 'O', 'B-mediz. Service', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Krankenhaus', 'O', 'B-mediz. Service', 'O', 'B-mediz. Service', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate_cat/10_epochs/distilbert_distilbert-base-german-cased_ate_cat_test_results.txt\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for GerMedBERT/medbert-512:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 575/575 [00:00<00:00, 5837.31 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:00<00:00, 3507.23 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/model_train_v2.py:669: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-anderer Service' 'B-anderer Service' 'B-mediz. Service' 'I-Personal'\n",
      " 'O' 'I-Pflegepersonal' 'B-Krankenhaus' 'B-Arzt' 'I-mediz. Service'\n",
      " 'I-Arzt' 'B-Pflegepersonal' 'B-Personal' 'I-Krankenhaus']\n",
      "{0: np.float64(78.56153846153846), 1: np.float64(5.651909241837299), 2: np.float64(2.846432552954292), 3: np.float64(71.41958041958041), 4: np.float64(0.08550450420280634), 5: np.float64(261.87179487179486), 6: np.float64(3.9280769230769232), 7: np.float64(5.493813878429263), 8: np.float64(23.806526806526808), 9: np.float64(18.705128205128204), 10: np.float64(9.465245597775718), 11: np.float64(13.545092838196286), 12: np.float64(29.096866096866098)}\n",
      "Training GerMedBERT/medbert-512 for 10 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2880' max='2880' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2880/2880 03:38, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.560103</td>\n",
       "      <td>0.356757</td>\n",
       "      <td>0.409938</td>\n",
       "      <td>0.381503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.415900</td>\n",
       "      <td>0.378509</td>\n",
       "      <td>0.578571</td>\n",
       "      <td>0.503106</td>\n",
       "      <td>0.538206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.415900</td>\n",
       "      <td>0.459142</td>\n",
       "      <td>0.518919</td>\n",
       "      <td>0.596273</td>\n",
       "      <td>0.554913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.206600</td>\n",
       "      <td>0.542074</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.596273</td>\n",
       "      <td>0.598131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.206600</td>\n",
       "      <td>0.651896</td>\n",
       "      <td>0.593548</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.582278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.073700</td>\n",
       "      <td>0.802876</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.559006</td>\n",
       "      <td>0.567823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.024100</td>\n",
       "      <td>0.756369</td>\n",
       "      <td>0.617450</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.593548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.024100</td>\n",
       "      <td>0.822646</td>\n",
       "      <td>0.573171</td>\n",
       "      <td>0.583851</td>\n",
       "      <td>0.578462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>0.823921</td>\n",
       "      <td>0.567251</td>\n",
       "      <td>0.602484</td>\n",
       "      <td>0.584337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>0.837292</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.596273</td>\n",
       "      <td>0.594427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Unexpected prediction 9617 found. Assigning 'O'.\n",
      "Warning: Unexpected prediction 3573 found. Assigning 'O'.\n",
      "Warning: Unexpected prediction 5198 found. Assigning 'O'.\n",
      "Warning: Unexpected prediction 9617 found. Assigning 'O'.\n",
      "Warning: Unexpected prediction 9617 found. Assigning 'O'.\n",
      "Warning: Unexpected prediction 9617 found. Assigning 'O'.\n",
      "Warning: Unexpected prediction 9617 found. Assigning 'O'.\n",
      "Warning: Unexpected prediction 3573 found. Assigning 'O'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:00<00:00, 4051.27 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {np.int64(0), np.int64(3), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(11), np.int64(13)}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.52      0.62      0.57        24\n",
      "    Krankenhaus       0.73      0.73      0.73        45\n",
      "       Personal       0.55      0.75      0.63         8\n",
      " Pflegepersonal       0.67      0.91      0.77        11\n",
      "anderer Service       0.30      0.38      0.33        16\n",
      " mediz. Service       0.65      0.42      0.51        31\n",
      "\n",
      "      micro avg       0.59      0.61      0.60       135\n",
      "      macro avg       0.57      0.64      0.59       135\n",
      "   weighted avg       0.61      0.61      0.60       135\n",
      "\n",
      "Precision Score: 0.5928571428571429\n",
      "Recall Score: 0.6148148148148148\n",
      "F1 Score: 0.6036363636363636\n",
      "Tokens     : ['Ich', 'habe', 'jeden', 'Tag', 'die', 'StationsÃ¤rztin', 'gesehen', ',', 'hier', 'nochmal', 'vielen', 'Dank', 'fÃ¼r', 'die', 'Geduld', 'und', 'die', 'fachliche', 'Betreuung', 'und', 'die', 'Empathie', 'die', 'mir', 'entgegengebracht', 'wurde', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'B-Arzt', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'B-anderer Service', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'B-Arzt', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Ich', 'bin', 'seit', 'Juni', '2023', 'in', 'der', 'Uni', 'in', 'Behandlung', 'wegen', 'Brustkrebs', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Krankenhaus', 'O', 'B-mediz. Service', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-Krankenhaus', 'O', 'B-mediz. Service', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate_cat/10_epochs/GerMedBERT_medbert-512_ate_cat_test_results.txt\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(f'training and results for {model}:')\n",
    "    ate_cat_model(data, model, rn1=42, rn2=42, epochs=10)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ca06ae-cec5-4bf9-9161-dc0f9a1c68ce",
   "metadata": {},
   "source": [
    "#### 2.1 category-aware ATE with k-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2122c1ba-cd96-4798-a566-10bd8fce7604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training and results for google-bert/bert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fold 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<00:00, 5802.73 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180/180 [00:00<00:00, 5473.53 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180/180 [00:00<00:00, 5902.21 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/model_train_v2.py:791: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-Pflegepersonal' 'B-Arzt' 'B-anderer Service' 'I-Personal' 'O'\n",
      " 'B-mediz. Service' 'I-anderer Service' 'I-Arzt' 'I-mediz. Service'\n",
      " 'B-Krankenhaus' 'I-Krankenhaus' 'B-Pflegepersonal' 'B-Personal']\n",
      "{0: np.float64(261.87179487179486), 1: np.float64(5.493813878429263), 2: np.float64(5.651909241837299), 3: np.float64(71.41958041958041), 4: np.float64(0.08550450420280634), 5: np.float64(2.846432552954292), 6: np.float64(78.56153846153846), 7: np.float64(18.705128205128204), 8: np.float64(23.806526806526808), 9: np.float64(3.9280769230769232), 10: np.float64(29.096866096866098), 11: np.float64(9.465245597775718), 12: np.float64(13.545092838196286)}\n",
      "Training fold 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 00:35, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.455390</td>\n",
       "      <td>0.638298</td>\n",
       "      <td>0.161290</td>\n",
       "      <td>0.257511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.371470</td>\n",
       "      <td>0.673729</td>\n",
       "      <td>0.427419</td>\n",
       "      <td>0.523026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.342624</td>\n",
       "      <td>0.634375</td>\n",
       "      <td>0.545699</td>\n",
       "      <td>0.586705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.342606</td>\n",
       "      <td>0.605405</td>\n",
       "      <td>0.602151</td>\n",
       "      <td>0.603774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.345547</td>\n",
       "      <td>0.660550</td>\n",
       "      <td>0.580645</td>\n",
       "      <td>0.618026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fold 1\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {np.int64(0), np.int64(3), np.int64(5), np.int64(6), np.int64(7), np.int64(9), np.int64(11), np.int64(13)}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.55      0.68      0.61        53\n",
      "    Krankenhaus       0.65      0.60      0.62       105\n",
      "       Personal       1.00      0.04      0.08        25\n",
      " Pflegepersonal       0.80      0.65      0.71        31\n",
      "anderer Service       0.50      0.10      0.16        61\n",
      " mediz. Service       0.57      0.67      0.62       127\n",
      "\n",
      "      micro avg       0.60      0.52      0.56       402\n",
      "      macro avg       0.68      0.46      0.47       402\n",
      "   weighted avg       0.62      0.52      0.52       402\n",
      "\n",
      "Fold 1 Results - Precision: 0.6045845272206304, Recall: 0.5248756218905473, F1: 0.5619174434087884\n",
      "Starting fold 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [00:00<00:00, 6132.15 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 179/179 [00:00<00:00, 5603.59 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180/180 [00:00<00:00, 5202.88 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/model_train_v2.py:791: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-Pflegepersonal' 'B-Arzt' 'B-anderer Service' 'I-Personal' 'O'\n",
      " 'B-mediz. Service' 'I-anderer Service' 'I-Arzt' 'I-mediz. Service'\n",
      " 'B-Krankenhaus' 'I-Krankenhaus' 'B-Pflegepersonal' 'B-Personal']\n",
      "{0: np.float64(261.87179487179486), 1: np.float64(5.493813878429263), 2: np.float64(5.651909241837299), 3: np.float64(71.41958041958041), 4: np.float64(0.08550450420280634), 5: np.float64(2.846432552954292), 6: np.float64(78.56153846153846), 7: np.float64(18.705128205128204), 8: np.float64(23.806526806526808), 9: np.float64(3.9280769230769232), 10: np.float64(29.096866096866098), 11: np.float64(9.465245597775718), 12: np.float64(13.545092838196286)}\n",
      "Training fold 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 00:35, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.177941</td>\n",
       "      <td>0.737327</td>\n",
       "      <td>0.739030</td>\n",
       "      <td>0.738178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.166044</td>\n",
       "      <td>0.731463</td>\n",
       "      <td>0.842956</td>\n",
       "      <td>0.783262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.158262</td>\n",
       "      <td>0.737805</td>\n",
       "      <td>0.838337</td>\n",
       "      <td>0.784865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.147720</td>\n",
       "      <td>0.766529</td>\n",
       "      <td>0.856813</td>\n",
       "      <td>0.809160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.147531</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.831409</td>\n",
       "      <td>0.804469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fold 2\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {np.int64(0), np.int64(3), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(11), np.int64(13)}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.63      0.85      0.73        47\n",
      "    Krankenhaus       0.72      0.90      0.80        97\n",
      "       Personal       0.64      0.41      0.50        22\n",
      " Pflegepersonal       0.82      0.83      0.82        48\n",
      "anderer Service       0.77      0.66      0.71        50\n",
      " mediz. Service       0.76      0.83      0.79       150\n",
      "\n",
      "      micro avg       0.74      0.80      0.77       414\n",
      "      macro avg       0.72      0.75      0.73       414\n",
      "   weighted avg       0.74      0.80      0.77       414\n",
      "\n",
      "Fold 2 Results - Precision: 0.7367256637168141, Recall: 0.8043478260869565, F1: 0.7690531177829099\n",
      "\n",
      "=== Final Cross-Validation Results ===\n",
      "Average Precision: 0.6706550954687223\n",
      "Average Recall: 0.6646117239887519\n",
      "Average F1 Score: 0.6654852805958491\n",
      "Training complete. Model directory for fold 1 deleted to free memory.\n",
      "Training complete. Model directory for fold 2 deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fold 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<00:00, 6016.23 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180/180 [00:00<00:00, 5513.98 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180/180 [00:00<00:00, 6008.70 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/model_train_v2.py:791: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-Pflegepersonal' 'B-Arzt' 'B-anderer Service' 'I-Personal' 'O'\n",
      " 'B-mediz. Service' 'I-anderer Service' 'I-Arzt' 'I-mediz. Service'\n",
      " 'B-Krankenhaus' 'I-Krankenhaus' 'B-Pflegepersonal' 'B-Personal']\n",
      "{0: np.float64(261.87179487179486), 1: np.float64(5.493813878429263), 2: np.float64(5.651909241837299), 3: np.float64(71.41958041958041), 4: np.float64(0.08550450420280634), 5: np.float64(2.846432552954292), 6: np.float64(78.56153846153846), 7: np.float64(18.705128205128204), 8: np.float64(23.806526806526808), 9: np.float64(3.9280769230769232), 10: np.float64(29.096866096866098), 11: np.float64(9.465245597775718), 12: np.float64(13.545092838196286)}\n",
      "Training fold 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 00:34, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.556370</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.414181</td>\n",
       "      <td>0.635922</td>\n",
       "      <td>0.361878</td>\n",
       "      <td>0.461268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.377731</td>\n",
       "      <td>0.614865</td>\n",
       "      <td>0.502762</td>\n",
       "      <td>0.553191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.357026</td>\n",
       "      <td>0.577143</td>\n",
       "      <td>0.558011</td>\n",
       "      <td>0.567416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.357232</td>\n",
       "      <td>0.593023</td>\n",
       "      <td>0.563536</td>\n",
       "      <td>0.577904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fold 1\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {np.int64(0), np.int64(3), np.int64(5), np.int64(6), np.int64(7), np.int64(9), np.int64(11), np.int64(13)}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.46      0.57      0.51        54\n",
      "    Krankenhaus       0.57      0.47      0.52       100\n",
      "       Personal       1.00      0.13      0.23        23\n",
      " Pflegepersonal       0.59      0.65      0.62        31\n",
      "anderer Service       0.57      0.07      0.12        61\n",
      " mediz. Service       0.54      0.63      0.58       118\n",
      "\n",
      "      micro avg       0.54      0.46      0.50       387\n",
      "      macro avg       0.62      0.42      0.43       387\n",
      "   weighted avg       0.57      0.46      0.46       387\n",
      "\n",
      "Fold 1 Results - Precision: 0.5391566265060241, Recall: 0.4625322997416021, F1: 0.49791376912378305\n",
      "Starting fold 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [00:00<00:00, 6157.71 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 179/179 [00:00<00:00, 5655.00 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180/180 [00:00<00:00, 5325.27 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/model_train_v2.py:791: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-Pflegepersonal' 'B-Arzt' 'B-anderer Service' 'I-Personal' 'O'\n",
      " 'B-mediz. Service' 'I-anderer Service' 'I-Arzt' 'I-mediz. Service'\n",
      " 'B-Krankenhaus' 'I-Krankenhaus' 'B-Pflegepersonal' 'B-Personal']\n",
      "{0: np.float64(261.87179487179486), 1: np.float64(5.493813878429263), 2: np.float64(5.651909241837299), 3: np.float64(71.41958041958041), 4: np.float64(0.08550450420280634), 5: np.float64(2.846432552954292), 6: np.float64(78.56153846153846), 7: np.float64(18.705128205128204), 8: np.float64(23.806526806526808), 9: np.float64(3.9280769230769232), 10: np.float64(29.096866096866098), 11: np.float64(9.465245597775718), 12: np.float64(13.545092838196286)}\n",
      "Training fold 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 00:34, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.215663</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.680851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.191817</td>\n",
       "      <td>0.721698</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.730310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.207120</td>\n",
       "      <td>0.661290</td>\n",
       "      <td>0.792271</td>\n",
       "      <td>0.720879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.199860</td>\n",
       "      <td>0.681913</td>\n",
       "      <td>0.792271</td>\n",
       "      <td>0.732961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.200088</td>\n",
       "      <td>0.687234</td>\n",
       "      <td>0.780193</td>\n",
       "      <td>0.730769</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fold 2\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {np.int64(0), np.int64(3), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(11), np.int64(13)}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.64      0.83      0.72        47\n",
      "    Krankenhaus       0.67      0.86      0.75        96\n",
      "       Personal       0.90      0.43      0.58        21\n",
      " Pflegepersonal       0.72      0.81      0.76        47\n",
      "anderer Service       0.55      0.59      0.57        49\n",
      " mediz. Service       0.71      0.87      0.78       133\n",
      "\n",
      "      micro avg       0.68      0.80      0.73       393\n",
      "      macro avg       0.70      0.73      0.69       393\n",
      "   weighted avg       0.68      0.80      0.73       393\n",
      "\n",
      "Fold 2 Results - Precision: 0.6767241379310345, Recall: 0.7989821882951654, F1: 0.7327887981330221\n",
      "\n",
      "=== Final Cross-Validation Results ===\n",
      "Average Precision: 0.6079403822185293\n",
      "Average Recall: 0.6307572440183837\n",
      "Average F1 Score: 0.6153512836284025\n",
      "Training complete. Model directory for fold 1 deleted to free memory.\n",
      "Training complete. Model directory for fold 2 deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-uncased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fold 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<00:00, 4430.91 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180/180 [00:00<00:00, 5349.80 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180/180 [00:00<00:00, 5732.01 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/model_train_v2.py:791: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-Pflegepersonal' 'B-Arzt' 'B-anderer Service' 'I-Personal' 'O'\n",
      " 'B-mediz. Service' 'I-anderer Service' 'I-Arzt' 'I-mediz. Service'\n",
      " 'B-Krankenhaus' 'I-Krankenhaus' 'B-Pflegepersonal' 'B-Personal']\n",
      "{0: np.float64(261.87179487179486), 1: np.float64(5.493813878429263), 2: np.float64(5.651909241837299), 3: np.float64(71.41958041958041), 4: np.float64(0.08550450420280634), 5: np.float64(2.846432552954292), 6: np.float64(78.56153846153846), 7: np.float64(18.705128205128204), 8: np.float64(23.806526806526808), 9: np.float64(3.9280769230769232), 10: np.float64(29.096866096866098), 11: np.float64(9.465245597775718), 12: np.float64(13.545092838196286)}\n",
      "Training fold 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 00:35, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.467376</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.038997</td>\n",
       "      <td>0.069825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.378710</td>\n",
       "      <td>0.594142</td>\n",
       "      <td>0.395543</td>\n",
       "      <td>0.474916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.348459</td>\n",
       "      <td>0.614198</td>\n",
       "      <td>0.554318</td>\n",
       "      <td>0.582723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.343690</td>\n",
       "      <td>0.612245</td>\n",
       "      <td>0.584958</td>\n",
       "      <td>0.598291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.346167</td>\n",
       "      <td>0.619760</td>\n",
       "      <td>0.576602</td>\n",
       "      <td>0.597403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fold 1\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {np.int64(0), np.int64(3), np.int64(5), np.int64(7), np.int64(9), np.int64(11)}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.45      0.75      0.56        61\n",
      "    Krankenhaus       0.59      0.61      0.60        99\n",
      "       Personal       0.00      0.00      0.00        23\n",
      " Pflegepersonal       0.70      0.50      0.58        28\n",
      "anderer Service       0.44      0.07      0.11        61\n",
      " mediz. Service       0.50      0.54      0.52       114\n",
      "\n",
      "      micro avg       0.52      0.48      0.50       386\n",
      "      macro avg       0.45      0.41      0.40       386\n",
      "   weighted avg       0.49      0.48      0.46       386\n",
      "\n",
      "Fold 1 Results - Precision: 0.5210084033613446, Recall: 0.48186528497409326, F1: 0.5006729475100942\n",
      "Starting fold 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [00:00<00:00, 5962.48 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 179/179 [00:00<00:00, 5400.09 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180/180 [00:00<00:00, 5094.85 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/model_train_v2.py:791: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-Pflegepersonal' 'B-Arzt' 'B-anderer Service' 'I-Personal' 'O'\n",
      " 'B-mediz. Service' 'I-anderer Service' 'I-Arzt' 'I-mediz. Service'\n",
      " 'B-Krankenhaus' 'I-Krankenhaus' 'B-Pflegepersonal' 'B-Personal']\n",
      "{0: np.float64(261.87179487179486), 1: np.float64(5.493813878429263), 2: np.float64(5.651909241837299), 3: np.float64(71.41958041958041), 4: np.float64(0.08550450420280634), 5: np.float64(2.846432552954292), 6: np.float64(78.56153846153846), 7: np.float64(18.705128205128204), 8: np.float64(23.806526806526808), 9: np.float64(3.9280769230769232), 10: np.float64(29.096866096866098), 11: np.float64(9.465245597775718), 12: np.float64(13.545092838196286)}\n",
      "Training fold 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 00:35, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.230841</td>\n",
       "      <td>0.646778</td>\n",
       "      <td>0.639151</td>\n",
       "      <td>0.642942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.212578</td>\n",
       "      <td>0.668192</td>\n",
       "      <td>0.688679</td>\n",
       "      <td>0.678281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.211445</td>\n",
       "      <td>0.682819</td>\n",
       "      <td>0.731132</td>\n",
       "      <td>0.706150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.212596</td>\n",
       "      <td>0.702765</td>\n",
       "      <td>0.719340</td>\n",
       "      <td>0.710956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.208785</td>\n",
       "      <td>0.689130</td>\n",
       "      <td>0.747642</td>\n",
       "      <td>0.717195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fold 2\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {np.int64(0), np.int64(3), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(11), np.int64(13)}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.60      0.88      0.71        57\n",
      "    Krankenhaus       0.77      0.83      0.80        99\n",
      "       Personal       0.60      0.29      0.39        21\n",
      " Pflegepersonal       0.78      0.63      0.70        46\n",
      "anderer Service       0.65      0.48      0.55        50\n",
      " mediz. Service       0.69      0.82      0.75       131\n",
      "\n",
      "      micro avg       0.69      0.74      0.71       404\n",
      "      macro avg       0.68      0.65      0.65       404\n",
      "   weighted avg       0.70      0.74      0.71       404\n",
      "\n",
      "Fold 2 Results - Precision: 0.6930232558139535, Recall: 0.7376237623762376, F1: 0.7146282973621103\n",
      "\n",
      "=== Final Cross-Validation Results ===\n",
      "Average Precision: 0.6070158295876491\n",
      "Average Recall: 0.6097445236751654\n",
      "Average F1 Score: 0.6076506224361022\n",
      "Training complete. Model directory for fold 1 deleted to free memory.\n",
      "Training complete. Model directory for fold 2 deleted to free memory.\n",
      "\n",
      "training and results for FacebookAI/xlm-roberta-base:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fold 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<00:00, 6007.83 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180/180 [00:00<00:00, 5641.55 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180/180 [00:00<00:00, 6047.05 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/model_train_v2.py:791: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-Pflegepersonal' 'B-Arzt' 'B-anderer Service' 'I-Personal' 'O'\n",
      " 'B-mediz. Service' 'I-anderer Service' 'I-Arzt' 'I-mediz. Service'\n",
      " 'B-Krankenhaus' 'I-Krankenhaus' 'B-Pflegepersonal' 'B-Personal']\n",
      "{0: np.float64(261.87179487179486), 1: np.float64(5.493813878429263), 2: np.float64(5.651909241837299), 3: np.float64(71.41958041958041), 4: np.float64(0.08550450420280634), 5: np.float64(2.846432552954292), 6: np.float64(78.56153846153846), 7: np.float64(18.705128205128204), 8: np.float64(23.806526806526808), 9: np.float64(3.9280769230769232), 10: np.float64(29.096866096866098), 11: np.float64(9.465245597775718), 12: np.float64(13.545092838196286)}\n",
      "Training fold 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 01:16, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.578754</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.493067</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.456439</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0.033019</td>\n",
       "      <td>0.059701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.450865</td>\n",
       "      <td>0.354978</td>\n",
       "      <td>0.193396</td>\n",
       "      <td>0.250382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.442501</td>\n",
       "      <td>0.402214</td>\n",
       "      <td>0.257075</td>\n",
       "      <td>0.313669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fold 1\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {np.int64(0), np.int64(5), np.int64(7), np.int64(9), np.int64(11)}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.45      0.14      0.21        64\n",
      "    Krankenhaus       0.29      0.33      0.31       112\n",
      "       Personal       0.00      0.00      0.00        30\n",
      " Pflegepersonal       0.71      0.45      0.55        38\n",
      "anderer Service       0.00      0.00      0.00        78\n",
      " mediz. Service       0.39      0.30      0.34       145\n",
      "\n",
      "      micro avg       0.37      0.23      0.28       467\n",
      "      macro avg       0.31      0.20      0.24       467\n",
      "   weighted avg       0.31      0.23      0.25       467\n",
      "\n",
      "Fold 1 Results - Precision: 0.3741258741258741, Recall: 0.2291220556745182, F1: 0.2841965471447543\n",
      "Starting fold 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [00:00<00:00, 6397.06 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 179/179 [00:00<00:00, 5837.79 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180/180 [00:00<00:00, 5551.57 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/model_train_v2.py:791: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-Pflegepersonal' 'B-Arzt' 'B-anderer Service' 'I-Personal' 'O'\n",
      " 'B-mediz. Service' 'I-anderer Service' 'I-Arzt' 'I-mediz. Service'\n",
      " 'B-Krankenhaus' 'I-Krankenhaus' 'B-Pflegepersonal' 'B-Personal']\n",
      "{0: np.float64(261.87179487179486), 1: np.float64(5.493813878429263), 2: np.float64(5.651909241837299), 3: np.float64(71.41958041958041), 4: np.float64(0.08550450420280634), 5: np.float64(2.846432552954292), 6: np.float64(78.56153846153846), 7: np.float64(18.705128205128204), 8: np.float64(23.806526806526808), 9: np.float64(3.9280769230769232), 10: np.float64(29.096866096866098), 11: np.float64(9.465245597775718), 12: np.float64(13.545092838196286)}\n",
      "Training fold 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 01:25, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.359174</td>\n",
       "      <td>0.546196</td>\n",
       "      <td>0.414433</td>\n",
       "      <td>0.471278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.321821</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.577320</td>\n",
       "      <td>0.546341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.304909</td>\n",
       "      <td>0.570370</td>\n",
       "      <td>0.635052</td>\n",
       "      <td>0.600976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.299644</td>\n",
       "      <td>0.586916</td>\n",
       "      <td>0.647423</td>\n",
       "      <td>0.615686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.293543</td>\n",
       "      <td>0.609615</td>\n",
       "      <td>0.653608</td>\n",
       "      <td>0.630846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fold 2\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {np.int64(0), np.int64(3), np.int64(5), np.int64(6), np.int64(7), np.int64(9), np.int64(11), np.int64(13)}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.54      0.84      0.66        58\n",
      "    Krankenhaus       0.53      0.78      0.63       108\n",
      "       Personal       1.00      0.04      0.07        26\n",
      " Pflegepersonal       0.67      0.70      0.68        63\n",
      "anderer Service       0.63      0.18      0.28        66\n",
      " mediz. Service       0.62      0.77      0.68       150\n",
      "\n",
      "      micro avg       0.58      0.65      0.61       471\n",
      "      macro avg       0.66      0.55      0.50       471\n",
      "   weighted avg       0.62      0.65      0.58       471\n",
      "\n",
      "Fold 2 Results - Precision: 0.5842911877394636, Recall: 0.6475583864118896, F1: 0.6143001007049346\n",
      "\n",
      "=== Final Cross-Validation Results ===\n",
      "Average Precision: 0.4792085309326689\n",
      "Average Recall: 0.4383402210432039\n",
      "Average F1 Score: 0.44924832392484443\n",
      "Training complete. Model directory for fold 1 deleted to free memory.\n",
      "Training complete. Model directory for fold 2 deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_best:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fold 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<00:00, 6553.37 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180/180 [00:00<00:00, 5842.55 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180/180 [00:00<00:00, 6292.45 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/model_train_v2.py:791: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-Pflegepersonal' 'B-Arzt' 'B-anderer Service' 'I-Personal' 'O'\n",
      " 'B-mediz. Service' 'I-anderer Service' 'I-Arzt' 'I-mediz. Service'\n",
      " 'B-Krankenhaus' 'I-Krankenhaus' 'B-Pflegepersonal' 'B-Personal']\n",
      "{0: np.float64(261.87179487179486), 1: np.float64(5.493813878429263), 2: np.float64(5.651909241837299), 3: np.float64(71.41958041958041), 4: np.float64(0.08550450420280634), 5: np.float64(2.846432552954292), 6: np.float64(78.56153846153846), 7: np.float64(18.705128205128204), 8: np.float64(23.806526806526808), 9: np.float64(3.9280769230769232), 10: np.float64(29.096866096866098), 11: np.float64(9.465245597775718), 12: np.float64(13.545092838196286)}\n",
      "Training fold 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 00:45, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.681662</td>\n",
       "      <td>0.245902</td>\n",
       "      <td>0.047771</td>\n",
       "      <td>0.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.585697</td>\n",
       "      <td>0.393617</td>\n",
       "      <td>0.353503</td>\n",
       "      <td>0.372483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.518120</td>\n",
       "      <td>0.540230</td>\n",
       "      <td>0.449045</td>\n",
       "      <td>0.490435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.467893</td>\n",
       "      <td>0.576208</td>\n",
       "      <td>0.493631</td>\n",
       "      <td>0.531732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.450444</td>\n",
       "      <td>0.570922</td>\n",
       "      <td>0.512739</td>\n",
       "      <td>0.540268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.decoder.weight', 'lm_head.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fold 1\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O_missing seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {np.int64(0), np.int64(97), np.int64(5), np.int64(6), np.int64(7), np.int64(9), np.int64(11), np.int64(13)}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
      "Warning: Unexpected prediction 97 found. Assigning 'O_missing'.\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.52      0.67      0.59        48\n",
      "    Krankenhaus       0.61      0.58      0.59        93\n",
      "       Personal       0.50      0.05      0.09        20\n",
      " Pflegepersonal       0.54      0.70      0.61        27\n",
      "anderer Service       0.00      0.00      0.00        53\n",
      " mediz. Service       0.50      0.56      0.53       107\n",
      "\n",
      "      micro avg       0.54      0.48      0.51       348\n",
      "      macro avg       0.45      0.43      0.40       348\n",
      "   weighted avg       0.46      0.48      0.46       348\n",
      "\n",
      "Fold 1 Results - Precision: 0.5424836601307189, Recall: 0.47701149425287354, F1: 0.5076452599388379\n",
      "Starting fold 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [00:00<00:00, 6621.63 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 179/179 [00:00<00:00, 6176.57 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180/180 [00:00<00:00, 5905.30 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/model_train_v2.py:791: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-Pflegepersonal' 'B-Arzt' 'B-anderer Service' 'I-Personal' 'O'\n",
      " 'B-mediz. Service' 'I-anderer Service' 'I-Arzt' 'I-mediz. Service'\n",
      " 'B-Krankenhaus' 'I-Krankenhaus' 'B-Pflegepersonal' 'B-Personal']\n",
      "{0: np.float64(261.87179487179486), 1: np.float64(5.493813878429263), 2: np.float64(5.651909241837299), 3: np.float64(71.41958041958041), 4: np.float64(0.08550450420280634), 5: np.float64(2.846432552954292), 6: np.float64(78.56153846153846), 7: np.float64(18.705128205128204), 8: np.float64(23.806526806526808), 9: np.float64(3.9280769230769232), 10: np.float64(29.096866096866098), 11: np.float64(9.465245597775718), 12: np.float64(13.545092838196286)}\n",
      "Training fold 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 00:45, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.336446</td>\n",
       "      <td>0.562914</td>\n",
       "      <td>0.734870</td>\n",
       "      <td>0.637500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.241901</td>\n",
       "      <td>0.581114</td>\n",
       "      <td>0.691643</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.220495</td>\n",
       "      <td>0.683616</td>\n",
       "      <td>0.697406</td>\n",
       "      <td>0.690442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.227430</td>\n",
       "      <td>0.667575</td>\n",
       "      <td>0.706052</td>\n",
       "      <td>0.686275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.219041</td>\n",
       "      <td>0.656489</td>\n",
       "      <td>0.743516</td>\n",
       "      <td>0.697297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.decoder.weight', 'lm_head.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fold 2\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {np.int64(0), np.int64(3), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(11), np.int64(13)}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.56      0.83      0.67        35\n",
      "    Krankenhaus       0.61      0.84      0.71        87\n",
      "       Personal       0.56      0.26      0.36        19\n",
      " Pflegepersonal       0.72      0.81      0.76        36\n",
      "anderer Service       0.67      0.45      0.54        40\n",
      " mediz. Service       0.62      0.73      0.67       117\n",
      "\n",
      "      micro avg       0.62      0.72      0.67       334\n",
      "      macro avg       0.62      0.65      0.62       334\n",
      "   weighted avg       0.63      0.72      0.66       334\n",
      "\n",
      "Fold 2 Results - Precision: 0.6223958333333334, Recall: 0.7155688622754491, F1: 0.6657381615598886\n",
      "\n",
      "=== Final Cross-Validation Results ===\n",
      "Average Precision: 0.5824397467320261\n",
      "Average Recall: 0.5962901782641613\n",
      "Average F1 Score: 0.5866917107493632\n",
      "Training complete. Model directory for fold 1 deleted to free memory.\n",
      "Training complete. Model directory for fold 2 deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_filtered_base_best:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fold 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<00:00, 6474.50 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180/180 [00:00<00:00, 5706.88 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180/180 [00:00<00:00, 6111.03 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/model_train_v2.py:791: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-Pflegepersonal' 'B-Arzt' 'B-anderer Service' 'I-Personal' 'O'\n",
      " 'B-mediz. Service' 'I-anderer Service' 'I-Arzt' 'I-mediz. Service'\n",
      " 'B-Krankenhaus' 'I-Krankenhaus' 'B-Pflegepersonal' 'B-Personal']\n",
      "{0: np.float64(261.87179487179486), 1: np.float64(5.493813878429263), 2: np.float64(5.651909241837299), 3: np.float64(71.41958041958041), 4: np.float64(0.08550450420280634), 5: np.float64(2.846432552954292), 6: np.float64(78.56153846153846), 7: np.float64(18.705128205128204), 8: np.float64(23.806526806526808), 9: np.float64(3.9280769230769232), 10: np.float64(29.096866096866098), 11: np.float64(9.465245597775718), 12: np.float64(13.545092838196286)}\n",
      "Training fold 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 00:44, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.684097</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.011111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.539212</td>\n",
       "      <td>0.469697</td>\n",
       "      <td>0.197452</td>\n",
       "      <td>0.278027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.456455</td>\n",
       "      <td>0.498246</td>\n",
       "      <td>0.452229</td>\n",
       "      <td>0.474124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.413883</td>\n",
       "      <td>0.538012</td>\n",
       "      <td>0.585987</td>\n",
       "      <td>0.560976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.400581</td>\n",
       "      <td>0.591065</td>\n",
       "      <td>0.547771</td>\n",
       "      <td>0.568595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.decoder.weight', 'lm_head.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fold 1\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: O_missing seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {np.int64(0), np.int64(5), np.int64(6), np.int64(7), np.int64(9), np.int64(10), np.int64(11), np.int64(23281)}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
      "Warning: Unexpected prediction 23281 found. Assigning 'O_missing'.\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.49      0.73      0.58        48\n",
      "    Krankenhaus       0.60      0.55      0.57        93\n",
      "       Personal       0.00      0.00      0.00        20\n",
      " Pflegepersonal       0.65      0.63      0.64        27\n",
      "anderer Service       0.00      0.00      0.00        53\n",
      " mediz. Service       0.48      0.51      0.50       107\n",
      "\n",
      "      micro avg       0.53      0.45      0.49       348\n",
      "      macro avg       0.37      0.40      0.38       348\n",
      "   weighted avg       0.43      0.45      0.44       348\n",
      "\n",
      "Fold 1 Results - Precision: 0.5302013422818792, Recall: 0.4540229885057471, F1: 0.4891640866873065\n",
      "Starting fold 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [00:00<00:00, 6605.12 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 179/179 [00:00<00:00, 6045.81 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180/180 [00:00<00:00, 5875.24 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/model_train_v2.py:791: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-Pflegepersonal' 'B-Arzt' 'B-anderer Service' 'I-Personal' 'O'\n",
      " 'B-mediz. Service' 'I-anderer Service' 'I-Arzt' 'I-mediz. Service'\n",
      " 'B-Krankenhaus' 'I-Krankenhaus' 'B-Pflegepersonal' 'B-Personal']\n",
      "{0: np.float64(261.87179487179486), 1: np.float64(5.493813878429263), 2: np.float64(5.651909241837299), 3: np.float64(71.41958041958041), 4: np.float64(0.08550450420280634), 5: np.float64(2.846432552954292), 6: np.float64(78.56153846153846), 7: np.float64(18.705128205128204), 8: np.float64(23.806526806526808), 9: np.float64(3.9280769230769232), 10: np.float64(29.096866096866098), 11: np.float64(9.465245597775718), 12: np.float64(13.545092838196286)}\n",
      "Training fold 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 00:45, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.280354</td>\n",
       "      <td>0.551570</td>\n",
       "      <td>0.708934</td>\n",
       "      <td>0.620429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.243453</td>\n",
       "      <td>0.745020</td>\n",
       "      <td>0.538905</td>\n",
       "      <td>0.625418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.209263</td>\n",
       "      <td>0.657068</td>\n",
       "      <td>0.723343</td>\n",
       "      <td>0.688615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.209812</td>\n",
       "      <td>0.682796</td>\n",
       "      <td>0.731988</td>\n",
       "      <td>0.706537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.206193</td>\n",
       "      <td>0.665829</td>\n",
       "      <td>0.763689</td>\n",
       "      <td>0.711409</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.decoder.weight', 'lm_head.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fold 2\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {np.int64(0), np.int64(3), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(11), np.int64(13)}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.64      0.83      0.73        35\n",
      "    Krankenhaus       0.62      0.79      0.70        87\n",
      "       Personal       0.57      0.42      0.48        19\n",
      " Pflegepersonal       0.72      0.81      0.76        36\n",
      "anderer Service       0.47      0.53      0.49        40\n",
      " mediz. Service       0.66      0.75      0.70       117\n",
      "\n",
      "      micro avg       0.63      0.73      0.68       334\n",
      "      macro avg       0.62      0.69      0.64       334\n",
      "   weighted avg       0.63      0.73      0.67       334\n",
      "\n",
      "Fold 2 Results - Precision: 0.6288659793814433, Recall: 0.7305389221556886, F1: 0.6759002770083102\n",
      "\n",
      "=== Final Cross-Validation Results ===\n",
      "Average Precision: 0.5795336608316612\n",
      "Average Recall: 0.5922809553307179\n",
      "Average F1 Score: 0.5825321818478084\n",
      "Training complete. Model directory for fold 1 deleted to free memory.\n",
      "Training complete. Model directory for fold 2 deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_last:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at TUM/GottBERT_base_last were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of the model checkpoint at TUM/GottBERT_base_last were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fold 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<00:00, 6547.25 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180/180 [00:00<00:00, 5869.67 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180/180 [00:00<00:00, 6185.33 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/model_train_v2.py:791: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-Pflegepersonal' 'B-Arzt' 'B-anderer Service' 'I-Personal' 'O'\n",
      " 'B-mediz. Service' 'I-anderer Service' 'I-Arzt' 'I-mediz. Service'\n",
      " 'B-Krankenhaus' 'I-Krankenhaus' 'B-Pflegepersonal' 'B-Personal']\n",
      "{0: np.float64(261.87179487179486), 1: np.float64(5.493813878429263), 2: np.float64(5.651909241837299), 3: np.float64(71.41958041958041), 4: np.float64(0.08550450420280634), 5: np.float64(2.846432552954292), 6: np.float64(78.56153846153846), 7: np.float64(18.705128205128204), 8: np.float64(23.806526806526808), 9: np.float64(3.9280769230769232), 10: np.float64(29.096866096866098), 11: np.float64(9.465245597775718), 12: np.float64(13.545092838196286)}\n",
      "Training fold 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 00:45, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.700529</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.025478</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.602503</td>\n",
       "      <td>0.425926</td>\n",
       "      <td>0.219745</td>\n",
       "      <td>0.289916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.530164</td>\n",
       "      <td>0.483254</td>\n",
       "      <td>0.321656</td>\n",
       "      <td>0.386233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.496689</td>\n",
       "      <td>0.548936</td>\n",
       "      <td>0.410828</td>\n",
       "      <td>0.469945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.465845</td>\n",
       "      <td>0.525253</td>\n",
       "      <td>0.496815</td>\n",
       "      <td>0.510638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.decoder.weight', 'lm_head.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fold 1\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {np.int64(0), np.int64(5), np.int64(6), np.int64(7), np.int64(9), np.int64(11), np.int64(13)}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.45      0.69      0.54        48\n",
      "    Krankenhaus       0.57      0.51      0.53        93\n",
      "       Personal       0.33      0.05      0.09        20\n",
      " Pflegepersonal       0.53      0.59      0.56        27\n",
      "anderer Service       0.00      0.00      0.00        53\n",
      " mediz. Service       0.45      0.50      0.47       107\n",
      "\n",
      "      micro avg       0.49      0.43      0.46       348\n",
      "      macro avg       0.39      0.39      0.37       348\n",
      "   weighted avg       0.41      0.43      0.41       348\n",
      "\n",
      "Fold 1 Results - Precision: 0.487012987012987, Recall: 0.43103448275862066, F1: 0.45731707317073167\n",
      "Starting fold 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [00:00<00:00, 6501.59 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 179/179 [00:00<00:00, 6042.21 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180/180 [00:00<00:00, 5884.26 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/model_train_v2.py:791: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-Pflegepersonal' 'B-Arzt' 'B-anderer Service' 'I-Personal' 'O'\n",
      " 'B-mediz. Service' 'I-anderer Service' 'I-Arzt' 'I-mediz. Service'\n",
      " 'B-Krankenhaus' 'I-Krankenhaus' 'B-Pflegepersonal' 'B-Personal']\n",
      "{0: np.float64(261.87179487179486), 1: np.float64(5.493813878429263), 2: np.float64(5.651909241837299), 3: np.float64(71.41958041958041), 4: np.float64(0.08550450420280634), 5: np.float64(2.846432552954292), 6: np.float64(78.56153846153846), 7: np.float64(18.705128205128204), 8: np.float64(23.806526806526808), 9: np.float64(3.9280769230769232), 10: np.float64(29.096866096866098), 11: np.float64(9.465245597775718), 12: np.float64(13.545092838196286)}\n",
      "Training fold 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 00:45, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.372455</td>\n",
       "      <td>0.522167</td>\n",
       "      <td>0.610951</td>\n",
       "      <td>0.563081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.266914</td>\n",
       "      <td>0.588542</td>\n",
       "      <td>0.651297</td>\n",
       "      <td>0.618331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.239906</td>\n",
       "      <td>0.598485</td>\n",
       "      <td>0.682997</td>\n",
       "      <td>0.637954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.256053</td>\n",
       "      <td>0.635171</td>\n",
       "      <td>0.697406</td>\n",
       "      <td>0.664835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.254847</td>\n",
       "      <td>0.594724</td>\n",
       "      <td>0.714697</td>\n",
       "      <td>0.649215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['lm_head.decoder.weight', 'lm_head.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fold 2\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {np.int64(0), np.int64(3), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(10), np.int64(11), np.int64(13)}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.58      0.83      0.68        35\n",
      "    Krankenhaus       0.56      0.80      0.66        87\n",
      "       Personal       0.27      0.16      0.20        19\n",
      " Pflegepersonal       0.61      0.75      0.67        36\n",
      "anderer Service       0.50      0.15      0.23        40\n",
      " mediz. Service       0.65      0.68      0.66       117\n",
      "\n",
      "      micro avg       0.59      0.64      0.61       334\n",
      "      macro avg       0.53      0.56      0.52       334\n",
      "   weighted avg       0.58      0.64      0.59       334\n",
      "\n",
      "Fold 2 Results - Precision: 0.5895316804407713, Recall: 0.6407185628742516, F1: 0.6140602582496414\n",
      "\n",
      "=== Final Cross-Validation Results ===\n",
      "Average Precision: 0.5382723337268791\n",
      "Average Recall: 0.5358765228164362\n",
      "Average F1 Score: 0.5356886657101865\n",
      "Training complete. Model directory for fold 1 deleted to free memory.\n",
      "Training complete. Model directory for fold 2 deleted to free memory.\n",
      "\n",
      "training and results for distilbert/distilbert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fold 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<00:00, 6548.16 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180/180 [00:00<00:00, 5943.47 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180/180 [00:00<00:00, 6497.26 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/model_train_v2.py:791: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-Pflegepersonal' 'B-Arzt' 'B-anderer Service' 'I-Personal' 'O'\n",
      " 'B-mediz. Service' 'I-anderer Service' 'I-Arzt' 'I-mediz. Service'\n",
      " 'B-Krankenhaus' 'I-Krankenhaus' 'B-Pflegepersonal' 'B-Personal']\n",
      "{0: np.float64(261.87179487179486), 1: np.float64(5.493813878429263), 2: np.float64(5.651909241837299), 3: np.float64(71.41958041958041), 4: np.float64(0.08550450420280634), 5: np.float64(2.846432552954292), 6: np.float64(78.56153846153846), 7: np.float64(18.705128205128204), 8: np.float64(23.806526806526808), 9: np.float64(3.9280769230769232), 10: np.float64(29.096866096866098), 11: np.float64(9.465245597775718), 12: np.float64(13.545092838196286)}\n",
      "Training fold 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 00:21, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.755667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.512207</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.027624</td>\n",
       "      <td>0.053191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.448723</td>\n",
       "      <td>0.546875</td>\n",
       "      <td>0.193370</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.424061</td>\n",
       "      <td>0.657343</td>\n",
       "      <td>0.259669</td>\n",
       "      <td>0.372277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.413659</td>\n",
       "      <td>0.653631</td>\n",
       "      <td>0.323204</td>\n",
       "      <td>0.432532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fold 1\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {np.int64(0), np.int64(5), np.int64(7), np.int64(9), np.int64(11)}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.62      0.44      0.52        54\n",
      "    Krankenhaus       0.45      0.26      0.33       100\n",
      "       Personal       0.00      0.00      0.00        23\n",
      " Pflegepersonal       0.79      0.35      0.49        31\n",
      "anderer Service       0.00      0.00      0.00        61\n",
      " mediz. Service       0.45      0.43      0.44       118\n",
      "\n",
      "      micro avg       0.50      0.29      0.37       387\n",
      "      macro avg       0.38      0.25      0.30       387\n",
      "   weighted avg       0.40      0.29      0.33       387\n",
      "\n",
      "Fold 1 Results - Precision: 0.5, Recall: 0.28940568475452194, F1: 0.36661211129296234\n",
      "Starting fold 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [00:00<00:00, 6582.43 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 179/179 [00:00<00:00, 6107.18 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180/180 [00:00<00:00, 5756.84 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/model_train_v2.py:791: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-Pflegepersonal' 'B-Arzt' 'B-anderer Service' 'I-Personal' 'O'\n",
      " 'B-mediz. Service' 'I-anderer Service' 'I-Arzt' 'I-mediz. Service'\n",
      " 'B-Krankenhaus' 'I-Krankenhaus' 'B-Pflegepersonal' 'B-Personal']\n",
      "{0: np.float64(261.87179487179486), 1: np.float64(5.493813878429263), 2: np.float64(5.651909241837299), 3: np.float64(71.41958041958041), 4: np.float64(0.08550450420280634), 5: np.float64(2.846432552954292), 6: np.float64(78.56153846153846), 7: np.float64(18.705128205128204), 8: np.float64(23.806526806526808), 9: np.float64(3.9280769230769232), 10: np.float64(29.096866096866098), 11: np.float64(9.465245597775718), 12: np.float64(13.545092838196286)}\n",
      "Training fold 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 00:21, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.349676</td>\n",
       "      <td>0.567474</td>\n",
       "      <td>0.396135</td>\n",
       "      <td>0.466572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.315241</td>\n",
       "      <td>0.620283</td>\n",
       "      <td>0.635266</td>\n",
       "      <td>0.627685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.306487</td>\n",
       "      <td>0.589520</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.619266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.291857</td>\n",
       "      <td>0.626424</td>\n",
       "      <td>0.664251</td>\n",
       "      <td>0.644783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.285538</td>\n",
       "      <td>0.650124</td>\n",
       "      <td>0.632850</td>\n",
       "      <td>0.641371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fold 2\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {np.int64(0), np.int64(3), np.int64(5), np.int64(6), np.int64(7), np.int64(9), np.int64(11), np.int64(13)}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.49      0.83      0.62        47\n",
      "    Krankenhaus       0.57      0.75      0.65        96\n",
      "       Personal       0.67      0.19      0.30        21\n",
      " Pflegepersonal       0.63      0.51      0.56        47\n",
      "anderer Service       0.75      0.12      0.21        49\n",
      " mediz. Service       0.62      0.80      0.70       133\n",
      "\n",
      "      micro avg       0.59      0.64      0.61       393\n",
      "      macro avg       0.62      0.53      0.51       393\n",
      "   weighted avg       0.61      0.64      0.58       393\n",
      "\n",
      "Fold 2 Results - Precision: 0.586046511627907, Recall: 0.6412213740458015, F1: 0.6123936816524909\n",
      "\n",
      "=== Final Cross-Validation Results ===\n",
      "Average Precision: 0.5430232558139535\n",
      "Average Recall: 0.4653135294001617\n",
      "Average F1 Score: 0.4895028964727266\n",
      "Training complete. Model directory for fold 1 deleted to free memory.\n",
      "Training complete. Model directory for fold 2 deleted to free memory.\n",
      "\n",
      "training and results for GerMedBERT/medbert-512:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting fold 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 359/359 [00:00<00:00, 5952.92 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180/180 [00:00<00:00, 5451.36 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180/180 [00:00<00:00, 5795.55 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/model_train_v2.py:791: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-Pflegepersonal' 'B-Arzt' 'B-anderer Service' 'I-Personal' 'O'\n",
      " 'B-mediz. Service' 'I-anderer Service' 'I-Arzt' 'I-mediz. Service'\n",
      " 'B-Krankenhaus' 'I-Krankenhaus' 'B-Pflegepersonal' 'B-Personal']\n",
      "{0: np.float64(261.87179487179486), 1: np.float64(5.493813878429263), 2: np.float64(5.651909241837299), 3: np.float64(71.41958041958041), 4: np.float64(0.08550450420280634), 5: np.float64(2.846432552954292), 6: np.float64(78.56153846153846), 7: np.float64(18.705128205128204), 8: np.float64(23.806526806526808), 9: np.float64(3.9280769230769232), 10: np.float64(29.096866096866098), 11: np.float64(9.465245597775718), 12: np.float64(13.545092838196286)}\n",
      "Training fold 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 00:39, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>8.840662</td>\n",
       "      <td>0.026854</td>\n",
       "      <td>0.246334</td>\n",
       "      <td>0.048429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>6.030432</td>\n",
       "      <td>0.031238</td>\n",
       "      <td>0.246334</td>\n",
       "      <td>0.055446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.913649</td>\n",
       "      <td>0.026863</td>\n",
       "      <td>0.246334</td>\n",
       "      <td>0.048443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.360380</td>\n",
       "      <td>0.027255</td>\n",
       "      <td>0.246334</td>\n",
       "      <td>0.049080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.173833</td>\n",
       "      <td>0.060092</td>\n",
       "      <td>0.228739</td>\n",
       "      <td>0.095180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fold 1\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {np.int64(0), np.int64(7)}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.00      0.00      0.00        44\n",
      "    Krankenhaus       0.07      0.93      0.12       102\n",
      "       Personal       0.00      0.00      0.00        25\n",
      " Pflegepersonal       0.00      0.00      0.00        32\n",
      "anderer Service       0.00      0.00      0.00        70\n",
      " mediz. Service       0.00      0.00      0.00       100\n",
      "\n",
      "      micro avg       0.07      0.25      0.10       373\n",
      "      macro avg       0.01      0.16      0.02       373\n",
      "   weighted avg       0.02      0.25      0.03       373\n",
      "\n",
      "Fold 1 Results - Precision: 0.0659264399722415, Recall: 0.2546916890080429, F1: 0.10474090407938257\n",
      "Starting fold 2/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 360/360 [00:00<00:00, 5967.59 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 179/179 [00:00<00:00, 5378.35 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 180/180 [00:00<00:00, 5283.79 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/model_train_v2.py:791: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I-Pflegepersonal' 'B-Arzt' 'B-anderer Service' 'I-Personal' 'O'\n",
      " 'B-mediz. Service' 'I-anderer Service' 'I-Arzt' 'I-mediz. Service'\n",
      " 'B-Krankenhaus' 'I-Krankenhaus' 'B-Pflegepersonal' 'B-Personal']\n",
      "{0: np.float64(261.87179487179486), 1: np.float64(5.493813878429263), 2: np.float64(5.651909241837299), 3: np.float64(71.41958041958041), 4: np.float64(0.08550450420280634), 5: np.float64(2.846432552954292), 6: np.float64(78.56153846153846), 7: np.float64(18.705128205128204), 8: np.float64(23.806526806526808), 9: np.float64(3.9280769230769232), 10: np.float64(29.096866096866098), 11: np.float64(9.465245597775718), 12: np.float64(13.545092838196286)}\n",
      "Training fold 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 00:39, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.922192</td>\n",
       "      <td>0.210667</td>\n",
       "      <td>0.204663</td>\n",
       "      <td>0.207622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.876802</td>\n",
       "      <td>0.307190</td>\n",
       "      <td>0.365285</td>\n",
       "      <td>0.333728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.305647</td>\n",
       "      <td>0.439353</td>\n",
       "      <td>0.422280</td>\n",
       "      <td>0.430647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.047339</td>\n",
       "      <td>0.451835</td>\n",
       "      <td>0.510363</td>\n",
       "      <td>0.479319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.964234</td>\n",
       "      <td>0.441913</td>\n",
       "      <td>0.502591</td>\n",
       "      <td>0.470303</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating fold 2\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {np.int64(0), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(11)}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.49      0.69      0.57        42\n",
      "    Krankenhaus       0.41      0.74      0.53        96\n",
      "       Personal       0.00      0.00      0.00        22\n",
      " Pflegepersonal       0.54      0.77      0.63        48\n",
      "anderer Service       0.00      0.00      0.00        55\n",
      " mediz. Service       0.45      0.65      0.53       106\n",
      "\n",
      "      micro avg       0.46      0.56      0.50       369\n",
      "      macro avg       0.32      0.48      0.38       369\n",
      "   weighted avg       0.36      0.56      0.44       369\n",
      "\n",
      "Fold 2 Results - Precision: 0.4557522123893805, Recall: 0.5582655826558266, F1: 0.5018270401948843\n",
      "\n",
      "=== Final Cross-Validation Results ===\n",
      "Average Precision: 0.260839326180811\n",
      "Average Recall: 0.4064786358319348\n",
      "Average F1 Score: 0.30328397213713343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete. Model directory for fold 1 deleted to free memory.\n",
      "Training complete. Model directory for fold 2 deleted to free memory.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(f'training and results for {model}:')\n",
    "    ate_cat_model_kfold(data, model, rn1=42, rn2=42, k=2, epochs=5)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8db48f35-76b6-4805-b317-795d463f19a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 575/575 [00:00<00:00, 5966.16 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:00<00:00, 4142.07 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/model_train_v2.py:414: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n",
      "Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-ASPECT' 'I-ASPECT']\n",
      "{0: np.float64(0.3705195182121608), 1: np.float64(3.78680014831294), 2: np.float64(27.01851851851852)}\n",
      "Training results for GerMedBERT/medbert-512 with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2016' max='2016' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2016/2016 02:33, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.302630</td>\n",
       "      <td>0.657534</td>\n",
       "      <td>0.596273</td>\n",
       "      <td>0.625407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.032800</td>\n",
       "      <td>0.241518</td>\n",
       "      <td>0.691781</td>\n",
       "      <td>0.627329</td>\n",
       "      <td>0.657980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.032800</td>\n",
       "      <td>0.276279</td>\n",
       "      <td>0.671875</td>\n",
       "      <td>0.534161</td>\n",
       "      <td>0.595156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.148300</td>\n",
       "      <td>0.434866</td>\n",
       "      <td>0.620112</td>\n",
       "      <td>0.689441</td>\n",
       "      <td>0.652941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.148300</td>\n",
       "      <td>0.502979</td>\n",
       "      <td>0.658385</td>\n",
       "      <td>0.658385</td>\n",
       "      <td>0.658385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.046400</td>\n",
       "      <td>0.574677</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>0.670807</td>\n",
       "      <td>0.662577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>0.630149</td>\n",
       "      <td>0.634286</td>\n",
       "      <td>0.689441</td>\n",
       "      <td>0.660714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Unexpected prediction 18 found. Assigning 'O'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['cls.predictions.decoder.weight', 'cls.predictions.decoder.bias'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 72/72 [00:00<00:00, 4259.98 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {np.int64(0), np.int64(1), np.int64(2)}\n",
      "Expected label IDs: {0, 1, 2}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.69      0.65      0.67       135\n",
      "\n",
      "   micro avg       0.69      0.65      0.67       135\n",
      "   macro avg       0.69      0.65      0.67       135\n",
      "weighted avg       0.69      0.65      0.67       135\n",
      "\n",
      "Precision Score: 0.6875\n",
      "Recall Score: 0.6518518518518519\n",
      "F1 Score: 0.6692015209125476\n",
      "Tokens     : ['Ich', 'habe', 'jeden', 'Tag', 'die', 'StationsÃ¤rztin', 'gesehen', ',', 'hier', 'nochmal', 'vielen', 'Dank', 'fÃ¼r', 'die', 'Geduld', 'und', 'die', 'fachliche', 'Betreuung', 'und', 'die', 'Empathie', 'die', 'mir', 'entgegengebracht', 'wurde', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Ich', 'bin', 'seit', 'Juni', '2023', 'in', 'der', 'Uni', 'in', 'Behandlung', 'wegen', 'Brustkrebs', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'B-ASPECT', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'B-ASPECT', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/ate/GerMedBERT_medbert-512_ate_test_results.txt\n",
      "Training complete. Model directory deleted to free memory.\n"
     ]
    }
   ],
   "source": [
    "ate_model(data, \"GerMedBERT/medbert-512\", rn1=42, rn2=42, epochs=7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ABSA-Check",
   "language": "python",
   "name": "absa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
