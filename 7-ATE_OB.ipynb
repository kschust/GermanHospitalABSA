{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c7f13c9-1b7b-407f-b179-1541ab837326",
   "metadata": {},
   "source": [
    "## Aspect Term Extraction (ATE) Training and Fine Tuning for Large Language Models on German hospital reviews using the special OB-Tagging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17fc434d-4822-48ea-bac7-e1807bafb6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sc.uni-leipzig.de/ch31qoni/venv/absa/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "import spacy\n",
    "import ast  # To safely evaluate strings as Python objects\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import evaluate\n",
    "\n",
    "from seqeval.metrics import precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# We need the sys package to load modules from another directory:\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from functions.ate_model_train_OB import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85f55757-4b3a-4569-a677-f10f1c26437d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is CUDA available: True\n",
      "CUDA version: 12.6\n",
      "GPU device name: NVIDIA A30\n"
     ]
    }
   ],
   "source": [
    "print(\"Is CUDA available:\", torch.cuda.is_available())\n",
    "print(\"CUDA version:\", torch.version.cuda)\n",
    "print(\"GPU device name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1946cb1e-d695-4c05-bd50-08835f24acac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset into a DataFrame\n",
    "data = pd.read_csv(\"./data/hospitalABSA/patient_review_labels_absa.csv\")\n",
    "data_ano = pd.read_csv(\"./data/hospitalABSA/patient_review_labels_absa_ano.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "276eba03-cc9e-45a2-b683-bc92ed6ce5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"google-bert/bert-base-german-cased\",\"dbmdz/bert-base-german-cased\", \"dbmdz/bert-base-german-uncased\",\n",
    "          \"FacebookAI/xlm-roberta-base\", \"TUM/GottBERT_base_best\", \"TUM/GottBERT_filtered_base_best\", \"TUM/GottBERT_base_last\",\n",
    "          \"distilbert/distilbert-base-german-cased\", \"GerMedBERT/medbert-512\", \"deepset/gbert-base\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3703225-2c68-436c-9dad-2e4602d0faa5",
   "metadata": {},
   "source": [
    "### 1. Train standard ATE Models for 5, 6, 7, 8, 10, 12 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "874487aa-43bb-49a9-ad41-cca27b523152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training and results for google-bert/bert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5543.37 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4695.36 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for google-bert/bert-base-german-cased with 5 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 02:29, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.142769</td>\n",
       "      <td>0.819328</td>\n",
       "      <td>0.747126</td>\n",
       "      <td>0.781563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.189000</td>\n",
       "      <td>0.166361</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.785441</td>\n",
       "      <td>0.808679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.083200</td>\n",
       "      <td>0.244248</td>\n",
       "      <td>0.795276</td>\n",
       "      <td>0.773946</td>\n",
       "      <td>0.784466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.025800</td>\n",
       "      <td>0.267005</td>\n",
       "      <td>0.818898</td>\n",
       "      <td>0.796935</td>\n",
       "      <td>0.807767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.013500</td>\n",
       "      <td>0.337622</td>\n",
       "      <td>0.823045</td>\n",
       "      <td>0.766284</td>\n",
       "      <td>0.793651</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_google-bert_bert-base-german-cased_42_42_5\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_google-bert_bert-base-german-cased_42_42_5\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4313.52 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.92      0.78      0.84       323\n",
      "\n",
      "   micro avg       0.92      0.78      0.84       323\n",
      "   macro avg       0.92      0.78      0.84       323\n",
      "weighted avg       0.92      0.78      0.84       323\n",
      "\n",
      "Precision Score: 0.9227941176470589\n",
      "Recall Score: 0.7770897832817337\n",
      "F1 Score: 0.8436974789915966\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/5_epochs/google-bert_bert-base-german-cased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/5_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5988.42 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4755.98 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for dbmdz/bert-base-german-cased with 5 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 02:30, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.141073</td>\n",
       "      <td>0.832618</td>\n",
       "      <td>0.763780</td>\n",
       "      <td>0.796715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.203200</td>\n",
       "      <td>0.158556</td>\n",
       "      <td>0.849785</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>0.813142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.095900</td>\n",
       "      <td>0.204931</td>\n",
       "      <td>0.849593</td>\n",
       "      <td>0.822835</td>\n",
       "      <td>0.836000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.037700</td>\n",
       "      <td>0.250930</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.807087</td>\n",
       "      <td>0.820000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>0.290485</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.807087</td>\n",
       "      <td>0.821643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_dbmdz_bert-base-german-cased_42_42_5\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_dbmdz_bert-base-german-cased_42_42_5\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4402.70 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.91      0.74      0.81       315\n",
      "\n",
      "   micro avg       0.91      0.74      0.81       315\n",
      "   macro avg       0.91      0.74      0.81       315\n",
      "weighted avg       0.91      0.74      0.81       315\n",
      "\n",
      "Precision Score: 0.9098039215686274\n",
      "Recall Score: 0.7365079365079366\n",
      "F1 Score: 0.8140350877192983\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/5_epochs/dbmdz_bert-base-german-cased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/5_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-uncased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5413.13 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4339.88 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for dbmdz/bert-base-german-uncased with 5 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 02:30, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.142309</td>\n",
       "      <td>0.832618</td>\n",
       "      <td>0.769841</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.192200</td>\n",
       "      <td>0.165703</td>\n",
       "      <td>0.855204</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.799154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.091500</td>\n",
       "      <td>0.243324</td>\n",
       "      <td>0.843049</td>\n",
       "      <td>0.746032</td>\n",
       "      <td>0.791579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>0.225724</td>\n",
       "      <td>0.839506</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.824242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.025700</td>\n",
       "      <td>0.257734</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.828571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_dbmdz_bert-base-german-uncased_42_42_5\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_dbmdz_bert-base-german-uncased_42_42_5\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4205.52 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.88      0.76      0.82       316\n",
      "\n",
      "   micro avg       0.88      0.76      0.82       316\n",
      "   macro avg       0.88      0.76      0.82       316\n",
      "weighted avg       0.88      0.76      0.82       316\n",
      "\n",
      "Precision Score: 0.8827838827838828\n",
      "Recall Score: 0.7626582278481012\n",
      "F1 Score: 0.8183361629881153\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/5_epochs/dbmdz_bert-base-german-uncased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/5_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for FacebookAI/xlm-roberta-base:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5695.11 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4952.30 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for FacebookAI/xlm-roberta-base with 5 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 04:15, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.191942</td>\n",
       "      <td>0.822642</td>\n",
       "      <td>0.754325</td>\n",
       "      <td>0.787004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.224400</td>\n",
       "      <td>0.180229</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.778547</td>\n",
       "      <td>0.809353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.153900</td>\n",
       "      <td>0.174498</td>\n",
       "      <td>0.865169</td>\n",
       "      <td>0.799308</td>\n",
       "      <td>0.830935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.095900</td>\n",
       "      <td>0.182869</td>\n",
       "      <td>0.840830</td>\n",
       "      <td>0.840830</td>\n",
       "      <td>0.840830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.067900</td>\n",
       "      <td>0.199222</td>\n",
       "      <td>0.837370</td>\n",
       "      <td>0.837370</td>\n",
       "      <td>0.837370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_FacebookAI_xlm-roberta-base_42_42_5\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_FacebookAI_xlm-roberta-base_42_42_5\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4555.72 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.84      0.77      0.80       346\n",
      "\n",
      "   micro avg       0.84      0.77      0.80       346\n",
      "   macro avg       0.84      0.77      0.80       346\n",
      "weighted avg       0.84      0.77      0.80       346\n",
      "\n",
      "Precision Score: 0.8369905956112853\n",
      "Recall Score: 0.7716763005780347\n",
      "F1 Score: 0.8030075187969926\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/5_epochs/FacebookAI_xlm-roberta-base_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/5_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_best:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at TUM/GottBERT_base_best and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6388.83 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4978.78 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for TUM/GottBERT_base_best with 5 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 02:41, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.158621</td>\n",
       "      <td>0.821782</td>\n",
       "      <td>0.783019</td>\n",
       "      <td>0.801932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.183600</td>\n",
       "      <td>0.152034</td>\n",
       "      <td>0.835749</td>\n",
       "      <td>0.816038</td>\n",
       "      <td>0.825776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.108300</td>\n",
       "      <td>0.189798</td>\n",
       "      <td>0.835749</td>\n",
       "      <td>0.816038</td>\n",
       "      <td>0.825776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.054900</td>\n",
       "      <td>0.199698</td>\n",
       "      <td>0.824074</td>\n",
       "      <td>0.839623</td>\n",
       "      <td>0.831776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.037200</td>\n",
       "      <td>0.216283</td>\n",
       "      <td>0.824645</td>\n",
       "      <td>0.820755</td>\n",
       "      <td>0.822695</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_TUM_GottBERT_base_best_42_42_5\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_TUM_GottBERT_base_best_42_42_5\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4695.27 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.86      0.82      0.84       279\n",
      "\n",
      "   micro avg       0.86      0.82      0.84       279\n",
      "   macro avg       0.86      0.82      0.84       279\n",
      "weighted avg       0.86      0.82      0.84       279\n",
      "\n",
      "Precision Score: 0.8641509433962264\n",
      "Recall Score: 0.8207885304659498\n",
      "F1 Score: 0.8419117647058825\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/5_epochs/TUM_GottBERT_base_best_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/5_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_filtered_base_best:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at TUM/GottBERT_filtered_base_best and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6355.24 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4908.18 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for TUM/GottBERT_filtered_base_best with 5 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 02:40, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.120732</td>\n",
       "      <td>0.836634</td>\n",
       "      <td>0.797170</td>\n",
       "      <td>0.816425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.174700</td>\n",
       "      <td>0.149519</td>\n",
       "      <td>0.801843</td>\n",
       "      <td>0.820755</td>\n",
       "      <td>0.811189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.100100</td>\n",
       "      <td>0.196196</td>\n",
       "      <td>0.809302</td>\n",
       "      <td>0.820755</td>\n",
       "      <td>0.814988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.041500</td>\n",
       "      <td>0.214591</td>\n",
       "      <td>0.813636</td>\n",
       "      <td>0.844340</td>\n",
       "      <td>0.828704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.029300</td>\n",
       "      <td>0.223136</td>\n",
       "      <td>0.823256</td>\n",
       "      <td>0.834906</td>\n",
       "      <td>0.829040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_TUM_GottBERT_filtered_base_best_42_42_5\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_TUM_GottBERT_filtered_base_best_42_42_5\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4499.10 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.87      0.78      0.82       279\n",
      "\n",
      "   micro avg       0.87      0.78      0.82       279\n",
      "   macro avg       0.87      0.78      0.82       279\n",
      "weighted avg       0.87      0.78      0.82       279\n",
      "\n",
      "Precision Score: 0.8656126482213439\n",
      "Recall Score: 0.7849462365591398\n",
      "F1 Score: 0.8233082706766918\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/5_epochs/TUM_GottBERT_filtered_base_best_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/5_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_last:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at TUM/GottBERT_base_last were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at TUM/GottBERT_base_last and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6280.13 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4784.56 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for TUM/GottBERT_base_last with 5 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 02:41, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.152716</td>\n",
       "      <td>0.835897</td>\n",
       "      <td>0.768868</td>\n",
       "      <td>0.800983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.177900</td>\n",
       "      <td>0.131368</td>\n",
       "      <td>0.845000</td>\n",
       "      <td>0.797170</td>\n",
       "      <td>0.820388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.110300</td>\n",
       "      <td>0.153732</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.825472</td>\n",
       "      <td>0.829384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.056700</td>\n",
       "      <td>0.214831</td>\n",
       "      <td>0.828431</td>\n",
       "      <td>0.797170</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>0.217990</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.838095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_TUM_GottBERT_base_last_42_42_5\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_TUM_GottBERT_base_last_42_42_5\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4513.53 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.87      0.81      0.84       279\n",
      "\n",
      "   micro avg       0.87      0.81      0.84       279\n",
      "   macro avg       0.87      0.81      0.84       279\n",
      "weighted avg       0.87      0.81      0.84       279\n",
      "\n",
      "Precision Score: 0.8664122137404581\n",
      "Recall Score: 0.8136200716845878\n",
      "F1 Score: 0.8391866913123844\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/5_epochs/TUM_GottBERT_base_last_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/5_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for distilbert/distilbert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6291.09 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5064.49 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for distilbert/distilbert-base-german-cased with 5 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 01:26, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.140078</td>\n",
       "      <td>0.818548</td>\n",
       "      <td>0.799213</td>\n",
       "      <td>0.808765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.208000</td>\n",
       "      <td>0.163722</td>\n",
       "      <td>0.843049</td>\n",
       "      <td>0.740157</td>\n",
       "      <td>0.788260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.104600</td>\n",
       "      <td>0.198602</td>\n",
       "      <td>0.873832</td>\n",
       "      <td>0.736220</td>\n",
       "      <td>0.799145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.054800</td>\n",
       "      <td>0.207215</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>0.796781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.039600</td>\n",
       "      <td>0.216795</td>\n",
       "      <td>0.829167</td>\n",
       "      <td>0.783465</td>\n",
       "      <td>0.805668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_distilbert_distilbert-base-german-cased_42_42_5\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_distilbert_distilbert-base-german-cased_42_42_5\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4786.63 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.81      0.77      0.79       315\n",
      "\n",
      "   micro avg       0.81      0.77      0.79       315\n",
      "   macro avg       0.81      0.77      0.79       315\n",
      "weighted avg       0.81      0.77      0.79       315\n",
      "\n",
      "Precision Score: 0.8114478114478114\n",
      "Recall Score: 0.765079365079365\n",
      "F1 Score: 0.7875816993464052\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/5_epochs/distilbert_distilbert-base-german-cased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/5_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for GerMedBERT/medbert-512:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Device set to use cuda:0\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at GerMedBERT/medbert-512 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5678.35 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4488.83 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for GerMedBERT/medbert-512 with 5 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 02:32, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.113728</td>\n",
       "      <td>0.828054</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.809735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.190200</td>\n",
       "      <td>0.145504</td>\n",
       "      <td>0.789683</td>\n",
       "      <td>0.861472</td>\n",
       "      <td>0.824017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.087200</td>\n",
       "      <td>0.198338</td>\n",
       "      <td>0.834081</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.819383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.215090</td>\n",
       "      <td>0.818565</td>\n",
       "      <td>0.839827</td>\n",
       "      <td>0.829060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.018600</td>\n",
       "      <td>0.263873</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.828947</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_GerMedBERT_medbert-512_42_42_5\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_GerMedBERT_medbert-512_42_42_5\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4200.60 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.90      0.78      0.83       288\n",
      "\n",
      "   micro avg       0.90      0.78      0.83       288\n",
      "   macro avg       0.90      0.78      0.83       288\n",
      "weighted avg       0.90      0.78      0.83       288\n",
      "\n",
      "Precision Score: 0.8995983935742972\n",
      "Recall Score: 0.7777777777777778\n",
      "F1 Score: 0.8342644320297952\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/5_epochs/GerMedBERT_medbert-512_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/5_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for deepset/gbert-base:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5799.49 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4641.50 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for deepset/gbert-base with 5 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 02:33, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.129026</td>\n",
       "      <td>0.808000</td>\n",
       "      <td>0.795276</td>\n",
       "      <td>0.801587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.190300</td>\n",
       "      <td>0.153711</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.826772</td>\n",
       "      <td>0.830040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.095500</td>\n",
       "      <td>0.203675</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.807087</td>\n",
       "      <td>0.821643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.038200</td>\n",
       "      <td>0.209330</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>0.850394</td>\n",
       "      <td>0.840467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.023900</td>\n",
       "      <td>0.232320</td>\n",
       "      <td>0.825095</td>\n",
       "      <td>0.854331</td>\n",
       "      <td>0.839458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_deepset_gbert-base_42_42_5\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_deepset_gbert-base_42_42_5\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4324.51 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.91      0.79      0.84       315\n",
      "\n",
      "   micro avg       0.91      0.79      0.84       315\n",
      "   macro avg       0.91      0.79      0.84       315\n",
      "weighted avg       0.91      0.79      0.84       315\n",
      "\n",
      "Precision Score: 0.9084249084249084\n",
      "Recall Score: 0.7873015873015873\n",
      "F1 Score: 0.8435374149659863\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/5_epochs/deepset_gbert-base_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/5_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(f'training and results for {model}:')\n",
    "    ate_model(data, model, rn1=42, rn2=42, epochs=5, save=True)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f1bc2c5-e7db-40e9-8a45-70b6734a4840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training and results for google-bert/bert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 3446.21 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4640.89 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for google-bert/bert-base-german-cased with 6 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2424' max='2424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2424/2424 02:44, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.143136</td>\n",
       "      <td>0.821577</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.788845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.188600</td>\n",
       "      <td>0.152802</td>\n",
       "      <td>0.817829</td>\n",
       "      <td>0.808429</td>\n",
       "      <td>0.813102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.080800</td>\n",
       "      <td>0.243848</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.735632</td>\n",
       "      <td>0.775758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.023300</td>\n",
       "      <td>0.261013</td>\n",
       "      <td>0.806324</td>\n",
       "      <td>0.781609</td>\n",
       "      <td>0.793774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.013100</td>\n",
       "      <td>0.327090</td>\n",
       "      <td>0.807229</td>\n",
       "      <td>0.770115</td>\n",
       "      <td>0.788235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.013100</td>\n",
       "      <td>0.343247</td>\n",
       "      <td>0.806202</td>\n",
       "      <td>0.796935</td>\n",
       "      <td>0.801541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_google-bert_bert-base-german-cased_42_42_6\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_google-bert_bert-base-german-cased_42_42_6\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4498.15 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.90      0.80      0.85       323\n",
      "\n",
      "   micro avg       0.90      0.80      0.85       323\n",
      "   macro avg       0.90      0.80      0.85       323\n",
      "weighted avg       0.90      0.80      0.85       323\n",
      "\n",
      "Precision Score: 0.9020979020979021\n",
      "Recall Score: 0.7987616099071208\n",
      "F1 Score: 0.8472906403940887\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/6_epochs/google-bert_bert-base-german-cased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/6_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6118.30 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4703.96 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for dbmdz/bert-base-german-cased with 6 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2424' max='2424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2424/2424 02:44, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.163448</td>\n",
       "      <td>0.822034</td>\n",
       "      <td>0.763780</td>\n",
       "      <td>0.791837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.198700</td>\n",
       "      <td>0.143190</td>\n",
       "      <td>0.851240</td>\n",
       "      <td>0.811024</td>\n",
       "      <td>0.830645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.099700</td>\n",
       "      <td>0.197719</td>\n",
       "      <td>0.849802</td>\n",
       "      <td>0.846457</td>\n",
       "      <td>0.848126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.041100</td>\n",
       "      <td>0.225006</td>\n",
       "      <td>0.837945</td>\n",
       "      <td>0.834646</td>\n",
       "      <td>0.836292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.023200</td>\n",
       "      <td>0.275418</td>\n",
       "      <td>0.831373</td>\n",
       "      <td>0.834646</td>\n",
       "      <td>0.833006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.023200</td>\n",
       "      <td>0.290995</td>\n",
       "      <td>0.838583</td>\n",
       "      <td>0.838583</td>\n",
       "      <td>0.838583</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_dbmdz_bert-base-german-cased_42_42_6\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_dbmdz_bert-base-german-cased_42_42_6\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4410.64 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.91      0.79      0.85       315\n",
      "\n",
      "   micro avg       0.91      0.79      0.85       315\n",
      "   macro avg       0.91      0.79      0.85       315\n",
      "weighted avg       0.91      0.79      0.85       315\n",
      "\n",
      "Precision Score: 0.9124087591240876\n",
      "Recall Score: 0.7936507936507936\n",
      "F1 Score: 0.8488964346349744\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/6_epochs/dbmdz_bert-base-german-cased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/6_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-uncased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5681.95 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4751.13 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for dbmdz/bert-base-german-uncased with 6 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2424' max='2424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2424/2424 02:45, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.148295</td>\n",
       "      <td>0.828194</td>\n",
       "      <td>0.746032</td>\n",
       "      <td>0.784969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.191100</td>\n",
       "      <td>0.168569</td>\n",
       "      <td>0.834783</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.796680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.091400</td>\n",
       "      <td>0.231687</td>\n",
       "      <td>0.849138</td>\n",
       "      <td>0.781746</td>\n",
       "      <td>0.814050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.031300</td>\n",
       "      <td>0.257203</td>\n",
       "      <td>0.839130</td>\n",
       "      <td>0.765873</td>\n",
       "      <td>0.800830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>0.289010</td>\n",
       "      <td>0.850427</td>\n",
       "      <td>0.789683</td>\n",
       "      <td>0.818930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>0.307134</td>\n",
       "      <td>0.830579</td>\n",
       "      <td>0.797619</td>\n",
       "      <td>0.813765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_dbmdz_bert-base-german-uncased_42_42_6\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_dbmdz_bert-base-german-uncased_42_42_6\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4484.81 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.89      0.71      0.79       316\n",
      "\n",
      "   micro avg       0.89      0.71      0.79       316\n",
      "   macro avg       0.89      0.71      0.79       316\n",
      "weighted avg       0.89      0.71      0.79       316\n",
      "\n",
      "Precision Score: 0.8884462151394422\n",
      "Recall Score: 0.7056962025316456\n",
      "F1 Score: 0.7865961199294532\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/6_epochs/dbmdz_bert-base-german-uncased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/6_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for FacebookAI/xlm-roberta-base:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5849.37 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5124.35 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for FacebookAI/xlm-roberta-base with 6 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2424' max='2424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2424/2424 04:17, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.174645</td>\n",
       "      <td>0.827715</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.794964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.220300</td>\n",
       "      <td>0.159190</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.813149</td>\n",
       "      <td>0.804795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.156000</td>\n",
       "      <td>0.193529</td>\n",
       "      <td>0.843636</td>\n",
       "      <td>0.802768</td>\n",
       "      <td>0.822695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.093800</td>\n",
       "      <td>0.199891</td>\n",
       "      <td>0.830325</td>\n",
       "      <td>0.795848</td>\n",
       "      <td>0.812721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.072100</td>\n",
       "      <td>0.216175</td>\n",
       "      <td>0.826389</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.824957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.072100</td>\n",
       "      <td>0.252078</td>\n",
       "      <td>0.823322</td>\n",
       "      <td>0.806228</td>\n",
       "      <td>0.814685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_FacebookAI_xlm-roberta-base_42_42_6\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_FacebookAI_xlm-roberta-base_42_42_6\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4647.53 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.84      0.81      0.82       346\n",
      "\n",
      "   micro avg       0.84      0.81      0.82       346\n",
      "   macro avg       0.84      0.81      0.82       346\n",
      "weighted avg       0.84      0.81      0.82       346\n",
      "\n",
      "Precision Score: 0.8403614457831325\n",
      "Recall Score: 0.8063583815028902\n",
      "F1 Score: 0.8230088495575221\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/6_epochs/FacebookAI_xlm-roberta-base_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/6_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_best:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at TUM/GottBERT_base_best and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6512.67 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5138.15 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for TUM/GottBERT_base_best with 6 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2424' max='2424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2424/2424 02:55, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.147684</td>\n",
       "      <td>0.852041</td>\n",
       "      <td>0.787736</td>\n",
       "      <td>0.818627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.182400</td>\n",
       "      <td>0.140712</td>\n",
       "      <td>0.827103</td>\n",
       "      <td>0.834906</td>\n",
       "      <td>0.830986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.108500</td>\n",
       "      <td>0.183245</td>\n",
       "      <td>0.849246</td>\n",
       "      <td>0.797170</td>\n",
       "      <td>0.822384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.054400</td>\n",
       "      <td>0.207949</td>\n",
       "      <td>0.822115</td>\n",
       "      <td>0.806604</td>\n",
       "      <td>0.814286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.270277</td>\n",
       "      <td>0.818605</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.824356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.314616</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.801909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_TUM_GottBERT_base_best_42_42_6\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_TUM_GottBERT_base_best_42_42_6\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4832.09 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.88      0.75      0.81       279\n",
      "\n",
      "   micro avg       0.88      0.75      0.81       279\n",
      "   macro avg       0.88      0.75      0.81       279\n",
      "weighted avg       0.88      0.75      0.81       279\n",
      "\n",
      "Precision Score: 0.8818565400843882\n",
      "Recall Score: 0.7491039426523297\n",
      "F1 Score: 0.810077519379845\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/6_epochs/TUM_GottBERT_base_best_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/6_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_filtered_base_best:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at TUM/GottBERT_filtered_base_best and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6548.45 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5106.93 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for TUM/GottBERT_filtered_base_best with 6 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2424' max='2424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2424/2424 02:55, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.150857</td>\n",
       "      <td>0.805687</td>\n",
       "      <td>0.801887</td>\n",
       "      <td>0.803783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.181600</td>\n",
       "      <td>0.131269</td>\n",
       "      <td>0.839623</td>\n",
       "      <td>0.839623</td>\n",
       "      <td>0.839623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.101600</td>\n",
       "      <td>0.229412</td>\n",
       "      <td>0.854839</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.798995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.183269</td>\n",
       "      <td>0.781893</td>\n",
       "      <td>0.896226</td>\n",
       "      <td>0.835165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>0.211739</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>0.853774</td>\n",
       "      <td>0.830275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>0.221422</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.806604</td>\n",
       "      <td>0.812352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_TUM_GottBERT_filtered_base_best_42_42_6\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_TUM_GottBERT_filtered_base_best_42_42_6\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4686.32 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.88      0.80      0.84       279\n",
      "\n",
      "   micro avg       0.88      0.80      0.84       279\n",
      "   macro avg       0.88      0.80      0.84       279\n",
      "weighted avg       0.88      0.80      0.84       279\n",
      "\n",
      "Precision Score: 0.8784313725490196\n",
      "Recall Score: 0.8028673835125448\n",
      "F1 Score: 0.8389513108614233\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/6_epochs/TUM_GottBERT_filtered_base_best_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/6_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_last:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at TUM/GottBERT_base_last were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at TUM/GottBERT_base_last and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6531.65 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5067.10 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for TUM/GottBERT_base_last with 6 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2424' max='2424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2424/2424 02:55, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.163724</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.792079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.183700</td>\n",
       "      <td>0.135094</td>\n",
       "      <td>0.834862</td>\n",
       "      <td>0.858491</td>\n",
       "      <td>0.846512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.111700</td>\n",
       "      <td>0.156065</td>\n",
       "      <td>0.822727</td>\n",
       "      <td>0.853774</td>\n",
       "      <td>0.837963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.060200</td>\n",
       "      <td>0.217409</td>\n",
       "      <td>0.837321</td>\n",
       "      <td>0.825472</td>\n",
       "      <td>0.831354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.038400</td>\n",
       "      <td>0.278484</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.801887</td>\n",
       "      <td>0.817308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.038400</td>\n",
       "      <td>0.281253</td>\n",
       "      <td>0.825472</td>\n",
       "      <td>0.825472</td>\n",
       "      <td>0.825472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_TUM_GottBERT_base_last_42_42_6\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_TUM_GottBERT_base_last_42_42_6\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4586.40 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.89      0.77      0.82       279\n",
      "\n",
      "   micro avg       0.89      0.77      0.82       279\n",
      "   macro avg       0.89      0.77      0.82       279\n",
      "weighted avg       0.89      0.77      0.82       279\n",
      "\n",
      "Precision Score: 0.8916666666666667\n",
      "Recall Score: 0.7670250896057348\n",
      "F1 Score: 0.8246628131021194\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/6_epochs/TUM_GottBERT_base_last_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/6_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for distilbert/distilbert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6517.57 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5066.92 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for distilbert/distilbert-base-german-cased with 6 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2424' max='2424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2424/2424 01:33, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.144710</td>\n",
       "      <td>0.850877</td>\n",
       "      <td>0.763780</td>\n",
       "      <td>0.804979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.202000</td>\n",
       "      <td>0.153486</td>\n",
       "      <td>0.837607</td>\n",
       "      <td>0.771654</td>\n",
       "      <td>0.803279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.102500</td>\n",
       "      <td>0.205724</td>\n",
       "      <td>0.866359</td>\n",
       "      <td>0.740157</td>\n",
       "      <td>0.798301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.048000</td>\n",
       "      <td>0.218037</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.767717</td>\n",
       "      <td>0.797546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.035300</td>\n",
       "      <td>0.252324</td>\n",
       "      <td>0.843478</td>\n",
       "      <td>0.763780</td>\n",
       "      <td>0.801653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.035300</td>\n",
       "      <td>0.256023</td>\n",
       "      <td>0.839662</td>\n",
       "      <td>0.783465</td>\n",
       "      <td>0.810591</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_distilbert_distilbert-base-german-cased_42_42_6\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_distilbert_distilbert-base-german-cased_42_42_6\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4864.01 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.90      0.77      0.83       315\n",
      "\n",
      "   micro avg       0.90      0.77      0.83       315\n",
      "   macro avg       0.90      0.77      0.83       315\n",
      "weighted avg       0.90      0.77      0.83       315\n",
      "\n",
      "Precision Score: 0.9\n",
      "Recall Score: 0.7714285714285715\n",
      "F1 Score: 0.8307692307692307\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/6_epochs/distilbert_distilbert-base-german-cased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/6_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for GerMedBERT/medbert-512:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Device set to use cuda:0\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at GerMedBERT/medbert-512 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5732.79 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4576.56 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for GerMedBERT/medbert-512 with 6 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2424' max='2424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2424/2424 02:46, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.115652</td>\n",
       "      <td>0.816667</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.832272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.187700</td>\n",
       "      <td>0.127233</td>\n",
       "      <td>0.815574</td>\n",
       "      <td>0.861472</td>\n",
       "      <td>0.837895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.087300</td>\n",
       "      <td>0.212654</td>\n",
       "      <td>0.834821</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.821978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.037900</td>\n",
       "      <td>0.214262</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.831169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>0.284796</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.836910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>0.283669</td>\n",
       "      <td>0.827731</td>\n",
       "      <td>0.852814</td>\n",
       "      <td>0.840085</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_GerMedBERT_medbert-512_42_42_6\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_GerMedBERT_medbert-512_42_42_6\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4226.88 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.93      0.77      0.84       288\n",
      "\n",
      "   micro avg       0.93      0.77      0.84       288\n",
      "   macro avg       0.93      0.77      0.84       288\n",
      "weighted avg       0.93      0.77      0.84       288\n",
      "\n",
      "Precision Score: 0.9324894514767933\n",
      "Recall Score: 0.7673611111111112\n",
      "F1 Score: 0.8419047619047619\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/6_epochs/GerMedBERT_medbert-512_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/6_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for deepset/gbert-base:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5868.43 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4782.45 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for deepset/gbert-base with 6 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2424' max='2424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2424/2424 02:47, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.141743</td>\n",
       "      <td>0.832618</td>\n",
       "      <td>0.763780</td>\n",
       "      <td>0.796715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.195200</td>\n",
       "      <td>0.146101</td>\n",
       "      <td>0.832700</td>\n",
       "      <td>0.862205</td>\n",
       "      <td>0.847195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.094100</td>\n",
       "      <td>0.255068</td>\n",
       "      <td>0.884444</td>\n",
       "      <td>0.783465</td>\n",
       "      <td>0.830898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.032100</td>\n",
       "      <td>0.248563</td>\n",
       "      <td>0.843373</td>\n",
       "      <td>0.826772</td>\n",
       "      <td>0.834990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>0.272559</td>\n",
       "      <td>0.830769</td>\n",
       "      <td>0.850394</td>\n",
       "      <td>0.840467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>0.302068</td>\n",
       "      <td>0.835341</td>\n",
       "      <td>0.818898</td>\n",
       "      <td>0.827038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_deepset_gbert-base_42_42_6\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_deepset_gbert-base_42_42_6\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4461.56 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.85      0.81      0.83       315\n",
      "\n",
      "   micro avg       0.85      0.81      0.83       315\n",
      "   macro avg       0.85      0.81      0.83       315\n",
      "weighted avg       0.85      0.81      0.83       315\n",
      "\n",
      "Precision Score: 0.85\n",
      "Recall Score: 0.8095238095238095\n",
      "F1 Score: 0.8292682926829269\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/6_epochs/deepset_gbert-base_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/6_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(f'training and results for {model}:')\n",
    "    ate_model(data, model, rn1=42, rn2=42, epochs=6, save=True)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f741704-d93b-4625-991b-3f1bb828ad0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training and results for google-bert/bert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5782.35 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4778.19 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for google-bert/bert-base-german-cased with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2828' max='2828' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2828/2828 03:14, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.152189</td>\n",
       "      <td>0.838298</td>\n",
       "      <td>0.754789</td>\n",
       "      <td>0.794355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.191800</td>\n",
       "      <td>0.140404</td>\n",
       "      <td>0.848980</td>\n",
       "      <td>0.796935</td>\n",
       "      <td>0.822134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.081200</td>\n",
       "      <td>0.261907</td>\n",
       "      <td>0.795181</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.776471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.022200</td>\n",
       "      <td>0.306329</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>0.785441</td>\n",
       "      <td>0.802348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>0.333421</td>\n",
       "      <td>0.798450</td>\n",
       "      <td>0.789272</td>\n",
       "      <td>0.793834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>0.370111</td>\n",
       "      <td>0.820408</td>\n",
       "      <td>0.770115</td>\n",
       "      <td>0.794466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>0.369743</td>\n",
       "      <td>0.817460</td>\n",
       "      <td>0.789272</td>\n",
       "      <td>0.803119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_google-bert_bert-base-german-cased_42_42_7\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_google-bert_bert-base-german-cased_42_42_7\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4316.09 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.92      0.76      0.84       323\n",
      "\n",
      "   micro avg       0.92      0.76      0.84       323\n",
      "   macro avg       0.92      0.76      0.84       323\n",
      "weighted avg       0.92      0.76      0.84       323\n",
      "\n",
      "Precision Score: 0.9216417910447762\n",
      "Recall Score: 0.7647058823529411\n",
      "F1 Score: 0.8358714043993233\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/7_epochs/google-bert_bert-base-german-cased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/7_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5851.94 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4766.74 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for dbmdz/bert-base-german-cased with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2828' max='2828' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2828/2828 03:13, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.160473</td>\n",
       "      <td>0.855204</td>\n",
       "      <td>0.744094</td>\n",
       "      <td>0.795789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.201500</td>\n",
       "      <td>0.139999</td>\n",
       "      <td>0.848361</td>\n",
       "      <td>0.814961</td>\n",
       "      <td>0.831325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.098100</td>\n",
       "      <td>0.203983</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.826772</td>\n",
       "      <td>0.820312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.041200</td>\n",
       "      <td>0.203095</td>\n",
       "      <td>0.819923</td>\n",
       "      <td>0.842520</td>\n",
       "      <td>0.831068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.021600</td>\n",
       "      <td>0.299440</td>\n",
       "      <td>0.840637</td>\n",
       "      <td>0.830709</td>\n",
       "      <td>0.835644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.021600</td>\n",
       "      <td>0.317098</td>\n",
       "      <td>0.853556</td>\n",
       "      <td>0.803150</td>\n",
       "      <td>0.827586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.335810</td>\n",
       "      <td>0.838057</td>\n",
       "      <td>0.814961</td>\n",
       "      <td>0.826347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_dbmdz_bert-base-german-cased_42_42_7\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_dbmdz_bert-base-german-cased_42_42_7\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4462.35 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.88      0.79      0.83       315\n",
      "\n",
      "   micro avg       0.88      0.79      0.83       315\n",
      "   macro avg       0.88      0.79      0.83       315\n",
      "weighted avg       0.88      0.79      0.83       315\n",
      "\n",
      "Precision Score: 0.8771929824561403\n",
      "Recall Score: 0.7936507936507936\n",
      "F1 Score: 0.8333333333333334\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/7_epochs/dbmdz_bert-base-german-cased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/7_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-uncased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5653.10 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4643.38 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for dbmdz/bert-base-german-uncased with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2828' max='2828' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2828/2828 03:14, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.149725</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.753968</td>\n",
       "      <td>0.788382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.191600</td>\n",
       "      <td>0.182563</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>0.726190</td>\n",
       "      <td>0.797386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.090300</td>\n",
       "      <td>0.232095</td>\n",
       "      <td>0.860360</td>\n",
       "      <td>0.757937</td>\n",
       "      <td>0.805907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.033800</td>\n",
       "      <td>0.240383</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.832653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>0.286075</td>\n",
       "      <td>0.830645</td>\n",
       "      <td>0.817460</td>\n",
       "      <td>0.824000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>0.297768</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.828402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.007000</td>\n",
       "      <td>0.302323</td>\n",
       "      <td>0.836653</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.834990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_dbmdz_bert-base-german-uncased_42_42_7\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_dbmdz_bert-base-german-uncased_42_42_7\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4407.19 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.91      0.76      0.83       316\n",
      "\n",
      "   micro avg       0.91      0.76      0.83       316\n",
      "   macro avg       0.91      0.76      0.83       316\n",
      "weighted avg       0.91      0.76      0.83       316\n",
      "\n",
      "Precision Score: 0.9060150375939849\n",
      "Recall Score: 0.7626582278481012\n",
      "F1 Score: 0.8281786941580755\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/7_epochs/dbmdz_bert-base-german-uncased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/7_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for FacebookAI/xlm-roberta-base:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5853.56 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4965.71 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for FacebookAI/xlm-roberta-base with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2828' max='2828' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2828/2828 05:02, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.144450</td>\n",
       "      <td>0.801370</td>\n",
       "      <td>0.809689</td>\n",
       "      <td>0.805508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.223600</td>\n",
       "      <td>0.162242</td>\n",
       "      <td>0.810345</td>\n",
       "      <td>0.813149</td>\n",
       "      <td>0.811744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.151500</td>\n",
       "      <td>0.179898</td>\n",
       "      <td>0.848708</td>\n",
       "      <td>0.795848</td>\n",
       "      <td>0.821429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.098500</td>\n",
       "      <td>0.186958</td>\n",
       "      <td>0.816993</td>\n",
       "      <td>0.865052</td>\n",
       "      <td>0.840336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.067100</td>\n",
       "      <td>0.221011</td>\n",
       "      <td>0.798722</td>\n",
       "      <td>0.865052</td>\n",
       "      <td>0.830565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.067100</td>\n",
       "      <td>0.250270</td>\n",
       "      <td>0.821918</td>\n",
       "      <td>0.830450</td>\n",
       "      <td>0.826162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.032800</td>\n",
       "      <td>0.266046</td>\n",
       "      <td>0.799353</td>\n",
       "      <td>0.854671</td>\n",
       "      <td>0.826087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_FacebookAI_xlm-roberta-base_42_42_7\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_FacebookAI_xlm-roberta-base_42_42_7\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4559.37 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.89      0.79      0.83       346\n",
      "\n",
      "   micro avg       0.89      0.79      0.83       346\n",
      "   macro avg       0.89      0.79      0.83       346\n",
      "weighted avg       0.89      0.79      0.83       346\n",
      "\n",
      "Precision Score: 0.8888888888888888\n",
      "Recall Score: 0.7861271676300579\n",
      "F1 Score: 0.8343558282208589\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/7_epochs/FacebookAI_xlm-roberta-base_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/7_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_best:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at TUM/GottBERT_base_best and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6496.79 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5048.38 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for TUM/GottBERT_base_best with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2828' max='2828' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2828/2828 03:24, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.153794</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.803922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.182800</td>\n",
       "      <td>0.116576</td>\n",
       "      <td>0.808889</td>\n",
       "      <td>0.858491</td>\n",
       "      <td>0.832952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.109600</td>\n",
       "      <td>0.185088</td>\n",
       "      <td>0.808411</td>\n",
       "      <td>0.816038</td>\n",
       "      <td>0.812207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.051500</td>\n",
       "      <td>0.200544</td>\n",
       "      <td>0.826484</td>\n",
       "      <td>0.853774</td>\n",
       "      <td>0.839907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>0.275151</td>\n",
       "      <td>0.816901</td>\n",
       "      <td>0.820755</td>\n",
       "      <td>0.818824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>0.289001</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.858491</td>\n",
       "      <td>0.834862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.304613</td>\n",
       "      <td>0.820755</td>\n",
       "      <td>0.820755</td>\n",
       "      <td>0.820755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_TUM_GottBERT_base_best_42_42_7\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_TUM_GottBERT_base_best_42_42_7\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4675.98 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.87      0.80      0.83       279\n",
      "\n",
      "   micro avg       0.87      0.80      0.83       279\n",
      "   macro avg       0.87      0.80      0.83       279\n",
      "weighted avg       0.87      0.80      0.83       279\n",
      "\n",
      "Precision Score: 0.8682170542635659\n",
      "Recall Score: 0.8028673835125448\n",
      "F1 Score: 0.8342644320297952\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/7_epochs/TUM_GottBERT_base_best_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/7_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_filtered_base_best:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at TUM/GottBERT_filtered_base_best and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6496.51 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5054.52 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for TUM/GottBERT_filtered_base_best with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2828' max='2828' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2828/2828 03:23, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.137183</td>\n",
       "      <td>0.822967</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.817102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.186300</td>\n",
       "      <td>0.172187</td>\n",
       "      <td>0.828431</td>\n",
       "      <td>0.797170</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.099200</td>\n",
       "      <td>0.207794</td>\n",
       "      <td>0.792627</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.801865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.051800</td>\n",
       "      <td>0.199818</td>\n",
       "      <td>0.807175</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.827586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.270295</td>\n",
       "      <td>0.838235</td>\n",
       "      <td>0.806604</td>\n",
       "      <td>0.822115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.030500</td>\n",
       "      <td>0.313414</td>\n",
       "      <td>0.839378</td>\n",
       "      <td>0.764151</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>0.302727</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.806604</td>\n",
       "      <td>0.812352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_TUM_GottBERT_filtered_base_best_42_42_7\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_TUM_GottBERT_filtered_base_best_42_42_7\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4656.48 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.82      0.79      0.80       279\n",
      "\n",
      "   micro avg       0.82      0.79      0.80       279\n",
      "   macro avg       0.82      0.79      0.80       279\n",
      "weighted avg       0.82      0.79      0.80       279\n",
      "\n",
      "Precision Score: 0.8208955223880597\n",
      "Recall Score: 0.7885304659498208\n",
      "F1 Score: 0.8043875685557587\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/7_epochs/TUM_GottBERT_filtered_base_best_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/7_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_last:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at TUM/GottBERT_base_last were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at TUM/GottBERT_base_last and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6588.24 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5057.84 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for TUM/GottBERT_base_last with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2828' max='2828' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2828/2828 03:23, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.180353</td>\n",
       "      <td>0.843434</td>\n",
       "      <td>0.787736</td>\n",
       "      <td>0.814634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.179900</td>\n",
       "      <td>0.123179</td>\n",
       "      <td>0.811060</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.820513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.110300</td>\n",
       "      <td>0.165871</td>\n",
       "      <td>0.830275</td>\n",
       "      <td>0.853774</td>\n",
       "      <td>0.841860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.054100</td>\n",
       "      <td>0.150279</td>\n",
       "      <td>0.812766</td>\n",
       "      <td>0.900943</td>\n",
       "      <td>0.854586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.043400</td>\n",
       "      <td>0.203105</td>\n",
       "      <td>0.816239</td>\n",
       "      <td>0.900943</td>\n",
       "      <td>0.856502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.043400</td>\n",
       "      <td>0.233076</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.877358</td>\n",
       "      <td>0.845455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.018300</td>\n",
       "      <td>0.268538</td>\n",
       "      <td>0.832558</td>\n",
       "      <td>0.844340</td>\n",
       "      <td>0.838407</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_TUM_GottBERT_base_last_42_42_7\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_TUM_GottBERT_base_last_42_42_7\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4671.48 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.86      0.84      0.85       279\n",
      "\n",
      "   micro avg       0.86      0.84      0.85       279\n",
      "   macro avg       0.86      0.84      0.85       279\n",
      "weighted avg       0.86      0.84      0.85       279\n",
      "\n",
      "Precision Score: 0.8571428571428571\n",
      "Recall Score: 0.8387096774193549\n",
      "F1 Score: 0.8478260869565217\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/7_epochs/TUM_GottBERT_base_last_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/7_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for distilbert/distilbert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6531.99 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5173.92 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for distilbert/distilbert-base-german-cased with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2828' max='2828' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2828/2828 01:48, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.139097</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.771654</td>\n",
       "      <td>0.796748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.205700</td>\n",
       "      <td>0.155902</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.755906</td>\n",
       "      <td>0.790123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.105200</td>\n",
       "      <td>0.212884</td>\n",
       "      <td>0.876777</td>\n",
       "      <td>0.728346</td>\n",
       "      <td>0.795699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.049400</td>\n",
       "      <td>0.211797</td>\n",
       "      <td>0.855263</td>\n",
       "      <td>0.767717</td>\n",
       "      <td>0.809129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>0.248456</td>\n",
       "      <td>0.867580</td>\n",
       "      <td>0.748031</td>\n",
       "      <td>0.803383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>0.253412</td>\n",
       "      <td>0.839827</td>\n",
       "      <td>0.763780</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>0.270706</td>\n",
       "      <td>0.850220</td>\n",
       "      <td>0.759843</td>\n",
       "      <td>0.802495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_distilbert_distilbert-base-german-cased_42_42_7\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_distilbert_distilbert-base-german-cased_42_42_7\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4872.10 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.87      0.76      0.81       315\n",
      "\n",
      "   micro avg       0.87      0.76      0.81       315\n",
      "   macro avg       0.87      0.76      0.81       315\n",
      "weighted avg       0.87      0.76      0.81       315\n",
      "\n",
      "Precision Score: 0.8695652173913043\n",
      "Recall Score: 0.7619047619047619\n",
      "F1 Score: 0.8121827411167514\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/7_epochs/distilbert_distilbert-base-german-cased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/7_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for GerMedBERT/medbert-512:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at GerMedBERT/medbert-512 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5722.43 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4643.53 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for GerMedBERT/medbert-512 with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2828' max='2828' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2828/2828 03:12, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.104758</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.829374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.190200</td>\n",
       "      <td>0.145571</td>\n",
       "      <td>0.797710</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.847870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.088600</td>\n",
       "      <td>0.209467</td>\n",
       "      <td>0.845794</td>\n",
       "      <td>0.783550</td>\n",
       "      <td>0.813483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.037600</td>\n",
       "      <td>0.224285</td>\n",
       "      <td>0.831111</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.820175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>0.275971</td>\n",
       "      <td>0.824034</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.827586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>0.309367</td>\n",
       "      <td>0.819742</td>\n",
       "      <td>0.826840</td>\n",
       "      <td>0.823276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.320667</td>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.825806</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_GerMedBERT_medbert-512_42_42_7\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_GerMedBERT_medbert-512_42_42_7\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4257.92 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.83      0.81      0.82       288\n",
      "\n",
      "   micro avg       0.83      0.81      0.82       288\n",
      "   macro avg       0.83      0.81      0.82       288\n",
      "weighted avg       0.83      0.81      0.82       288\n",
      "\n",
      "Precision Score: 0.8268551236749117\n",
      "Recall Score: 0.8125\n",
      "F1 Score: 0.8196147110332749\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/7_epochs/GerMedBERT_medbert-512_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/7_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for deepset/gbert-base:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5853.21 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4829.39 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for deepset/gbert-base with 7 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2828' max='2828' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2828/2828 03:11, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.123697</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.814961</td>\n",
       "      <td>0.818182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.190100</td>\n",
       "      <td>0.145844</td>\n",
       "      <td>0.831373</td>\n",
       "      <td>0.834646</td>\n",
       "      <td>0.833006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.089500</td>\n",
       "      <td>0.233380</td>\n",
       "      <td>0.860169</td>\n",
       "      <td>0.799213</td>\n",
       "      <td>0.828571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.033400</td>\n",
       "      <td>0.235083</td>\n",
       "      <td>0.843373</td>\n",
       "      <td>0.826772</td>\n",
       "      <td>0.834990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.276270</td>\n",
       "      <td>0.813688</td>\n",
       "      <td>0.842520</td>\n",
       "      <td>0.827853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.298147</td>\n",
       "      <td>0.819923</td>\n",
       "      <td>0.842520</td>\n",
       "      <td>0.831068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>0.300986</td>\n",
       "      <td>0.831373</td>\n",
       "      <td>0.834646</td>\n",
       "      <td>0.833006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_deepset_gbert-base_42_42_7\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_deepset_gbert-base_42_42_7\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4474.49 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.91      0.77      0.84       315\n",
      "\n",
      "   micro avg       0.91      0.77      0.84       315\n",
      "   macro avg       0.91      0.77      0.84       315\n",
      "weighted avg       0.91      0.77      0.84       315\n",
      "\n",
      "Precision Score: 0.9070631970260223\n",
      "Recall Score: 0.7746031746031746\n",
      "F1 Score: 0.8356164383561643\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/7_epochs/deepset_gbert-base_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/7_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(f'training and results for {model}:')\n",
    "    ate_model(data, model, rn1=42, rn2=42, epochs=7, save=True)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7037318b-7a20-40d7-9bd1-a5e4e7586e07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training and results for google-bert/bert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5618.77 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4816.16 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for google-bert/bert-base-german-cased with 8 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3232' max='3232' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3232/3232 03:37, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.149254</td>\n",
       "      <td>0.815900</td>\n",
       "      <td>0.747126</td>\n",
       "      <td>0.780000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.192400</td>\n",
       "      <td>0.186539</td>\n",
       "      <td>0.838983</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.796781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.081300</td>\n",
       "      <td>0.255996</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.747126</td>\n",
       "      <td>0.792683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.022700</td>\n",
       "      <td>0.280217</td>\n",
       "      <td>0.832636</td>\n",
       "      <td>0.762452</td>\n",
       "      <td>0.796000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.015200</td>\n",
       "      <td>0.375729</td>\n",
       "      <td>0.819328</td>\n",
       "      <td>0.747126</td>\n",
       "      <td>0.781563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.015200</td>\n",
       "      <td>0.402640</td>\n",
       "      <td>0.823293</td>\n",
       "      <td>0.785441</td>\n",
       "      <td>0.803922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.406842</td>\n",
       "      <td>0.820717</td>\n",
       "      <td>0.789272</td>\n",
       "      <td>0.804688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.429536</td>\n",
       "      <td>0.829960</td>\n",
       "      <td>0.785441</td>\n",
       "      <td>0.807087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_google-bert_bert-base-german-cased_42_42_8\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_google-bert_bert-base-german-cased_42_42_8\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4382.49 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.91      0.77      0.83       323\n",
      "\n",
      "   micro avg       0.91      0.77      0.83       323\n",
      "   macro avg       0.91      0.77      0.83       323\n",
      "weighted avg       0.91      0.77      0.83       323\n",
      "\n",
      "Precision Score: 0.9084249084249084\n",
      "Recall Score: 0.7678018575851393\n",
      "F1 Score: 0.8322147651006712\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/8_epochs/google-bert_bert-base-german-cased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/8_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6021.20 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4875.19 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for dbmdz/bert-base-german-cased with 8 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3232' max='3232' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3232/3232 03:37, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.141909</td>\n",
       "      <td>0.789272</td>\n",
       "      <td>0.811024</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.200700</td>\n",
       "      <td>0.156389</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.846457</td>\n",
       "      <td>0.839844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.099100</td>\n",
       "      <td>0.210994</td>\n",
       "      <td>0.801471</td>\n",
       "      <td>0.858268</td>\n",
       "      <td>0.828897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.037600</td>\n",
       "      <td>0.228102</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.885827</td>\n",
       "      <td>0.842697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>0.309773</td>\n",
       "      <td>0.821970</td>\n",
       "      <td>0.854331</td>\n",
       "      <td>0.837838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>0.366385</td>\n",
       "      <td>0.843478</td>\n",
       "      <td>0.763780</td>\n",
       "      <td>0.801653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>0.361147</td>\n",
       "      <td>0.840637</td>\n",
       "      <td>0.830709</td>\n",
       "      <td>0.835644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.360834</td>\n",
       "      <td>0.835938</td>\n",
       "      <td>0.842520</td>\n",
       "      <td>0.839216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_dbmdz_bert-base-german-cased_42_42_8\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_dbmdz_bert-base-german-cased_42_42_8\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4469.62 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.85      0.85      0.85       315\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       315\n",
      "   macro avg       0.85      0.85      0.85       315\n",
      "weighted avg       0.85      0.85      0.85       315\n",
      "\n",
      "Precision Score: 0.8503184713375797\n",
      "Recall Score: 0.8476190476190476\n",
      "F1 Score: 0.848966613672496\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/8_epochs/dbmdz_bert-base-german-cased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/8_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-uncased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5666.05 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4772.43 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for dbmdz/bert-base-german-uncased with 8 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3232' max='3232' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3232/3232 03:38, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.137137</td>\n",
       "      <td>0.835498</td>\n",
       "      <td>0.765873</td>\n",
       "      <td>0.799172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.186700</td>\n",
       "      <td>0.166352</td>\n",
       "      <td>0.843478</td>\n",
       "      <td>0.769841</td>\n",
       "      <td>0.804979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.090500</td>\n",
       "      <td>0.215347</td>\n",
       "      <td>0.859574</td>\n",
       "      <td>0.801587</td>\n",
       "      <td>0.829569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.033800</td>\n",
       "      <td>0.243860</td>\n",
       "      <td>0.844262</td>\n",
       "      <td>0.817460</td>\n",
       "      <td>0.830645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.018900</td>\n",
       "      <td>0.292529</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.825397</td>\n",
       "      <td>0.833667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.018900</td>\n",
       "      <td>0.304921</td>\n",
       "      <td>0.820611</td>\n",
       "      <td>0.853175</td>\n",
       "      <td>0.836576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.323235</td>\n",
       "      <td>0.841897</td>\n",
       "      <td>0.845238</td>\n",
       "      <td>0.843564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.328161</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.842105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_dbmdz_bert-base-german-uncased_42_42_8\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_dbmdz_bert-base-german-uncased_42_42_8\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4513.38 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.89      0.77      0.83       316\n",
      "\n",
      "   micro avg       0.89      0.77      0.83       316\n",
      "   macro avg       0.89      0.77      0.83       316\n",
      "weighted avg       0.89      0.77      0.83       316\n",
      "\n",
      "Precision Score: 0.8933823529411765\n",
      "Recall Score: 0.7689873417721519\n",
      "F1 Score: 0.826530612244898\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/8_epochs/dbmdz_bert-base-german-uncased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/8_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for FacebookAI/xlm-roberta-base:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5888.87 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5063.16 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for FacebookAI/xlm-roberta-base with 8 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3232' max='3232' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3232/3232 05:39, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.151830</td>\n",
       "      <td>0.815498</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.789286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.212300</td>\n",
       "      <td>0.148696</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.775087</td>\n",
       "      <td>0.798574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.142600</td>\n",
       "      <td>0.155815</td>\n",
       "      <td>0.864769</td>\n",
       "      <td>0.840830</td>\n",
       "      <td>0.852632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.080400</td>\n",
       "      <td>0.189003</td>\n",
       "      <td>0.774854</td>\n",
       "      <td>0.916955</td>\n",
       "      <td>0.839937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.056500</td>\n",
       "      <td>0.228572</td>\n",
       "      <td>0.808176</td>\n",
       "      <td>0.889273</td>\n",
       "      <td>0.846787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.056500</td>\n",
       "      <td>0.298263</td>\n",
       "      <td>0.836237</td>\n",
       "      <td>0.830450</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>0.286758</td>\n",
       "      <td>0.786787</td>\n",
       "      <td>0.906574</td>\n",
       "      <td>0.842444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.024300</td>\n",
       "      <td>0.267071</td>\n",
       "      <td>0.819355</td>\n",
       "      <td>0.878893</td>\n",
       "      <td>0.848080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_FacebookAI_xlm-roberta-base_42_42_8\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_FacebookAI_xlm-roberta-base_42_42_8\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4642.49 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.88      0.75      0.81       346\n",
      "\n",
      "   micro avg       0.88      0.75      0.81       346\n",
      "   macro avg       0.88      0.75      0.81       346\n",
      "weighted avg       0.88      0.75      0.81       346\n",
      "\n",
      "Precision Score: 0.8847457627118644\n",
      "Recall Score: 0.7543352601156069\n",
      "F1 Score: 0.814352574102964\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/8_epochs/FacebookAI_xlm-roberta-base_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/8_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_best:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at TUM/GottBERT_base_best and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6540.12 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5099.73 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for TUM/GottBERT_base_best with 8 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3232' max='3232' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3232/3232 03:50, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.190343</td>\n",
       "      <td>0.851190</td>\n",
       "      <td>0.674528</td>\n",
       "      <td>0.752632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.182800</td>\n",
       "      <td>0.144139</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.836105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.109300</td>\n",
       "      <td>0.178813</td>\n",
       "      <td>0.801724</td>\n",
       "      <td>0.877358</td>\n",
       "      <td>0.837838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.050600</td>\n",
       "      <td>0.215727</td>\n",
       "      <td>0.816038</td>\n",
       "      <td>0.816038</td>\n",
       "      <td>0.816038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.034100</td>\n",
       "      <td>0.269656</td>\n",
       "      <td>0.793860</td>\n",
       "      <td>0.853774</td>\n",
       "      <td>0.822727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.034100</td>\n",
       "      <td>0.299629</td>\n",
       "      <td>0.808219</td>\n",
       "      <td>0.834906</td>\n",
       "      <td>0.821346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>0.312673</td>\n",
       "      <td>0.810811</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.829493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>0.330588</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.806604</td>\n",
       "      <td>0.810427</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_TUM_GottBERT_base_best_42_42_8\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_TUM_GottBERT_base_best_42_42_8\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4775.73 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.81      0.79      0.80       279\n",
      "\n",
      "   micro avg       0.81      0.79      0.80       279\n",
      "   macro avg       0.81      0.79      0.80       279\n",
      "weighted avg       0.81      0.79      0.80       279\n",
      "\n",
      "Precision Score: 0.8118081180811808\n",
      "Recall Score: 0.7885304659498208\n",
      "F1 Score: 0.8\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/8_epochs/TUM_GottBERT_base_best_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/8_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_filtered_base_best:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at TUM/GottBERT_filtered_base_best and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6582.85 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5060.99 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for TUM/GottBERT_filtered_base_best with 8 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3232' max='3232' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3232/3232 03:51, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.129274</td>\n",
       "      <td>0.810427</td>\n",
       "      <td>0.806604</td>\n",
       "      <td>0.808511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.147977</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.820755</td>\n",
       "      <td>0.816901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.102200</td>\n",
       "      <td>0.177405</td>\n",
       "      <td>0.823256</td>\n",
       "      <td>0.834906</td>\n",
       "      <td>0.829040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.051500</td>\n",
       "      <td>0.188275</td>\n",
       "      <td>0.803653</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.816705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.031200</td>\n",
       "      <td>0.245680</td>\n",
       "      <td>0.807175</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.827586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.031200</td>\n",
       "      <td>0.287995</td>\n",
       "      <td>0.801724</td>\n",
       "      <td>0.877358</td>\n",
       "      <td>0.837838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.009500</td>\n",
       "      <td>0.285110</td>\n",
       "      <td>0.809735</td>\n",
       "      <td>0.863208</td>\n",
       "      <td>0.835616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.292516</td>\n",
       "      <td>0.805310</td>\n",
       "      <td>0.858491</td>\n",
       "      <td>0.831050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_TUM_GottBERT_filtered_base_best_42_42_8\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_TUM_GottBERT_filtered_base_best_42_42_8\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4671.18 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.86      0.81      0.83       279\n",
      "\n",
      "   micro avg       0.86      0.81      0.83       279\n",
      "   macro avg       0.86      0.81      0.83       279\n",
      "weighted avg       0.86      0.81      0.83       279\n",
      "\n",
      "Precision Score: 0.8620689655172413\n",
      "Recall Score: 0.8064516129032258\n",
      "F1 Score: 0.8333333333333334\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/8_epochs/TUM_GottBERT_filtered_base_best_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/8_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_last:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at TUM/GottBERT_base_last were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at TUM/GottBERT_base_last and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6551.89 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5060.02 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for TUM/GottBERT_base_last with 8 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3232' max='3232' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3232/3232 03:51, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.179930</td>\n",
       "      <td>0.817734</td>\n",
       "      <td>0.783019</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.181400</td>\n",
       "      <td>0.152914</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.807692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.112200</td>\n",
       "      <td>0.199777</td>\n",
       "      <td>0.820388</td>\n",
       "      <td>0.797170</td>\n",
       "      <td>0.808612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.060100</td>\n",
       "      <td>0.178344</td>\n",
       "      <td>0.820628</td>\n",
       "      <td>0.863208</td>\n",
       "      <td>0.841379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.042600</td>\n",
       "      <td>0.294801</td>\n",
       "      <td>0.793722</td>\n",
       "      <td>0.834906</td>\n",
       "      <td>0.813793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.042600</td>\n",
       "      <td>0.333246</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.809639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>0.393153</td>\n",
       "      <td>0.819095</td>\n",
       "      <td>0.768868</td>\n",
       "      <td>0.793187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.007700</td>\n",
       "      <td>0.378625</td>\n",
       "      <td>0.805825</td>\n",
       "      <td>0.783019</td>\n",
       "      <td>0.794258</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_TUM_GottBERT_base_last_42_42_8\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_TUM_GottBERT_base_last_42_42_8\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4614.10 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.87      0.81      0.84       279\n",
      "\n",
      "   micro avg       0.87      0.81      0.84       279\n",
      "   macro avg       0.87      0.81      0.84       279\n",
      "weighted avg       0.87      0.81      0.84       279\n",
      "\n",
      "Precision Score: 0.8725868725868726\n",
      "Recall Score: 0.8100358422939068\n",
      "F1 Score: 0.8401486988847584\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/8_epochs/TUM_GottBERT_base_last_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/8_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for distilbert/distilbert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6432.66 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5251.07 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for distilbert/distilbert-base-german-cased with 8 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3232' max='3232' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3232/3232 02:03, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.144885</td>\n",
       "      <td>0.829167</td>\n",
       "      <td>0.783465</td>\n",
       "      <td>0.805668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.208200</td>\n",
       "      <td>0.169265</td>\n",
       "      <td>0.835498</td>\n",
       "      <td>0.759843</td>\n",
       "      <td>0.795876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.102900</td>\n",
       "      <td>0.199689</td>\n",
       "      <td>0.839130</td>\n",
       "      <td>0.759843</td>\n",
       "      <td>0.797521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.048100</td>\n",
       "      <td>0.234594</td>\n",
       "      <td>0.834783</td>\n",
       "      <td>0.755906</td>\n",
       "      <td>0.793388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.031300</td>\n",
       "      <td>0.266809</td>\n",
       "      <td>0.827731</td>\n",
       "      <td>0.775591</td>\n",
       "      <td>0.800813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.031300</td>\n",
       "      <td>0.284576</td>\n",
       "      <td>0.825911</td>\n",
       "      <td>0.803150</td>\n",
       "      <td>0.814371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.304624</td>\n",
       "      <td>0.827869</td>\n",
       "      <td>0.795276</td>\n",
       "      <td>0.811245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.005400</td>\n",
       "      <td>0.314198</td>\n",
       "      <td>0.834711</td>\n",
       "      <td>0.795276</td>\n",
       "      <td>0.814516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_distilbert_distilbert-base-german-cased_42_42_8\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_distilbert_distilbert-base-german-cased_42_42_8\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4852.48 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.86      0.75      0.80       315\n",
      "\n",
      "   micro avg       0.86      0.75      0.80       315\n",
      "   macro avg       0.86      0.75      0.80       315\n",
      "weighted avg       0.86      0.75      0.80       315\n",
      "\n",
      "Precision Score: 0.864963503649635\n",
      "Recall Score: 0.7523809523809524\n",
      "F1 Score: 0.8047538200339559\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/8_epochs/distilbert_distilbert-base-german-cased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/8_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for GerMedBERT/medbert-512:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Device set to use cuda:0\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at GerMedBERT/medbert-512 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5755.69 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4579.88 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for GerMedBERT/medbert-512 with 8 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3232' max='3232' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3232/3232 03:40, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.113751</td>\n",
       "      <td>0.835749</td>\n",
       "      <td>0.748918</td>\n",
       "      <td>0.789954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.189800</td>\n",
       "      <td>0.150909</td>\n",
       "      <td>0.816000</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.848233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.088500</td>\n",
       "      <td>0.207060</td>\n",
       "      <td>0.818565</td>\n",
       "      <td>0.839827</td>\n",
       "      <td>0.829060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.037600</td>\n",
       "      <td>0.233955</td>\n",
       "      <td>0.807531</td>\n",
       "      <td>0.835498</td>\n",
       "      <td>0.821277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>0.288862</td>\n",
       "      <td>0.807377</td>\n",
       "      <td>0.852814</td>\n",
       "      <td>0.829474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.019100</td>\n",
       "      <td>0.313762</td>\n",
       "      <td>0.807531</td>\n",
       "      <td>0.835498</td>\n",
       "      <td>0.821277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.321680</td>\n",
       "      <td>0.830435</td>\n",
       "      <td>0.826840</td>\n",
       "      <td>0.828633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.320143</td>\n",
       "      <td>0.810700</td>\n",
       "      <td>0.852814</td>\n",
       "      <td>0.831224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_GerMedBERT_medbert-512_42_42_8\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_GerMedBERT_medbert-512_42_42_8\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4216.25 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.87      0.78      0.82       288\n",
      "\n",
      "   micro avg       0.87      0.78      0.82       288\n",
      "   macro avg       0.87      0.78      0.82       288\n",
      "weighted avg       0.87      0.78      0.82       288\n",
      "\n",
      "Precision Score: 0.8653846153846154\n",
      "Recall Score: 0.78125\n",
      "F1 Score: 0.8211678832116789\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/8_epochs/GerMedBERT_medbert-512_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/8_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for deepset/gbert-base:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5817.70 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4689.90 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for deepset/gbert-base with 8 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3232' max='3232' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3232/3232 03:40, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.142960</td>\n",
       "      <td>0.839130</td>\n",
       "      <td>0.759843</td>\n",
       "      <td>0.797521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.190500</td>\n",
       "      <td>0.138249</td>\n",
       "      <td>0.861925</td>\n",
       "      <td>0.811024</td>\n",
       "      <td>0.835700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.089300</td>\n",
       "      <td>0.231621</td>\n",
       "      <td>0.845188</td>\n",
       "      <td>0.795276</td>\n",
       "      <td>0.819473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.031600</td>\n",
       "      <td>0.226515</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.834646</td>\n",
       "      <td>0.837945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.283137</td>\n",
       "      <td>0.833977</td>\n",
       "      <td>0.850394</td>\n",
       "      <td>0.842105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>0.272008</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.866142</td>\n",
       "      <td>0.849421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>0.304230</td>\n",
       "      <td>0.844000</td>\n",
       "      <td>0.830709</td>\n",
       "      <td>0.837302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>0.285747</td>\n",
       "      <td>0.833977</td>\n",
       "      <td>0.850394</td>\n",
       "      <td>0.842105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_deepset_gbert-base_42_42_8\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_deepset_gbert-base_42_42_8\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4399.89 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.87      0.80      0.84       315\n",
      "\n",
      "   micro avg       0.87      0.80      0.84       315\n",
      "   macro avg       0.87      0.80      0.84       315\n",
      "weighted avg       0.87      0.80      0.84       315\n",
      "\n",
      "Precision Score: 0.8724137931034482\n",
      "Recall Score: 0.8031746031746032\n",
      "F1 Score: 0.8363636363636363\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/8_epochs/deepset_gbert-base_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/8_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(f'training and results for {model}:')\n",
    "    ate_model(data, model, rn1=42, rn2=42, epochs=8, save=True)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "feb29b42-4015-4892-a978-ec998d25932f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training and results for google-bert/bert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5910.34 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4784.23 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for google-bert/bert-base-german-cased with 10 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4040' max='4040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4040/4040 04:30, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.155934</td>\n",
       "      <td>0.817021</td>\n",
       "      <td>0.735632</td>\n",
       "      <td>0.774194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.189800</td>\n",
       "      <td>0.155716</td>\n",
       "      <td>0.822134</td>\n",
       "      <td>0.796935</td>\n",
       "      <td>0.809339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.081400</td>\n",
       "      <td>0.238581</td>\n",
       "      <td>0.798507</td>\n",
       "      <td>0.819923</td>\n",
       "      <td>0.809074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.023800</td>\n",
       "      <td>0.315927</td>\n",
       "      <td>0.807229</td>\n",
       "      <td>0.770115</td>\n",
       "      <td>0.788235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>0.370965</td>\n",
       "      <td>0.824219</td>\n",
       "      <td>0.808429</td>\n",
       "      <td>0.816248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.014300</td>\n",
       "      <td>0.419910</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.802372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>0.426093</td>\n",
       "      <td>0.832653</td>\n",
       "      <td>0.781609</td>\n",
       "      <td>0.806324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.435215</td>\n",
       "      <td>0.833992</td>\n",
       "      <td>0.808429</td>\n",
       "      <td>0.821012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.448985</td>\n",
       "      <td>0.828685</td>\n",
       "      <td>0.796935</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.456094</td>\n",
       "      <td>0.828685</td>\n",
       "      <td>0.796935</td>\n",
       "      <td>0.812500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_google-bert_bert-base-german-cased_42_42_10\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_google-bert_bert-base-german-cased_42_42_10\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4493.24 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.91      0.78      0.84       323\n",
      "\n",
      "   micro avg       0.91      0.78      0.84       323\n",
      "   macro avg       0.91      0.78      0.84       323\n",
      "weighted avg       0.91      0.78      0.84       323\n",
      "\n",
      "Precision Score: 0.9100719424460432\n",
      "Recall Score: 0.7832817337461301\n",
      "F1 Score: 0.8419301164725459\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/10_epochs/google-bert_bert-base-german-cased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/10_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5895.41 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4782.72 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for dbmdz/bert-base-german-cased with 10 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4040' max='4040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4040/4040 04:29, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.147201</td>\n",
       "      <td>0.813008</td>\n",
       "      <td>0.787402</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.200200</td>\n",
       "      <td>0.163032</td>\n",
       "      <td>0.835391</td>\n",
       "      <td>0.799213</td>\n",
       "      <td>0.816901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.099000</td>\n",
       "      <td>0.240881</td>\n",
       "      <td>0.835443</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>0.806517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.034700</td>\n",
       "      <td>0.288684</td>\n",
       "      <td>0.789655</td>\n",
       "      <td>0.901575</td>\n",
       "      <td>0.841912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>0.355788</td>\n",
       "      <td>0.803150</td>\n",
       "      <td>0.803150</td>\n",
       "      <td>0.803150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>0.358243</td>\n",
       "      <td>0.832669</td>\n",
       "      <td>0.822835</td>\n",
       "      <td>0.827723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.007400</td>\n",
       "      <td>0.346879</td>\n",
       "      <td>0.832061</td>\n",
       "      <td>0.858268</td>\n",
       "      <td>0.844961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.396509</td>\n",
       "      <td>0.838583</td>\n",
       "      <td>0.838583</td>\n",
       "      <td>0.838583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.419361</td>\n",
       "      <td>0.826772</td>\n",
       "      <td>0.826772</td>\n",
       "      <td>0.826772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.430270</td>\n",
       "      <td>0.826772</td>\n",
       "      <td>0.826772</td>\n",
       "      <td>0.826772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_dbmdz_bert-base-german-cased_42_42_10\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_dbmdz_bert-base-german-cased_42_42_10\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4444.78 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.88      0.82      0.85       315\n",
      "\n",
      "   micro avg       0.88      0.82      0.85       315\n",
      "   macro avg       0.88      0.82      0.85       315\n",
      "weighted avg       0.88      0.82      0.85       315\n",
      "\n",
      "Precision Score: 0.8839590443686007\n",
      "Recall Score: 0.8222222222222222\n",
      "F1 Score: 0.8519736842105263\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/10_epochs/dbmdz_bert-base-german-cased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/10_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-uncased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5635.12 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4758.92 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for dbmdz/bert-base-german-uncased with 10 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4040' max='4040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4040/4040 04:30, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.145257</td>\n",
       "      <td>0.830435</td>\n",
       "      <td>0.757937</td>\n",
       "      <td>0.792531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.191600</td>\n",
       "      <td>0.186798</td>\n",
       "      <td>0.859031</td>\n",
       "      <td>0.773810</td>\n",
       "      <td>0.814196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.092600</td>\n",
       "      <td>0.225076</td>\n",
       "      <td>0.838298</td>\n",
       "      <td>0.781746</td>\n",
       "      <td>0.809035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.032600</td>\n",
       "      <td>0.218240</td>\n",
       "      <td>0.819923</td>\n",
       "      <td>0.849206</td>\n",
       "      <td>0.834308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.020600</td>\n",
       "      <td>0.332044</td>\n",
       "      <td>0.821862</td>\n",
       "      <td>0.805556</td>\n",
       "      <td>0.813627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.020600</td>\n",
       "      <td>0.371450</td>\n",
       "      <td>0.829365</td>\n",
       "      <td>0.829365</td>\n",
       "      <td>0.829365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.399477</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.813492</td>\n",
       "      <td>0.824950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.402862</td>\n",
       "      <td>0.835294</td>\n",
       "      <td>0.845238</td>\n",
       "      <td>0.840237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.432827</td>\n",
       "      <td>0.842742</td>\n",
       "      <td>0.829365</td>\n",
       "      <td>0.836000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.418345</td>\n",
       "      <td>0.833992</td>\n",
       "      <td>0.837302</td>\n",
       "      <td>0.835644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_dbmdz_bert-base-german-uncased_42_42_10\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_dbmdz_bert-base-german-uncased_42_42_10\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4540.83 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.88      0.78      0.83       316\n",
      "\n",
      "   micro avg       0.88      0.78      0.83       316\n",
      "   macro avg       0.88      0.78      0.83       316\n",
      "weighted avg       0.88      0.78      0.83       316\n",
      "\n",
      "Precision Score: 0.875886524822695\n",
      "Recall Score: 0.7816455696202531\n",
      "F1 Score: 0.8260869565217391\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/10_epochs/dbmdz_bert-base-german-uncased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/10_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for FacebookAI/xlm-roberta-base:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5853.70 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5033.62 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for FacebookAI/xlm-roberta-base with 10 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4040' max='4040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4040/4040 07:04, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.142815</td>\n",
       "      <td>0.826241</td>\n",
       "      <td>0.806228</td>\n",
       "      <td>0.816112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.216400</td>\n",
       "      <td>0.168245</td>\n",
       "      <td>0.804054</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.813675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.145400</td>\n",
       "      <td>0.183943</td>\n",
       "      <td>0.827119</td>\n",
       "      <td>0.844291</td>\n",
       "      <td>0.835616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.093000</td>\n",
       "      <td>0.205133</td>\n",
       "      <td>0.830450</td>\n",
       "      <td>0.830450</td>\n",
       "      <td>0.830450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.066800</td>\n",
       "      <td>0.302071</td>\n",
       "      <td>0.798701</td>\n",
       "      <td>0.851211</td>\n",
       "      <td>0.824121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.066800</td>\n",
       "      <td>0.299186</td>\n",
       "      <td>0.803987</td>\n",
       "      <td>0.837370</td>\n",
       "      <td>0.820339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.033400</td>\n",
       "      <td>0.307390</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.885813</td>\n",
       "      <td>0.829822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>0.332037</td>\n",
       "      <td>0.794953</td>\n",
       "      <td>0.871972</td>\n",
       "      <td>0.831683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.341836</td>\n",
       "      <td>0.795527</td>\n",
       "      <td>0.861592</td>\n",
       "      <td>0.827243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>0.346254</td>\n",
       "      <td>0.796178</td>\n",
       "      <td>0.865052</td>\n",
       "      <td>0.829187</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_FacebookAI_xlm-roberta-base_42_42_10\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_FacebookAI_xlm-roberta-base_42_42_10\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4607.34 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.82      0.75      0.79       346\n",
      "\n",
      "   micro avg       0.82      0.75      0.79       346\n",
      "   macro avg       0.82      0.75      0.79       346\n",
      "weighted avg       0.82      0.75      0.79       346\n",
      "\n",
      "Precision Score: 0.8227848101265823\n",
      "Recall Score: 0.7514450867052023\n",
      "F1 Score: 0.7854984894259818\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/10_epochs/FacebookAI_xlm-roberta-base_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/10_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_best:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at TUM/GottBERT_base_best and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6464.58 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5036.80 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for TUM/GottBERT_base_best with 10 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4040' max='4040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4040/4040 04:45, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.147691</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.809639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.181200</td>\n",
       "      <td>0.148894</td>\n",
       "      <td>0.842857</td>\n",
       "      <td>0.834906</td>\n",
       "      <td>0.838863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.108500</td>\n",
       "      <td>0.177760</td>\n",
       "      <td>0.817352</td>\n",
       "      <td>0.844340</td>\n",
       "      <td>0.830626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.058200</td>\n",
       "      <td>0.175909</td>\n",
       "      <td>0.804255</td>\n",
       "      <td>0.891509</td>\n",
       "      <td>0.845638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.043300</td>\n",
       "      <td>0.297100</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.806604</td>\n",
       "      <td>0.810427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.043300</td>\n",
       "      <td>0.282738</td>\n",
       "      <td>0.812785</td>\n",
       "      <td>0.839623</td>\n",
       "      <td>0.825986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.017200</td>\n",
       "      <td>0.401498</td>\n",
       "      <td>0.836842</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.791045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.006700</td>\n",
       "      <td>0.376106</td>\n",
       "      <td>0.813397</td>\n",
       "      <td>0.801887</td>\n",
       "      <td>0.807601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.392271</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.778302</td>\n",
       "      <td>0.800971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.403141</td>\n",
       "      <td>0.820896</td>\n",
       "      <td>0.778302</td>\n",
       "      <td>0.799031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_TUM_GottBERT_base_best_42_42_10\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_TUM_GottBERT_base_best_42_42_10\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4712.91 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.85      0.83      0.84       279\n",
      "\n",
      "   micro avg       0.85      0.83      0.84       279\n",
      "   macro avg       0.85      0.83      0.84       279\n",
      "weighted avg       0.85      0.83      0.84       279\n",
      "\n",
      "Precision Score: 0.8498168498168498\n",
      "Recall Score: 0.8315412186379928\n",
      "F1 Score: 0.8405797101449275\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/10_epochs/TUM_GottBERT_base_best_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/10_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_filtered_base_best:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at TUM/GottBERT_filtered_base_best and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6523.00 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5084.19 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for TUM/GottBERT_filtered_base_best with 10 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4040' max='4040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4040/4040 04:44, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.148790</td>\n",
       "      <td>0.814070</td>\n",
       "      <td>0.764151</td>\n",
       "      <td>0.788321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.186500</td>\n",
       "      <td>0.210977</td>\n",
       "      <td>0.798122</td>\n",
       "      <td>0.801887</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.099000</td>\n",
       "      <td>0.149225</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.858491</td>\n",
       "      <td>0.848485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.049400</td>\n",
       "      <td>0.177294</td>\n",
       "      <td>0.857868</td>\n",
       "      <td>0.797170</td>\n",
       "      <td>0.826406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.034600</td>\n",
       "      <td>0.250404</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.034600</td>\n",
       "      <td>0.240946</td>\n",
       "      <td>0.822511</td>\n",
       "      <td>0.896226</td>\n",
       "      <td>0.857788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>0.299077</td>\n",
       "      <td>0.842640</td>\n",
       "      <td>0.783019</td>\n",
       "      <td>0.811736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.007300</td>\n",
       "      <td>0.315060</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.820755</td>\n",
       "      <td>0.824645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.295691</td>\n",
       "      <td>0.834821</td>\n",
       "      <td>0.882075</td>\n",
       "      <td>0.857798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.341165</td>\n",
       "      <td>0.840796</td>\n",
       "      <td>0.797170</td>\n",
       "      <td>0.818402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_TUM_GottBERT_filtered_base_best_42_42_10\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_TUM_GottBERT_filtered_base_best_42_42_10\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4693.83 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.86      0.78      0.82       279\n",
      "\n",
      "   micro avg       0.86      0.78      0.82       279\n",
      "   macro avg       0.86      0.78      0.82       279\n",
      "weighted avg       0.86      0.78      0.82       279\n",
      "\n",
      "Precision Score: 0.857707509881423\n",
      "Recall Score: 0.7777777777777778\n",
      "F1 Score: 0.8157894736842106\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/10_epochs/TUM_GottBERT_filtered_base_best_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/10_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_last:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at TUM/GottBERT_base_last were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at TUM/GottBERT_base_last and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6457.71 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5062.19 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for TUM/GottBERT_base_last with 10 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4040' max='4040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4040/4040 04:45, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.237963</td>\n",
       "      <td>0.838889</td>\n",
       "      <td>0.712264</td>\n",
       "      <td>0.770408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.157235</td>\n",
       "      <td>0.804545</td>\n",
       "      <td>0.834906</td>\n",
       "      <td>0.819444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.113600</td>\n",
       "      <td>0.181280</td>\n",
       "      <td>0.801802</td>\n",
       "      <td>0.839623</td>\n",
       "      <td>0.820276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.059100</td>\n",
       "      <td>0.171909</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.806604</td>\n",
       "      <td>0.816229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.045800</td>\n",
       "      <td>0.268680</td>\n",
       "      <td>0.808219</td>\n",
       "      <td>0.834906</td>\n",
       "      <td>0.821346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.045800</td>\n",
       "      <td>0.338653</td>\n",
       "      <td>0.829146</td>\n",
       "      <td>0.778302</td>\n",
       "      <td>0.802920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.378633</td>\n",
       "      <td>0.834197</td>\n",
       "      <td>0.759434</td>\n",
       "      <td>0.795062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.375693</td>\n",
       "      <td>0.810680</td>\n",
       "      <td>0.787736</td>\n",
       "      <td>0.799043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>0.380848</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.807692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.005800</td>\n",
       "      <td>0.387219</td>\n",
       "      <td>0.820896</td>\n",
       "      <td>0.778302</td>\n",
       "      <td>0.799031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_TUM_GottBERT_base_last_42_42_10\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_TUM_GottBERT_base_last_42_42_10\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4754.87 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.86      0.81      0.83       279\n",
      "\n",
      "   micro avg       0.86      0.81      0.83       279\n",
      "   macro avg       0.86      0.81      0.83       279\n",
      "weighted avg       0.86      0.81      0.83       279\n",
      "\n",
      "Precision Score: 0.8593155893536122\n",
      "Recall Score: 0.8100358422939068\n",
      "F1 Score: 0.8339483394833949\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/10_epochs/TUM_GottBERT_base_last_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/10_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for distilbert/distilbert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6513.12 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5260.33 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for distilbert/distilbert-base-german-cased with 10 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4040' max='4040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4040/4040 02:32, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.144258</td>\n",
       "      <td>0.827731</td>\n",
       "      <td>0.775591</td>\n",
       "      <td>0.800813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.205500</td>\n",
       "      <td>0.162938</td>\n",
       "      <td>0.821739</td>\n",
       "      <td>0.744094</td>\n",
       "      <td>0.780992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.101200</td>\n",
       "      <td>0.226657</td>\n",
       "      <td>0.859813</td>\n",
       "      <td>0.724409</td>\n",
       "      <td>0.786325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.045200</td>\n",
       "      <td>0.229085</td>\n",
       "      <td>0.802281</td>\n",
       "      <td>0.830709</td>\n",
       "      <td>0.816248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.034400</td>\n",
       "      <td>0.262624</td>\n",
       "      <td>0.816000</td>\n",
       "      <td>0.803150</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.034400</td>\n",
       "      <td>0.305888</td>\n",
       "      <td>0.817797</td>\n",
       "      <td>0.759843</td>\n",
       "      <td>0.787755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.012800</td>\n",
       "      <td>0.360086</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.803150</td>\n",
       "      <td>0.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.359875</td>\n",
       "      <td>0.795367</td>\n",
       "      <td>0.811024</td>\n",
       "      <td>0.803119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.366117</td>\n",
       "      <td>0.792308</td>\n",
       "      <td>0.811024</td>\n",
       "      <td>0.801556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.370863</td>\n",
       "      <td>0.792308</td>\n",
       "      <td>0.811024</td>\n",
       "      <td>0.801556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_distilbert_distilbert-base-german-cased_42_42_10\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_distilbert_distilbert-base-german-cased_42_42_10\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4814.15 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.86      0.81      0.83       315\n",
      "\n",
      "   micro avg       0.86      0.81      0.83       315\n",
      "   macro avg       0.86      0.81      0.83       315\n",
      "weighted avg       0.86      0.81      0.83       315\n",
      "\n",
      "Precision Score: 0.8639455782312925\n",
      "Recall Score: 0.8063492063492064\n",
      "F1 Score: 0.8341543513957307\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/10_epochs/distilbert_distilbert-base-german-cased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/10_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for GerMedBERT/medbert-512:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at GerMedBERT/medbert-512 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5757.05 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4618.57 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for GerMedBERT/medbert-512 with 10 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4040' max='4040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4040/4040 04:31, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.109198</td>\n",
       "      <td>0.817021</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.824034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.189900</td>\n",
       "      <td>0.141898</td>\n",
       "      <td>0.794466</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.830579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.222649</td>\n",
       "      <td>0.843902</td>\n",
       "      <td>0.748918</td>\n",
       "      <td>0.793578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.036800</td>\n",
       "      <td>0.183271</td>\n",
       "      <td>0.823045</td>\n",
       "      <td>0.865801</td>\n",
       "      <td>0.843882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.023100</td>\n",
       "      <td>0.265912</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.835443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.023100</td>\n",
       "      <td>0.288966</td>\n",
       "      <td>0.834783</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.832972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.004200</td>\n",
       "      <td>0.316017</td>\n",
       "      <td>0.812245</td>\n",
       "      <td>0.861472</td>\n",
       "      <td>0.836134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.330555</td>\n",
       "      <td>0.823045</td>\n",
       "      <td>0.865801</td>\n",
       "      <td>0.843882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.341773</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.836910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.342800</td>\n",
       "      <td>0.824268</td>\n",
       "      <td>0.852814</td>\n",
       "      <td>0.838298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_GerMedBERT_medbert-512_42_42_10\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_GerMedBERT_medbert-512_42_42_10\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4222.95 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.87      0.75      0.81       288\n",
      "\n",
      "   micro avg       0.87      0.75      0.81       288\n",
      "   macro avg       0.87      0.75      0.81       288\n",
      "weighted avg       0.87      0.75      0.81       288\n",
      "\n",
      "Precision Score: 0.8739837398373984\n",
      "Recall Score: 0.7465277777777778\n",
      "F1 Score: 0.8052434456928839\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/10_epochs/GerMedBERT_medbert-512_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/10_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for deepset/gbert-base:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5814.19 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4803.87 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for deepset/gbert-base with 10 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4040' max='4040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4040/4040 04:32, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.144171</td>\n",
       "      <td>0.815261</td>\n",
       "      <td>0.799213</td>\n",
       "      <td>0.807157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.190400</td>\n",
       "      <td>0.174801</td>\n",
       "      <td>0.811765</td>\n",
       "      <td>0.814961</td>\n",
       "      <td>0.813360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.089000</td>\n",
       "      <td>0.237684</td>\n",
       "      <td>0.861472</td>\n",
       "      <td>0.783465</td>\n",
       "      <td>0.820619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.033400</td>\n",
       "      <td>0.263219</td>\n",
       "      <td>0.860759</td>\n",
       "      <td>0.803150</td>\n",
       "      <td>0.830957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.018300</td>\n",
       "      <td>0.326294</td>\n",
       "      <td>0.845833</td>\n",
       "      <td>0.799213</td>\n",
       "      <td>0.821862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.018300</td>\n",
       "      <td>0.352128</td>\n",
       "      <td>0.823308</td>\n",
       "      <td>0.862205</td>\n",
       "      <td>0.842308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>0.395983</td>\n",
       "      <td>0.862069</td>\n",
       "      <td>0.787402</td>\n",
       "      <td>0.823045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.388542</td>\n",
       "      <td>0.830040</td>\n",
       "      <td>0.826772</td>\n",
       "      <td>0.828402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.393355</td>\n",
       "      <td>0.836735</td>\n",
       "      <td>0.807087</td>\n",
       "      <td>0.821643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.392739</td>\n",
       "      <td>0.841463</td>\n",
       "      <td>0.814961</td>\n",
       "      <td>0.828000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_deepset_gbert-base_42_42_10\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_deepset_gbert-base_42_42_10\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4431.11 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.90      0.79      0.84       315\n",
      "\n",
      "   micro avg       0.90      0.79      0.84       315\n",
      "   macro avg       0.90      0.79      0.84       315\n",
      "weighted avg       0.90      0.79      0.84       315\n",
      "\n",
      "Precision Score: 0.8953068592057761\n",
      "Recall Score: 0.7873015873015873\n",
      "F1 Score: 0.8378378378378378\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/10_epochs/deepset_gbert-base_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/10_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(f'training and results for {model}:')\n",
    "    ate_model(data, model, rn1=42, rn2=42, epochs=10, save=True)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739aff3f-aea3-4a89-8570-c3b8ecc941d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training and results for google-bert/bert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5786.81 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4766.04 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for google-bert/bert-base-german-cased with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4848' max='4848' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4848/4848 05:26, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.152613</td>\n",
       "      <td>0.826271</td>\n",
       "      <td>0.747126</td>\n",
       "      <td>0.784708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.192700</td>\n",
       "      <td>0.157459</td>\n",
       "      <td>0.836653</td>\n",
       "      <td>0.804598</td>\n",
       "      <td>0.820312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.084000</td>\n",
       "      <td>0.256477</td>\n",
       "      <td>0.814516</td>\n",
       "      <td>0.773946</td>\n",
       "      <td>0.793713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.025200</td>\n",
       "      <td>0.246607</td>\n",
       "      <td>0.836820</td>\n",
       "      <td>0.766284</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.013700</td>\n",
       "      <td>0.389142</td>\n",
       "      <td>0.823045</td>\n",
       "      <td>0.766284</td>\n",
       "      <td>0.793651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.013700</td>\n",
       "      <td>0.425228</td>\n",
       "      <td>0.824786</td>\n",
       "      <td>0.739464</td>\n",
       "      <td>0.779798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.390524</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.781609</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.439598</td>\n",
       "      <td>0.814516</td>\n",
       "      <td>0.773946</td>\n",
       "      <td>0.793713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.459527</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.747126</td>\n",
       "      <td>0.786290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.450793</td>\n",
       "      <td>0.824490</td>\n",
       "      <td>0.773946</td>\n",
       "      <td>0.798419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.453361</td>\n",
       "      <td>0.821862</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.799213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.457225</td>\n",
       "      <td>0.821862</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.799213</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_google-bert_bert-base-german-cased_42_42_12\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_google-bert_bert-base-german-cased_42_42_12\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4355.23 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.91      0.77      0.83       323\n",
      "\n",
      "   micro avg       0.91      0.77      0.83       323\n",
      "   macro avg       0.91      0.77      0.83       323\n",
      "weighted avg       0.91      0.77      0.83       323\n",
      "\n",
      "Precision Score: 0.9054545454545454\n",
      "Recall Score: 0.7708978328173375\n",
      "F1 Score: 0.8327759197324415\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/12_epochs/google-bert_bert-base-german-cased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/12_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5732.15 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4760.74 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for dbmdz/bert-base-german-cased with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4848' max='4848' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4848/4848 05:26, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.149743</td>\n",
       "      <td>0.794466</td>\n",
       "      <td>0.791339</td>\n",
       "      <td>0.792899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.206900</td>\n",
       "      <td>0.168503</td>\n",
       "      <td>0.862661</td>\n",
       "      <td>0.791339</td>\n",
       "      <td>0.825462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.098600</td>\n",
       "      <td>0.253586</td>\n",
       "      <td>0.823970</td>\n",
       "      <td>0.866142</td>\n",
       "      <td>0.844530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.041100</td>\n",
       "      <td>0.278187</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.834646</td>\n",
       "      <td>0.816956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.023200</td>\n",
       "      <td>0.390024</td>\n",
       "      <td>0.767123</td>\n",
       "      <td>0.881890</td>\n",
       "      <td>0.820513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.023200</td>\n",
       "      <td>0.402914</td>\n",
       "      <td>0.857778</td>\n",
       "      <td>0.759843</td>\n",
       "      <td>0.805846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.444511</td>\n",
       "      <td>0.827004</td>\n",
       "      <td>0.771654</td>\n",
       "      <td>0.798371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.432876</td>\n",
       "      <td>0.807843</td>\n",
       "      <td>0.811024</td>\n",
       "      <td>0.809430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.457051</td>\n",
       "      <td>0.831933</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>0.804878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.485857</td>\n",
       "      <td>0.829167</td>\n",
       "      <td>0.783465</td>\n",
       "      <td>0.805668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.494606</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.767717</td>\n",
       "      <td>0.797546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.488748</td>\n",
       "      <td>0.823045</td>\n",
       "      <td>0.787402</td>\n",
       "      <td>0.804829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_dbmdz_bert-base-german-cased_42_42_12\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_dbmdz_bert-base-german-cased_42_42_12\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4481.05 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.87      0.82      0.84       315\n",
      "\n",
      "   micro avg       0.87      0.82      0.84       315\n",
      "   macro avg       0.87      0.82      0.84       315\n",
      "weighted avg       0.87      0.82      0.84       315\n",
      "\n",
      "Precision Score: 0.8716216216216216\n",
      "Recall Score: 0.819047619047619\n",
      "F1 Score: 0.8445171849427168\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/12_epochs/dbmdz_bert-base-german-cased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/12_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-uncased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5512.05 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4592.88 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for dbmdz/bert-base-german-uncased with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4848' max='4848' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4848/4848 05:25, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.140258</td>\n",
       "      <td>0.844828</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.809917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.187200</td>\n",
       "      <td>0.158992</td>\n",
       "      <td>0.850622</td>\n",
       "      <td>0.813492</td>\n",
       "      <td>0.831643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.089400</td>\n",
       "      <td>0.227017</td>\n",
       "      <td>0.836820</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.814664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.032800</td>\n",
       "      <td>0.224848</td>\n",
       "      <td>0.820717</td>\n",
       "      <td>0.817460</td>\n",
       "      <td>0.819085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.021900</td>\n",
       "      <td>0.312917</td>\n",
       "      <td>0.818898</td>\n",
       "      <td>0.825397</td>\n",
       "      <td>0.822134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.021900</td>\n",
       "      <td>0.373301</td>\n",
       "      <td>0.829365</td>\n",
       "      <td>0.829365</td>\n",
       "      <td>0.829365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.004900</td>\n",
       "      <td>0.419680</td>\n",
       "      <td>0.814229</td>\n",
       "      <td>0.817460</td>\n",
       "      <td>0.815842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.421972</td>\n",
       "      <td>0.816733</td>\n",
       "      <td>0.813492</td>\n",
       "      <td>0.815109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.444466</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.819802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.432362</td>\n",
       "      <td>0.825911</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.817635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.448791</td>\n",
       "      <td>0.825911</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.817635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.451783</td>\n",
       "      <td>0.824000</td>\n",
       "      <td>0.817460</td>\n",
       "      <td>0.820717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_dbmdz_bert-base-german-uncased_42_42_12\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_dbmdz_bert-base-german-uncased_42_42_12\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4213.31 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.93      0.75      0.83       316\n",
      "\n",
      "   micro avg       0.93      0.75      0.83       316\n",
      "   macro avg       0.93      0.75      0.83       316\n",
      "weighted avg       0.93      0.75      0.83       316\n",
      "\n",
      "Precision Score: 0.9260700389105059\n",
      "Recall Score: 0.7531645569620253\n",
      "F1 Score: 0.830715532286213\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/12_epochs/dbmdz_bert-base-german-uncased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/12_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for FacebookAI/xlm-roberta-base:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5753.53 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4965.83 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for FacebookAI/xlm-roberta-base with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4848' max='4848' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4848/4848 08:27, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.160928</td>\n",
       "      <td>0.792388</td>\n",
       "      <td>0.792388</td>\n",
       "      <td>0.792388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.217400</td>\n",
       "      <td>0.148956</td>\n",
       "      <td>0.856618</td>\n",
       "      <td>0.806228</td>\n",
       "      <td>0.830660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.155000</td>\n",
       "      <td>0.175109</td>\n",
       "      <td>0.830986</td>\n",
       "      <td>0.816609</td>\n",
       "      <td>0.823735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0.213291</td>\n",
       "      <td>0.815436</td>\n",
       "      <td>0.840830</td>\n",
       "      <td>0.827939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.079500</td>\n",
       "      <td>0.254736</td>\n",
       "      <td>0.796825</td>\n",
       "      <td>0.868512</td>\n",
       "      <td>0.831126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.079500</td>\n",
       "      <td>0.274454</td>\n",
       "      <td>0.817881</td>\n",
       "      <td>0.854671</td>\n",
       "      <td>0.835871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.042300</td>\n",
       "      <td>0.316326</td>\n",
       "      <td>0.774775</td>\n",
       "      <td>0.892734</td>\n",
       "      <td>0.829582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.027300</td>\n",
       "      <td>0.323452</td>\n",
       "      <td>0.792332</td>\n",
       "      <td>0.858131</td>\n",
       "      <td>0.823920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>0.349600</td>\n",
       "      <td>0.817276</td>\n",
       "      <td>0.851211</td>\n",
       "      <td>0.833898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>0.345608</td>\n",
       "      <td>0.818770</td>\n",
       "      <td>0.875433</td>\n",
       "      <td>0.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>0.366497</td>\n",
       "      <td>0.798107</td>\n",
       "      <td>0.875433</td>\n",
       "      <td>0.834983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.009400</td>\n",
       "      <td>0.371277</td>\n",
       "      <td>0.796825</td>\n",
       "      <td>0.868512</td>\n",
       "      <td>0.831126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_FacebookAI_xlm-roberta-base_42_42_12\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_FacebookAI_xlm-roberta-base_42_42_12\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4561.41 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.86      0.75      0.80       346\n",
      "\n",
      "   micro avg       0.86      0.75      0.80       346\n",
      "   macro avg       0.86      0.75      0.80       346\n",
      "weighted avg       0.86      0.75      0.80       346\n",
      "\n",
      "Precision Score: 0.8557377049180328\n",
      "Recall Score: 0.7543352601156069\n",
      "F1 Score: 0.8018433179723502\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/12_epochs/FacebookAI_xlm-roberta-base_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/12_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_best:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at TUM/GottBERT_base_best and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6523.07 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4988.99 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for TUM/GottBERT_base_best with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4848' max='4848' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4848/4848 05:42, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.189320</td>\n",
       "      <td>0.836066</td>\n",
       "      <td>0.721698</td>\n",
       "      <td>0.774684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.183900</td>\n",
       "      <td>0.150063</td>\n",
       "      <td>0.803738</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.807512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.113500</td>\n",
       "      <td>0.182954</td>\n",
       "      <td>0.801688</td>\n",
       "      <td>0.896226</td>\n",
       "      <td>0.846325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.056600</td>\n",
       "      <td>0.230458</td>\n",
       "      <td>0.789216</td>\n",
       "      <td>0.759434</td>\n",
       "      <td>0.774038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.042700</td>\n",
       "      <td>0.297693</td>\n",
       "      <td>0.787037</td>\n",
       "      <td>0.801887</td>\n",
       "      <td>0.794393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.042700</td>\n",
       "      <td>0.358697</td>\n",
       "      <td>0.835979</td>\n",
       "      <td>0.745283</td>\n",
       "      <td>0.788030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.014900</td>\n",
       "      <td>0.381509</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.778302</td>\n",
       "      <td>0.791367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.008600</td>\n",
       "      <td>0.450220</td>\n",
       "      <td>0.823834</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.785185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.437428</td>\n",
       "      <td>0.824742</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.788177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.438994</td>\n",
       "      <td>0.815166</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.813239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.444915</td>\n",
       "      <td>0.828283</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.444532</td>\n",
       "      <td>0.829897</td>\n",
       "      <td>0.759434</td>\n",
       "      <td>0.793103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_TUM_GottBERT_base_best_42_42_12\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_TUM_GottBERT_base_best_42_42_12\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4659.93 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.84      0.82      0.83       279\n",
      "\n",
      "   micro avg       0.84      0.82      0.83       279\n",
      "   macro avg       0.84      0.82      0.83       279\n",
      "weighted avg       0.84      0.82      0.83       279\n",
      "\n",
      "Precision Score: 0.8394160583941606\n",
      "Recall Score: 0.8243727598566308\n",
      "F1 Score: 0.8318264014466547\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/12_epochs/TUM_GottBERT_base_best_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/12_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_filtered_base_best:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at TUM/GottBERT_filtered_base_best and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6559.66 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4969.44 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for TUM/GottBERT_filtered_base_best with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4848' max='4848' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4848/4848 05:40, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.131867</td>\n",
       "      <td>0.796296</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.803738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.176600</td>\n",
       "      <td>0.144252</td>\n",
       "      <td>0.783186</td>\n",
       "      <td>0.834906</td>\n",
       "      <td>0.808219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.102400</td>\n",
       "      <td>0.213909</td>\n",
       "      <td>0.804651</td>\n",
       "      <td>0.816038</td>\n",
       "      <td>0.810304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.048300</td>\n",
       "      <td>0.212191</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.832579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.285013</td>\n",
       "      <td>0.800885</td>\n",
       "      <td>0.853774</td>\n",
       "      <td>0.826484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.035500</td>\n",
       "      <td>0.309983</td>\n",
       "      <td>0.811060</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>0.820513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.320235</td>\n",
       "      <td>0.798122</td>\n",
       "      <td>0.801887</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>0.405206</td>\n",
       "      <td>0.825397</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.778055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.344410</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.811321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.380798</td>\n",
       "      <td>0.795238</td>\n",
       "      <td>0.787736</td>\n",
       "      <td>0.791469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.380101</td>\n",
       "      <td>0.806763</td>\n",
       "      <td>0.787736</td>\n",
       "      <td>0.797136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000500</td>\n",
       "      <td>0.375320</td>\n",
       "      <td>0.810427</td>\n",
       "      <td>0.806604</td>\n",
       "      <td>0.808511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_TUM_GottBERT_filtered_base_best_42_42_12\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_TUM_GottBERT_filtered_base_best_42_42_12\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4724.41 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.83      0.83      0.83       279\n",
      "\n",
      "   micro avg       0.83      0.83      0.83       279\n",
      "   macro avg       0.83      0.83      0.83       279\n",
      "weighted avg       0.83      0.83      0.83       279\n",
      "\n",
      "Precision Score: 0.8279569892473119\n",
      "Recall Score: 0.8279569892473119\n",
      "F1 Score: 0.8279569892473119\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/12_epochs/TUM_GottBERT_filtered_base_best_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/12_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_last:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at TUM/GottBERT_base_last were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at TUM/GottBERT_base_last and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6532.18 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5068.01 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for TUM/GottBERT_base_last with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4848' max='4848' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4848/4848 05:42, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.170278</td>\n",
       "      <td>0.834225</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.781955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.179300</td>\n",
       "      <td>0.151724</td>\n",
       "      <td>0.813953</td>\n",
       "      <td>0.825472</td>\n",
       "      <td>0.819672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.114000</td>\n",
       "      <td>0.192040</td>\n",
       "      <td>0.832512</td>\n",
       "      <td>0.797170</td>\n",
       "      <td>0.814458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.056900</td>\n",
       "      <td>0.213357</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.786571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.038200</td>\n",
       "      <td>0.264790</td>\n",
       "      <td>0.795556</td>\n",
       "      <td>0.844340</td>\n",
       "      <td>0.819222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.038200</td>\n",
       "      <td>0.329480</td>\n",
       "      <td>0.815534</td>\n",
       "      <td>0.792453</td>\n",
       "      <td>0.803828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.013600</td>\n",
       "      <td>0.377215</td>\n",
       "      <td>0.815920</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.794189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>0.437810</td>\n",
       "      <td>0.795000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.771845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>0.443204</td>\n",
       "      <td>0.823834</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.785185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.435113</td>\n",
       "      <td>0.812183</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.782396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.396472</td>\n",
       "      <td>0.810680</td>\n",
       "      <td>0.787736</td>\n",
       "      <td>0.799043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.406420</td>\n",
       "      <td>0.804878</td>\n",
       "      <td>0.778302</td>\n",
       "      <td>0.791367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_TUM_GottBERT_base_last_42_42_12\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_TUM_GottBERT_base_last_42_42_12\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4656.38 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.90      0.74      0.81       279\n",
      "\n",
      "   micro avg       0.90      0.74      0.81       279\n",
      "   macro avg       0.90      0.74      0.81       279\n",
      "weighted avg       0.90      0.74      0.81       279\n",
      "\n",
      "Precision Score: 0.8956521739130435\n",
      "Recall Score: 0.7383512544802867\n",
      "F1 Score: 0.8094302554027505\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/12_epochs/TUM_GottBERT_base_last_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/12_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for distilbert/distilbert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6546.21 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5177.58 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for distilbert/distilbert-base-german-cased with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4848' max='4848' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4848/4848 03:02, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.138312</td>\n",
       "      <td>0.808765</td>\n",
       "      <td>0.799213</td>\n",
       "      <td>0.803960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.209300</td>\n",
       "      <td>0.160013</td>\n",
       "      <td>0.846847</td>\n",
       "      <td>0.740157</td>\n",
       "      <td>0.789916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.098600</td>\n",
       "      <td>0.190818</td>\n",
       "      <td>0.821577</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.045500</td>\n",
       "      <td>0.225302</td>\n",
       "      <td>0.839662</td>\n",
       "      <td>0.783465</td>\n",
       "      <td>0.810591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.030200</td>\n",
       "      <td>0.259969</td>\n",
       "      <td>0.804688</td>\n",
       "      <td>0.811024</td>\n",
       "      <td>0.807843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.030200</td>\n",
       "      <td>0.294629</td>\n",
       "      <td>0.816733</td>\n",
       "      <td>0.807087</td>\n",
       "      <td>0.811881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.012000</td>\n",
       "      <td>0.322201</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.818898</td>\n",
       "      <td>0.815686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.005300</td>\n",
       "      <td>0.356954</td>\n",
       "      <td>0.827160</td>\n",
       "      <td>0.791339</td>\n",
       "      <td>0.808853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.362175</td>\n",
       "      <td>0.799242</td>\n",
       "      <td>0.830709</td>\n",
       "      <td>0.814672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.380429</td>\n",
       "      <td>0.801556</td>\n",
       "      <td>0.811024</td>\n",
       "      <td>0.806262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.387027</td>\n",
       "      <td>0.804688</td>\n",
       "      <td>0.811024</td>\n",
       "      <td>0.807843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.387343</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.787402</td>\n",
       "      <td>0.801603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_distilbert_distilbert-base-german-cased_42_42_12\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_distilbert_distilbert-base-german-cased_42_42_12\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4892.44 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.86      0.80      0.83       315\n",
      "\n",
      "   micro avg       0.86      0.80      0.83       315\n",
      "   macro avg       0.86      0.80      0.83       315\n",
      "weighted avg       0.86      0.80      0.83       315\n",
      "\n",
      "Precision Score: 0.863013698630137\n",
      "Recall Score: 0.8\n",
      "F1 Score: 0.8303130148270181\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/12_epochs/distilbert_distilbert-base-german-cased_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/12_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for GerMedBERT/medbert-512:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at GerMedBERT/medbert-512 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5730.50 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4597.02 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-ASPECT' 'O']\n",
      "{0: 4.755042290175667, 1: 0.5587538226299694}\n",
      "Training results for GerMedBERT/medbert-512 with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1202' max='4848' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1202/4848 01:15 < 03:48, 15.93 it/s, Epoch 2.97/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.110661</td>\n",
       "      <td>0.837209</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.807175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.189600</td>\n",
       "      <td>0.157961</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.836910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(f'training and results for {model}:')\n",
    "    ate_model(data, model, rn1=42, rn2=42, epochs=12, save=True)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c05e9e2c-271c-4627-9fc3-bdcc81066364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training and results for GerMedBERT/medbert-512:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Device set to use cuda:0\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at GerMedBERT/medbert-512 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5612.39 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4681.61 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-ASPECT']\n",
      "{0: 0.5587538226299694, 1: 4.755042290175667}\n",
      "Training results for GerMedBERT/medbert-512 with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4848' max='4848' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4848/4848 05:23, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.115053</td>\n",
       "      <td>0.815668</td>\n",
       "      <td>0.766234</td>\n",
       "      <td>0.790179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.189400</td>\n",
       "      <td>0.146322</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.812903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.084300</td>\n",
       "      <td>0.178711</td>\n",
       "      <td>0.826271</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.835118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.037700</td>\n",
       "      <td>0.215008</td>\n",
       "      <td>0.800797</td>\n",
       "      <td>0.870130</td>\n",
       "      <td>0.834025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.272521</td>\n",
       "      <td>0.825532</td>\n",
       "      <td>0.839827</td>\n",
       "      <td>0.832618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.021800</td>\n",
       "      <td>0.323538</td>\n",
       "      <td>0.837719</td>\n",
       "      <td>0.826840</td>\n",
       "      <td>0.832244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.344278</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.823529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.358251</td>\n",
       "      <td>0.826840</td>\n",
       "      <td>0.826840</td>\n",
       "      <td>0.826840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.400780</td>\n",
       "      <td>0.825328</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.821739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.406954</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.822270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.412218</td>\n",
       "      <td>0.809917</td>\n",
       "      <td>0.848485</td>\n",
       "      <td>0.828753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.414579</td>\n",
       "      <td>0.811966</td>\n",
       "      <td>0.822511</td>\n",
       "      <td>0.817204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_GerMedBERT_medbert-512_42_42_12\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_GerMedBERT_medbert-512_42_42_12\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4342.72 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.89      0.73      0.80       288\n",
      "\n",
      "   micro avg       0.89      0.73      0.80       288\n",
      "   macro avg       0.89      0.73      0.80       288\n",
      "weighted avg       0.89      0.73      0.80       288\n",
      "\n",
      "Precision Score: 0.8860759493670886\n",
      "Recall Score: 0.7291666666666666\n",
      "F1 Score: 0.8\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/12_epochs/GerMedBERT_medbert-512_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/12_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for deepset/gbert-base:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mapping of the data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6026.86 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4929.37 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:420: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-ASPECT']\n",
      "{0: 0.5587538226299694, 1: 4.755042290175667}\n",
      "Training results for deepset/gbert-base with 12 epochs and random seeds: 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4848' max='4848' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4848/4848 05:24, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.138880</td>\n",
       "      <td>0.851528</td>\n",
       "      <td>0.767717</td>\n",
       "      <td>0.807453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.187600</td>\n",
       "      <td>0.168863</td>\n",
       "      <td>0.837945</td>\n",
       "      <td>0.834646</td>\n",
       "      <td>0.836292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.093600</td>\n",
       "      <td>0.234688</td>\n",
       "      <td>0.857724</td>\n",
       "      <td>0.830709</td>\n",
       "      <td>0.844000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.034600</td>\n",
       "      <td>0.216671</td>\n",
       "      <td>0.828358</td>\n",
       "      <td>0.874016</td>\n",
       "      <td>0.850575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>0.307312</td>\n",
       "      <td>0.832700</td>\n",
       "      <td>0.862205</td>\n",
       "      <td>0.847195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.020800</td>\n",
       "      <td>0.341299</td>\n",
       "      <td>0.856574</td>\n",
       "      <td>0.846457</td>\n",
       "      <td>0.851485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.008900</td>\n",
       "      <td>0.335284</td>\n",
       "      <td>0.856574</td>\n",
       "      <td>0.846457</td>\n",
       "      <td>0.851485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>0.331235</td>\n",
       "      <td>0.844358</td>\n",
       "      <td>0.854331</td>\n",
       "      <td>0.849315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.002200</td>\n",
       "      <td>0.386206</td>\n",
       "      <td>0.827068</td>\n",
       "      <td>0.866142</td>\n",
       "      <td>0.846154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.381521</td>\n",
       "      <td>0.849802</td>\n",
       "      <td>0.846457</td>\n",
       "      <td>0.848126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.002300</td>\n",
       "      <td>0.383774</td>\n",
       "      <td>0.842308</td>\n",
       "      <td>0.862205</td>\n",
       "      <td>0.852140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.001300</td>\n",
       "      <td>0.388204</td>\n",
       "      <td>0.842308</td>\n",
       "      <td>0.862205</td>\n",
       "      <td>0.852140</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_deepset_gbert-base_42_42_12\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_deepset_gbert-base_42_42_12\n",
      "mapping the test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4484.99 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 1}\n",
      "Expected label IDs: {0, 1}\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      ASPECT       0.90      0.78      0.83       315\n",
      "\n",
      "   micro avg       0.90      0.78      0.83       315\n",
      "   macro avg       0.90      0.78      0.83       315\n",
      "weighted avg       0.90      0.78      0.83       315\n",
      "\n",
      "Precision Score: 0.9007352941176471\n",
      "Recall Score: 0.7777777777777778\n",
      "F1 Score: 0.8347529812606475\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-ASPECT', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate/12_epochs/deepset_gbert-base_ate_test_results.txt\n",
      "Confusion matrix saved to testresult/ate/12_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in [\"GerMedBERT/medbert-512\", \"deepset/gbert-base\"]:\n",
    "    print(f'training and results for {model}:')\n",
    "    ate_model(data, model, rn1=42, rn2=42, epochs=12, save=True)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38413b56-c91d-4900-8516-bac3dc4f879a",
   "metadata": {},
   "source": [
    "### 2. Train category-aware ATE Models for 5, 6, 7, 8, 10, 12 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e69d9f9-3dcf-4e7f-9ca1-fe2f12f2c79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training and results for google-bert/bert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5855.83 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4847.46 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-mediz. Service' 'B-Pflegepersonal' 'B-Arzt' 'B-anderer Service'\n",
      " 'B-Krankenhaus' 'B-Personal']\n",
      "{0: 0.1596439493228484, 1: 4.959959280624364, 2: 14.014381591562799, 3: 6.8239962651727355, 4: 10.546176046176047, 5: 5.983217355710193, 6: 18.317042606516292}\n",
      "Training google-bert/bert-base-german-cased for 5 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 02:18, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.224869</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.590038</td>\n",
       "      <td>0.644351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.330800</td>\n",
       "      <td>0.190629</td>\n",
       "      <td>0.747788</td>\n",
       "      <td>0.647510</td>\n",
       "      <td>0.694045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.138700</td>\n",
       "      <td>0.210872</td>\n",
       "      <td>0.764957</td>\n",
       "      <td>0.685824</td>\n",
       "      <td>0.723232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.053500</td>\n",
       "      <td>0.233231</td>\n",
       "      <td>0.771084</td>\n",
       "      <td>0.735632</td>\n",
       "      <td>0.752941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.029300</td>\n",
       "      <td>0.252053</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.712644</td>\n",
       "      <td>0.725146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_google-bert_bert-base-german-cased_42_42_5\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_google-bert_bert-base-german-cased_42_42_5\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4337.09 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.86      0.92      0.89        52\n",
      "    Krankenhaus       0.90      0.71      0.79       119\n",
      "       Personal       0.75      0.64      0.69        14\n",
      " Pflegepersonal       0.94      0.94      0.94        18\n",
      "anderer Service       0.68      0.39      0.50        33\n",
      " mediz. Service       0.82      0.76      0.79        87\n",
      "\n",
      "      micro avg       0.85      0.73      0.79       323\n",
      "      macro avg       0.83      0.73      0.77       323\n",
      "   weighted avg       0.85      0.73      0.78       323\n",
      "\n",
      "Precision Score: 0.8525179856115108\n",
      "Recall Score: 0.7337461300309598\n",
      "F1 Score: 0.788685524126456\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/5_epochs/google-bert_bert-base-german-cased_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/5_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5939.80 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4806.16 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-mediz. Service' 'B-Pflegepersonal' 'B-Arzt' 'B-anderer Service'\n",
      " 'B-Krankenhaus' 'B-Personal']\n",
      "{0: 0.1596439493228484, 1: 4.959959280624364, 2: 14.014381591562799, 3: 6.8239962651727355, 4: 10.546176046176047, 5: 5.983217355710193, 6: 18.317042606516292}\n",
      "Training dbmdz/bert-base-german-cased for 5 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 02:17, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.221302</td>\n",
       "      <td>0.686916</td>\n",
       "      <td>0.578740</td>\n",
       "      <td>0.628205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.353600</td>\n",
       "      <td>0.202281</td>\n",
       "      <td>0.724576</td>\n",
       "      <td>0.673228</td>\n",
       "      <td>0.697959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.156100</td>\n",
       "      <td>0.229355</td>\n",
       "      <td>0.771552</td>\n",
       "      <td>0.704724</td>\n",
       "      <td>0.736626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.071100</td>\n",
       "      <td>0.262558</td>\n",
       "      <td>0.748988</td>\n",
       "      <td>0.728346</td>\n",
       "      <td>0.738523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.038000</td>\n",
       "      <td>0.280303</td>\n",
       "      <td>0.755020</td>\n",
       "      <td>0.740157</td>\n",
       "      <td>0.747515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_dbmdz_bert-base-german-cased_42_42_5\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_dbmdz_bert-base-german-cased_42_42_5\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4417.47 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.90      0.95      0.92        55\n",
      "    Krankenhaus       0.86      0.64      0.74       117\n",
      "       Personal       0.67      0.46      0.55        13\n",
      " Pflegepersonal       1.00      0.94      0.97        18\n",
      "anderer Service       0.69      0.57      0.62        35\n",
      " mediz. Service       0.79      0.75      0.77        77\n",
      "\n",
      "      micro avg       0.84      0.72      0.78       315\n",
      "      macro avg       0.82      0.72      0.76       315\n",
      "   weighted avg       0.83      0.72      0.77       315\n",
      "\n",
      "Precision Score: 0.8351648351648352\n",
      "Recall Score: 0.7238095238095238\n",
      "F1 Score: 0.7755102040816326\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/5_epochs/dbmdz_bert-base-german-cased_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/5_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-uncased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5664.95 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4729.22 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-mediz. Service' 'B-Pflegepersonal' 'B-Arzt' 'B-anderer Service'\n",
      " 'B-Krankenhaus' 'B-Personal']\n",
      "{0: 0.1596439493228484, 1: 4.959959280624364, 2: 14.014381591562799, 3: 6.8239962651727355, 4: 10.546176046176047, 5: 5.983217355710193, 6: 18.317042606516292}\n",
      "Training dbmdz/bert-base-german-uncased for 5 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 02:18, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.224606</td>\n",
       "      <td>0.723301</td>\n",
       "      <td>0.591270</td>\n",
       "      <td>0.650655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.326400</td>\n",
       "      <td>0.234411</td>\n",
       "      <td>0.763636</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.711864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.241171</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.771429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.064700</td>\n",
       "      <td>0.269833</td>\n",
       "      <td>0.773663</td>\n",
       "      <td>0.746032</td>\n",
       "      <td>0.759596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.046400</td>\n",
       "      <td>0.273208</td>\n",
       "      <td>0.783673</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.772636</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_dbmdz_bert-base-german-uncased_42_42_5\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_dbmdz_bert-base-german-uncased_42_42_5\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4383.44 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.90      0.90      0.90        63\n",
      "    Krankenhaus       0.92      0.60      0.72       112\n",
      "       Personal       0.75      0.86      0.80        14\n",
      " Pflegepersonal       1.00      0.95      0.97        19\n",
      "anderer Service       0.63      0.35      0.45        34\n",
      " mediz. Service       0.85      0.77      0.81        74\n",
      "\n",
      "      micro avg       0.87      0.71      0.78       316\n",
      "      macro avg       0.84      0.74      0.78       316\n",
      "   weighted avg       0.87      0.71      0.77       316\n",
      "\n",
      "Precision Score: 0.87109375\n",
      "Recall Score: 0.7056962025316456\n",
      "F1 Score: 0.7797202797202798\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/5_epochs/dbmdz_bert-base-german-uncased_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/5_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for FacebookAI/xlm-roberta-base:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5837.36 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5026.16 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-mediz. Service' 'B-Pflegepersonal' 'B-Arzt' 'B-anderer Service'\n",
      " 'B-Krankenhaus' 'B-Personal']\n",
      "{0: 0.1596439493228484, 1: 4.959959280624364, 2: 14.014381591562799, 3: 6.8239962651727355, 4: 10.546176046176047, 5: 5.983217355710193, 6: 18.317042606516292}\n",
      "Training FacebookAI/xlm-roberta-base for 5 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 03:35, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.283657</td>\n",
       "      <td>0.586777</td>\n",
       "      <td>0.491349</td>\n",
       "      <td>0.534840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.421400</td>\n",
       "      <td>0.221515</td>\n",
       "      <td>0.691275</td>\n",
       "      <td>0.712803</td>\n",
       "      <td>0.701874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.227300</td>\n",
       "      <td>0.211442</td>\n",
       "      <td>0.716312</td>\n",
       "      <td>0.698962</td>\n",
       "      <td>0.707531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.136900</td>\n",
       "      <td>0.205753</td>\n",
       "      <td>0.724252</td>\n",
       "      <td>0.754325</td>\n",
       "      <td>0.738983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.102100</td>\n",
       "      <td>0.216718</td>\n",
       "      <td>0.728223</td>\n",
       "      <td>0.723183</td>\n",
       "      <td>0.725694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_FacebookAI_xlm-roberta-base_42_42_5\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_FacebookAI_xlm-roberta-base_42_42_5\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4289.47 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.82      0.93      0.87        59\n",
      "    Krankenhaus       0.79      0.79      0.79       120\n",
      "       Personal       0.67      0.67      0.67        15\n",
      " Pflegepersonal       1.00      0.88      0.93        24\n",
      "anderer Service       0.48      0.33      0.39        45\n",
      " mediz. Service       0.70      0.67      0.69        83\n",
      "\n",
      "      micro avg       0.75      0.73      0.74       346\n",
      "      macro avg       0.74      0.71      0.72       346\n",
      "   weighted avg       0.74      0.73      0.73       346\n",
      "\n",
      "Precision Score: 0.7522388059701492\n",
      "Recall Score: 0.7283236994219653\n",
      "F1 Score: 0.7400881057268722\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/5_epochs/FacebookAI_xlm-roberta-base_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/5_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_best:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at TUM/GottBERT_base_best and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6517.35 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5059.29 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-mediz. Service' 'B-Pflegepersonal' 'B-Arzt' 'B-anderer Service'\n",
      " 'B-Krankenhaus' 'B-Personal']\n",
      "{0: 0.1596439493228484, 1: 4.959959280624364, 2: 14.014381591562799, 3: 6.8239962651727355, 4: 10.546176046176047, 5: 5.983217355710193, 6: 18.317042606516292}\n",
      "Training TUM/GottBERT_base_best for 5 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 02:26, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.233069</td>\n",
       "      <td>0.711957</td>\n",
       "      <td>0.617925</td>\n",
       "      <td>0.661616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.318700</td>\n",
       "      <td>0.185063</td>\n",
       "      <td>0.743842</td>\n",
       "      <td>0.712264</td>\n",
       "      <td>0.727711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.173200</td>\n",
       "      <td>0.213243</td>\n",
       "      <td>0.737864</td>\n",
       "      <td>0.716981</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.084500</td>\n",
       "      <td>0.283493</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.679245</td>\n",
       "      <td>0.705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.057500</td>\n",
       "      <td>0.274932</td>\n",
       "      <td>0.730392</td>\n",
       "      <td>0.702830</td>\n",
       "      <td>0.716346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_TUM_GottBERT_base_best_42_42_5\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_TUM_GottBERT_base_best_42_42_5\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4767.00 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.88      0.98      0.93        52\n",
      "    Krankenhaus       0.85      0.65      0.74       104\n",
      "       Personal       0.70      0.58      0.64        12\n",
      " Pflegepersonal       0.93      0.93      0.93        14\n",
      "anderer Service       0.83      0.33      0.48        30\n",
      " mediz. Service       0.79      0.81      0.80        67\n",
      "\n",
      "      micro avg       0.84      0.73      0.78       279\n",
      "      macro avg       0.83      0.71      0.75       279\n",
      "   weighted avg       0.84      0.73      0.77       279\n",
      "\n",
      "Precision Score: 0.8388429752066116\n",
      "Recall Score: 0.7275985663082437\n",
      "F1 Score: 0.7792706333973128\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/5_epochs/TUM_GottBERT_base_best_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/5_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_filtered_base_best:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at TUM/GottBERT_filtered_base_best and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6443.90 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5059.96 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-mediz. Service' 'B-Pflegepersonal' 'B-Arzt' 'B-anderer Service'\n",
      " 'B-Krankenhaus' 'B-Personal']\n",
      "{0: 0.1596439493228484, 1: 4.959959280624364, 2: 14.014381591562799, 3: 6.8239962651727355, 4: 10.546176046176047, 5: 5.983217355710193, 6: 18.317042606516292}\n",
      "Training TUM/GottBERT_filtered_base_best for 5 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 02:27, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.209740</td>\n",
       "      <td>0.761628</td>\n",
       "      <td>0.617925</td>\n",
       "      <td>0.682292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.321700</td>\n",
       "      <td>0.177827</td>\n",
       "      <td>0.767327</td>\n",
       "      <td>0.731132</td>\n",
       "      <td>0.748792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.160200</td>\n",
       "      <td>0.178644</td>\n",
       "      <td>0.763547</td>\n",
       "      <td>0.731132</td>\n",
       "      <td>0.746988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.082200</td>\n",
       "      <td>0.214671</td>\n",
       "      <td>0.771845</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.760766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.052700</td>\n",
       "      <td>0.210250</td>\n",
       "      <td>0.771845</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.760766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_TUM_GottBERT_filtered_base_best_42_42_5\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_TUM_GottBERT_filtered_base_best_42_42_5\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4737.44 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.91      0.96      0.93        52\n",
      "    Krankenhaus       0.91      0.66      0.77       104\n",
      "       Personal       0.75      0.75      0.75        12\n",
      " Pflegepersonal       0.93      0.93      0.93        14\n",
      "anderer Service       0.59      0.33      0.43        30\n",
      " mediz. Service       0.78      0.73      0.75        67\n",
      "\n",
      "      micro avg       0.84      0.72      0.78       279\n",
      "      macro avg       0.81      0.73      0.76       279\n",
      "   weighted avg       0.84      0.72      0.77       279\n",
      "\n",
      "Precision Score: 0.8438818565400844\n",
      "Recall Score: 0.7168458781362007\n",
      "F1 Score: 0.7751937984496124\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/5_epochs/TUM_GottBERT_filtered_base_best_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/5_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_last:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at TUM/GottBERT_base_last were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at TUM/GottBERT_base_last and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6457.95 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4988.46 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-mediz. Service' 'B-Pflegepersonal' 'B-Arzt' 'B-anderer Service'\n",
      " 'B-Krankenhaus' 'B-Personal']\n",
      "{0: 0.1596439493228484, 1: 4.959959280624364, 2: 14.014381591562799, 3: 6.8239962651727355, 4: 10.546176046176047, 5: 5.983217355710193, 6: 18.317042606516292}\n",
      "Training TUM/GottBERT_base_last for 5 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 02:22, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.235655</td>\n",
       "      <td>0.734463</td>\n",
       "      <td>0.613208</td>\n",
       "      <td>0.668380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.313000</td>\n",
       "      <td>0.175196</td>\n",
       "      <td>0.757426</td>\n",
       "      <td>0.721698</td>\n",
       "      <td>0.739130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.167600</td>\n",
       "      <td>0.201712</td>\n",
       "      <td>0.764423</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.757143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.083800</td>\n",
       "      <td>0.251479</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.716981</td>\n",
       "      <td>0.756219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.054600</td>\n",
       "      <td>0.256751</td>\n",
       "      <td>0.785000</td>\n",
       "      <td>0.740566</td>\n",
       "      <td>0.762136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_TUM_GottBERT_base_last_42_42_5\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_TUM_GottBERT_base_last_42_42_5\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4653.34 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.96      0.98      0.97        52\n",
      "    Krankenhaus       0.90      0.76      0.82       104\n",
      "       Personal       0.69      0.75      0.72        12\n",
      " Pflegepersonal       1.00      1.00      1.00        14\n",
      "anderer Service       0.63      0.57      0.60        30\n",
      " mediz. Service       0.67      0.70      0.69        67\n",
      "\n",
      "      micro avg       0.82      0.78      0.80       279\n",
      "      macro avg       0.81      0.79      0.80       279\n",
      "   weighted avg       0.82      0.78      0.80       279\n",
      "\n",
      "Precision Score: 0.8188679245283019\n",
      "Recall Score: 0.7777777777777778\n",
      "F1 Score: 0.7977941176470589\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/5_epochs/TUM_GottBERT_base_last_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/5_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for distilbert/distilbert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6479.63 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5237.95 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-mediz. Service' 'B-Pflegepersonal' 'B-Arzt' 'B-anderer Service'\n",
      " 'B-Krankenhaus' 'B-Personal']\n",
      "{0: 0.1596439493228484, 1: 4.959959280624364, 2: 14.014381591562799, 3: 6.8239962651727355, 4: 10.546176046176047, 5: 5.983217355710193, 6: 18.317042606516292}\n",
      "Training distilbert/distilbert-base-german-cased for 5 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 01:17, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.241931</td>\n",
       "      <td>0.632558</td>\n",
       "      <td>0.535433</td>\n",
       "      <td>0.579957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.397300</td>\n",
       "      <td>0.222672</td>\n",
       "      <td>0.715556</td>\n",
       "      <td>0.633858</td>\n",
       "      <td>0.672234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.172500</td>\n",
       "      <td>0.243207</td>\n",
       "      <td>0.748792</td>\n",
       "      <td>0.610236</td>\n",
       "      <td>0.672451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.096700</td>\n",
       "      <td>0.243671</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.685039</td>\n",
       "      <td>0.716049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.069700</td>\n",
       "      <td>0.255058</td>\n",
       "      <td>0.736170</td>\n",
       "      <td>0.681102</td>\n",
       "      <td>0.707566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_distilbert_distilbert-base-german-cased_42_42_5\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_distilbert_distilbert-base-german-cased_42_42_5\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4687.40 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.89      0.93      0.91        55\n",
      "    Krankenhaus       0.94      0.56      0.71       117\n",
      "       Personal       0.60      0.46      0.52        13\n",
      " Pflegepersonal       0.94      0.89      0.91        18\n",
      "anderer Service       0.75      0.34      0.47        35\n",
      " mediz. Service       0.68      0.68      0.68        77\n",
      "\n",
      "      micro avg       0.82      0.64      0.72       315\n",
      "      macro avg       0.80      0.64      0.70       315\n",
      "   weighted avg       0.83      0.64      0.71       315\n",
      "\n",
      "Precision Score: 0.8218623481781376\n",
      "Recall Score: 0.6444444444444445\n",
      "F1 Score: 0.7224199288256228\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/5_epochs/distilbert_distilbert-base-german-cased_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/5_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for GerMedBERT/medbert-512:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at GerMedBERT/medbert-512 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5663.47 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4554.52 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-mediz. Service' 'B-Pflegepersonal' 'B-Arzt' 'B-anderer Service'\n",
      " 'B-Krankenhaus' 'B-Personal']\n",
      "{0: 0.1596439493228484, 1: 4.959959280624364, 2: 14.014381591562799, 3: 6.8239962651727355, 4: 10.546176046176047, 5: 5.983217355710193, 6: 18.317042606516292}\n",
      "Training GerMedBERT/medbert-512 for 5 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 02:14, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.202199</td>\n",
       "      <td>0.685279</td>\n",
       "      <td>0.584416</td>\n",
       "      <td>0.630841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.320200</td>\n",
       "      <td>0.171366</td>\n",
       "      <td>0.703540</td>\n",
       "      <td>0.688312</td>\n",
       "      <td>0.695842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.146400</td>\n",
       "      <td>0.216500</td>\n",
       "      <td>0.752427</td>\n",
       "      <td>0.670996</td>\n",
       "      <td>0.709382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.063300</td>\n",
       "      <td>0.233945</td>\n",
       "      <td>0.728889</td>\n",
       "      <td>0.709957</td>\n",
       "      <td>0.719298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.040300</td>\n",
       "      <td>0.249321</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.709957</td>\n",
       "      <td>0.720879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_GerMedBERT_medbert-512_42_42_5\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_GerMedBERT_medbert-512_42_42_5\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4172.09 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.98      0.96      0.97        54\n",
      "    Krankenhaus       0.89      0.76      0.82       105\n",
      "       Personal       0.93      0.88      0.90        16\n",
      " Pflegepersonal       0.93      0.93      0.93        15\n",
      "anderer Service       0.56      0.40      0.47        35\n",
      " mediz. Service       0.79      0.60      0.68        63\n",
      "\n",
      "      micro avg       0.86      0.74      0.79       288\n",
      "      macro avg       0.85      0.76      0.80       288\n",
      "   weighted avg       0.85      0.74      0.79       288\n",
      "\n",
      "Precision Score: 0.8617886178861789\n",
      "Recall Score: 0.7361111111111112\n",
      "F1 Score: 0.7940074906367042\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/5_epochs/GerMedBERT_medbert-512_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/5_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for deepset/gbert-base:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5843.76 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4748.14 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-mediz. Service' 'B-Pflegepersonal' 'B-Arzt' 'B-anderer Service'\n",
      " 'B-Krankenhaus' 'B-Personal']\n",
      "{0: 0.1596439493228484, 1: 4.959959280624364, 2: 14.014381591562799, 3: 6.8239962651727355, 4: 10.546176046176047, 5: 5.983217355710193, 6: 18.317042606516292}\n",
      "Training deepset/gbert-base for 5 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2020' max='2020' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2020/2020 02:21, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.230418</td>\n",
       "      <td>0.686636</td>\n",
       "      <td>0.586614</td>\n",
       "      <td>0.632696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.337500</td>\n",
       "      <td>0.192138</td>\n",
       "      <td>0.764151</td>\n",
       "      <td>0.637795</td>\n",
       "      <td>0.695279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.147500</td>\n",
       "      <td>0.219408</td>\n",
       "      <td>0.752137</td>\n",
       "      <td>0.692913</td>\n",
       "      <td>0.721311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.059800</td>\n",
       "      <td>0.244842</td>\n",
       "      <td>0.768240</td>\n",
       "      <td>0.704724</td>\n",
       "      <td>0.735113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>0.257871</td>\n",
       "      <td>0.759184</td>\n",
       "      <td>0.732283</td>\n",
       "      <td>0.745491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_deepset_gbert-base_42_42_5\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_deepset_gbert-base_42_42_5\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4399.57 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.90      0.95      0.92        55\n",
      "    Krankenhaus       0.90      0.62      0.73       117\n",
      "       Personal       0.73      0.62      0.67        13\n",
      " Pflegepersonal       1.00      0.94      0.97        18\n",
      "anderer Service       0.73      0.46      0.56        35\n",
      " mediz. Service       0.88      0.73      0.79        77\n",
      "\n",
      "      micro avg       0.88      0.70      0.78       315\n",
      "      macro avg       0.85      0.72      0.77       315\n",
      "   weighted avg       0.87      0.70      0.77       315\n",
      "\n",
      "Precision Score: 0.876984126984127\n",
      "Recall Score: 0.7015873015873015\n",
      "F1 Score: 0.7795414462081128\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/5_epochs/deepset_gbert-base_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/5_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(f'training and results for {model}:')\n",
    "    ate_cat_model(data, model, rn1=42, rn2=42, epochs=5, save=True)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9837ae1c-c880-43f2-b642-a9cb1c573ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training and results for google-bert/bert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5777.21 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4646.03 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-mediz. Service' 'B-Pflegepersonal' 'B-Arzt' 'B-anderer Service'\n",
      " 'B-Krankenhaus' 'B-Personal']\n",
      "{0: 0.1596439493228484, 1: 4.959959280624364, 2: 14.014381591562799, 3: 6.8239962651727355, 4: 10.546176046176047, 5: 5.983217355710193, 6: 18.317042606516292}\n",
      "Training google-bert/bert-base-german-cased for 6 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2424' max='2424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2424/2424 02:46, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.223776</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.582375</td>\n",
       "      <td>0.637317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.325700</td>\n",
       "      <td>0.207315</td>\n",
       "      <td>0.698276</td>\n",
       "      <td>0.620690</td>\n",
       "      <td>0.657201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.134500</td>\n",
       "      <td>0.220423</td>\n",
       "      <td>0.767347</td>\n",
       "      <td>0.720307</td>\n",
       "      <td>0.743083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>0.257904</td>\n",
       "      <td>0.775424</td>\n",
       "      <td>0.701149</td>\n",
       "      <td>0.736419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.298462</td>\n",
       "      <td>0.760684</td>\n",
       "      <td>0.681992</td>\n",
       "      <td>0.719192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.024000</td>\n",
       "      <td>0.310660</td>\n",
       "      <td>0.757322</td>\n",
       "      <td>0.693487</td>\n",
       "      <td>0.724000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_google-bert_bert-base-german-cased_42_42_6\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_google-bert_bert-base-german-cased_42_42_6\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4388.47 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.86      0.96      0.91        52\n",
      "    Krankenhaus       0.92      0.61      0.73       119\n",
      "       Personal       0.67      0.43      0.52        14\n",
      " Pflegepersonal       1.00      0.94      0.97        18\n",
      "anderer Service       0.68      0.45      0.55        33\n",
      " mediz. Service       0.77      0.80      0.79        87\n",
      "\n",
      "      micro avg       0.84      0.71      0.77       323\n",
      "      macro avg       0.82      0.70      0.74       323\n",
      "   weighted avg       0.84      0.71      0.76       323\n",
      "\n",
      "Precision Score: 0.8363636363636363\n",
      "Recall Score: 0.7120743034055728\n",
      "F1 Score: 0.7692307692307693\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/6_epochs/google-bert_bert-base-german-cased_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/6_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5779.66 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4844.19 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-mediz. Service' 'B-Pflegepersonal' 'B-Arzt' 'B-anderer Service'\n",
      " 'B-Krankenhaus' 'B-Personal']\n",
      "{0: 0.1596439493228484, 1: 4.959959280624364, 2: 14.014381591562799, 3: 6.8239962651727355, 4: 10.546176046176047, 5: 5.983217355710193, 6: 18.317042606516292}\n",
      "Training dbmdz/bert-base-german-cased for 6 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2424' max='2424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2424/2424 02:47, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.221050</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.610236</td>\n",
       "      <td>0.654008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.342700</td>\n",
       "      <td>0.199783</td>\n",
       "      <td>0.750988</td>\n",
       "      <td>0.748031</td>\n",
       "      <td>0.749507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.233014</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.767717</td>\n",
       "      <td>0.751445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.074800</td>\n",
       "      <td>0.232670</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.740157</td>\n",
       "      <td>0.767347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.044900</td>\n",
       "      <td>0.269969</td>\n",
       "      <td>0.740876</td>\n",
       "      <td>0.799213</td>\n",
       "      <td>0.768939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.044900</td>\n",
       "      <td>0.277904</td>\n",
       "      <td>0.765152</td>\n",
       "      <td>0.795276</td>\n",
       "      <td>0.779923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_dbmdz_bert-base-german-cased_42_42_6\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_dbmdz_bert-base-german-cased_42_42_6\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4463.65 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.87      0.95      0.90        55\n",
      "    Krankenhaus       0.91      0.74      0.82       117\n",
      "       Personal       0.64      0.54      0.58        13\n",
      " Pflegepersonal       0.94      0.94      0.94        18\n",
      "anderer Service       0.69      0.57      0.62        35\n",
      " mediz. Service       0.79      0.79      0.79        77\n",
      "\n",
      "      micro avg       0.84      0.77      0.80       315\n",
      "      macro avg       0.81      0.75      0.78       315\n",
      "   weighted avg       0.84      0.77      0.80       315\n",
      "\n",
      "Precision Score: 0.8408304498269896\n",
      "Recall Score: 0.7714285714285715\n",
      "F1 Score: 0.804635761589404\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/6_epochs/dbmdz_bert-base-german-cased_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/6_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-uncased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5536.11 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4686.74 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-mediz. Service' 'B-Pflegepersonal' 'B-Arzt' 'B-anderer Service'\n",
      " 'B-Krankenhaus' 'B-Personal']\n",
      "{0: 0.1596439493228484, 1: 4.959959280624364, 2: 14.014381591562799, 3: 6.8239962651727355, 4: 10.546176046176047, 5: 5.983217355710193, 6: 18.317042606516292}\n",
      "Training dbmdz/bert-base-german-uncased for 6 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2424' max='2424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2424/2424 02:48, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.228741</td>\n",
       "      <td>0.679825</td>\n",
       "      <td>0.615079</td>\n",
       "      <td>0.645833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.325300</td>\n",
       "      <td>0.228101</td>\n",
       "      <td>0.738938</td>\n",
       "      <td>0.662698</td>\n",
       "      <td>0.698745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.219872</td>\n",
       "      <td>0.772358</td>\n",
       "      <td>0.753968</td>\n",
       "      <td>0.763052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.061300</td>\n",
       "      <td>0.259166</td>\n",
       "      <td>0.812766</td>\n",
       "      <td>0.757937</td>\n",
       "      <td>0.784394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.040100</td>\n",
       "      <td>0.262348</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.780876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.040100</td>\n",
       "      <td>0.305934</td>\n",
       "      <td>0.774059</td>\n",
       "      <td>0.734127</td>\n",
       "      <td>0.753564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_dbmdz_bert-base-german-uncased_42_42_6\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_dbmdz_bert-base-german-uncased_42_42_6\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4439.43 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.97      0.97      0.97        63\n",
      "    Krankenhaus       0.98      0.47      0.64       112\n",
      "       Personal       0.75      0.86      0.80        14\n",
      " Pflegepersonal       1.00      0.95      0.97        19\n",
      "anderer Service       0.64      0.41      0.50        34\n",
      " mediz. Service       0.88      0.76      0.81        74\n",
      "\n",
      "      micro avg       0.90      0.68      0.77       316\n",
      "      macro avg       0.87      0.74      0.78       316\n",
      "   weighted avg       0.91      0.68      0.76       316\n",
      "\n",
      "Precision Score: 0.9029535864978903\n",
      "Recall Score: 0.6772151898734177\n",
      "F1 Score: 0.7739602169981916\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/6_epochs/dbmdz_bert-base-german-uncased_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/6_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for FacebookAI/xlm-roberta-base:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5752.94 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4837.39 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-mediz. Service' 'B-Pflegepersonal' 'B-Arzt' 'B-anderer Service'\n",
      " 'B-Krankenhaus' 'B-Personal']\n",
      "{0: 0.1596439493228484, 1: 4.959959280624364, 2: 14.014381591562799, 3: 6.8239962651727355, 4: 10.546176046176047, 5: 5.983217355710193, 6: 18.317042606516292}\n",
      "Training FacebookAI/xlm-roberta-base for 6 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2424' max='2424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2424/2424 04:17, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.278038</td>\n",
       "      <td>0.637131</td>\n",
       "      <td>0.522491</td>\n",
       "      <td>0.574144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.419000</td>\n",
       "      <td>0.222709</td>\n",
       "      <td>0.735632</td>\n",
       "      <td>0.664360</td>\n",
       "      <td>0.698182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.226500</td>\n",
       "      <td>0.218506</td>\n",
       "      <td>0.748175</td>\n",
       "      <td>0.709343</td>\n",
       "      <td>0.728242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.133300</td>\n",
       "      <td>0.244461</td>\n",
       "      <td>0.740876</td>\n",
       "      <td>0.702422</td>\n",
       "      <td>0.721137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.096300</td>\n",
       "      <td>0.256283</td>\n",
       "      <td>0.720779</td>\n",
       "      <td>0.768166</td>\n",
       "      <td>0.743719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.096300</td>\n",
       "      <td>0.262530</td>\n",
       "      <td>0.734483</td>\n",
       "      <td>0.737024</td>\n",
       "      <td>0.735751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_FacebookAI_xlm-roberta-base_42_42_6\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_FacebookAI_xlm-roberta-base_42_42_6\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4606.25 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.82      0.93      0.87        59\n",
      "    Krankenhaus       0.79      0.86      0.82       120\n",
      "       Personal       0.71      0.67      0.69        15\n",
      " Pflegepersonal       1.00      0.96      0.98        24\n",
      "anderer Service       0.67      0.49      0.56        45\n",
      " mediz. Service       0.78      0.75      0.77        83\n",
      "\n",
      "      micro avg       0.79      0.79      0.79       346\n",
      "      macro avg       0.80      0.78      0.78       346\n",
      "   weighted avg       0.79      0.79      0.79       346\n",
      "\n",
      "Precision Score: 0.792507204610951\n",
      "Recall Score: 0.7947976878612717\n",
      "F1 Score: 0.7936507936507936\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/6_epochs/FacebookAI_xlm-roberta-base_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/6_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_best:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at TUM/GottBERT_base_best and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6479.67 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5055.37 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-mediz. Service' 'B-Pflegepersonal' 'B-Arzt' 'B-anderer Service'\n",
      " 'B-Krankenhaus' 'B-Personal']\n",
      "{0: 0.1596439493228484, 1: 4.959959280624364, 2: 14.014381591562799, 3: 6.8239962651727355, 4: 10.546176046176047, 5: 5.983217355710193, 6: 18.317042606516292}\n",
      "Training TUM/GottBERT_base_best for 6 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2424' max='2424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2424/2424 02:55, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.241105</td>\n",
       "      <td>0.706522</td>\n",
       "      <td>0.613208</td>\n",
       "      <td>0.656566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.323200</td>\n",
       "      <td>0.209590</td>\n",
       "      <td>0.752747</td>\n",
       "      <td>0.646226</td>\n",
       "      <td>0.695431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.166600</td>\n",
       "      <td>0.232567</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.726415</td>\n",
       "      <td>0.731591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.084100</td>\n",
       "      <td>0.276728</td>\n",
       "      <td>0.722488</td>\n",
       "      <td>0.712264</td>\n",
       "      <td>0.717340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.052500</td>\n",
       "      <td>0.299214</td>\n",
       "      <td>0.696429</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.715596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.052500</td>\n",
       "      <td>0.322898</td>\n",
       "      <td>0.688372</td>\n",
       "      <td>0.698113</td>\n",
       "      <td>0.693208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_TUM_GottBERT_base_best_42_42_6\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_TUM_GottBERT_base_best_42_42_6\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4691.20 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.94      0.98      0.96        52\n",
      "    Krankenhaus       0.92      0.64      0.76       104\n",
      "       Personal       0.64      0.75      0.69        12\n",
      " Pflegepersonal       0.93      0.93      0.93        14\n",
      "anderer Service       0.67      0.47      0.55        30\n",
      " mediz. Service       0.68      0.78      0.72        67\n",
      "\n",
      "      micro avg       0.81      0.74      0.77       279\n",
      "      macro avg       0.80      0.76      0.77       279\n",
      "   weighted avg       0.83      0.74      0.77       279\n",
      "\n",
      "Precision Score: 0.8142292490118577\n",
      "Recall Score: 0.7383512544802867\n",
      "F1 Score: 0.7744360902255639\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/6_epochs/TUM_GottBERT_base_best_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/6_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_filtered_base_best:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at TUM/GottBERT_filtered_base_best and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6422.38 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5021.39 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-mediz. Service' 'B-Pflegepersonal' 'B-Arzt' 'B-anderer Service'\n",
      " 'B-Krankenhaus' 'B-Personal']\n",
      "{0: 0.1596439493228484, 1: 4.959959280624364, 2: 14.014381591562799, 3: 6.8239962651727355, 4: 10.546176046176047, 5: 5.983217355710193, 6: 18.317042606516292}\n",
      "Training TUM/GottBERT_filtered_base_best for 6 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2424' max='2424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2424/2424 02:55, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.213365</td>\n",
       "      <td>0.694301</td>\n",
       "      <td>0.632075</td>\n",
       "      <td>0.661728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.319900</td>\n",
       "      <td>0.155376</td>\n",
       "      <td>0.787879</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.760976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.170500</td>\n",
       "      <td>0.183111</td>\n",
       "      <td>0.770833</td>\n",
       "      <td>0.698113</td>\n",
       "      <td>0.732673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.085200</td>\n",
       "      <td>0.158645</td>\n",
       "      <td>0.758294</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.756501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.058300</td>\n",
       "      <td>0.250049</td>\n",
       "      <td>0.751295</td>\n",
       "      <td>0.683962</td>\n",
       "      <td>0.716049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.058300</td>\n",
       "      <td>0.229074</td>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.679245</td>\n",
       "      <td>0.705882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_TUM_GottBERT_filtered_base_best_42_42_6\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_TUM_GottBERT_filtered_base_best_42_42_6\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4695.99 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.93      0.98      0.95        52\n",
      "    Krankenhaus       0.92      0.66      0.77       104\n",
      "       Personal       0.73      0.67      0.70        12\n",
      " Pflegepersonal       0.87      0.93      0.90        14\n",
      "anderer Service       0.64      0.30      0.41        30\n",
      " mediz. Service       0.82      0.81      0.81        67\n",
      "\n",
      "      micro avg       0.86      0.73      0.79       279\n",
      "      macro avg       0.82      0.72      0.76       279\n",
      "   weighted avg       0.86      0.73      0.78       279\n",
      "\n",
      "Precision Score: 0.864406779661017\n",
      "Recall Score: 0.7311827956989247\n",
      "F1 Score: 0.7922330097087378\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/6_epochs/TUM_GottBERT_filtered_base_best_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/6_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_last:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at TUM/GottBERT_base_last were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at TUM/GottBERT_base_last and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6431.25 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5095.62 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-mediz. Service' 'B-Pflegepersonal' 'B-Arzt' 'B-anderer Service'\n",
      " 'B-Krankenhaus' 'B-Personal']\n",
      "{0: 0.1596439493228484, 1: 4.959959280624364, 2: 14.014381591562799, 3: 6.8239962651727355, 4: 10.546176046176047, 5: 5.983217355710193, 6: 18.317042606516292}\n",
      "Training TUM/GottBERT_base_last for 6 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2424' max='2424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2424/2424 02:55, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.223606</td>\n",
       "      <td>0.698225</td>\n",
       "      <td>0.556604</td>\n",
       "      <td>0.619423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.337400</td>\n",
       "      <td>0.188333</td>\n",
       "      <td>0.761421</td>\n",
       "      <td>0.707547</td>\n",
       "      <td>0.733496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.175700</td>\n",
       "      <td>0.241469</td>\n",
       "      <td>0.746341</td>\n",
       "      <td>0.721698</td>\n",
       "      <td>0.733813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.090200</td>\n",
       "      <td>0.248286</td>\n",
       "      <td>0.752525</td>\n",
       "      <td>0.702830</td>\n",
       "      <td>0.726829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.058500</td>\n",
       "      <td>0.310955</td>\n",
       "      <td>0.716981</td>\n",
       "      <td>0.716981</td>\n",
       "      <td>0.716981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.058500</td>\n",
       "      <td>0.338784</td>\n",
       "      <td>0.710900</td>\n",
       "      <td>0.707547</td>\n",
       "      <td>0.709220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_TUM_GottBERT_base_last_42_42_6\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_TUM_GottBERT_base_last_42_42_6\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4660.08 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.94      0.98      0.96        52\n",
      "    Krankenhaus       0.94      0.62      0.75       104\n",
      "       Personal       0.67      0.67      0.67        12\n",
      " Pflegepersonal       0.93      0.93      0.93        14\n",
      "anderer Service       0.53      0.33      0.41        30\n",
      " mediz. Service       0.70      0.84      0.76        67\n",
      "\n",
      "      micro avg       0.82      0.73      0.77       279\n",
      "      macro avg       0.78      0.73      0.75       279\n",
      "   weighted avg       0.83      0.73      0.76       279\n",
      "\n",
      "Precision Score: 0.8185483870967742\n",
      "Recall Score: 0.7275985663082437\n",
      "F1 Score: 0.7703984819734346\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/6_epochs/TUM_GottBERT_base_last_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/6_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for distilbert/distilbert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6500.53 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5163.57 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-mediz. Service' 'B-Pflegepersonal' 'B-Arzt' 'B-anderer Service'\n",
      " 'B-Krankenhaus' 'B-Personal']\n",
      "{0: 0.1596439493228484, 1: 4.959959280624364, 2: 14.014381591562799, 3: 6.8239962651727355, 4: 10.546176046176047, 5: 5.983217355710193, 6: 18.317042606516292}\n",
      "Training distilbert/distilbert-base-german-cased for 6 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2424' max='2424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2424/2424 01:33, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.232993</td>\n",
       "      <td>0.648402</td>\n",
       "      <td>0.559055</td>\n",
       "      <td>0.600423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.388600</td>\n",
       "      <td>0.218969</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>0.661417</td>\n",
       "      <td>0.674699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.173900</td>\n",
       "      <td>0.232267</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.649606</td>\n",
       "      <td>0.696203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.091800</td>\n",
       "      <td>0.240863</td>\n",
       "      <td>0.757202</td>\n",
       "      <td>0.724409</td>\n",
       "      <td>0.740443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.062200</td>\n",
       "      <td>0.266235</td>\n",
       "      <td>0.759494</td>\n",
       "      <td>0.708661</td>\n",
       "      <td>0.733198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.062200</td>\n",
       "      <td>0.280191</td>\n",
       "      <td>0.741667</td>\n",
       "      <td>0.700787</td>\n",
       "      <td>0.720648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_distilbert_distilbert-base-german-cased_42_42_6\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_distilbert_distilbert-base-german-cased_42_42_6\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4782.13 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.91      0.93      0.92        55\n",
      "    Krankenhaus       0.92      0.61      0.73       117\n",
      "       Personal       0.62      0.62      0.62        13\n",
      " Pflegepersonal       1.00      0.89      0.94        18\n",
      "anderer Service       0.78      0.40      0.53        35\n",
      " mediz. Service       0.65      0.71      0.68        77\n",
      "\n",
      "      micro avg       0.81      0.68      0.74       315\n",
      "      macro avg       0.81      0.69      0.74       315\n",
      "   weighted avg       0.83      0.68      0.74       315\n",
      "\n",
      "Precision Score: 0.8113207547169812\n",
      "Recall Score: 0.6825396825396826\n",
      "F1 Score: 0.7413793103448275\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/6_epochs/distilbert_distilbert-base-german-cased_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/6_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for GerMedBERT/medbert-512:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at GerMedBERT/medbert-512 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5726.06 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4561.58 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-mediz. Service' 'B-Pflegepersonal' 'B-Arzt' 'B-anderer Service'\n",
      " 'B-Krankenhaus' 'B-Personal']\n",
      "{0: 0.1596439493228484, 1: 4.959959280624364, 2: 14.014381591562799, 3: 6.8239962651727355, 4: 10.546176046176047, 5: 5.983217355710193, 6: 18.317042606516292}\n",
      "Training GerMedBERT/medbert-512 for 6 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2424' max='2424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2424/2424 02:47, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.190527</td>\n",
       "      <td>0.707692</td>\n",
       "      <td>0.597403</td>\n",
       "      <td>0.647887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.320100</td>\n",
       "      <td>0.167318</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.723684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.148900</td>\n",
       "      <td>0.226242</td>\n",
       "      <td>0.763285</td>\n",
       "      <td>0.683983</td>\n",
       "      <td>0.721461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.063200</td>\n",
       "      <td>0.248719</td>\n",
       "      <td>0.740566</td>\n",
       "      <td>0.679654</td>\n",
       "      <td>0.708804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.036700</td>\n",
       "      <td>0.277726</td>\n",
       "      <td>0.725664</td>\n",
       "      <td>0.709957</td>\n",
       "      <td>0.717724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.036700</td>\n",
       "      <td>0.286306</td>\n",
       "      <td>0.734513</td>\n",
       "      <td>0.718615</td>\n",
       "      <td>0.726477</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_GerMedBERT_medbert-512_42_42_6\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_GerMedBERT_medbert-512_42_42_6\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4245.37 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       1.00      0.98      0.99        54\n",
      "    Krankenhaus       0.86      0.79      0.82       105\n",
      "       Personal       1.00      0.62      0.77        16\n",
      " Pflegepersonal       0.79      1.00      0.88        15\n",
      "anderer Service       0.58      0.40      0.47        35\n",
      " mediz. Service       0.85      0.70      0.77        63\n",
      "\n",
      "      micro avg       0.86      0.76      0.81       288\n",
      "      macro avg       0.85      0.75      0.78       288\n",
      "   weighted avg       0.85      0.76      0.80       288\n",
      "\n",
      "Precision Score: 0.8588235294117647\n",
      "Recall Score: 0.7604166666666666\n",
      "F1 Score: 0.8066298342541436\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/6_epochs/GerMedBERT_medbert-512_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/6_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for deepset/gbert-base:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5915.46 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4655.17 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-mediz. Service' 'B-Pflegepersonal' 'B-Arzt' 'B-anderer Service'\n",
      " 'B-Krankenhaus' 'B-Personal']\n",
      "{0: 0.1596439493228484, 1: 4.959959280624364, 2: 14.014381591562799, 3: 6.8239962651727355, 4: 10.546176046176047, 5: 5.983217355710193, 6: 18.317042606516292}\n",
      "Training deepset/gbert-base for 6 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2424' max='2424' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2424/2424 02:46, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.238325</td>\n",
       "      <td>0.688372</td>\n",
       "      <td>0.582677</td>\n",
       "      <td>0.631130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.330400</td>\n",
       "      <td>0.185145</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.661417</td>\n",
       "      <td>0.702929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.142500</td>\n",
       "      <td>0.218466</td>\n",
       "      <td>0.793249</td>\n",
       "      <td>0.740157</td>\n",
       "      <td>0.765784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.057400</td>\n",
       "      <td>0.230707</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.728346</td>\n",
       "      <td>0.756646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.034700</td>\n",
       "      <td>0.236863</td>\n",
       "      <td>0.765385</td>\n",
       "      <td>0.783465</td>\n",
       "      <td>0.774319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.034700</td>\n",
       "      <td>0.241630</td>\n",
       "      <td>0.786561</td>\n",
       "      <td>0.783465</td>\n",
       "      <td>0.785010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_deepset_gbert-base_42_42_6\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_deepset_gbert-base_42_42_6\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4378.90 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.88      0.96      0.92        55\n",
      "    Krankenhaus       0.92      0.82      0.87       117\n",
      "       Personal       0.64      0.69      0.67        13\n",
      " Pflegepersonal       1.00      0.94      0.97        18\n",
      "anderer Service       0.59      0.46      0.52        35\n",
      " mediz. Service       0.84      0.75      0.79        77\n",
      "\n",
      "      micro avg       0.86      0.79      0.82       315\n",
      "      macro avg       0.81      0.77      0.79       315\n",
      "   weighted avg       0.85      0.79      0.82       315\n",
      "\n",
      "Precision Score: 0.8556701030927835\n",
      "Recall Score: 0.7904761904761904\n",
      "F1 Score: 0.8217821782178217\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/6_epochs/deepset_gbert-base_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/6_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(f'training and results for {model}:')\n",
    "    ate_cat_model(data, model, rn1=42, rn2=42, epochs=6, save=True)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f26c682f-6a7f-42d4-9f1c-3959c1b747cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training and results for google-bert/bert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5743.69 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4616.46 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-mediz. Service' 'B-Pflegepersonal' 'B-Arzt' 'B-anderer Service'\n",
      " 'B-Krankenhaus' 'B-Personal']\n",
      "{0: 0.1596439493228484, 1: 4.959959280624364, 2: 14.014381591562799, 3: 6.8239962651727355, 4: 10.546176046176047, 5: 5.983217355710193, 6: 18.317042606516292}\n",
      "Training google-bert/bert-base-german-cased for 7 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2828' max='2828' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2828/2828 03:15, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.223721</td>\n",
       "      <td>0.690909</td>\n",
       "      <td>0.582375</td>\n",
       "      <td>0.632017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.332800</td>\n",
       "      <td>0.191899</td>\n",
       "      <td>0.756198</td>\n",
       "      <td>0.701149</td>\n",
       "      <td>0.727634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.136400</td>\n",
       "      <td>0.240071</td>\n",
       "      <td>0.738956</td>\n",
       "      <td>0.704981</td>\n",
       "      <td>0.721569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.048900</td>\n",
       "      <td>0.290693</td>\n",
       "      <td>0.748899</td>\n",
       "      <td>0.651341</td>\n",
       "      <td>0.696721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.025500</td>\n",
       "      <td>0.332394</td>\n",
       "      <td>0.763485</td>\n",
       "      <td>0.704981</td>\n",
       "      <td>0.733068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.025500</td>\n",
       "      <td>0.348486</td>\n",
       "      <td>0.768240</td>\n",
       "      <td>0.685824</td>\n",
       "      <td>0.724696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.359796</td>\n",
       "      <td>0.760504</td>\n",
       "      <td>0.693487</td>\n",
       "      <td>0.725451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_google-bert_bert-base-german-cased_42_42_7\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_google-bert_bert-base-german-cased_42_42_7\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4347.18 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.80      0.92      0.86        52\n",
      "    Krankenhaus       0.88      0.64      0.74       119\n",
      "       Personal       0.67      0.57      0.62        14\n",
      " Pflegepersonal       0.89      0.94      0.92        18\n",
      "anderer Service       0.68      0.45      0.55        33\n",
      " mediz. Service       0.89      0.78      0.83        87\n",
      "\n",
      "      micro avg       0.84      0.72      0.78       323\n",
      "      macro avg       0.80      0.72      0.75       323\n",
      "   weighted avg       0.84      0.72      0.77       323\n",
      "\n",
      "Precision Score: 0.8436363636363636\n",
      "Recall Score: 0.718266253869969\n",
      "F1 Score: 0.7759197324414716\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/7_epochs/google-bert_bert-base-german-cased_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/7_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5807.17 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4660.70 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-mediz. Service' 'B-Pflegepersonal' 'B-Arzt' 'B-anderer Service'\n",
      " 'B-Krankenhaus' 'B-Personal']\n",
      "{0: 0.1596439493228484, 1: 4.959959280624364, 2: 14.014381591562799, 3: 6.8239962651727355, 4: 10.546176046176047, 5: 5.983217355710193, 6: 18.317042606516292}\n",
      "Training dbmdz/bert-base-german-cased for 7 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2828' max='2828' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2828/2828 03:16, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.248914</td>\n",
       "      <td>0.695853</td>\n",
       "      <td>0.594488</td>\n",
       "      <td>0.641189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.355300</td>\n",
       "      <td>0.169604</td>\n",
       "      <td>0.743191</td>\n",
       "      <td>0.751969</td>\n",
       "      <td>0.747554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.162900</td>\n",
       "      <td>0.199503</td>\n",
       "      <td>0.783465</td>\n",
       "      <td>0.783465</td>\n",
       "      <td>0.783465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.068700</td>\n",
       "      <td>0.218836</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>0.755906</td>\n",
       "      <td>0.771084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.038200</td>\n",
       "      <td>0.245226</td>\n",
       "      <td>0.782101</td>\n",
       "      <td>0.791339</td>\n",
       "      <td>0.786693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.038200</td>\n",
       "      <td>0.255656</td>\n",
       "      <td>0.755556</td>\n",
       "      <td>0.803150</td>\n",
       "      <td>0.778626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.268988</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.799213</td>\n",
       "      <td>0.788350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_dbmdz_bert-base-german-cased_42_42_7\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_dbmdz_bert-base-german-cased_42_42_7\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4252.55 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.93      0.95      0.94        55\n",
      "    Krankenhaus       0.89      0.74      0.80       117\n",
      "       Personal       0.83      0.77      0.80        13\n",
      " Pflegepersonal       1.00      1.00      1.00        18\n",
      "anderer Service       0.68      0.49      0.57        35\n",
      " mediz. Service       0.79      0.81      0.80        77\n",
      "\n",
      "      micro avg       0.86      0.78      0.82       315\n",
      "      macro avg       0.85      0.79      0.82       315\n",
      "   weighted avg       0.85      0.78      0.81       315\n",
      "\n",
      "Precision Score: 0.8566433566433567\n",
      "Recall Score: 0.7777777777777778\n",
      "F1 Score: 0.8153078202995009\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/7_epochs/dbmdz_bert-base-german-cased_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/7_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-uncased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5499.55 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4609.02 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-mediz. Service' 'B-Pflegepersonal' 'B-Arzt' 'B-anderer Service'\n",
      " 'B-Krankenhaus' 'B-Personal']\n",
      "{0: 0.1596439493228484, 1: 4.959959280624364, 2: 14.014381591562799, 3: 6.8239962651727355, 4: 10.546176046176047, 5: 5.983217355710193, 6: 18.317042606516292}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training dbmdz/bert-base-german-uncased for 7 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2828' max='2828' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2828/2828 03:15, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.232232</td>\n",
       "      <td>0.707317</td>\n",
       "      <td>0.575397</td>\n",
       "      <td>0.634573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.334500</td>\n",
       "      <td>0.211842</td>\n",
       "      <td>0.764444</td>\n",
       "      <td>0.682540</td>\n",
       "      <td>0.721174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.148200</td>\n",
       "      <td>0.231706</td>\n",
       "      <td>0.775330</td>\n",
       "      <td>0.698413</td>\n",
       "      <td>0.734864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.061100</td>\n",
       "      <td>0.243154</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.787402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.282041</td>\n",
       "      <td>0.776423</td>\n",
       "      <td>0.757937</td>\n",
       "      <td>0.767068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.297592</td>\n",
       "      <td>0.797521</td>\n",
       "      <td>0.765873</td>\n",
       "      <td>0.781377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.010500</td>\n",
       "      <td>0.321191</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.773810</td>\n",
       "      <td>0.776892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_dbmdz_bert-base-german-uncased_42_42_7\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_dbmdz_bert-base-german-uncased_42_42_7\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4409.69 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.91      0.92      0.91        63\n",
      "    Krankenhaus       0.92      0.62      0.74       112\n",
      "       Personal       0.69      0.79      0.73        14\n",
      " Pflegepersonal       1.00      0.95      0.97        19\n",
      "anderer Service       0.47      0.44      0.45        34\n",
      " mediz. Service       0.83      0.77      0.80        74\n",
      "\n",
      "      micro avg       0.83      0.72      0.77       316\n",
      "      macro avg       0.80      0.75      0.77       316\n",
      "   weighted avg       0.84      0.72      0.77       316\n",
      "\n",
      "Precision Score: 0.8321167883211679\n",
      "Recall Score: 0.7215189873417721\n",
      "F1 Score: 0.7728813559322033\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/7_epochs/dbmdz_bert-base-german-uncased_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/7_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for FacebookAI/xlm-roberta-base:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5757.83 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4867.46 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-mediz. Service' 'B-Pflegepersonal' 'B-Arzt' 'B-anderer Service'\n",
      " 'B-Krankenhaus' 'B-Personal']\n",
      "{0: 0.1596439493228484, 1: 4.959959280624364, 2: 14.014381591562799, 3: 6.8239962651727355, 4: 10.546176046176047, 5: 5.983217355710193, 6: 18.317042606516292}\n",
      "Training FacebookAI/xlm-roberta-base for 7 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2828' max='2828' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2828/2828 05:01, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.268955</td>\n",
       "      <td>0.609375</td>\n",
       "      <td>0.539792</td>\n",
       "      <td>0.572477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.447000</td>\n",
       "      <td>0.212149</td>\n",
       "      <td>0.737255</td>\n",
       "      <td>0.650519</td>\n",
       "      <td>0.691176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.235300</td>\n",
       "      <td>0.185120</td>\n",
       "      <td>0.757042</td>\n",
       "      <td>0.743945</td>\n",
       "      <td>0.750436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.136100</td>\n",
       "      <td>0.226553</td>\n",
       "      <td>0.776952</td>\n",
       "      <td>0.723183</td>\n",
       "      <td>0.749104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.096600</td>\n",
       "      <td>0.223770</td>\n",
       "      <td>0.760943</td>\n",
       "      <td>0.782007</td>\n",
       "      <td>0.771331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.096600</td>\n",
       "      <td>0.267362</td>\n",
       "      <td>0.779783</td>\n",
       "      <td>0.747405</td>\n",
       "      <td>0.763251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.066600</td>\n",
       "      <td>0.268247</td>\n",
       "      <td>0.767123</td>\n",
       "      <td>0.775087</td>\n",
       "      <td>0.771084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_FacebookAI_xlm-roberta-base_42_42_7\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_FacebookAI_xlm-roberta-base_42_42_7\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4611.31 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.82      0.93      0.87        59\n",
      "    Krankenhaus       0.81      0.83      0.82       120\n",
      "       Personal       0.77      0.67      0.71        15\n",
      " Pflegepersonal       0.88      0.96      0.92        24\n",
      "anderer Service       0.58      0.33      0.42        45\n",
      " mediz. Service       0.69      0.77      0.73        83\n",
      "\n",
      "      micro avg       0.77      0.77      0.77       346\n",
      "      macro avg       0.76      0.75      0.75       346\n",
      "   weighted avg       0.76      0.77      0.76       346\n",
      "\n",
      "Precision Score: 0.7672413793103449\n",
      "Recall Score: 0.7716763005780347\n",
      "F1 Score: 0.7694524495677234\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/7_epochs/FacebookAI_xlm-roberta-base_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/7_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_best:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at TUM/GottBERT_base_best and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6407.32 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5016.81 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-mediz. Service' 'B-Pflegepersonal' 'B-Arzt' 'B-anderer Service'\n",
      " 'B-Krankenhaus' 'B-Personal']\n",
      "{0: 0.1596439493228484, 1: 4.959959280624364, 2: 14.014381591562799, 3: 6.8239962651727355, 4: 10.546176046176047, 5: 5.983217355710193, 6: 18.317042606516292}\n",
      "Training TUM/GottBERT_base_best for 7 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2828' max='2828' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2828/2828 03:23, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.285238</td>\n",
       "      <td>0.728916</td>\n",
       "      <td>0.570755</td>\n",
       "      <td>0.640212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.335000</td>\n",
       "      <td>0.195575</td>\n",
       "      <td>0.737374</td>\n",
       "      <td>0.688679</td>\n",
       "      <td>0.712195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.172900</td>\n",
       "      <td>0.276536</td>\n",
       "      <td>0.717073</td>\n",
       "      <td>0.693396</td>\n",
       "      <td>0.705036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.085700</td>\n",
       "      <td>0.300896</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.641509</td>\n",
       "      <td>0.681704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.337240</td>\n",
       "      <td>0.696262</td>\n",
       "      <td>0.702830</td>\n",
       "      <td>0.699531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.394077</td>\n",
       "      <td>0.723077</td>\n",
       "      <td>0.665094</td>\n",
       "      <td>0.692875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.023800</td>\n",
       "      <td>0.394472</td>\n",
       "      <td>0.731707</td>\n",
       "      <td>0.707547</td>\n",
       "      <td>0.719424</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_TUM_GottBERT_base_best_42_42_7\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_TUM_GottBERT_base_best_42_42_7\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4666.08 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.93      0.98      0.95        52\n",
      "    Krankenhaus       0.87      0.80      0.83       104\n",
      "       Personal       0.75      0.75      0.75        12\n",
      " Pflegepersonal       1.00      1.00      1.00        14\n",
      "anderer Service       0.64      0.47      0.54        30\n",
      " mediz. Service       0.66      0.73      0.70        67\n",
      "\n",
      "      micro avg       0.81      0.79      0.80       279\n",
      "      macro avg       0.81      0.79      0.80       279\n",
      "   weighted avg       0.81      0.79      0.80       279\n",
      "\n",
      "Precision Score: 0.8088235294117647\n",
      "Recall Score: 0.7885304659498208\n",
      "F1 Score: 0.7985480943738655\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/7_epochs/TUM_GottBERT_base_best_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/7_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_filtered_base_best:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at TUM/GottBERT_filtered_base_best and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6439.23 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4975.22 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-mediz. Service' 'B-Pflegepersonal' 'B-Arzt' 'B-anderer Service'\n",
      " 'B-Krankenhaus' 'B-Personal']\n",
      "{0: 0.1596439493228484, 1: 4.959959280624364, 2: 14.014381591562799, 3: 6.8239962651727355, 4: 10.546176046176047, 5: 5.983217355710193, 6: 18.317042606516292}\n",
      "Training TUM/GottBERT_filtered_base_best for 7 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2828' max='2828' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2828/2828 03:21, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.198280</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.603774</td>\n",
       "      <td>0.646465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.328500</td>\n",
       "      <td>0.166925</td>\n",
       "      <td>0.748768</td>\n",
       "      <td>0.716981</td>\n",
       "      <td>0.732530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.162800</td>\n",
       "      <td>0.175944</td>\n",
       "      <td>0.760331</td>\n",
       "      <td>0.867925</td>\n",
       "      <td>0.810573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.079300</td>\n",
       "      <td>0.226092</td>\n",
       "      <td>0.751174</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.752941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.050200</td>\n",
       "      <td>0.273639</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.726415</td>\n",
       "      <td>0.742169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.050200</td>\n",
       "      <td>0.255691</td>\n",
       "      <td>0.767773</td>\n",
       "      <td>0.764151</td>\n",
       "      <td>0.765957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.021500</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.759434</td>\n",
       "      <td>0.763033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_TUM_GottBERT_filtered_base_best_42_42_7\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_TUM_GottBERT_filtered_base_best_42_42_7\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4720.08 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.96      0.98      0.97        52\n",
      "    Krankenhaus       0.82      0.67      0.74       104\n",
      "       Personal       0.64      0.75      0.69        12\n",
      " Pflegepersonal       0.87      0.93      0.90        14\n",
      "anderer Service       0.59      0.33      0.43        30\n",
      " mediz. Service       0.59      0.84      0.69        67\n",
      "\n",
      "      micro avg       0.75      0.75      0.75       279\n",
      "      macro avg       0.75      0.75      0.74       279\n",
      "   weighted avg       0.76      0.75      0.74       279\n",
      "\n",
      "Precision Score: 0.7491039426523297\n",
      "Recall Score: 0.7491039426523297\n",
      "F1 Score: 0.7491039426523297\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/7_epochs/TUM_GottBERT_filtered_base_best_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/7_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_last:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at TUM/GottBERT_base_last were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at TUM/GottBERT_base_last and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6519.86 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4902.78 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-mediz. Service' 'B-Pflegepersonal' 'B-Arzt' 'B-anderer Service'\n",
      " 'B-Krankenhaus' 'B-Personal']\n",
      "{0: 0.1596439493228484, 1: 4.959959280624364, 2: 14.014381591562799, 3: 6.8239962651727355, 4: 10.546176046176047, 5: 5.983217355710193, 6: 18.317042606516292}\n",
      "Training TUM/GottBERT_base_last for 7 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2828' max='2828' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2828/2828 03:22, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.240597</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.561321</td>\n",
       "      <td>0.652055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.349400</td>\n",
       "      <td>0.186103</td>\n",
       "      <td>0.747368</td>\n",
       "      <td>0.669811</td>\n",
       "      <td>0.706468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.180700</td>\n",
       "      <td>0.198872</td>\n",
       "      <td>0.717703</td>\n",
       "      <td>0.707547</td>\n",
       "      <td>0.712589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.095200</td>\n",
       "      <td>0.267394</td>\n",
       "      <td>0.717822</td>\n",
       "      <td>0.683962</td>\n",
       "      <td>0.700483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.056800</td>\n",
       "      <td>0.324792</td>\n",
       "      <td>0.710280</td>\n",
       "      <td>0.716981</td>\n",
       "      <td>0.713615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.056800</td>\n",
       "      <td>0.369378</td>\n",
       "      <td>0.712871</td>\n",
       "      <td>0.679245</td>\n",
       "      <td>0.695652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.025900</td>\n",
       "      <td>0.381289</td>\n",
       "      <td>0.719807</td>\n",
       "      <td>0.702830</td>\n",
       "      <td>0.711217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_TUM_GottBERT_base_last_42_42_7\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_TUM_GottBERT_base_last_42_42_7\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4836.68 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.94      0.98      0.96        52\n",
      "    Krankenhaus       0.85      0.75      0.80       104\n",
      "       Personal       0.71      0.83      0.77        12\n",
      " Pflegepersonal       0.93      1.00      0.97        14\n",
      "anderer Service       0.71      0.57      0.63        30\n",
      " mediz. Service       0.70      0.82      0.75        67\n",
      "\n",
      "      micro avg       0.81      0.81      0.81       279\n",
      "      macro avg       0.81      0.83      0.81       279\n",
      "   weighted avg       0.81      0.81      0.81       279\n",
      "\n",
      "Precision Score: 0.8093525179856115\n",
      "Recall Score: 0.8064516129032258\n",
      "F1 Score: 0.8078994614003591\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/7_epochs/TUM_GottBERT_base_last_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/7_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for distilbert/distilbert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6608.13 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5321.12 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-mediz. Service' 'B-Pflegepersonal' 'B-Arzt' 'B-anderer Service'\n",
      " 'B-Krankenhaus' 'B-Personal']\n",
      "{0: 0.1596439493228484, 1: 4.959959280624364, 2: 14.014381591562799, 3: 6.8239962651727355, 4: 10.546176046176047, 5: 5.983217355710193, 6: 18.317042606516292}\n",
      "Training distilbert/distilbert-base-german-cased for 7 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2828' max='2828' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2828/2828 01:47, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.235504</td>\n",
       "      <td>0.701923</td>\n",
       "      <td>0.574803</td>\n",
       "      <td>0.632035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.394800</td>\n",
       "      <td>0.207470</td>\n",
       "      <td>0.703390</td>\n",
       "      <td>0.653543</td>\n",
       "      <td>0.677551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.179500</td>\n",
       "      <td>0.229822</td>\n",
       "      <td>0.771028</td>\n",
       "      <td>0.649606</td>\n",
       "      <td>0.705128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.091800</td>\n",
       "      <td>0.237030</td>\n",
       "      <td>0.758065</td>\n",
       "      <td>0.740157</td>\n",
       "      <td>0.749004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.062200</td>\n",
       "      <td>0.250153</td>\n",
       "      <td>0.743083</td>\n",
       "      <td>0.740157</td>\n",
       "      <td>0.741617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.062200</td>\n",
       "      <td>0.261610</td>\n",
       "      <td>0.762846</td>\n",
       "      <td>0.759843</td>\n",
       "      <td>0.761341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.276165</td>\n",
       "      <td>0.762097</td>\n",
       "      <td>0.744094</td>\n",
       "      <td>0.752988</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_distilbert_distilbert-base-german-cased_42_42_7\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_distilbert_distilbert-base-german-cased_42_42_7\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4989.43 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.87      0.95      0.90        55\n",
      "    Krankenhaus       0.94      0.54      0.68       117\n",
      "       Personal       0.75      0.46      0.57        13\n",
      " Pflegepersonal       0.94      0.94      0.94        18\n",
      "anderer Service       0.71      0.43      0.54        35\n",
      " mediz. Service       0.63      0.75      0.69        77\n",
      "\n",
      "      micro avg       0.79      0.67      0.73       315\n",
      "      macro avg       0.81      0.68      0.72       315\n",
      "   weighted avg       0.82      0.67      0.72       315\n",
      "\n",
      "Precision Score: 0.793233082706767\n",
      "Recall Score: 0.6698412698412698\n",
      "F1 Score: 0.7263339070567986\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/7_epochs/distilbert_distilbert-base-german-cased_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/7_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for GerMedBERT/medbert-512:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at GerMedBERT/medbert-512 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5745.20 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4645.72 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-mediz. Service' 'B-Pflegepersonal' 'B-Arzt' 'B-anderer Service'\n",
      " 'B-Krankenhaus' 'B-Personal']\n",
      "{0: 0.1596439493228484, 1: 4.959959280624364, 2: 14.014381591562799, 3: 6.8239962651727355, 4: 10.546176046176047, 5: 5.983217355710193, 6: 18.317042606516292}\n",
      "Training GerMedBERT/medbert-512 for 7 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2828' max='2828' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2828/2828 03:13, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.208703</td>\n",
       "      <td>0.653266</td>\n",
       "      <td>0.562771</td>\n",
       "      <td>0.604651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.319400</td>\n",
       "      <td>0.188274</td>\n",
       "      <td>0.709402</td>\n",
       "      <td>0.718615</td>\n",
       "      <td>0.713978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.146400</td>\n",
       "      <td>0.233929</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.688312</td>\n",
       "      <td>0.717833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.071400</td>\n",
       "      <td>0.247591</td>\n",
       "      <td>0.764423</td>\n",
       "      <td>0.688312</td>\n",
       "      <td>0.724374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.035900</td>\n",
       "      <td>0.262979</td>\n",
       "      <td>0.738397</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.747863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.035900</td>\n",
       "      <td>0.293432</td>\n",
       "      <td>0.746667</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.736842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.011900</td>\n",
       "      <td>0.299482</td>\n",
       "      <td>0.744589</td>\n",
       "      <td>0.744589</td>\n",
       "      <td>0.744589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_GerMedBERT_medbert-512_42_42_7\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_GerMedBERT_medbert-512_42_42_7\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4267.56 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.98      0.96      0.97        54\n",
      "    Krankenhaus       0.81      0.78      0.80       105\n",
      "       Personal       0.93      0.88      0.90        16\n",
      " Pflegepersonal       0.93      0.93      0.93        15\n",
      "anderer Service       0.65      0.43      0.52        35\n",
      " mediz. Service       0.85      0.63      0.73        63\n",
      "\n",
      "      micro avg       0.85      0.75      0.80       288\n",
      "      macro avg       0.86      0.77      0.81       288\n",
      "   weighted avg       0.85      0.75      0.79       288\n",
      "\n",
      "Precision Score: 0.8543307086614174\n",
      "Recall Score: 0.7534722222222222\n",
      "F1 Score: 0.8007380073800738\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/7_epochs/GerMedBERT_medbert-512_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/7_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for deepset/gbert-base:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5879.70 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4859.86 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-mediz. Service' 'B-Pflegepersonal' 'B-Arzt' 'B-anderer Service'\n",
      " 'B-Krankenhaus' 'B-Personal']\n",
      "{0: 0.1596439493228484, 1: 4.959959280624364, 2: 14.014381591562799, 3: 6.8239962651727355, 4: 10.546176046176047, 5: 5.983217355710193, 6: 18.317042606516292}\n",
      "Training deepset/gbert-base for 7 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2828' max='2828' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2828/2828 03:13, Epoch 7/7]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.238920</td>\n",
       "      <td>0.709845</td>\n",
       "      <td>0.539370</td>\n",
       "      <td>0.612975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.327400</td>\n",
       "      <td>0.200220</td>\n",
       "      <td>0.766520</td>\n",
       "      <td>0.685039</td>\n",
       "      <td>0.723493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.144800</td>\n",
       "      <td>0.232330</td>\n",
       "      <td>0.765217</td>\n",
       "      <td>0.692913</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.057800</td>\n",
       "      <td>0.245363</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.732283</td>\n",
       "      <td>0.741036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.034800</td>\n",
       "      <td>0.260847</td>\n",
       "      <td>0.736059</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>0.757170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.034800</td>\n",
       "      <td>0.271232</td>\n",
       "      <td>0.746154</td>\n",
       "      <td>0.763780</td>\n",
       "      <td>0.754864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>0.281120</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>0.771654</td>\n",
       "      <td>0.762646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_deepset_gbert-base_42_42_7\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_deepset_gbert-base_42_42_7\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4417.75 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.88      0.93      0.90        55\n",
      "    Krankenhaus       0.90      0.72      0.80       117\n",
      "       Personal       0.75      0.69      0.72        13\n",
      " Pflegepersonal       0.85      0.94      0.89        18\n",
      "anderer Service       0.81      0.49      0.61        35\n",
      " mediz. Service       0.76      0.78      0.77        77\n",
      "\n",
      "      micro avg       0.84      0.76      0.80       315\n",
      "      macro avg       0.83      0.76      0.78       315\n",
      "   weighted avg       0.84      0.76      0.79       315\n",
      "\n",
      "Precision Score: 0.8409893992932862\n",
      "Recall Score: 0.7555555555555555\n",
      "F1 Score: 0.7959866220735786\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/7_epochs/deepset_gbert-base_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/7_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(f'training and results for {model}:')\n",
    "    ate_cat_model(data, model, rn1=42, rn2=42, epochs=7, save=True)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27ab529d-6242-4860-9d13-b5001ed068e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training and results for google-bert/bert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5857.90 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4763.63 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-mediz. Service' 'B-Pflegepersonal' 'B-Arzt' 'B-anderer Service'\n",
      " 'B-Krankenhaus' 'B-Personal']\n",
      "{0: 0.1596439493228484, 1: 4.959959280624364, 2: 14.014381591562799, 3: 6.8239962651727355, 4: 10.546176046176047, 5: 5.983217355710193, 6: 18.317042606516292}\n",
      "Training google-bert/bert-base-german-cased for 8 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3232' max='3232' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3232/3232 03:38, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.225879</td>\n",
       "      <td>0.746479</td>\n",
       "      <td>0.609195</td>\n",
       "      <td>0.670886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.329900</td>\n",
       "      <td>0.215424</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.643678</td>\n",
       "      <td>0.687117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.131400</td>\n",
       "      <td>0.227239</td>\n",
       "      <td>0.741176</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.732558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.049800</td>\n",
       "      <td>0.249514</td>\n",
       "      <td>0.766129</td>\n",
       "      <td>0.727969</td>\n",
       "      <td>0.746562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>0.326890</td>\n",
       "      <td>0.751092</td>\n",
       "      <td>0.659004</td>\n",
       "      <td>0.702041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>0.331667</td>\n",
       "      <td>0.763052</td>\n",
       "      <td>0.727969</td>\n",
       "      <td>0.745098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.006100</td>\n",
       "      <td>0.359499</td>\n",
       "      <td>0.741803</td>\n",
       "      <td>0.693487</td>\n",
       "      <td>0.716832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.359407</td>\n",
       "      <td>0.747967</td>\n",
       "      <td>0.704981</td>\n",
       "      <td>0.725838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_google-bert_bert-base-german-cased_42_42_8\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_google-bert_bert-base-german-cased_42_42_8\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4141.80 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.86      0.96      0.91        52\n",
      "    Krankenhaus       0.91      0.67      0.77       119\n",
      "       Personal       0.71      0.71      0.71        14\n",
      " Pflegepersonal       1.00      0.94      0.97        18\n",
      "anderer Service       0.63      0.52      0.57        33\n",
      " mediz. Service       0.87      0.76      0.81        87\n",
      "\n",
      "      micro avg       0.86      0.74      0.80       323\n",
      "      macro avg       0.83      0.76      0.79       323\n",
      "   weighted avg       0.86      0.74      0.79       323\n",
      "\n",
      "Precision Score: 0.8571428571428571\n",
      "Recall Score: 0.7430340557275542\n",
      "F1 Score: 0.7960199004975125\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/8_epochs/google-bert_bert-base-german-cased_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/8_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5814.70 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4774.58 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-mediz. Service' 'B-Pflegepersonal' 'B-Arzt' 'B-anderer Service'\n",
      " 'B-Krankenhaus' 'B-Personal']\n",
      "{0: 0.1596439493228484, 1: 4.959959280624364, 2: 14.014381591562799, 3: 6.8239962651727355, 4: 10.546176046176047, 5: 5.983217355710193, 6: 18.317042606516292}\n",
      "Training dbmdz/bert-base-german-cased for 8 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3232' max='3232' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3232/3232 03:39, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.212539</td>\n",
       "      <td>0.662338</td>\n",
       "      <td>0.602362</td>\n",
       "      <td>0.630928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.342500</td>\n",
       "      <td>0.190894</td>\n",
       "      <td>0.784141</td>\n",
       "      <td>0.700787</td>\n",
       "      <td>0.740125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.149700</td>\n",
       "      <td>0.206935</td>\n",
       "      <td>0.749049</td>\n",
       "      <td>0.775591</td>\n",
       "      <td>0.762089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.068900</td>\n",
       "      <td>0.233781</td>\n",
       "      <td>0.781481</td>\n",
       "      <td>0.830709</td>\n",
       "      <td>0.805344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.034400</td>\n",
       "      <td>0.291955</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.748031</td>\n",
       "      <td>0.753968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.034400</td>\n",
       "      <td>0.290576</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>0.822835</td>\n",
       "      <td>0.806950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.010400</td>\n",
       "      <td>0.323501</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>0.771654</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.006300</td>\n",
       "      <td>0.326282</td>\n",
       "      <td>0.785992</td>\n",
       "      <td>0.795276</td>\n",
       "      <td>0.790607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_dbmdz_bert-base-german-cased_42_42_8\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_dbmdz_bert-base-german-cased_42_42_8\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4450.79 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.90      0.95      0.92        55\n",
      "    Krankenhaus       0.88      0.60      0.71       117\n",
      "       Personal       0.75      0.69      0.72        13\n",
      " Pflegepersonal       1.00      0.94      0.97        18\n",
      "anderer Service       0.74      0.49      0.59        35\n",
      " mediz. Service       0.71      0.84      0.77        77\n",
      "\n",
      "      micro avg       0.82      0.73      0.77       315\n",
      "      macro avg       0.83      0.75      0.78       315\n",
      "   weighted avg       0.83      0.73      0.76       315\n",
      "\n",
      "Precision Score: 0.8185053380782918\n",
      "Recall Score: 0.7301587301587301\n",
      "F1 Score: 0.7718120805369129\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/8_epochs/dbmdz_bert-base-german-cased_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/8_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-uncased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5508.41 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4601.02 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-mediz. Service' 'B-Pflegepersonal' 'B-Arzt' 'B-anderer Service'\n",
      " 'B-Krankenhaus' 'B-Personal']\n",
      "{0: 0.1596439493228484, 1: 4.959959280624364, 2: 14.014381591562799, 3: 6.8239962651727355, 4: 10.546176046176047, 5: 5.983217355710193, 6: 18.317042606516292}\n",
      "Training dbmdz/bert-base-german-uncased for 8 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3232' max='3232' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3232/3232 03:39, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.213718</td>\n",
       "      <td>0.761194</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.675497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.322300</td>\n",
       "      <td>0.202240</td>\n",
       "      <td>0.759657</td>\n",
       "      <td>0.702381</td>\n",
       "      <td>0.729897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.146700</td>\n",
       "      <td>0.216141</td>\n",
       "      <td>0.808696</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.771784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.059800</td>\n",
       "      <td>0.231258</td>\n",
       "      <td>0.766129</td>\n",
       "      <td>0.753968</td>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.037400</td>\n",
       "      <td>0.259934</td>\n",
       "      <td>0.790514</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.792079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.037400</td>\n",
       "      <td>0.294663</td>\n",
       "      <td>0.776892</td>\n",
       "      <td>0.773810</td>\n",
       "      <td>0.775348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>0.317299</td>\n",
       "      <td>0.790984</td>\n",
       "      <td>0.765873</td>\n",
       "      <td>0.778226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>0.309103</td>\n",
       "      <td>0.773946</td>\n",
       "      <td>0.801587</td>\n",
       "      <td>0.787524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_dbmdz_bert-base-german-uncased_42_42_8\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_dbmdz_bert-base-german-uncased_42_42_8\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4319.44 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.95      0.89      0.92        63\n",
      "    Krankenhaus       0.88      0.67      0.76       112\n",
      "       Personal       0.62      0.57      0.59        14\n",
      " Pflegepersonal       1.00      0.84      0.91        19\n",
      "anderer Service       0.58      0.32      0.42        34\n",
      " mediz. Service       0.79      0.77      0.78        74\n",
      "\n",
      "      micro avg       0.84      0.71      0.77       316\n",
      "      macro avg       0.80      0.68      0.73       316\n",
      "   weighted avg       0.84      0.71      0.76       316\n",
      "\n",
      "Precision Score: 0.8446969696969697\n",
      "Recall Score: 0.7056962025316456\n",
      "F1 Score: 0.7689655172413793\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/8_epochs/dbmdz_bert-base-german-uncased_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/8_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for FacebookAI/xlm-roberta-base:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5762.26 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4836.01 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-mediz. Service' 'B-Pflegepersonal' 'B-Arzt' 'B-anderer Service'\n",
      " 'B-Krankenhaus' 'B-Personal']\n",
      "{0: 0.1596439493228484, 1: 4.959959280624364, 2: 14.014381591562799, 3: 6.8239962651727355, 4: 10.546176046176047, 5: 5.983217355710193, 6: 18.317042606516292}\n",
      "Training FacebookAI/xlm-roberta-base for 8 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3232' max='3232' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3232/3232 05:41, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.256555</td>\n",
       "      <td>0.695473</td>\n",
       "      <td>0.584775</td>\n",
       "      <td>0.635338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.404200</td>\n",
       "      <td>0.222601</td>\n",
       "      <td>0.759336</td>\n",
       "      <td>0.633218</td>\n",
       "      <td>0.690566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.215300</td>\n",
       "      <td>0.241274</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.740484</td>\n",
       "      <td>0.724196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.134300</td>\n",
       "      <td>0.220489</td>\n",
       "      <td>0.749141</td>\n",
       "      <td>0.754325</td>\n",
       "      <td>0.751724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.094800</td>\n",
       "      <td>0.244191</td>\n",
       "      <td>0.737374</td>\n",
       "      <td>0.757785</td>\n",
       "      <td>0.747440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.094800</td>\n",
       "      <td>0.279263</td>\n",
       "      <td>0.779026</td>\n",
       "      <td>0.719723</td>\n",
       "      <td>0.748201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.053800</td>\n",
       "      <td>0.294028</td>\n",
       "      <td>0.757895</td>\n",
       "      <td>0.747405</td>\n",
       "      <td>0.752613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.035200</td>\n",
       "      <td>0.289657</td>\n",
       "      <td>0.750853</td>\n",
       "      <td>0.761246</td>\n",
       "      <td>0.756014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_FacebookAI_xlm-roberta-base_42_42_8\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_FacebookAI_xlm-roberta-base_42_42_8\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4650.56 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.90      0.92      0.91        59\n",
      "    Krankenhaus       0.87      0.78      0.82       120\n",
      "       Personal       0.85      0.73      0.79        15\n",
      " Pflegepersonal       0.86      1.00      0.92        24\n",
      "anderer Service       0.55      0.36      0.43        45\n",
      " mediz. Service       0.70      0.67      0.69        83\n",
      "\n",
      "      micro avg       0.80      0.74      0.77       346\n",
      "      macro avg       0.79      0.74      0.76       346\n",
      "   weighted avg       0.79      0.74      0.76       346\n",
      "\n",
      "Precision Score: 0.8018867924528302\n",
      "Recall Score: 0.7369942196531792\n",
      "F1 Score: 0.7680722891566266\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/8_epochs/FacebookAI_xlm-roberta-base_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/8_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_best:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at TUM/GottBERT_base_best and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6533.15 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5029.62 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-mediz. Service' 'B-Pflegepersonal' 'B-Arzt' 'B-anderer Service'\n",
      " 'B-Krankenhaus' 'B-Personal']\n",
      "{0: 0.1596439493228484, 1: 4.959959280624364, 2: 14.014381591562799, 3: 6.8239962651727355, 4: 10.546176046176047, 5: 5.983217355710193, 6: 18.317042606516292}\n",
      "Training TUM/GottBERT_base_best for 8 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3232' max='3232' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3232/3232 03:48, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.257883</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.561321</td>\n",
       "      <td>0.650273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.316900</td>\n",
       "      <td>0.197205</td>\n",
       "      <td>0.759358</td>\n",
       "      <td>0.669811</td>\n",
       "      <td>0.711779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.167400</td>\n",
       "      <td>0.219021</td>\n",
       "      <td>0.734884</td>\n",
       "      <td>0.745283</td>\n",
       "      <td>0.740047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.084200</td>\n",
       "      <td>0.238142</td>\n",
       "      <td>0.761468</td>\n",
       "      <td>0.783019</td>\n",
       "      <td>0.772093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.052900</td>\n",
       "      <td>0.287468</td>\n",
       "      <td>0.700422</td>\n",
       "      <td>0.783019</td>\n",
       "      <td>0.739421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.052900</td>\n",
       "      <td>0.325055</td>\n",
       "      <td>0.778846</td>\n",
       "      <td>0.764151</td>\n",
       "      <td>0.771429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.019400</td>\n",
       "      <td>0.345750</td>\n",
       "      <td>0.754545</td>\n",
       "      <td>0.783019</td>\n",
       "      <td>0.768519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>0.355956</td>\n",
       "      <td>0.743243</td>\n",
       "      <td>0.778302</td>\n",
       "      <td>0.760369</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_TUM_GottBERT_base_best_42_42_8\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_TUM_GottBERT_base_best_42_42_8\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4804.31 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.96      0.94      0.95        52\n",
      "    Krankenhaus       0.89      0.69      0.78       104\n",
      "       Personal       0.80      0.67      0.73        12\n",
      " Pflegepersonal       0.93      1.00      0.97        14\n",
      "anderer Service       0.86      0.40      0.55        30\n",
      " mediz. Service       0.69      0.75      0.72        67\n",
      "\n",
      "      micro avg       0.84      0.73      0.79       279\n",
      "      macro avg       0.86      0.74      0.78       279\n",
      "   weighted avg       0.85      0.73      0.78       279\n",
      "\n",
      "Precision Score: 0.8436213991769548\n",
      "Recall Score: 0.7347670250896058\n",
      "F1 Score: 0.7854406130268201\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/8_epochs/TUM_GottBERT_base_best_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/8_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_filtered_base_best:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at TUM/GottBERT_filtered_base_best and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6584.76 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5135.53 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-mediz. Service' 'B-Pflegepersonal' 'B-Arzt' 'B-anderer Service'\n",
      " 'B-Krankenhaus' 'B-Personal']\n",
      "{0: 0.1596439493228484, 1: 4.959959280624364, 2: 14.014381591562799, 3: 6.8239962651727355, 4: 10.546176046176047, 5: 5.983217355710193, 6: 18.317042606516292}\n",
      "Training TUM/GottBERT_filtered_base_best for 8 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3232' max='3232' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3232/3232 03:49, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.208711</td>\n",
       "      <td>0.757062</td>\n",
       "      <td>0.632075</td>\n",
       "      <td>0.688946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.315700</td>\n",
       "      <td>0.149860</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.778302</td>\n",
       "      <td>0.772834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.163700</td>\n",
       "      <td>0.145058</td>\n",
       "      <td>0.795455</td>\n",
       "      <td>0.825472</td>\n",
       "      <td>0.810185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.086000</td>\n",
       "      <td>0.174111</td>\n",
       "      <td>0.775229</td>\n",
       "      <td>0.797170</td>\n",
       "      <td>0.786047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.054500</td>\n",
       "      <td>0.214192</td>\n",
       "      <td>0.774510</td>\n",
       "      <td>0.745283</td>\n",
       "      <td>0.759615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.054500</td>\n",
       "      <td>0.227282</td>\n",
       "      <td>0.780488</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.767386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.024200</td>\n",
       "      <td>0.255428</td>\n",
       "      <td>0.792746</td>\n",
       "      <td>0.721698</td>\n",
       "      <td>0.755556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>0.240525</td>\n",
       "      <td>0.793103</td>\n",
       "      <td>0.759434</td>\n",
       "      <td>0.775904</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_TUM_GottBERT_filtered_base_best_42_42_8\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_TUM_GottBERT_filtered_base_best_42_42_8\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4754.28 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.85      0.98      0.91        52\n",
      "    Krankenhaus       0.88      0.70      0.78       104\n",
      "       Personal       0.64      0.75      0.69        12\n",
      " Pflegepersonal       0.87      0.93      0.90        14\n",
      "anderer Service       0.62      0.33      0.43        30\n",
      " mediz. Service       0.71      0.84      0.77        67\n",
      "\n",
      "      micro avg       0.79      0.76      0.78       279\n",
      "      macro avg       0.76      0.76      0.75       279\n",
      "   weighted avg       0.79      0.76      0.77       279\n",
      "\n",
      "Precision Score: 0.7940074906367042\n",
      "Recall Score: 0.7598566308243727\n",
      "F1 Score: 0.7765567765567766\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/8_epochs/TUM_GottBERT_filtered_base_best_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/8_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_last:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at TUM/GottBERT_base_last were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at TUM/GottBERT_base_last and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6615.52 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5117.35 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-mediz. Service' 'B-Pflegepersonal' 'B-Arzt' 'B-anderer Service'\n",
      " 'B-Krankenhaus' 'B-Personal']\n",
      "{0: 0.1596439493228484, 1: 4.959959280624364, 2: 14.014381591562799, 3: 6.8239962651727355, 4: 10.546176046176047, 5: 5.983217355710193, 6: 18.317042606516292}\n",
      "Training TUM/GottBERT_base_last for 8 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3232' max='3232' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3232/3232 03:49, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.245245</td>\n",
       "      <td>0.736842</td>\n",
       "      <td>0.528302</td>\n",
       "      <td>0.615385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.315100</td>\n",
       "      <td>0.190415</td>\n",
       "      <td>0.748744</td>\n",
       "      <td>0.702830</td>\n",
       "      <td>0.725061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.165100</td>\n",
       "      <td>0.203098</td>\n",
       "      <td>0.755760</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.764569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.086600</td>\n",
       "      <td>0.243735</td>\n",
       "      <td>0.734300</td>\n",
       "      <td>0.716981</td>\n",
       "      <td>0.725537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.056900</td>\n",
       "      <td>0.286926</td>\n",
       "      <td>0.684874</td>\n",
       "      <td>0.768868</td>\n",
       "      <td>0.724444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.056900</td>\n",
       "      <td>0.332139</td>\n",
       "      <td>0.742574</td>\n",
       "      <td>0.707547</td>\n",
       "      <td>0.724638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.025400</td>\n",
       "      <td>0.338537</td>\n",
       "      <td>0.725225</td>\n",
       "      <td>0.759434</td>\n",
       "      <td>0.741935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.350346</td>\n",
       "      <td>0.702222</td>\n",
       "      <td>0.745283</td>\n",
       "      <td>0.723112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_TUM_GottBERT_base_last_42_42_8\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_TUM_GottBERT_base_last_42_42_8\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4821.75 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.93      0.98      0.95        52\n",
      "    Krankenhaus       0.91      0.64      0.75       104\n",
      "       Personal       0.69      0.75      0.72        12\n",
      " Pflegepersonal       0.93      1.00      0.97        14\n",
      "anderer Service       0.65      0.37      0.47        30\n",
      " mediz. Service       0.68      0.84      0.75        67\n",
      "\n",
      "      micro avg       0.81      0.75      0.78       279\n",
      "      macro avg       0.80      0.76      0.77       279\n",
      "   weighted avg       0.82      0.75      0.77       279\n",
      "\n",
      "Precision Score: 0.8125\n",
      "Recall Score: 0.7455197132616488\n",
      "F1 Score: 0.777570093457944\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/8_epochs/TUM_GottBERT_base_last_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/8_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for distilbert/distilbert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6696.92 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5353.66 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-mediz. Service' 'B-Pflegepersonal' 'B-Arzt' 'B-anderer Service'\n",
      " 'B-Krankenhaus' 'B-Personal']\n",
      "{0: 0.1596439493228484, 1: 4.959959280624364, 2: 14.014381591562799, 3: 6.8239962651727355, 4: 10.546176046176047, 5: 5.983217355710193, 6: 18.317042606516292}\n",
      "Training distilbert/distilbert-base-german-cased for 8 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3232' max='3232' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3232/3232 02:01, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.238099</td>\n",
       "      <td>0.649770</td>\n",
       "      <td>0.555118</td>\n",
       "      <td>0.598726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.393000</td>\n",
       "      <td>0.221648</td>\n",
       "      <td>0.748837</td>\n",
       "      <td>0.633858</td>\n",
       "      <td>0.686567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.168900</td>\n",
       "      <td>0.220918</td>\n",
       "      <td>0.783019</td>\n",
       "      <td>0.653543</td>\n",
       "      <td>0.712446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.090800</td>\n",
       "      <td>0.250110</td>\n",
       "      <td>0.767544</td>\n",
       "      <td>0.688976</td>\n",
       "      <td>0.726141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.059300</td>\n",
       "      <td>0.253673</td>\n",
       "      <td>0.757812</td>\n",
       "      <td>0.763780</td>\n",
       "      <td>0.760784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.059300</td>\n",
       "      <td>0.260656</td>\n",
       "      <td>0.773109</td>\n",
       "      <td>0.724409</td>\n",
       "      <td>0.747967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>0.274106</td>\n",
       "      <td>0.756198</td>\n",
       "      <td>0.720472</td>\n",
       "      <td>0.737903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.017900</td>\n",
       "      <td>0.277571</td>\n",
       "      <td>0.757202</td>\n",
       "      <td>0.724409</td>\n",
       "      <td>0.740443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_distilbert_distilbert-base-german-cased_42_42_8\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_distilbert_distilbert-base-german-cased_42_42_8\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4937.66 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.87      0.95      0.90        55\n",
      "    Krankenhaus       0.95      0.59      0.73       117\n",
      "       Personal       0.80      0.31      0.44        13\n",
      " Pflegepersonal       0.81      0.94      0.87        18\n",
      "anderer Service       0.59      0.37      0.46        35\n",
      " mediz. Service       0.60      0.70      0.65        77\n",
      "\n",
      "      micro avg       0.77      0.66      0.71       315\n",
      "      macro avg       0.77      0.64      0.67       315\n",
      "   weighted avg       0.79      0.66      0.70       315\n",
      "\n",
      "Precision Score: 0.7712177121771218\n",
      "Recall Score: 0.6634920634920635\n",
      "F1 Score: 0.7133105802047781\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/8_epochs/distilbert_distilbert-base-german-cased_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/8_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for GerMedBERT/medbert-512:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at GerMedBERT/medbert-512 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5779.32 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4727.37 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-mediz. Service' 'B-Pflegepersonal' 'B-Arzt' 'B-anderer Service'\n",
      " 'B-Krankenhaus' 'B-Personal']\n",
      "{0: 0.1596439493228484, 1: 4.959959280624364, 2: 14.014381591562799, 3: 6.8239962651727355, 4: 10.546176046176047, 5: 5.983217355710193, 6: 18.317042606516292}\n",
      "Training GerMedBERT/medbert-512 for 8 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3232' max='3232' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3232/3232 03:39, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.191477</td>\n",
       "      <td>0.678049</td>\n",
       "      <td>0.601732</td>\n",
       "      <td>0.637615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.326500</td>\n",
       "      <td>0.196000</td>\n",
       "      <td>0.725322</td>\n",
       "      <td>0.731602</td>\n",
       "      <td>0.728448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.151600</td>\n",
       "      <td>0.259559</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.695035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.067900</td>\n",
       "      <td>0.248632</td>\n",
       "      <td>0.746606</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.730088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>0.302660</td>\n",
       "      <td>0.709163</td>\n",
       "      <td>0.770563</td>\n",
       "      <td>0.738589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>0.316533</td>\n",
       "      <td>0.757709</td>\n",
       "      <td>0.744589</td>\n",
       "      <td>0.751092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.331507</td>\n",
       "      <td>0.745690</td>\n",
       "      <td>0.748918</td>\n",
       "      <td>0.747300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.005700</td>\n",
       "      <td>0.341789</td>\n",
       "      <td>0.746725</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.743478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_GerMedBERT_medbert-512_42_42_8\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_GerMedBERT_medbert-512_42_42_8\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4305.62 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       1.00      0.96      0.98        54\n",
      "    Krankenhaus       0.85      0.79      0.82       105\n",
      "       Personal       0.88      0.94      0.91        16\n",
      " Pflegepersonal       1.00      0.93      0.97        15\n",
      "anderer Service       0.61      0.49      0.54        35\n",
      " mediz. Service       0.86      0.59      0.70        63\n",
      "\n",
      "      micro avg       0.87      0.76      0.81       288\n",
      "      macro avg       0.87      0.78      0.82       288\n",
      "   weighted avg       0.86      0.76      0.80       288\n",
      "\n",
      "Precision Score: 0.8650793650793651\n",
      "Recall Score: 0.7569444444444444\n",
      "F1 Score: 0.8074074074074075\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/8_epochs/GerMedBERT_medbert-512_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/8_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for deepset/gbert-base:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5881.77 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4709.40 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O' 'B-mediz. Service' 'B-Pflegepersonal' 'B-Arzt' 'B-anderer Service'\n",
      " 'B-Krankenhaus' 'B-Personal']\n",
      "{0: 0.1596439493228484, 1: 4.959959280624364, 2: 14.014381591562799, 3: 6.8239962651727355, 4: 10.546176046176047, 5: 5.983217355710193, 6: 18.317042606516292}\n",
      "Training deepset/gbert-base for 8 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3232' max='3232' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3232/3232 03:38, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.227274</td>\n",
       "      <td>0.712329</td>\n",
       "      <td>0.614173</td>\n",
       "      <td>0.659619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.316000</td>\n",
       "      <td>0.181655</td>\n",
       "      <td>0.752066</td>\n",
       "      <td>0.716535</td>\n",
       "      <td>0.733871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.146400</td>\n",
       "      <td>0.209302</td>\n",
       "      <td>0.776062</td>\n",
       "      <td>0.791339</td>\n",
       "      <td>0.783626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.057600</td>\n",
       "      <td>0.272403</td>\n",
       "      <td>0.762097</td>\n",
       "      <td>0.744094</td>\n",
       "      <td>0.752988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.036100</td>\n",
       "      <td>0.265152</td>\n",
       "      <td>0.736059</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>0.757170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.036100</td>\n",
       "      <td>0.258910</td>\n",
       "      <td>0.785992</td>\n",
       "      <td>0.795276</td>\n",
       "      <td>0.790607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>0.280936</td>\n",
       "      <td>0.754579</td>\n",
       "      <td>0.811024</td>\n",
       "      <td>0.781784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.006000</td>\n",
       "      <td>0.283672</td>\n",
       "      <td>0.760300</td>\n",
       "      <td>0.799213</td>\n",
       "      <td>0.779271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_deepset_gbert-base_42_42_8\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_deepset_gbert-base_42_42_8\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4442.06 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.93      0.93      0.93        55\n",
      "    Krankenhaus       0.90      0.65      0.76       117\n",
      "       Personal       0.70      0.54      0.61        13\n",
      " Pflegepersonal       0.90      1.00      0.95        18\n",
      "anderer Service       0.71      0.57      0.63        35\n",
      " mediz. Service       0.85      0.73      0.78        77\n",
      "\n",
      "      micro avg       0.87      0.72      0.79       315\n",
      "      macro avg       0.83      0.74      0.78       315\n",
      "   weighted avg       0.87      0.72      0.78       315\n",
      "\n",
      "Precision Score: 0.8669201520912547\n",
      "Recall Score: 0.7238095238095238\n",
      "F1 Score: 0.7889273356401384\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/8_epochs/deepset_gbert-base_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/8_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(f'training and results for {model}:')\n",
    "    ate_cat_model(data, model, rn1=42, rn2=42, epochs=8, save=True)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca4024ac-8b4e-4817-ae28-8f9787f19b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training and results for google-bert/bert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5233.86 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4842.75 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Krankenhaus' 'B-anderer Service' 'B-Pflegepersonal' 'B-Personal'\n",
      " 'B-Arzt' 'B-mediz. Service' 'O']\n",
      "{0: 5.983217355710193, 1: 10.546176046176047, 2: 14.014381591562799, 3: 18.317042606516292, 4: 6.8239962651727355, 5: 4.959959280624364, 6: 0.1596439493228484}\n",
      "Training google-bert/bert-base-german-cased for 10 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4040' max='4040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4040/4040 04:30, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.223472</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.567050</td>\n",
       "      <td>0.636559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.317200</td>\n",
       "      <td>0.192512</td>\n",
       "      <td>0.716981</td>\n",
       "      <td>0.727969</td>\n",
       "      <td>0.722433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.222244</td>\n",
       "      <td>0.736059</td>\n",
       "      <td>0.758621</td>\n",
       "      <td>0.747170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.052100</td>\n",
       "      <td>0.268146</td>\n",
       "      <td>0.724528</td>\n",
       "      <td>0.735632</td>\n",
       "      <td>0.730038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.025300</td>\n",
       "      <td>0.390602</td>\n",
       "      <td>0.724138</td>\n",
       "      <td>0.643678</td>\n",
       "      <td>0.681542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.025300</td>\n",
       "      <td>0.407243</td>\n",
       "      <td>0.746835</td>\n",
       "      <td>0.678161</td>\n",
       "      <td>0.710843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.431870</td>\n",
       "      <td>0.712551</td>\n",
       "      <td>0.674330</td>\n",
       "      <td>0.692913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.002400</td>\n",
       "      <td>0.432829</td>\n",
       "      <td>0.708171</td>\n",
       "      <td>0.697318</td>\n",
       "      <td>0.702703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.446251</td>\n",
       "      <td>0.702381</td>\n",
       "      <td>0.678161</td>\n",
       "      <td>0.690058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.447266</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.689655</td>\n",
       "      <td>0.697674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_google-bert_bert-base-german-cased_42_42_10\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_google-bert_bert-base-german-cased_42_42_10\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4502.22 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.78      0.94      0.85        52\n",
      "    Krankenhaus       0.86      0.55      0.67       119\n",
      "       Personal       0.67      0.43      0.52        14\n",
      " Pflegepersonal       0.94      0.94      0.94        18\n",
      "anderer Service       0.57      0.52      0.54        33\n",
      " mediz. Service       0.77      0.78      0.78        87\n",
      "\n",
      "      micro avg       0.78      0.69      0.73       323\n",
      "      macro avg       0.76      0.69      0.72       323\n",
      "   weighted avg       0.79      0.69      0.72       323\n",
      "\n",
      "Precision Score: 0.7816901408450704\n",
      "Recall Score: 0.6873065015479877\n",
      "F1 Score: 0.7314662273476112\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/10_epochs/google-bert_bert-base-german-cased_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/10_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6042.23 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4854.69 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Krankenhaus' 'B-anderer Service' 'B-Pflegepersonal' 'B-Personal'\n",
      " 'B-Arzt' 'B-mediz. Service' 'O']\n",
      "{0: 5.983217355710193, 1: 10.546176046176047, 2: 14.014381591562799, 3: 18.317042606516292, 4: 6.8239962651727355, 5: 4.959959280624364, 6: 0.1596439493228484}\n",
      "Training dbmdz/bert-base-german-cased for 10 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4040' max='4040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4040/4040 04:31, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.230677</td>\n",
       "      <td>0.669643</td>\n",
       "      <td>0.590551</td>\n",
       "      <td>0.627615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.349900</td>\n",
       "      <td>0.191492</td>\n",
       "      <td>0.765432</td>\n",
       "      <td>0.732283</td>\n",
       "      <td>0.748491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.158700</td>\n",
       "      <td>0.213762</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>0.773438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.069700</td>\n",
       "      <td>0.258253</td>\n",
       "      <td>0.737255</td>\n",
       "      <td>0.740157</td>\n",
       "      <td>0.738703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.036300</td>\n",
       "      <td>0.312374</td>\n",
       "      <td>0.765957</td>\n",
       "      <td>0.708661</td>\n",
       "      <td>0.736196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.036300</td>\n",
       "      <td>0.333826</td>\n",
       "      <td>0.768000</td>\n",
       "      <td>0.755906</td>\n",
       "      <td>0.761905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.350229</td>\n",
       "      <td>0.773438</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>0.776471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.006500</td>\n",
       "      <td>0.363329</td>\n",
       "      <td>0.734848</td>\n",
       "      <td>0.763780</td>\n",
       "      <td>0.749035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.374735</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>0.787402</td>\n",
       "      <td>0.754717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.003200</td>\n",
       "      <td>0.366855</td>\n",
       "      <td>0.742424</td>\n",
       "      <td>0.771654</td>\n",
       "      <td>0.756757</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_dbmdz_bert-base-german-cased_42_42_10\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_dbmdz_bert-base-german-cased_42_42_10\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4425.65 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.95      0.95      0.95        55\n",
      "    Krankenhaus       0.86      0.62      0.72       117\n",
      "       Personal       0.85      0.85      0.85        13\n",
      " Pflegepersonal       0.86      1.00      0.92        18\n",
      "anderer Service       0.79      0.43      0.56        35\n",
      " mediz. Service       0.81      0.75      0.78        77\n",
      "\n",
      "      micro avg       0.86      0.72      0.78       315\n",
      "      macro avg       0.85      0.77      0.80       315\n",
      "   weighted avg       0.85      0.72      0.77       315\n",
      "\n",
      "Precision Score: 0.8566037735849057\n",
      "Recall Score: 0.7206349206349206\n",
      "F1 Score: 0.7827586206896552\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/10_epochs/dbmdz_bert-base-german-cased_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/10_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-uncased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5668.77 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4784.02 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Krankenhaus' 'B-anderer Service' 'B-Pflegepersonal' 'B-Personal'\n",
      " 'B-Arzt' 'B-mediz. Service' 'O']\n",
      "{0: 5.983217355710193, 1: 10.546176046176047, 2: 14.014381591562799, 3: 18.317042606516292, 4: 6.8239962651727355, 5: 4.959959280624364, 6: 0.1596439493228484}\n",
      "Training dbmdz/bert-base-german-uncased for 10 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4040' max='4040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4040/4040 04:30, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.221900</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.653846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.327700</td>\n",
       "      <td>0.219372</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>0.658730</td>\n",
       "      <td>0.712446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.148800</td>\n",
       "      <td>0.227801</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.770186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.066800</td>\n",
       "      <td>0.267928</td>\n",
       "      <td>0.749035</td>\n",
       "      <td>0.769841</td>\n",
       "      <td>0.759295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.040600</td>\n",
       "      <td>0.300276</td>\n",
       "      <td>0.752000</td>\n",
       "      <td>0.746032</td>\n",
       "      <td>0.749004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.040600</td>\n",
       "      <td>0.309222</td>\n",
       "      <td>0.768293</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.759036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>0.353222</td>\n",
       "      <td>0.741313</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.751468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.006900</td>\n",
       "      <td>0.352309</td>\n",
       "      <td>0.747967</td>\n",
       "      <td>0.730159</td>\n",
       "      <td>0.738956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>0.360980</td>\n",
       "      <td>0.747036</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.748515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.364593</td>\n",
       "      <td>0.749035</td>\n",
       "      <td>0.769841</td>\n",
       "      <td>0.759295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_dbmdz_bert-base-german-uncased_42_42_10\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_dbmdz_bert-base-german-uncased_42_42_10\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4498.20 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.89      0.94      0.91        63\n",
      "    Krankenhaus       0.96      0.45      0.61       112\n",
      "       Personal       0.71      0.86      0.77        14\n",
      " Pflegepersonal       1.00      0.95      0.97        19\n",
      "anderer Service       0.86      0.35      0.50        34\n",
      " mediz. Service       0.86      0.77      0.81        74\n",
      "\n",
      "      micro avg       0.89      0.66      0.76       316\n",
      "      macro avg       0.88      0.72      0.76       316\n",
      "   weighted avg       0.90      0.66      0.74       316\n",
      "\n",
      "Precision Score: 0.8927038626609443\n",
      "Recall Score: 0.6582278481012658\n",
      "F1 Score: 0.7577413479052822\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/10_epochs/dbmdz_bert-base-german-uncased_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/10_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for FacebookAI/xlm-roberta-base:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5788.52 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5123.54 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Krankenhaus' 'B-anderer Service' 'B-Pflegepersonal' 'B-Personal'\n",
      " 'B-Arzt' 'B-mediz. Service' 'O']\n",
      "{0: 5.983217355710193, 1: 10.546176046176047, 2: 14.014381591562799, 3: 18.317042606516292, 4: 6.8239962651727355, 5: 4.959959280624364, 6: 0.1596439493228484}\n",
      "Training FacebookAI/xlm-roberta-base for 10 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4040' max='4040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4040/4040 07:00, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.299480</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.456747</td>\n",
       "      <td>0.548857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.461100</td>\n",
       "      <td>0.227516</td>\n",
       "      <td>0.745387</td>\n",
       "      <td>0.698962</td>\n",
       "      <td>0.721429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.241600</td>\n",
       "      <td>0.226161</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.709343</td>\n",
       "      <td>0.711806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.143800</td>\n",
       "      <td>0.236383</td>\n",
       "      <td>0.723684</td>\n",
       "      <td>0.761246</td>\n",
       "      <td>0.741990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.103700</td>\n",
       "      <td>0.304264</td>\n",
       "      <td>0.726644</td>\n",
       "      <td>0.726644</td>\n",
       "      <td>0.726644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.103700</td>\n",
       "      <td>0.285069</td>\n",
       "      <td>0.761404</td>\n",
       "      <td>0.750865</td>\n",
       "      <td>0.756098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.054900</td>\n",
       "      <td>0.334264</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.775087</td>\n",
       "      <td>0.741722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.034100</td>\n",
       "      <td>0.303019</td>\n",
       "      <td>0.738411</td>\n",
       "      <td>0.771626</td>\n",
       "      <td>0.754653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.025500</td>\n",
       "      <td>0.323546</td>\n",
       "      <td>0.754153</td>\n",
       "      <td>0.785467</td>\n",
       "      <td>0.769492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>0.327147</td>\n",
       "      <td>0.752508</td>\n",
       "      <td>0.778547</td>\n",
       "      <td>0.765306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_FacebookAI_xlm-roberta-base_42_42_10\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_FacebookAI_xlm-roberta-base_42_42_10\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4656.33 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.86      0.93      0.89        59\n",
      "    Krankenhaus       0.84      0.80      0.82       120\n",
      "       Personal       1.00      0.40      0.57        15\n",
      " Pflegepersonal       0.80      1.00      0.89        24\n",
      "anderer Service       0.67      0.49      0.56        45\n",
      " mediz. Service       0.73      0.73      0.73        83\n",
      "\n",
      "      micro avg       0.80      0.76      0.78       346\n",
      "      macro avg       0.82      0.73      0.75       346\n",
      "   weighted avg       0.80      0.76      0.77       346\n",
      "\n",
      "Precision Score: 0.8\n",
      "Recall Score: 0.7630057803468208\n",
      "F1 Score: 0.7810650887573964\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/10_epochs/FacebookAI_xlm-roberta-base_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/10_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_best:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at TUM/GottBERT_base_best and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6521.92 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5123.98 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Krankenhaus' 'B-anderer Service' 'B-Pflegepersonal' 'B-Personal'\n",
      " 'B-Arzt' 'B-mediz. Service' 'O']\n",
      "{0: 5.983217355710193, 1: 10.546176046176047, 2: 14.014381591562799, 3: 18.317042606516292, 4: 6.8239962651727355, 5: 4.959959280624364, 6: 0.1596439493228484}\n",
      "Training TUM/GottBERT_base_best for 10 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4040' max='4040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4040/4040 04:46, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.268073</td>\n",
       "      <td>0.712575</td>\n",
       "      <td>0.561321</td>\n",
       "      <td>0.627968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.323100</td>\n",
       "      <td>0.187483</td>\n",
       "      <td>0.781250</td>\n",
       "      <td>0.707547</td>\n",
       "      <td>0.742574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.171600</td>\n",
       "      <td>0.223834</td>\n",
       "      <td>0.718062</td>\n",
       "      <td>0.768868</td>\n",
       "      <td>0.742597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.083900</td>\n",
       "      <td>0.254508</td>\n",
       "      <td>0.706140</td>\n",
       "      <td>0.759434</td>\n",
       "      <td>0.731818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.054600</td>\n",
       "      <td>0.360901</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.707547</td>\n",
       "      <td>0.700935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.054600</td>\n",
       "      <td>0.366790</td>\n",
       "      <td>0.732057</td>\n",
       "      <td>0.721698</td>\n",
       "      <td>0.726841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.022300</td>\n",
       "      <td>0.407067</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.660377</td>\n",
       "      <td>0.686275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.013700</td>\n",
       "      <td>0.422206</td>\n",
       "      <td>0.721393</td>\n",
       "      <td>0.683962</td>\n",
       "      <td>0.702179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.006400</td>\n",
       "      <td>0.414087</td>\n",
       "      <td>0.721698</td>\n",
       "      <td>0.721698</td>\n",
       "      <td>0.721698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.003400</td>\n",
       "      <td>0.421214</td>\n",
       "      <td>0.714953</td>\n",
       "      <td>0.721698</td>\n",
       "      <td>0.718310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_TUM_GottBERT_base_best_42_42_10\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_TUM_GottBERT_base_best_42_42_10\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4809.82 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.91      0.98      0.94        52\n",
      "    Krankenhaus       0.85      0.69      0.76       104\n",
      "       Personal       0.64      0.75      0.69        12\n",
      " Pflegepersonal       1.00      0.93      0.96        14\n",
      "anderer Service       0.65      0.43      0.52        30\n",
      " mediz. Service       0.68      0.81      0.73        67\n",
      "\n",
      "      micro avg       0.79      0.76      0.78       279\n",
      "      macro avg       0.79      0.77      0.77       279\n",
      "   weighted avg       0.80      0.76      0.77       279\n",
      "\n",
      "Precision Score: 0.7910447761194029\n",
      "Recall Score: 0.7598566308243727\n",
      "F1 Score: 0.7751371115173674\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/10_epochs/TUM_GottBERT_base_best_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/10_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_filtered_base_best:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at TUM/GottBERT_filtered_base_best and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6583.47 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5089.93 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Krankenhaus' 'B-anderer Service' 'B-Pflegepersonal' 'B-Personal'\n",
      " 'B-Arzt' 'B-mediz. Service' 'O']\n",
      "{0: 5.983217355710193, 1: 10.546176046176047, 2: 14.014381591562799, 3: 18.317042606516292, 4: 6.8239962651727355, 5: 4.959959280624364, 6: 0.1596439493228484}\n",
      "Training TUM/GottBERT_filtered_base_best for 10 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4040' max='4040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4040/4040 04:46, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.211675</td>\n",
       "      <td>0.747126</td>\n",
       "      <td>0.613208</td>\n",
       "      <td>0.673575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.332600</td>\n",
       "      <td>0.168921</td>\n",
       "      <td>0.778378</td>\n",
       "      <td>0.679245</td>\n",
       "      <td>0.725441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.166400</td>\n",
       "      <td>0.158010</td>\n",
       "      <td>0.777273</td>\n",
       "      <td>0.806604</td>\n",
       "      <td>0.791667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.078800</td>\n",
       "      <td>0.186920</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.716981</td>\n",
       "      <td>0.756219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.056400</td>\n",
       "      <td>0.247739</td>\n",
       "      <td>0.729858</td>\n",
       "      <td>0.726415</td>\n",
       "      <td>0.728132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.056400</td>\n",
       "      <td>0.250029</td>\n",
       "      <td>0.781553</td>\n",
       "      <td>0.759434</td>\n",
       "      <td>0.770335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.243337</td>\n",
       "      <td>0.732143</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.752294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>0.276199</td>\n",
       "      <td>0.765550</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.760095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.005600</td>\n",
       "      <td>0.291894</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.290057</td>\n",
       "      <td>0.759434</td>\n",
       "      <td>0.759434</td>\n",
       "      <td>0.759434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_TUM_GottBERT_filtered_base_best_42_42_10\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_TUM_GottBERT_filtered_base_best_42_42_10\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4707.88 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.94      0.98      0.96        52\n",
      "    Krankenhaus       0.90      0.66      0.76       104\n",
      "       Personal       0.64      0.75      0.69        12\n",
      " Pflegepersonal       1.00      0.93      0.96        14\n",
      "anderer Service       0.77      0.33      0.47        30\n",
      " mediz. Service       0.69      0.81      0.74        67\n",
      "\n",
      "      micro avg       0.83      0.74      0.78       279\n",
      "      macro avg       0.82      0.74      0.76       279\n",
      "   weighted avg       0.84      0.74      0.77       279\n",
      "\n",
      "Precision Score: 0.8273092369477911\n",
      "Recall Score: 0.7383512544802867\n",
      "F1 Score: 0.7803030303030303\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/10_epochs/TUM_GottBERT_filtered_base_best_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/10_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_last:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at TUM/GottBERT_base_last were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at TUM/GottBERT_base_last and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6494.20 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5042.31 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Krankenhaus' 'B-anderer Service' 'B-Pflegepersonal' 'B-Personal'\n",
      " 'B-Arzt' 'B-mediz. Service' 'O']\n",
      "{0: 5.983217355710193, 1: 10.546176046176047, 2: 14.014381591562799, 3: 18.317042606516292, 4: 6.8239962651727355, 5: 4.959959280624364, 6: 0.1596439493228484}\n",
      "Training TUM/GottBERT_base_last for 10 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4040' max='4040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4040/4040 04:45, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.260157</td>\n",
       "      <td>0.721893</td>\n",
       "      <td>0.575472</td>\n",
       "      <td>0.640420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.323000</td>\n",
       "      <td>0.169120</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.693396</td>\n",
       "      <td>0.733167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.178600</td>\n",
       "      <td>0.241927</td>\n",
       "      <td>0.687204</td>\n",
       "      <td>0.683962</td>\n",
       "      <td>0.685579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.089400</td>\n",
       "      <td>0.239260</td>\n",
       "      <td>0.767327</td>\n",
       "      <td>0.731132</td>\n",
       "      <td>0.748792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.058300</td>\n",
       "      <td>0.326706</td>\n",
       "      <td>0.706897</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.738739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.058300</td>\n",
       "      <td>0.316070</td>\n",
       "      <td>0.793970</td>\n",
       "      <td>0.745283</td>\n",
       "      <td>0.768856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.024600</td>\n",
       "      <td>0.327118</td>\n",
       "      <td>0.758140</td>\n",
       "      <td>0.768868</td>\n",
       "      <td>0.763466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.014100</td>\n",
       "      <td>0.383991</td>\n",
       "      <td>0.781095</td>\n",
       "      <td>0.740566</td>\n",
       "      <td>0.760291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.009200</td>\n",
       "      <td>0.349479</td>\n",
       "      <td>0.762557</td>\n",
       "      <td>0.787736</td>\n",
       "      <td>0.774942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.352938</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.778302</td>\n",
       "      <td>0.783848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_TUM_GottBERT_base_last_42_42_10\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_TUM_GottBERT_base_last_42_42_10\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4660.19 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.94      0.98      0.96        52\n",
      "    Krankenhaus       0.92      0.67      0.78       104\n",
      "       Personal       0.73      0.67      0.70        12\n",
      " Pflegepersonal       1.00      1.00      1.00        14\n",
      "anderer Service       0.68      0.57      0.62        30\n",
      " mediz. Service       0.66      0.75      0.70        67\n",
      "\n",
      "      micro avg       0.82      0.75      0.79       279\n",
      "      macro avg       0.82      0.77      0.79       279\n",
      "   weighted avg       0.83      0.75      0.78       279\n",
      "\n",
      "Precision Score: 0.8203125\n",
      "Recall Score: 0.7526881720430108\n",
      "F1 Score: 0.7850467289719626\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/10_epochs/TUM_GottBERT_base_last_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/10_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for distilbert/distilbert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6498.52 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5274.93 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Krankenhaus' 'B-anderer Service' 'B-Pflegepersonal' 'B-Personal'\n",
      " 'B-Arzt' 'B-mediz. Service' 'O']\n",
      "{0: 5.983217355710193, 1: 10.546176046176047, 2: 14.014381591562799, 3: 18.317042606516292, 4: 6.8239962651727355, 5: 4.959959280624364, 6: 0.1596439493228484}\n",
      "Training distilbert/distilbert-base-german-cased for 10 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4040' max='4040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4040/4040 02:32, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.244423</td>\n",
       "      <td>0.656250</td>\n",
       "      <td>0.578740</td>\n",
       "      <td>0.615063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.392400</td>\n",
       "      <td>0.225741</td>\n",
       "      <td>0.721739</td>\n",
       "      <td>0.653543</td>\n",
       "      <td>0.685950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.172200</td>\n",
       "      <td>0.256577</td>\n",
       "      <td>0.776744</td>\n",
       "      <td>0.657480</td>\n",
       "      <td>0.712154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.087700</td>\n",
       "      <td>0.265688</td>\n",
       "      <td>0.735294</td>\n",
       "      <td>0.688976</td>\n",
       "      <td>0.711382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.055900</td>\n",
       "      <td>0.295494</td>\n",
       "      <td>0.734127</td>\n",
       "      <td>0.728346</td>\n",
       "      <td>0.731225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.055900</td>\n",
       "      <td>0.312017</td>\n",
       "      <td>0.776860</td>\n",
       "      <td>0.740157</td>\n",
       "      <td>0.758065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.024400</td>\n",
       "      <td>0.318798</td>\n",
       "      <td>0.750973</td>\n",
       "      <td>0.759843</td>\n",
       "      <td>0.755382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.014700</td>\n",
       "      <td>0.341944</td>\n",
       "      <td>0.759657</td>\n",
       "      <td>0.696850</td>\n",
       "      <td>0.726899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.011500</td>\n",
       "      <td>0.340218</td>\n",
       "      <td>0.761317</td>\n",
       "      <td>0.728346</td>\n",
       "      <td>0.744467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.345061</td>\n",
       "      <td>0.765432</td>\n",
       "      <td>0.732283</td>\n",
       "      <td>0.748491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_distilbert_distilbert-base-german-cased_42_42_10\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_distilbert_distilbert-base-german-cased_42_42_10\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4946.80 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.90      0.95      0.92        55\n",
      "    Krankenhaus       0.93      0.59      0.72       117\n",
      "       Personal       0.67      0.46      0.55        13\n",
      " Pflegepersonal       0.89      0.94      0.92        18\n",
      "anderer Service       0.68      0.37      0.48        35\n",
      " mediz. Service       0.60      0.69      0.64        77\n",
      "\n",
      "      micro avg       0.79      0.67      0.72       315\n",
      "      macro avg       0.78      0.67      0.71       315\n",
      "   weighted avg       0.80      0.67      0.71       315\n",
      "\n",
      "Precision Score: 0.7865168539325843\n",
      "Recall Score: 0.6666666666666666\n",
      "F1 Score: 0.7216494845360824\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/10_epochs/distilbert_distilbert-base-german-cased_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/10_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for GerMedBERT/medbert-512:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Device set to use cuda:0\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at GerMedBERT/medbert-512 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5795.66 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4612.19 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Krankenhaus' 'B-anderer Service' 'B-Pflegepersonal' 'B-Personal'\n",
      " 'B-Arzt' 'B-mediz. Service' 'O']\n",
      "{0: 5.983217355710193, 1: 10.546176046176047, 2: 14.014381591562799, 3: 18.317042606516292, 4: 6.8239962651727355, 5: 4.959959280624364, 6: 0.1596439493228484}\n",
      "Training GerMedBERT/medbert-512 for 10 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4040' max='4040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4040/4040 04:33, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.195355</td>\n",
       "      <td>0.694581</td>\n",
       "      <td>0.610390</td>\n",
       "      <td>0.649770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.318600</td>\n",
       "      <td>0.175384</td>\n",
       "      <td>0.733624</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.730435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.150200</td>\n",
       "      <td>0.266162</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.640693</td>\n",
       "      <td>0.706444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.072100</td>\n",
       "      <td>0.254510</td>\n",
       "      <td>0.734513</td>\n",
       "      <td>0.718615</td>\n",
       "      <td>0.726477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.039200</td>\n",
       "      <td>0.280344</td>\n",
       "      <td>0.699588</td>\n",
       "      <td>0.735931</td>\n",
       "      <td>0.717300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.039200</td>\n",
       "      <td>0.301701</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>0.718615</td>\n",
       "      <td>0.746067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.010100</td>\n",
       "      <td>0.332243</td>\n",
       "      <td>0.729258</td>\n",
       "      <td>0.722944</td>\n",
       "      <td>0.726087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.007100</td>\n",
       "      <td>0.349217</td>\n",
       "      <td>0.714894</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.721030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.357856</td>\n",
       "      <td>0.748837</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.721973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.355737</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.723684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_GerMedBERT_medbert-512_42_42_10\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_GerMedBERT_medbert-512_42_42_10\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4296.15 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.95      0.98      0.96        54\n",
      "    Krankenhaus       0.96      0.70      0.81       105\n",
      "       Personal       0.79      0.69      0.73        16\n",
      " Pflegepersonal       0.93      0.87      0.90        15\n",
      "anderer Service       0.60      0.43      0.50        35\n",
      " mediz. Service       0.86      0.60      0.71        63\n",
      "\n",
      "      micro avg       0.89      0.70      0.79       288\n",
      "      macro avg       0.85      0.71      0.77       288\n",
      "   weighted avg       0.88      0.70      0.78       288\n",
      "\n",
      "Precision Score: 0.8864628820960698\n",
      "Recall Score: 0.7048611111111112\n",
      "F1 Score: 0.7852998065764023\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/10_epochs/GerMedBERT_medbert-512_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/10_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for deepset/gbert-base:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5914.12 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4736.25 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Krankenhaus' 'B-anderer Service' 'B-Pflegepersonal' 'B-Personal'\n",
      " 'B-Arzt' 'B-mediz. Service' 'O']\n",
      "{0: 5.983217355710193, 1: 10.546176046176047, 2: 14.014381591562799, 3: 18.317042606516292, 4: 6.8239962651727355, 5: 4.959959280624364, 6: 0.1596439493228484}\n",
      "Training deepset/gbert-base for 10 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4040' max='4040' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4040/4040 04:35, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.212766</td>\n",
       "      <td>0.789216</td>\n",
       "      <td>0.633858</td>\n",
       "      <td>0.703057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.324100</td>\n",
       "      <td>0.201206</td>\n",
       "      <td>0.802817</td>\n",
       "      <td>0.673228</td>\n",
       "      <td>0.732334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.147400</td>\n",
       "      <td>0.207261</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>0.744094</td>\n",
       "      <td>0.765182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.062800</td>\n",
       "      <td>0.262745</td>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.692913</td>\n",
       "      <td>0.748936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.038500</td>\n",
       "      <td>0.276008</td>\n",
       "      <td>0.739300</td>\n",
       "      <td>0.748031</td>\n",
       "      <td>0.743640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.038500</td>\n",
       "      <td>0.273169</td>\n",
       "      <td>0.795745</td>\n",
       "      <td>0.736220</td>\n",
       "      <td>0.764826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.015600</td>\n",
       "      <td>0.308614</td>\n",
       "      <td>0.750958</td>\n",
       "      <td>0.771654</td>\n",
       "      <td>0.761165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.007800</td>\n",
       "      <td>0.317918</td>\n",
       "      <td>0.772549</td>\n",
       "      <td>0.775591</td>\n",
       "      <td>0.774067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.004800</td>\n",
       "      <td>0.330287</td>\n",
       "      <td>0.765625</td>\n",
       "      <td>0.771654</td>\n",
       "      <td>0.768627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.328902</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>0.773438</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_deepset_gbert-base_42_42_10\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_deepset_gbert-base_42_42_10\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4431.89 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.86      0.93      0.89        55\n",
      "    Krankenhaus       0.92      0.72      0.81       117\n",
      "       Personal       0.69      0.69      0.69        13\n",
      " Pflegepersonal       0.85      0.94      0.89        18\n",
      "anderer Service       0.78      0.51      0.62        35\n",
      " mediz. Service       0.76      0.74      0.75        77\n",
      "\n",
      "      micro avg       0.84      0.75      0.79       315\n",
      "      macro avg       0.81      0.76      0.78       315\n",
      "   weighted avg       0.84      0.75      0.79       315\n",
      "\n",
      "Precision Score: 0.8398576512455516\n",
      "Recall Score: 0.7492063492063492\n",
      "F1 Score: 0.7919463087248322\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/10_epochs/deepset_gbert-base_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/10_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(f'training and results for {model}:')\n",
    "    ate_cat_model(data, model, rn1=42, rn2=42, epochs=10, save=True)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fdff1b5b-f400-4443-a64f-f72d02fcc1ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training and results for google-bert/bert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5831.33 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4566.35 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Krankenhaus' 'B-anderer Service' 'B-Pflegepersonal' 'B-Personal'\n",
      " 'B-Arzt' 'B-mediz. Service' 'O']\n",
      "{0: 5.983217355710193, 1: 10.546176046176047, 2: 14.014381591562799, 3: 18.317042606516292, 4: 6.8239962651727355, 5: 4.959959280624364, 6: 0.1596439493228484}\n",
      "Training google-bert/bert-base-german-cased for 12 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4848' max='4848' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4848/4848 05:29, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.211180</td>\n",
       "      <td>0.723502</td>\n",
       "      <td>0.601533</td>\n",
       "      <td>0.656904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.332900</td>\n",
       "      <td>0.194919</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.703030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.132700</td>\n",
       "      <td>0.260497</td>\n",
       "      <td>0.737903</td>\n",
       "      <td>0.701149</td>\n",
       "      <td>0.719057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.052000</td>\n",
       "      <td>0.265018</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.711656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.027700</td>\n",
       "      <td>0.351346</td>\n",
       "      <td>0.710744</td>\n",
       "      <td>0.659004</td>\n",
       "      <td>0.683897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.027700</td>\n",
       "      <td>0.384536</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.643678</td>\n",
       "      <td>0.682927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.006600</td>\n",
       "      <td>0.403812</td>\n",
       "      <td>0.721116</td>\n",
       "      <td>0.693487</td>\n",
       "      <td>0.707031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.423429</td>\n",
       "      <td>0.694779</td>\n",
       "      <td>0.662835</td>\n",
       "      <td>0.678431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.410853</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.697318</td>\n",
       "      <td>0.709552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.441680</td>\n",
       "      <td>0.702041</td>\n",
       "      <td>0.659004</td>\n",
       "      <td>0.679842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>0.450249</td>\n",
       "      <td>0.709677</td>\n",
       "      <td>0.674330</td>\n",
       "      <td>0.691552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.452963</td>\n",
       "      <td>0.710843</td>\n",
       "      <td>0.678161</td>\n",
       "      <td>0.694118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_google-bert_bert-base-german-cased_42_42_12\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_google-bert_bert-base-german-cased_42_42_12\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4378.46 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.82      0.98      0.89        52\n",
      "    Krankenhaus       0.84      0.59      0.69       119\n",
      "       Personal       0.73      0.57      0.64        14\n",
      " Pflegepersonal       0.94      0.94      0.94        18\n",
      "anderer Service       0.70      0.42      0.53        33\n",
      " mediz. Service       0.81      0.79      0.80        87\n",
      "\n",
      "      micro avg       0.82      0.71      0.76       323\n",
      "      macro avg       0.81      0.72      0.75       323\n",
      "   weighted avg       0.82      0.71      0.75       323\n",
      "\n",
      "Precision Score: 0.8207885304659498\n",
      "Recall Score: 0.7089783281733746\n",
      "F1 Score: 0.7607973421926909\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/12_epochs/google-bert_bert-base-german-cased_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/12_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5818.50 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4800.66 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Krankenhaus' 'B-anderer Service' 'B-Pflegepersonal' 'B-Personal'\n",
      " 'B-Arzt' 'B-mediz. Service' 'O']\n",
      "{0: 5.983217355710193, 1: 10.546176046176047, 2: 14.014381591562799, 3: 18.317042606516292, 4: 6.8239962651727355, 5: 4.959959280624364, 6: 0.1596439493228484}\n",
      "Training dbmdz/bert-base-german-cased for 12 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4848' max='4848' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4848/4848 05:28, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.248845</td>\n",
       "      <td>0.741784</td>\n",
       "      <td>0.622047</td>\n",
       "      <td>0.676660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.341100</td>\n",
       "      <td>0.234615</td>\n",
       "      <td>0.768182</td>\n",
       "      <td>0.665354</td>\n",
       "      <td>0.713080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.156100</td>\n",
       "      <td>0.197918</td>\n",
       "      <td>0.814346</td>\n",
       "      <td>0.759843</td>\n",
       "      <td>0.786151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.071200</td>\n",
       "      <td>0.256327</td>\n",
       "      <td>0.829787</td>\n",
       "      <td>0.767717</td>\n",
       "      <td>0.797546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.035100</td>\n",
       "      <td>0.298312</td>\n",
       "      <td>0.792829</td>\n",
       "      <td>0.783465</td>\n",
       "      <td>0.788119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.035100</td>\n",
       "      <td>0.331760</td>\n",
       "      <td>0.809129</td>\n",
       "      <td>0.767717</td>\n",
       "      <td>0.787879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.009900</td>\n",
       "      <td>0.331911</td>\n",
       "      <td>0.783133</td>\n",
       "      <td>0.767717</td>\n",
       "      <td>0.775348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.409032</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.708661</td>\n",
       "      <td>0.746888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.003100</td>\n",
       "      <td>0.335819</td>\n",
       "      <td>0.778626</td>\n",
       "      <td>0.803150</td>\n",
       "      <td>0.790698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.343177</td>\n",
       "      <td>0.762963</td>\n",
       "      <td>0.811024</td>\n",
       "      <td>0.786260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.001400</td>\n",
       "      <td>0.365769</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.767717</td>\n",
       "      <td>0.778443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.361265</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>0.781065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_dbmdz_bert-base-german-cased_42_42_12\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_dbmdz_bert-base-german-cased_42_42_12\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4442.66 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.98      0.93      0.95        55\n",
      "    Krankenhaus       0.89      0.54      0.67       117\n",
      "       Personal       0.67      0.92      0.77        13\n",
      " Pflegepersonal       1.00      0.89      0.94        18\n",
      "anderer Service       0.75      0.43      0.55        35\n",
      " mediz. Service       0.69      0.74      0.71        77\n",
      "\n",
      "      micro avg       0.82      0.68      0.74       315\n",
      "      macro avg       0.83      0.74      0.77       315\n",
      "   weighted avg       0.84      0.68      0.74       315\n",
      "\n",
      "Precision Score: 0.823076923076923\n",
      "Recall Score: 0.6793650793650794\n",
      "F1 Score: 0.7443478260869565\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/12_epochs/dbmdz_bert-base-german-cased_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/12_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for dbmdz/bert-base-german-uncased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-german-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5580.67 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4587.46 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Krankenhaus' 'B-anderer Service' 'B-Pflegepersonal' 'B-Personal'\n",
      " 'B-Arzt' 'B-mediz. Service' 'O']\n",
      "{0: 5.983217355710193, 1: 10.546176046176047, 2: 14.014381591562799, 3: 18.317042606516292, 4: 6.8239962651727355, 5: 4.959959280624364, 6: 0.1596439493228484}\n",
      "Training dbmdz/bert-base-german-uncased for 12 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4848' max='4848' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4848/4848 05:27, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.241119</td>\n",
       "      <td>0.704225</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.645161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.325700</td>\n",
       "      <td>0.243878</td>\n",
       "      <td>0.775120</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.702820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.149900</td>\n",
       "      <td>0.276914</td>\n",
       "      <td>0.786364</td>\n",
       "      <td>0.686508</td>\n",
       "      <td>0.733051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.061700</td>\n",
       "      <td>0.274966</td>\n",
       "      <td>0.758893</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.760396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.032200</td>\n",
       "      <td>0.338818</td>\n",
       "      <td>0.704380</td>\n",
       "      <td>0.765873</td>\n",
       "      <td>0.733840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.032200</td>\n",
       "      <td>0.332746</td>\n",
       "      <td>0.808511</td>\n",
       "      <td>0.753968</td>\n",
       "      <td>0.780287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.012500</td>\n",
       "      <td>0.382021</td>\n",
       "      <td>0.728682</td>\n",
       "      <td>0.746032</td>\n",
       "      <td>0.737255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.006800</td>\n",
       "      <td>0.443337</td>\n",
       "      <td>0.719844</td>\n",
       "      <td>0.734127</td>\n",
       "      <td>0.726916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.002800</td>\n",
       "      <td>0.447263</td>\n",
       "      <td>0.736000</td>\n",
       "      <td>0.730159</td>\n",
       "      <td>0.733068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.442026</td>\n",
       "      <td>0.726923</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.738281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.432179</td>\n",
       "      <td>0.767347</td>\n",
       "      <td>0.746032</td>\n",
       "      <td>0.756539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.426419</td>\n",
       "      <td>0.751969</td>\n",
       "      <td>0.757937</td>\n",
       "      <td>0.754941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_dbmdz_bert-base-german-uncased_42_42_12\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_dbmdz_bert-base-german-uncased_42_42_12\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4422.04 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.87      0.94      0.90        63\n",
      "    Krankenhaus       0.93      0.46      0.61       112\n",
      "       Personal       0.75      0.64      0.69        14\n",
      " Pflegepersonal       1.00      1.00      1.00        19\n",
      "anderer Service       0.56      0.41      0.47        34\n",
      " mediz. Service       0.83      0.78      0.81        74\n",
      "\n",
      "      micro avg       0.84      0.66      0.74       316\n",
      "      macro avg       0.82      0.71      0.75       316\n",
      "   weighted avg       0.85      0.66      0.73       316\n",
      "\n",
      "Precision Score: 0.8433734939759037\n",
      "Recall Score: 0.6645569620253164\n",
      "F1 Score: 0.7433628318584071\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/12_epochs/dbmdz_bert-base-german-uncased_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/12_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for FacebookAI/xlm-roberta-base:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at FacebookAI/xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5844.21 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5002.12 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Krankenhaus' 'B-anderer Service' 'B-Pflegepersonal' 'B-Personal'\n",
      " 'B-Arzt' 'B-mediz. Service' 'O']\n",
      "{0: 5.983217355710193, 1: 10.546176046176047, 2: 14.014381591562799, 3: 18.317042606516292, 4: 6.8239962651727355, 5: 4.959959280624364, 6: 0.1596439493228484}\n",
      "Training FacebookAI/xlm-roberta-base for 12 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4848' max='4848' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4848/4848 08:31, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.262373</td>\n",
       "      <td>0.737327</td>\n",
       "      <td>0.553633</td>\n",
       "      <td>0.632411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.385500</td>\n",
       "      <td>0.197599</td>\n",
       "      <td>0.739464</td>\n",
       "      <td>0.667820</td>\n",
       "      <td>0.701818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.216600</td>\n",
       "      <td>0.196081</td>\n",
       "      <td>0.765886</td>\n",
       "      <td>0.792388</td>\n",
       "      <td>0.778912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.132200</td>\n",
       "      <td>0.215590</td>\n",
       "      <td>0.765125</td>\n",
       "      <td>0.743945</td>\n",
       "      <td>0.754386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.108600</td>\n",
       "      <td>0.278568</td>\n",
       "      <td>0.697987</td>\n",
       "      <td>0.719723</td>\n",
       "      <td>0.708688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.108600</td>\n",
       "      <td>0.261659</td>\n",
       "      <td>0.759398</td>\n",
       "      <td>0.698962</td>\n",
       "      <td>0.727928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.057300</td>\n",
       "      <td>0.324861</td>\n",
       "      <td>0.711475</td>\n",
       "      <td>0.750865</td>\n",
       "      <td>0.730640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.034200</td>\n",
       "      <td>0.358700</td>\n",
       "      <td>0.722408</td>\n",
       "      <td>0.747405</td>\n",
       "      <td>0.734694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>0.368425</td>\n",
       "      <td>0.748201</td>\n",
       "      <td>0.719723</td>\n",
       "      <td>0.733686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>0.345504</td>\n",
       "      <td>0.725753</td>\n",
       "      <td>0.750865</td>\n",
       "      <td>0.738095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>0.385334</td>\n",
       "      <td>0.723906</td>\n",
       "      <td>0.743945</td>\n",
       "      <td>0.733788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.007200</td>\n",
       "      <td>0.379486</td>\n",
       "      <td>0.720930</td>\n",
       "      <td>0.750865</td>\n",
       "      <td>0.735593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_FacebookAI_xlm-roberta-base_42_42_12\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_FacebookAI_xlm-roberta-base_42_42_12\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4610.76 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.79      0.95      0.86        59\n",
      "    Krankenhaus       0.75      0.65      0.70       120\n",
      "       Personal       0.71      0.67      0.69        15\n",
      " Pflegepersonal       0.77      0.96      0.85        24\n",
      "anderer Service       0.54      0.29      0.38        45\n",
      " mediz. Service       0.65      0.76      0.70        83\n",
      "\n",
      "      micro avg       0.71      0.70      0.71       346\n",
      "      macro avg       0.70      0.71      0.70       346\n",
      "   weighted avg       0.71      0.70      0.69       346\n",
      "\n",
      "Precision Score: 0.7147058823529412\n",
      "Recall Score: 0.7023121387283237\n",
      "F1 Score: 0.7084548104956269\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/12_epochs/FacebookAI_xlm-roberta-base_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/12_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_best:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at TUM/GottBERT_base_best and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6535.80 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5108.41 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Krankenhaus' 'B-anderer Service' 'B-Pflegepersonal' 'B-Personal'\n",
      " 'B-Arzt' 'B-mediz. Service' 'O']\n",
      "{0: 5.983217355710193, 1: 10.546176046176047, 2: 14.014381591562799, 3: 18.317042606516292, 4: 6.8239962651727355, 5: 4.959959280624364, 6: 0.1596439493228484}\n",
      "Training TUM/GottBERT_base_best for 12 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4848' max='4848' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4848/4848 05:43, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.231569</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.561321</td>\n",
       "      <td>0.626316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.325200</td>\n",
       "      <td>0.199338</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.707547</td>\n",
       "      <td>0.728155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.170700</td>\n",
       "      <td>0.241882</td>\n",
       "      <td>0.752381</td>\n",
       "      <td>0.745283</td>\n",
       "      <td>0.748815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.088600</td>\n",
       "      <td>0.216694</td>\n",
       "      <td>0.756881</td>\n",
       "      <td>0.778302</td>\n",
       "      <td>0.767442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.056300</td>\n",
       "      <td>0.284586</td>\n",
       "      <td>0.765766</td>\n",
       "      <td>0.801887</td>\n",
       "      <td>0.783410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.056300</td>\n",
       "      <td>0.342332</td>\n",
       "      <td>0.764103</td>\n",
       "      <td>0.702830</td>\n",
       "      <td>0.732187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.022800</td>\n",
       "      <td>0.396987</td>\n",
       "      <td>0.760204</td>\n",
       "      <td>0.702830</td>\n",
       "      <td>0.730392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.392228</td>\n",
       "      <td>0.772277</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.753623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.009800</td>\n",
       "      <td>0.399680</td>\n",
       "      <td>0.755760</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.764569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.364672</td>\n",
       "      <td>0.743119</td>\n",
       "      <td>0.764151</td>\n",
       "      <td>0.753488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.371588</td>\n",
       "      <td>0.754630</td>\n",
       "      <td>0.768868</td>\n",
       "      <td>0.761682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.379194</td>\n",
       "      <td>0.767773</td>\n",
       "      <td>0.764151</td>\n",
       "      <td>0.765957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_TUM_GottBERT_base_best_42_42_12\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_TUM_GottBERT_base_best_42_42_12\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4788.23 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.89      0.98      0.94        52\n",
      "    Krankenhaus       0.86      0.70      0.77       104\n",
      "       Personal       0.75      0.75      0.75        12\n",
      " Pflegepersonal       1.00      1.00      1.00        14\n",
      "anderer Service       0.69      0.60      0.64        30\n",
      " mediz. Service       0.68      0.84      0.75        67\n",
      "\n",
      "      micro avg       0.80      0.79      0.80       279\n",
      "      macro avg       0.81      0.81      0.81       279\n",
      "   weighted avg       0.81      0.79      0.79       279\n",
      "\n",
      "Precision Score: 0.8007246376811594\n",
      "Recall Score: 0.7921146953405018\n",
      "F1 Score: 0.7963963963963964\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/12_epochs/TUM_GottBERT_base_best_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/12_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_filtered_base_best:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at TUM/GottBERT_filtered_base_best and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6583.39 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5072.07 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Krankenhaus' 'B-anderer Service' 'B-Pflegepersonal' 'B-Personal'\n",
      " 'B-Arzt' 'B-mediz. Service' 'O']\n",
      "{0: 5.983217355710193, 1: 10.546176046176047, 2: 14.014381591562799, 3: 18.317042606516292, 4: 6.8239962651727355, 5: 4.959959280624364, 6: 0.1596439493228484}\n",
      "Training TUM/GottBERT_filtered_base_best for 12 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4848' max='4848' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4848/4848 05:43, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.203168</td>\n",
       "      <td>0.741379</td>\n",
       "      <td>0.608491</td>\n",
       "      <td>0.668394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.328000</td>\n",
       "      <td>0.161616</td>\n",
       "      <td>0.776744</td>\n",
       "      <td>0.787736</td>\n",
       "      <td>0.782201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.164200</td>\n",
       "      <td>0.184541</td>\n",
       "      <td>0.757709</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.783599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.088800</td>\n",
       "      <td>0.198257</td>\n",
       "      <td>0.709957</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.740406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.048200</td>\n",
       "      <td>0.276285</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.759434</td>\n",
       "      <td>0.763033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.048200</td>\n",
       "      <td>0.220852</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.764151</td>\n",
       "      <td>0.786408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.021600</td>\n",
       "      <td>0.312418</td>\n",
       "      <td>0.736585</td>\n",
       "      <td>0.712264</td>\n",
       "      <td>0.724221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.009300</td>\n",
       "      <td>0.289894</td>\n",
       "      <td>0.765766</td>\n",
       "      <td>0.801887</td>\n",
       "      <td>0.783410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.325752</td>\n",
       "      <td>0.786408</td>\n",
       "      <td>0.764151</td>\n",
       "      <td>0.775120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.338122</td>\n",
       "      <td>0.783654</td>\n",
       "      <td>0.768868</td>\n",
       "      <td>0.776190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.001500</td>\n",
       "      <td>0.374128</td>\n",
       "      <td>0.773399</td>\n",
       "      <td>0.740566</td>\n",
       "      <td>0.756627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.001100</td>\n",
       "      <td>0.360328</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.773585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_TUM_GottBERT_filtered_base_best_42_42_12\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_TUM_GottBERT_filtered_base_best_42_42_12\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4734.08 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.96      0.96      0.96        52\n",
      "    Krankenhaus       0.95      0.69      0.80       104\n",
      "       Personal       0.64      0.75      0.69        12\n",
      " Pflegepersonal       1.00      0.93      0.96        14\n",
      "anderer Service       0.69      0.37      0.48        30\n",
      " mediz. Service       0.76      0.75      0.75        67\n",
      "\n",
      "      micro avg       0.86      0.73      0.79       279\n",
      "      macro avg       0.83      0.74      0.77       279\n",
      "   weighted avg       0.87      0.73      0.79       279\n",
      "\n",
      "Precision Score: 0.8649789029535865\n",
      "Recall Score: 0.7347670250896058\n",
      "F1 Score: 0.7945736434108528\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/12_epochs/TUM_GottBERT_filtered_base_best_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/12_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for TUM/GottBERT_base_last:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at TUM/GottBERT_base_last were not used when initializing RobertaForMaskedLM: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at TUM/GottBERT_base_last and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6658.67 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5042.43 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Krankenhaus' 'B-anderer Service' 'B-Pflegepersonal' 'B-Personal'\n",
      " 'B-Arzt' 'B-mediz. Service' 'O']\n",
      "{0: 5.983217355710193, 1: 10.546176046176047, 2: 14.014381591562799, 3: 18.317042606516292, 4: 6.8239962651727355, 5: 4.959959280624364, 6: 0.1596439493228484}\n",
      "Training TUM/GottBERT_base_last for 12 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4848' max='4848' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4848/4848 05:43, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.232755</td>\n",
       "      <td>0.748387</td>\n",
       "      <td>0.547170</td>\n",
       "      <td>0.632153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.329900</td>\n",
       "      <td>0.228068</td>\n",
       "      <td>0.757062</td>\n",
       "      <td>0.632075</td>\n",
       "      <td>0.688946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.161700</td>\n",
       "      <td>0.222531</td>\n",
       "      <td>0.743119</td>\n",
       "      <td>0.764151</td>\n",
       "      <td>0.753488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.080800</td>\n",
       "      <td>0.223668</td>\n",
       "      <td>0.743719</td>\n",
       "      <td>0.698113</td>\n",
       "      <td>0.720195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>0.277180</td>\n",
       "      <td>0.696721</td>\n",
       "      <td>0.801887</td>\n",
       "      <td>0.745614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>0.313491</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.778302</td>\n",
       "      <td>0.755149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.021700</td>\n",
       "      <td>0.348781</td>\n",
       "      <td>0.718182</td>\n",
       "      <td>0.745283</td>\n",
       "      <td>0.731481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.008800</td>\n",
       "      <td>0.354017</td>\n",
       "      <td>0.722467</td>\n",
       "      <td>0.773585</td>\n",
       "      <td>0.747153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.380010</td>\n",
       "      <td>0.723502</td>\n",
       "      <td>0.740566</td>\n",
       "      <td>0.731935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.386166</td>\n",
       "      <td>0.734300</td>\n",
       "      <td>0.716981</td>\n",
       "      <td>0.725537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.377077</td>\n",
       "      <td>0.718182</td>\n",
       "      <td>0.745283</td>\n",
       "      <td>0.731481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.386768</td>\n",
       "      <td>0.718182</td>\n",
       "      <td>0.745283</td>\n",
       "      <td>0.731481</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_TUM_GottBERT_base_last_42_42_12\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_TUM_GottBERT_base_last_42_42_12\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4692.18 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.98      0.98      0.98        52\n",
      "    Krankenhaus       0.90      0.59      0.71       104\n",
      "       Personal       0.77      0.83      0.80        12\n",
      " Pflegepersonal       1.00      1.00      1.00        14\n",
      "anderer Service       0.58      0.37      0.45        30\n",
      " mediz. Service       0.61      0.78      0.68        67\n",
      "\n",
      "      micro avg       0.79      0.71      0.75       279\n",
      "      macro avg       0.81      0.76      0.77       279\n",
      "   weighted avg       0.81      0.71      0.74       279\n",
      "\n",
      "Precision Score: 0.7928286852589641\n",
      "Recall Score: 0.7132616487455197\n",
      "F1 Score: 0.750943396226415\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/12_epochs/TUM_GottBERT_base_last_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/12_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for distilbert/distilbert-base-german-cased:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert/distilbert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 6598.25 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 5155.40 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Krankenhaus' 'B-anderer Service' 'B-Pflegepersonal' 'B-Personal'\n",
      " 'B-Arzt' 'B-mediz. Service' 'O']\n",
      "{0: 5.983217355710193, 1: 10.546176046176047, 2: 14.014381591562799, 3: 18.317042606516292, 4: 6.8239962651727355, 5: 4.959959280624364, 6: 0.1596439493228484}\n",
      "Training distilbert/distilbert-base-german-cased for 12 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4848' max='4848' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4848/4848 03:03, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.225392</td>\n",
       "      <td>0.696682</td>\n",
       "      <td>0.578740</td>\n",
       "      <td>0.632258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.394000</td>\n",
       "      <td>0.222005</td>\n",
       "      <td>0.707424</td>\n",
       "      <td>0.637795</td>\n",
       "      <td>0.670807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.171900</td>\n",
       "      <td>0.225770</td>\n",
       "      <td>0.795349</td>\n",
       "      <td>0.673228</td>\n",
       "      <td>0.729211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.084700</td>\n",
       "      <td>0.254331</td>\n",
       "      <td>0.765217</td>\n",
       "      <td>0.692913</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.049600</td>\n",
       "      <td>0.262513</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.748031</td>\n",
       "      <td>0.758483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.049600</td>\n",
       "      <td>0.293082</td>\n",
       "      <td>0.773810</td>\n",
       "      <td>0.767717</td>\n",
       "      <td>0.770751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.023600</td>\n",
       "      <td>0.308278</td>\n",
       "      <td>0.751938</td>\n",
       "      <td>0.763780</td>\n",
       "      <td>0.757812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>0.326156</td>\n",
       "      <td>0.776000</td>\n",
       "      <td>0.763780</td>\n",
       "      <td>0.769841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.005500</td>\n",
       "      <td>0.342221</td>\n",
       "      <td>0.787234</td>\n",
       "      <td>0.728346</td>\n",
       "      <td>0.756646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.347006</td>\n",
       "      <td>0.784553</td>\n",
       "      <td>0.759843</td>\n",
       "      <td>0.772000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.004600</td>\n",
       "      <td>0.359929</td>\n",
       "      <td>0.791489</td>\n",
       "      <td>0.732283</td>\n",
       "      <td>0.760736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.357871</td>\n",
       "      <td>0.796610</td>\n",
       "      <td>0.740157</td>\n",
       "      <td>0.767347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_distilbert_distilbert-base-german-cased_42_42_12\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_distilbert_distilbert-base-german-cased_42_42_12\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4805.93 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.86      0.89      0.88        55\n",
      "    Krankenhaus       0.95      0.60      0.73       117\n",
      "       Personal       0.67      0.31      0.42        13\n",
      " Pflegepersonal       0.78      1.00      0.88        18\n",
      "anderer Service       0.70      0.40      0.51        35\n",
      " mediz. Service       0.68      0.71      0.70        77\n",
      "\n",
      "      micro avg       0.80      0.67      0.73       315\n",
      "      macro avg       0.77      0.65      0.69       315\n",
      "   weighted avg       0.82      0.67      0.72       315\n",
      "\n",
      "Precision Score: 0.8045977011494253\n",
      "Recall Score: 0.6666666666666666\n",
      "F1 Score: 0.7291666666666666\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/12_epochs/distilbert_distilbert-base-german-cased_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/12_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for GerMedBERT/medbert-512:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at GerMedBERT/medbert-512 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5818.24 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4692.03 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Krankenhaus' 'B-anderer Service' 'B-Pflegepersonal' 'B-Personal'\n",
      " 'B-Arzt' 'B-mediz. Service' 'O']\n",
      "{0: 5.983217355710193, 1: 10.546176046176047, 2: 14.014381591562799, 3: 18.317042606516292, 4: 6.8239962651727355, 5: 4.959959280624364, 6: 0.1596439493228484}\n",
      "Training GerMedBERT/medbert-512 for 12 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4848' max='4848' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4848/4848 06:27, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.199582</td>\n",
       "      <td>0.695876</td>\n",
       "      <td>0.584416</td>\n",
       "      <td>0.635294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.322200</td>\n",
       "      <td>0.168744</td>\n",
       "      <td>0.718615</td>\n",
       "      <td>0.718615</td>\n",
       "      <td>0.718615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.151900</td>\n",
       "      <td>0.272795</td>\n",
       "      <td>0.776536</td>\n",
       "      <td>0.601732</td>\n",
       "      <td>0.678049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.066400</td>\n",
       "      <td>0.233735</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.721519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.036100</td>\n",
       "      <td>0.284757</td>\n",
       "      <td>0.721239</td>\n",
       "      <td>0.705628</td>\n",
       "      <td>0.713348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.036100</td>\n",
       "      <td>0.309507</td>\n",
       "      <td>0.737557</td>\n",
       "      <td>0.705628</td>\n",
       "      <td>0.721239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>0.402408</td>\n",
       "      <td>0.748815</td>\n",
       "      <td>0.683983</td>\n",
       "      <td>0.714932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>0.352384</td>\n",
       "      <td>0.733624</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.730435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.418202</td>\n",
       "      <td>0.729858</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.696833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.417191</td>\n",
       "      <td>0.727700</td>\n",
       "      <td>0.670996</td>\n",
       "      <td>0.698198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.001700</td>\n",
       "      <td>0.394080</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.727273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.399442</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.723684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_GerMedBERT_medbert-512_42_42_12\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_GerMedBERT_medbert-512_42_42_12\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4267.82 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.96      0.96      0.96        54\n",
      "    Krankenhaus       0.85      0.75      0.80       105\n",
      "       Personal       0.69      0.69      0.69        16\n",
      " Pflegepersonal       0.88      0.93      0.90        15\n",
      "anderer Service       0.59      0.49      0.53        35\n",
      " mediz. Service       0.75      0.63      0.69        63\n",
      "\n",
      "      micro avg       0.82      0.74      0.78       288\n",
      "      macro avg       0.79      0.74      0.76       288\n",
      "   weighted avg       0.81      0.74      0.77       288\n",
      "\n",
      "Precision Score: 0.8160919540229885\n",
      "Recall Score: 0.7395833333333334\n",
      "F1 Score: 0.7759562841530055\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/12_epochs/GerMedBERT_medbert-512_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/12_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n",
      "training and results for deepset/gbert-base:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/gbert-base were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Device set to use cuda:0\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at deepset/gbert-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 808/808 [00:00<00:00, 5843.86 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 101/101 [00:00<00:00, 4770.01 examples/s]\n",
      "/home/sc.uni-leipzig.de/ch31qoni/venv/py312_2/lib/python3.12/site-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "/home/sc.uni-leipzig.de/ch31qoni/ABSA/ate_model_train_OB.py:698: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B-Krankenhaus' 'B-anderer Service' 'B-Pflegepersonal' 'B-Personal'\n",
      " 'B-Arzt' 'B-mediz. Service' 'O']\n",
      "{0: 5.983217355710193, 1: 10.546176046176047, 2: 14.014381591562799, 3: 18.317042606516292, 4: 6.8239962651727355, 5: 4.959959280624364, 6: 0.1596439493228484}\n",
      "Training deepset/gbert-base for 12 epochs with random seeds 42, 42\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4848' max='4848' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4848/4848 06:19, Epoch 12/12]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.227519</td>\n",
       "      <td>0.702326</td>\n",
       "      <td>0.594488</td>\n",
       "      <td>0.643923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.329600</td>\n",
       "      <td>0.194476</td>\n",
       "      <td>0.741525</td>\n",
       "      <td>0.688976</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.150800</td>\n",
       "      <td>0.210085</td>\n",
       "      <td>0.790514</td>\n",
       "      <td>0.787402</td>\n",
       "      <td>0.788955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.056400</td>\n",
       "      <td>0.246850</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.779528</td>\n",
       "      <td>0.781065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.032300</td>\n",
       "      <td>0.307670</td>\n",
       "      <td>0.719858</td>\n",
       "      <td>0.799213</td>\n",
       "      <td>0.757463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.032300</td>\n",
       "      <td>0.264187</td>\n",
       "      <td>0.785185</td>\n",
       "      <td>0.834646</td>\n",
       "      <td>0.809160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.014000</td>\n",
       "      <td>0.264680</td>\n",
       "      <td>0.784906</td>\n",
       "      <td>0.818898</td>\n",
       "      <td>0.801541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>0.302801</td>\n",
       "      <td>0.754647</td>\n",
       "      <td>0.799213</td>\n",
       "      <td>0.776291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.320325</td>\n",
       "      <td>0.759857</td>\n",
       "      <td>0.834646</td>\n",
       "      <td>0.795497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.301080</td>\n",
       "      <td>0.790875</td>\n",
       "      <td>0.818898</td>\n",
       "      <td>0.804642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.001900</td>\n",
       "      <td>0.311113</td>\n",
       "      <td>0.774545</td>\n",
       "      <td>0.838583</td>\n",
       "      <td>0.805293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>0.308711</td>\n",
       "      <td>0.790262</td>\n",
       "      <td>0.830709</td>\n",
       "      <td>0.809981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Model saved at: ./saved_models/ate_cat_deepset_gbert-base_42_42_12\n",
      "\n",
      "Tokenizer for best Model saved at: ./saved_tokenizers/ate_cat_deepset_gbert-base_42_42_12\n",
      "Evaluating on test data\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 102/102 [00:00<00:00, 4420.30 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique predicted label IDs: {0, 2, 3, 4, 5, 6, 7}\n",
      "Expected label IDs: {0, 1, 2, 3, 4, 5, 6, 7}\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "           Arzt       0.87      0.95      0.90        55\n",
      "    Krankenhaus       0.89      0.79      0.84       117\n",
      "       Personal       0.75      0.69      0.72        13\n",
      " Pflegepersonal       0.89      0.94      0.92        18\n",
      "anderer Service       0.70      0.46      0.55        35\n",
      " mediz. Service       0.82      0.79      0.81        77\n",
      "\n",
      "      micro avg       0.85      0.79      0.82       315\n",
      "      macro avg       0.82      0.77      0.79       315\n",
      "   weighted avg       0.84      0.79      0.81       315\n",
      "\n",
      "Precision Score: 0.8464163822525598\n",
      "Recall Score: 0.7873015873015873\n",
      "F1 Score: 0.8157894736842106\n",
      "Tokens     : ['Nun', 'sind', '3', 'Jahre', 'seit', 'der', 'Operation', 'vergangen', 'und', 'es', 'mir', 'gut', '.']\n",
      "True Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'O', 'O', 'O', 'O', 'B-mediz. Service', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Tokens     : ['Insbesondere', 'bei', 'Unikliniken', ',', 'mit', 'anderen', 'Krankheitsbildern', 'haben', 'sie', 'leider', 'ab', 'und', 'zu', 'Probleme', '.']\n",
      "True Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "Pred Labels: ['O', 'O', 'B-Krankenhaus', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "==================================================\n",
      "Results saved to testresult/BO/ate_cat/12_epochs/deepset_gbert-base_ate_cat_test_results.txt\n",
      "Confusion matrix saved to testresult/ate_cat/12_epochs/\n",
      "Training complete. Model directory deleted to free memory.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    print(f'training and results for {model}:')\n",
    "    ate_cat_model(data, model, rn1=42, rn2=42, epochs=12, save=True)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ABSA-Check",
   "language": "python",
   "name": "absa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
